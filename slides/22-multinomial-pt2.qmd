---
title: "Multinomial logistic regression"
subtitle: "Part 2"
author: "Prof. Maria Tackett"
date: "2025-04-08"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 210 - Spring 2025](https://sta210-sp25.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
  html: 
    output-file: 22-multinomial-pt2-notes.html
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 8, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)

library(countdown)
```

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 8, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)

library(countdown)
```

## Announcements {.midi}

-   HW 04 due TODAY at 11:59pm

-   Team Feedback (email from TEAMMATES) due Tuesday, April 8 at 11:59pm (check email)

-   Exam 02 - April 17

-   Next project milestone: Draft and peer review in April 21 lab

-   Statistics experience due April 15

## Topics

::: nonincremental
-   Predictions
-   Model selection
-   Checking conditions
:::

## Computational setup

```{r}
#| echo: true

# load packages
library(tidyverse)
library(tidymodels)
library(NHANES)
library(knitr)
library(patchwork)
library(colorblindr)
library(pROC)
library(Stat2Data)
library(nnet)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))
```

## NHANES Data

::: nonincremental
-   [National Health and Nutrition Examination Survey](https://www.cdc.gov/nchs/nhanes/?CDC_AAref_Val=https://www.cdc.gov/nchs/nhanes/index.htm) is conducted by the National Center for Health Statistics (NCHS).
-   The goal is to *"assess the health and nutritional status of adults and children in the United States".*
-   This survey includes an interview and a physical examination.
:::

## Variables

**Goal:** Use a person's age and whether they do regular physical activity to predict their self-reported health rating.

-   Outcome: `HealthGen`: Self-reported rating of participant's health in general. Excellent, Vgood, Good, Fair, or Poor.

-   Predictors:

    -   `Age`: Age at time of screening (in years). Participants 80 or older were recorded as 80.
    -   `PhysActive`: Participant does moderate to vigorous-intensity sports, fitness or recreational activities.

## The data

```{r}
nhanes_adult <- NHANES |>
  filter(Age >= 18) |>
  select(HealthGen, Age, PhysActive, Education) |>
  drop_na() |>
  mutate(obs_num = 1:n())
```

```{r}
glimpse(nhanes_adult)
```

## Model in R

```{r}
#| results: hide

library(nnet)
health_fit <- multinom(HealthGen ~ Age + PhysActive, 
                     data = nhanes_adult)
```

## Model summary {.small}

```{r}
tidy(health_fit) |> kable(digits = 3)
```

# Predictions

## Calculating probabilities {.smaller}

-   Suppose the response variable has $K$ categories and $k = 1$ is the baseline category. For categories $2,\ldots,K$, the probability that the $i^{th}$ observation is in the $j^{th}$ category is

    $$
    \hat{\pi}_{ij} = \frac{\exp\{\hat{\beta}_{0j} + \hat{\beta}_{1j}x_{i1} + \dots + \hat{\beta}_{pj}x_{ip}\}}{1 + \sum\limits_{k=2}^K \exp\{\hat{\beta}_{0k} + \hat{\beta}_{1k}x_{i1} + \dots \hat{\beta}_{pk}x_{ip}\}}
    $$

-   For the baseline category, $k=1$, we calculate the probability $\hat{\pi}_{i1}$ as

    $$
    \hat{\pi}_{i1} = 1- \sum\limits_{k=2}^K \hat{\pi}_{ik}
    $$

## Predicted probability 

```{r}
# compute predicted probabilities 
pred_probs <- predict(health_fit, type = "probs")

# add to original data 
nhanes_adult <- nhanes_adult |> 
  bind_cols(pred_probs)
```

. . .

```{r}
#| echo: false

set.seed(210)
nhanes_adult |>
  select(Age, PhysActive, Excellent: Poor) |>
  sample_n(10)
  
```

## Actual vs. predicted health rating

For each observation, the predicted perceived health rating is the category with the highest predicted probability.

```{r}
# get predicted classes
pred_class <- predict(health_fit, type = "class")

# add to original data 
nhanes_adult <- nhanes_adult |> 
  bind_cols(pred_class = pred_class) #save as column named pred_class
```

## Confusion matrix

```{r}
nhanes_adult |>
  conf_mat(HealthGen, pred_class)  |>
  autoplot(type = "heatmap")
```

## Actual vs. predicted health rating

::: question
Why do you think no observations were predicted to have a rating of "Excellent", "Fair", or "Poor"?
:::

```{r}
#| echo: false
#| out-width: "100%"
#| fig-width: 10
#| layout-ncol: 2

ggplot(nhanes_adult, aes(x = HealthGen)) + 
  geom_bar() +
  labs(title = "Self-reported rating of overall health")

ggplot(nhanes_adult, aes(x = HealthGen, fill = pred_class)) + 
  geom_bar() +
  scale_fill_OkabeIto() +
  labs(title = "Predicted vs.\nself-reported rating of overall health") +
  theme(legend.position = c(0.8, 0.8))
```

## ROC curves

ROC curves for multiclass outcomes use a one-vs-all approach: calculate multiple curves, one per level vs.Â all other levels.

```{r}
#| eval: false

nhanes_adult |> 
  roc_curve(
    truth = HealthGen, 
    Excellent:Poor
  ) |> 
  autoplot()
```

## Area Under the Curve (AUC)

::::: columns
::: {.column width="50%"}
<center>**Average AUC**</center>

```{r}
nhanes_adult |> 
  roc_auc(
    truth = HealthGen, 
    Excellent:Poor,
    estimator = "macro"
  )
```
:::

::: {.column width="50%"}
<center>**Average AUC weighted by \# of observations**</center>

```{r}
nhanes_adult |> 
  roc_auc(
    truth = HealthGen, 
    Excellent:Poor,
    estimator = "macro_weighted"
  )
```
:::
:::::

# Application exercise

::: appex
ðŸ“‹ <https://sta210-sp25.netlify.app/ae/ae-11-multinomial.html>
:::

# Checking conditions for inference

## Conditions for inference

We want to check the following conditions for inference for the multinomial logistic regression model:

1.  Linearity: Is there a linear relationship between the log-odds and the predictor variables?

2.  Randomness: Was the sample randomly selected? Or can we reasonably treat it as random?

3.  Independence: Are the observations independent?

## Checking linearity

Similar to logistic regression, we will check linearity by examining empirical logit plots between each level of the response and the quantitative predictor variables.

```{r}
nhanes_adult <- nhanes_adult |>
  mutate(
    Excellent = factor(if_else(HealthGen == "Excellent", "1", "0")),
    Vgood = factor(if_else(HealthGen == "Vgood", "1", "0")),
    Good = factor(if_else(HealthGen == "Good", "1", "0")),
    Fair = factor(if_else(HealthGen == "Fair", "1", "0")),
    Poor = factor(if_else(HealthGen == "Poor", "1", "0"))
  )
```

## Checking linearity

```{r}
#| layout-ncol: 2

emplogitplot1(Excellent ~ Age, data = nhanes_adult, 
              ngroups = 10, main = "Excellent vs. Age")
emplogitplot1(Vgood ~ Age, data = nhanes_adult, 
              ngroups = 10, main = "Vgood vs. Age")
```

## Checking linearity

```{r}
#| layout-ncol: 2
#| out-width: "100%"

emplogitplot1(Good ~ Age, data = nhanes_adult, 
              ngroups = 10, main = "Good vs. Age")
emplogitplot1(Fair ~ Age, data = nhanes_adult, 
              ngroups = 10, main = "Fair vs. Age")
```

## Checking linearity

```{r}
emplogitplot1(Poor ~ Age, data = nhanes_adult, 
              ngroups = 10, main = "Poor vs. Age")
```

. . .

âœ… The linearity condition is satisfied. There is generally a linear relationship between the empirical logit and the quantitative predictor variable, Age, for each level of the response.

## Checking randomness

We can check the randomness condition based on the context of the data and how the observations were collected.

-   Was the sample randomly selected?

-   If the sample was not randomly selected, ask whether there is reason to believe the observations in the sample differ systematically from the population of interest.

. . .

âœ… The randomness condition is satisfied. The participants were randomly selected, and thus we do not have reason to believe that the participants in this study differ systematically from adults in the U.S.

## Checking independence

We can check the independence condition based on the context of the data and how the observations were collected.

Independence is most often violated if the data were collected over time or there is a strong spatial relationship between the observations.

. . .

âœ… The independence condition is satisfied. The participants were randomly selected, so it is reasonable to conclude that the participants' health and behavior characteristics are independent of one another.

## Recap

-   Predictions
-   Model selection for inference
-   Checking conditions for inference

## Full multinomial modeling workflow

-   [juliasilge.com/blog/multinomial-volcano-eruptions](https://juliasilge.com/blog/multinomial-volcano-eruptions/)

-   [juliasilge.com/blog/nber-papers](https://juliasilge.com/blog/nber-papers/)
