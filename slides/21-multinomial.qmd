---
title: "Multinomial Logistic Regression"
author: "Prof. Maria Tackett"
date: "2025-04-03"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 210 - Spring 2025](https://sta210-sp25.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
  html: 
    output-file: 21-multinomial-notes.html
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 8, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)

library(countdown)
```

## Topics

::: nonincremental
-   Conditions for logistic regression AE

-   Multinomial logistic regression

-   Interpret model coefficients

-   Inference for a coefficient $\beta_{jk}$
:::

## Computational setup

```{r}
#| echo: true

# load packages
library(tidyverse)
library(tidymodels)
library(NHANES) #data set
library(knitr)
library(patchwork)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))
```

# Generalized Linear Models

## Generalized Linear Models (GLMs) {.smaller}

-   In practice, there are many different types of outcome variables:

    ::: nonincremental
    -   **Continuous:** Price of house
    -   **Binary**: Win or Lose
    -   **Nominal**: Democrat, Republican or Third Party candidate
    -   **Ordered**: Movie rating (1 - 5 stars)
    -   and others...
    :::

-   Predicting each of these outcomes requires a **generalized linear model**, a broader class of models that *generalize* the multiple linear regression model

::: callout-note
Recommended reading for more details about GLMs: [*Generalized Linear Models: A Unifying Theory*](https://bookdown.org/roback/bookdown-bysh/ch-glms.html).
:::

## Binary outcome (Logistic)

-   Given $P(y_i=1|x_i)= \hat{p}_i\hspace{5mm} \text{ and } \hspace{5mm}P(y_i=0|x_i) = 1-\hat{p}_i$

    $$
    \log\Big(\frac{\hat{p}_i}{1-\hat{p}_i}\Big) = \hat{\beta}_0 + \hat{\beta}_1 x_{i} + \dots \hat{\beta}_px_p
    $$

-   We can calculate $\hat{p}_i$ by solving the logit equation:

    $$
    \hat{p}_i = \frac{\exp\{\hat{\beta}_0 + \hat{\beta}_1 x_{i} + \dots +\hat{\beta}_px_p\}}{1 + \exp\{\hat{\beta}_0 + \hat{\beta}_1 x_{i} + \dots +\hat{\beta}_px_p\}}
    $$

## Binary outcome (Logistic) {.smaller}

::: incremental
-   Suppose we consider $y=0$ the **baseline category** such that

    $$
    P(y_i=1|x_i) = \hat{p}_{i1} \hspace{2mm}  \text{ and } \hspace{2mm} P(y_i=0|x_i) = \hat{p}_{i0}
    $$

-   Then the logistic regression model is

    $$
    \log\bigg(\frac{\hat{p}_{i1}}{1- \hat{p}_{i1}}\bigg) = \log\bigg(\frac{\hat{p}_{i1}}{\hat{p}_{i0}}\bigg) = \hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \dots \hat{\beta}_px_{ip}
    $$

-   **Slope**, $\hat{\beta}_j$: When $x$ increases by one unit, the odds of $y=1$ versus the baseline $y=0$ are expected to multiply by a factor of $\exp\{\hat{\beta}_j\}$

-   **Intercept**, $\hat{\beta}_0$: When $x=0$, the predicted odds of $y=1$ versus the baseline $y=0$ are $\exp\{\hat{\beta}_0\}$
:::

## Multinomial outcome variable

-   Suppose the outcome variable $y$ is categorical and can take values $1, 2, \ldots, K$ such that $(K > 2)$

-   **Multinomial Distribution:**

    $$
    P(y=1) = p_1, P(y=2) = p_2, \ldots, P(y=K) = p_K
    $$

    such that $\sum\limits_{k=1}^{K} p_k = 1$

## Multinomial Logistic Regression {.small}

::: incremental
-   If we have an predictor variables $x_1, \ldots, x_p$, then we want to fit a model such that $P(y = k) = p_k$ is a function of $x_1, \ldots,x_p$

-   Choose a baseline category. Let's choose $y=1$. Then,

    $$
    \log\bigg(\frac{p_{ik}}{p_{i1}}\bigg) = \beta_{0k} + \beta_{1k} x_{i1} + \dots + \beta_{pk}x_{ip}
    $$

-   In the multinomial logistic model, we have a separate equation for each category of the outcome relative to the baseline category

    -   If the outcome has $K$ possible categories, there will be $K-1$ equations as part of the multinomial logistic model
:::

## Multinomial Logistic Regression

-   Suppose we have a outcome variable $y$ that can take three possible outcomes that are coded as "A", "B", "C"

-   Let "A" be the baseline category. Then

    $$
    \begin{aligned}
    \log\bigg(\frac{p_{iB}}{p_{iA}}\bigg) &= \beta_{0B} + \beta_{1B}x_{i1} + \dots \beta_{pB}x_{ip} \\[10pt]
    \log\bigg(\frac{p_{iC}}{p_{iA}}\bigg) &= \beta_{0C} + \beta_{1C} x_{i1} + \dots +\beta_{pC}x_{ip}
    \end{aligned}
    $$

# Data

## NHANES Data

-   [National Health and Nutrition Examination Survey](https://www.cdc.gov/nchs/nhanes/?CDC_AAref_Val=https://www.cdc.gov/nchs/nhanes/index.htm) is conducted by the National Center for Health Statistics (NCHS)

-   The goal is to *"assess the health and nutritional status of adults and children in the United States"*

-   This survey includes an interview and a physical examination

## NHANES Data

-   We will use the data from the `NHANES` R package

-   Contains 75 variables for the 2009 - 2010 and 2011 - 2012 sample years

-   The data in this package is modified for educational purposes and should **not** be used for research

-   Original data can be obtained from the [NCHS website](https://www.cdc.gov/nchs/data_access/index.htm) for research purposes

-   Type `?NHANES` in console to see list of variables and definitions

## Variables {.midi}

**Goal:** Use a person's age and whether they do regular physical activity to predict their self-reported health rating.

-   Outcome:

    -   `HealthGen`: Self-reported rating of participant's health in general. Excellent, Vgood, Good, Fair, or Poor.

-   Predictors:

    -   `Age`: Age at time of screening (in years). Participants 80 or older were recorded as 80.
    -   `PhysActive`: Participant does moderate to vigorous-intensity sports, fitness or recreational activities.

## The data

```{r}
nhanes_adult <- NHANES |>
  filter(Age >= 18) |>
  select(HealthGen, Age, PhysActive) |>
  filter(!(is.na(HealthGen))) |>
  mutate(obs_num = 1:n())
```

```{r}
glimpse(nhanes_adult)
```

## Exploratory data analysis

```{r}
#| echo: false
#| out-width: "80%"
#| fig-width: 12

p1 <- ggplot(data = nhanes_adult, aes(x = Age)) + 
  geom_histogram(binwidth = 2, fill = "steelblue", color = "black") +
  labs(title = "Distribution of Age")

p2 <- ggplot(data = nhanes_adult, aes(x = PhysActive)) + 
  geom_bar(color = "black", fill = "steelblue") +
  labs(title = "Moderate or vigorous\nsport or exercise")

p3 <- ggplot(data = nhanes_adult, aes(y = HealthGen)) + 
  geom_bar(fill = "darkcyan", color = "black") +
  labs(title = "Self-reported rating\nof overall health")

p3 + (p1 / p2)
```

## Exploratory data analysis

```{r}
#| echo: false
#| out-width: "80%"
#| fig-width: 12

p1 <- ggplot(data = nhanes_adult, aes(x = HealthGen, y = Age)) +
  geom_boxplot(fill = "#D9E3E4") + 
  labs(title = "Age vs.\nHealth Rating") +
  coord_flip()

p2 <- ggplot(data = nhanes_adult, aes(x = PhysActive, fill = HealthGen)) +
  geom_bar(position = "fill") +
  labs(y = "Proportion", 
       title = "Physical Activity vs.\nHealth Rating") +
  scale_fill_viridis_d(end = 0.9)

p1 + p2
```

# Fitting a multinomial logistic regression model

## Model in R

Use the `multinom` function from the **nnet** R package

```{r}
#| results: hide
library(nnet)
health_fit <- multinom(HealthGen ~ Age + PhysActive, 
                     data = nhanes_adult)
```

<br>

Use code chunk option `#| results: hide` to suppress convergence output

## Model result

```{r}
health_fit
```

## Tidy model output

```{r}
#| error: true

tidy(health_fit)
```

## Tidy model output, with CI

```{r}
tidy(health_fit, conf.int = TRUE)
```

## Neatly display model output {.smaller}

```{r}
#| echo: false
tidy(health_fit, conf.int = TRUE) |>
  kable(digits = 3)
```

## Fair vs. Excellent Health

The baseline category for the model is `Excellent`.

. . .

The model equation for the log-odds a person rates themselves as having "Fair" health vs. "Excellent" is

$$
\log\Big(\frac{\hat{p}_{Fair}}{\hat{p}_{Excellent}}\Big) = 0.915  + 0.003 ~ \text{age} - 1.645 ~ \text{PhysActive}
$$

## Interpretations {.midi}

$$
\log\Big(\frac{\hat{p}_{Fair}}{\hat{p}_{Excellent}}\Big) = 0.915  + 0.003 ~ \text{age} - 1.645 ~ \text{PhysActive}
$$

For each additional year in age, the odds a person rates themselves as having fair health versus excellent health are expected to multiply by `r round(exp(0.003), 3)` (exp(0.003)), holding physical activity constant.

<br>

. . .

The odds a person who does physical activity will rate themselves as having fair health versus excellent health are expected to be `r round(exp(-1.645 ),3)` (exp(-1.645)) times the odds for a person who doesn't do physical activity, holding age constant.

## Interpretations

$$
\log\Big(\frac{\hat{p}_{Fair}}{\hat{p}_{Excellent}}\Big) = 0.915  + 0.003 ~ \text{age} - 1.645 ~ \text{PhysActive}
$$

The odds a 0 year old person who doesn't do physical activity rates themselves as having fair health vs. excellent health are `r round(exp(0.915),3)` (exp(0.915)).

. . .

::: callout-warning
**Need to mean-center age for the intercept to have a meaningful interpretation!**
:::

## Practice

:::::: columns
::: {.column width="50%"}
```{r}
#| echo: false

tidy(health_fit) |>
  select(y.level, term, estimate)|>
  kable(digits = 3)
```
:::

:::: {.column width="50%"}
::: question
-   Write the equation for Very good (`Vgood`) versus Excellent.

-   Interpret `Age` in the context of the data.

-   Interpret `PhysActiveYes` in the context of the data.
:::
::::
::::::

## Recap

-   Introduce multinomial logistic regression

-   Interpret model coefficients
