---
title: "Model evaluation"
author: "Prof. Maria Tackett"
date: "2025-02-04"
date-format: "MMM DD, YYYY"
footer: "[üîó STA 210 - Spring 2025](https://sta210-sp25.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
  html: 
    output-file: 08-model-eval-notes.html
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 10, fig.asp = 0.618,
  fig.retina = 3, dpi = 300, fig.align = "center"
)
```

## Announcements

-   Lab 02 due Thursday at 11:59pm

-   HW 02 released later today

-   [Click here](https://prodduke.sharepoint.com/:p:/s/ARCStaff839/EZ4PKTRTlCVMpFZiR6XoRycB4UUlRMuI2_Rda9hKxNZtsA) to learn more about the Academic Resource Center

-   [Statistics experience](../hw/stats-experience.html) due Tuesday, April 15

## Office hours poll

<!--# ADD this-->

## Topics

::: nonincremental
-   Recap of MLR and predictor types
-   Interaction terms
-   ANOVA and sum of squares
-   $R^2$ and RMSE
-   Adjusted $R^2$
-   Comparing models with $R^2$ vs. $R^2_{adj}$
:::

## Computational setup

```{r}
#| echo: true

# load packages
library(tidyverse)
library(tidymodels)
library(patchwork)
library(knitr)
library(kableExtra)
library(colorblindr)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_bw(base_size = 20))
```

# Recap: Multiple linear regression

## Data: Palmer penguins {.midi}

The `penguins` data set contains data for penguins found on three islands in the Palmer Archipelago, Antarctica. Data were collected and made available by [Dr.¬†Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a member of the [Long Term Ecological Research Network](https://lternet.edu/). These data can be found in the **palmerpenguins** R package.

. . .

```{r}
#| echo: false

penguins <- penguins |>
  select(body_mass_g, flipper_length_mm, bill_length_mm, species) |>
  drop_na()

penguins
```

## Variables

**Predictors**:

-   `bill_length_mm`: Bill length in millimeters
-   `flipper_length_mm`: Flipper length in millimeters
-   `species`: Adelie, Gentoo, or Chinstrap species

**Response**: `body_mass_g`: Body mass in grams

<br>

**The goal of this analysis is to use the bill length, flipper length, and species to predict body mass.**

## Response vs. predictors {.small}

```{r}
#| echo: false
p4 <- ggplot(penguins, aes(x = species, y = body_mass_g)) +
  geom_boxplot(fill = "steelblue") +
  labs(
    y = "Body mass in grams",
    x = "Species"
  )

p5 <- ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point(color = "steelblue") +
  labs(
    y = NULL,
    x = "Flipper length in mm"
  )


p6 <- ggplot(penguins, aes(x = bill_length_mm, y = body_mass_g)) +
  geom_point(color = "steelblue") +
  labs(
    y = NULL,
    x = "Bill length in mm"
  )

p4 + p5 / p6
```

## Model fit

```{r}
#| echo: true

penguin_fit <- lm(body_mass_g ~ flipper_length_mm + species + 
                bill_length_mm, data = penguins)

tidy(penguin_fit) |>
  kable(digits = 3)
```

## Interpreting $\hat{\beta}_j$

-   The estimated coefficient $\hat{\beta}_j$ is the expected change in the mean of $Y$ when $X_j$ increases by one unit, <i>holding the values of all other predictor variables constant</i>.

. . .

-   **Example:** The estimated coefficient for `flipper_length_mm` is 27.429. This means for each additional millimeter in a penguin's flipper length, its body mass is expected to be greater by 27.429 grams, on average, *holding species and bill length constant.*

## Indicator variables

```{r}
#| echo: false
tidy(penguin_fit, conf.int  = T) |>
  kable(digits = 3) |>
  row_spec(c(3,4), background = "#dce5b2")
```

<br>

::: question
Interpret the coefficient of `Gentoo` in the context of the data.
:::

## Centering {.midi}

-   Centering a quantitative predictor means shifting every value by some constant $C$

$$
X_{cent} = X  - C
$$

-   One common type of centering is **mean-centering**, in which every value of a predictor is shifted by its mean

-   Only quantitative predictors are centered

-   Center all quantitative predictors in the model for ease of interpretation

::: question
How does centering change the model and/or interpretations?
:::

## Standardizing {.midi}

-   Standardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable

$$
X_{std} = \frac{X - \bar{X}}{S_X}
$$

-   Only quantitative predictors are standardized

-   Standardize all quantitative predictors in the model for ease of interpretation

::: question
How does standardizing change the model and/or interpretations?
:::

# Interaction terms

## Interaction terms

-   Sometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.
-   This is an **interaction effect**.
-   To account for this, we can include **interaction terms** in the model.

## Bill length versus species

If the lines are not parallel, there is indication of a potential **interaction effect**, i.e., the slope of bill length may differ based on the species.

```{r}
#| echo: false

p1 <- ggplot(penguins, 
             aes(x = bill_length_mm, y = body_mass_g)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Bill length in millimeters",
    y = "Body mass in grams"
  )

p2 <- ggplot(penguins, 
             aes(x = bill_length_mm, y = body_mass_g,
                 color = species)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Bill length in millimeters", y = NULL, color = NULL) +
  theme(legend.position = c(0.3, 0.9)) +
  scale_color_OkabeIto()

p1 + p2 +
  plot_annotation(title = "Body mass versus bill length")
```

## Interaction term in model {.smaller}

```{r}
#| echo: true
penguin_int_fit <- lm(body_mass_g ~ flipper_length_mm + species + bill_length_mm + species * bill_length_mm,
      data = penguins)
```

```{r}
#| echo: false
tidy(penguin_int_fit) |>
  kable(digits = 3) |>
  row_spec(c(6,7), background = "#dce5b2")
```

## Interaction terms in the model

```{r}
#| echo: false
tidy(penguin_int_fit) |>
  kable(digits = 3) |>
  row_spec(c(6,7), background = "#dce5b2")
```

<br>

::: question
-   Write the model equation for penguins in the Adelie species.
-   Write the model equation for penguins in the Chinstrap species.
:::

## Interpreting interaction terms

-   What the interaction means: The effect of bill length on the body mass is 41.035 less when the penguin is from the Chinstrap species compared to the effect for the Adelie species, holding all else constant.
-   Interpreting `bill_length_mm` for Chinstrap: For each additional millimeter in bill length, we expect the body mass of Chinstrap penguins to increase by 31.657 grams (72.692 - 41.035), holding all else constant.

## Summary

<br>

::: question
In general, how do

indicators for categorical predictors impact the model equation?

interaction terms impact the model equation?
:::

# Model evaluation

## Data: Restaurant tips

Which variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.

```{r}
#| echo: false
#| message: false
tips <- read_csv(here::here("slides", "data/tip-data.csv")) |>
  filter(!is.na(Party))
```

```{r}
#| echo: false
tips |>
  select(Tip, Party, Meal, Age)
```

:::: aside
::: small
Dahlquist, Samantha, and Jin Dong. 2011. ‚ÄúThe Effects of Credit Cards on Tipping.‚Äù Project for Statistics 212-Statistics for the Sciences, St. Olaf College
:::
::::

## Variables

**Predictors**:

::: nonincremental
-   `Party`: Number of people in the party
-   `Meal`: Time of day (Lunch, Dinner, Late Night)
-   `Age`: Age category of person paying the bill (Yadult, Middle, SenCit)
:::

**Response**: `Tip`: Amount of tip

## Response: `Tip`

```{r}
#| echo: false
ggplot(tips, aes(x = Tip)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Distribution of tips")
```

## Predictors

```{r}
#| echo: false
p1 <- ggplot(tips, aes(x = Party)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Number of people in party")

p2 <- ggplot(tips, aes(x = Meal)) +
  geom_bar() +
  labs(title = "Meal type")

p3 <- ggplot(tips, aes(x = Age)) +
  geom_bar() +
  labs(title = "Age of payer")

p1 + (p2 / p3)
```

## Relevel categorical predictors

```{r}
#| echo: true

tips <- tips |>
  mutate(
    Meal = fct_relevel(Meal, "Lunch", "Dinner", "Late Night"),
    Age  = fct_relevel(Age, "Yadult", "Middle", "SenCit")
  )
```

## Predictors, again

```{r}
#| echo: false
p1 <- ggplot(tips, aes(x = Party)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Number of people in party")

p2 <- ggplot(tips, aes(x = Meal, fill = Meal)) +
  geom_bar() +
  labs(title = "Meal type") +
  scale_fill_viridis_d(end = 0.8)

p3 <- ggplot(tips, aes(x = Age, fill = Age)) +
  geom_bar() +
  labs(title = "Age of payer") +
  scale_fill_viridis_d(option = "E", end = 0.8)

p1 + (p2 / p3)

```

## Response vs. predictors

```{r}
#| echo: false
#| fig.width: 12
#| fig.height: 4

p4 <- ggplot(tips, aes(x = Party, y = Tip)) +
  geom_point(color = "#5B888C")

p5 <- ggplot(tips, aes(x = Meal, y = Tip, fill = Meal)) +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_viridis_d(end = 0.8)

p6 <- ggplot(tips, aes(x = Age, y = Tip, fill = Age)) +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_viridis_d(option = "E", end = 0.8)

p4 + p5 + p6
```

## Fit and summarize model {.midi}

```{r}
#| echo: true

tip_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(Tip ~ Party + Age, data = tips)

tidy(tip_fit) |>
  kable(digits = 3)
```

. . .

<br>

::: question
Overall, how well does this model help us understand variablility n tips?
:::

## Two statistics

-   **Root mean square error, RMSE**: A measure of the average error (average difference between observed and predicted values of the outcome)

-   **R-squared**, $R^2$ : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)

::: question
What indicates a good model fit? Higher or lower RMSE? Higher or lower $R^2$?
:::

## RMSE

$$
RMSE = \sqrt{\frac{\sum_{i=1}^n(y_i - \hat{y}_i)^2}{n}} = \sqrt{\frac{\sum_{i=1}^ne_i^2}{n}}
$$

. . .

::: incremental
-   Ranges between 0 (perfect predictor) and infinity (terrible predictor)

-   Same units as the response variable

-   The value of RMSE is more useful for comparing across models than evaluating a single model
:::

# Analysis of variance (ANOVA)

## Analysis of variance (ANOVA)

**Analysis of Variance (ANOVA)**: Technique to partition variability in Y by the sources of variability

![](images/clipboard-3964457409-01.png)

## ANOVA

-   **Main Idea:** Decompose the total variation in the response into
    -   the variation that can be explained by the each of the variables in the model

    -   the variation that **can't** be explained by the model (left in the residuals)
-   If the variation that can be explained by the variables in the model is greater than the variation in the residuals, this signals that the model might be "valuable" (at least one of the $\beta$'s not equal to 0)

## Sum of Squares

<br>

$$
\begin{aligned}
\color{#407E99}{SST} \hspace{5mm}&= &\color{#993399}{SSM} &\hspace{5mm} +  &\color{#8BB174}{SSR} \\[10pt]
\color{#407E99}{\sum_{i=1}^n(y_i - \bar{y})^2} \hspace{5mm}&= &\color{#993399}{\sum_{i = 1}^{n}(\hat{y}_i - \bar{y})^2} &\hspace{5mm}+ &\color{#8BB174}{\sum_{i = 1}^{n}(y_i - \hat{y}_i)^2}
\end{aligned}
$$

::: aside
[Click here](https://introregression.netlify.app/98-appendix#sum-of-squares) to see why this equality holds.
:::

## ANOVA output in R[^1]

[^1]: [Click here](anova-table.html) for explanation about the way R calculates sum of squares for each variable.

```{r}
#| echo: true
anova(tip_fit$fit) |>
  tidy() |>
  kable(digits = 2)
```

## ANOVA output, with totals

```{r}
#| echo: false
anova(tip_fit$fit) |>
  tidy() |>
  mutate(across(where(is.numeric), round, 2)) |>
  janitor::adorn_totals(where = "row", cols = 1:3, fill = "") |>
  mutate(
    statistic = if_else(is.na(statistic), "", statistic),
    p.value = if_else(is.na(p.value), "", p.value)
    ) |>
  kable()
```

## Sum of squares

::::: columns
::: {.column width="50%"}
```{r}
#| echo: false
anova(tip_fit$fit) |>
  tidy() |>
  mutate(across(where(is.numeric), round, 2)) |>
  select(term, df, sumsq) |>
  janitor::adorn_totals(where = "row", cols = 1:3, fill = "") |>
  kable() |>
  column_spec(3, background = "#D9E3E4")
```
:::

::: {.column width="50%"}
-   $SST$: Total sum of squares, variability of Response, $\sum_{i = 1}^n (y_i - \bar{y})^2$
-   $SSR$: Residual sum of squares, variability of residuals, $\sum_{i = 1}^n (y_i - \hat{y}_i)^2$
-   $SSM = SST - SSR$: Model sum of squares, variability explained by the model
:::
:::::

## Sum of squares: $SST$

```{r}
#| echo: false
anova_df <- anova(tip_fit$fit) |>
  tidy() |>
  mutate(across(where(is.numeric), round, 2)) |>
  select(term, df, sumsq) 

anova_df |>
  janitor::adorn_totals(where = "row", cols = 1:3, fill = "") |>
  kable() |>
  row_spec(4, background = "#D9E3E4")
```

<br>

<center>

$SST$: Total sum of squares, variability of the response

<br>

$\sum_{i = 1}^n (y_i - \bar{y})^2$ = `r sum(anova_df$sumsq[1:3])`

</center>

## Sum of squares: $SSR$

```{r}
#| echo: false
anova_df <- anova(tip_fit$fit) |>
  tidy() |>
  mutate(across(where(is.numeric), round, 2)) |>
  select(term, df, sumsq) 

anova_df |>
  janitor::adorn_totals(where = "row", cols = 1:3, fill = "") |>
  kable() |>
  row_spec(3, background = "#D9E3E4")
```

<br>

<center>

$SSR$: Residual sum of squares, variability of residuals

<br>

$\sum_{i = 1}^n (y_i - \hat{y}_i)^2$ = `r anova_df$sumsq[3]`

</center>

## Sum of squares: $SSM$

```{r}
#| echo: false
anova_df <- anova(tip_fit$fit) |>
  tidy() |>
  mutate(across(where(is.numeric), round, 2)) |>
  select(term, df, sumsq) 

anova_df |>
  janitor::adorn_totals(where = "row", cols = 1:3, fill = "") |>
  kable() |>
  row_spec(c(1,2), background = "#D9E3E4")
```

<br>

<center>

$SSM$: Variability explained by the model

<br>

$SST - SSR$ = `r sum(anova_df$sumsq[1:2])`

</center>

## R-squared, $R^2$

The **coefficient of determination** $R^2$ is the proportion of variation in the response, \$Y\$, that is explained by the regression model

. . .

$$
R^2 = \frac{SSM}{SST} = 1 - \frac{SSR}{SST} = 1 - \frac{686.44}{1913.11} = 0.641
$$

. . .

::: question
What is the range of $R^2$ Does $R^2$ have units?
:::

```{r}
#| echo: true
glance(tip_fit)$r.squared
```

## Interpreting $R^2$ 

# Application exercise? 
