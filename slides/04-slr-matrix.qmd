---
title: "SLR: Matrix representation"
author: "Prof. Maria Tackett"
date: "2024-09-05"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 221 - Fall 2024](https://sta221-fa24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r setup}
#| include: false

library(countdown)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.618,
  fig.retina = 3,
  dpi = 300,
  out.width = "80%",
  fig.align = "center"
)
```

## Topics

-   Matrix representation for simple linear regression
    -   Model from
    -   Least square estimate
    -   Fitted (predicted) values
    -   Residuals
-   Matrix representation in R

## Computing set up

```{r packages}
#| echo: true
#| message: false

# load packages
library(tidyverse)   # for data wrangling and visualization
library(tidymodels)  # for modeling (includes broom, yardstick, and other packages)
library(openintro)   # for the duke_forest dataset
library(scales)      # for pretty axis labels
library(knitr)       # for pretty tables
library(patchwork)   # arrange plots

# set default theme for ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

# Matrix form for simple linear regression

## SLR: Statistical model (population)

When we have a quantitative response, $Y$, and a single quantitative predictor, $X$, we can use a **simple linear regression** model to describe the relationship between $Y$ and $X$. $$\large{Y = \mathbf{\beta_0 + \beta_1 X} + \epsilon}, \hspace{8mm} \epsilon \sim N(0, \sigma_{\epsilon}^2)$$

<br>

-   $\beta_1$: Population (true) slope of the relationship between $X$ and $Y$
-   $\beta_0$: Population (true) intercept of the relationship between $X$ and $Y$
-   $\epsilon$: Error

## SLR in matrix form

Suppose we have $n$ observations.

$$
\underbrace{
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix} }_
{\mathbf{y}} \hspace{3mm}
= 
\hspace{3mm}
\underbrace{
\begin{bmatrix}
1 & \dots &x_1 \\
\vdots & \ddots & \vdots \\
1 & \dots & x_n
\end{bmatrix}
}_{\mathbf{X}}
\hspace{2mm}
\underbrace{
\begin{bmatrix}
\beta_0 \\
\beta_1
\end{bmatrix}
}_{\boldsymbol{\beta}}
\hspace{3mm}
+
\hspace{3mm}
\underbrace{
\begin{bmatrix}
\epsilon_1 \\
\vdots\\
\epsilon_n
\end{bmatrix}
}_\boldsymbol{\epsilon}
$$

<br>

::: question
What are the dimensions of $\mathbf{y}$, $\mathbf{X}$, $\boldsymbol{\beta}$, and $\boldsymbol{\epsilon}$?
:::

## Sum of squared residuals

We will use the sum of squared residuals (also called "sum of squared error") to find the least squares line:

$$
SSR = \sum_{i=1}^ne_i^2 = \boldsymbol{e}^T\boldsymbol{e} = (\mathbf{y} - \hat{\mathbf{y}})^T(\mathbf{y} - \hat{\mathbf{y}})
$$

<br>

::: question
-   What is the dimension of SSR?

-   What is $\hat{\mathbf{y}}$ in terms of $\mathbf{y}$, $\mathbf{X}$, and/or $\boldsymbol{\beta}$ ?
:::

## Minimize sum of squared residuals

We want to find $\boldsymbol{\beta} = \begin{bmatrix}\beta_0 \\ \beta_1 \end{bmatrix}$ that minimizes the sum of squared residuals $$
\begin{aligned}
\boldsymbol{e}^T\boldsymbol{e} &= (\mathbf{y} - \mathbf{X}\boldsymbol{\beta})^T(\mathbf{y} - \mathbf{X}\boldsymbol{\beta}) \\[10pt]
&= (\mathbf{y}^T - \boldsymbol{\beta}^T\mathbf{X}^T)(\mathbf{y} - \mathbf{X}\boldsymbol{\beta})\\[10pt]
&=\mathbf{y}^T\mathbf{y} - \mathbf{y}^T\mathbf{X}\boldsymbol{\beta} - \boldsymbol{\beta}^T\mathbf{X}^T\mathbf{y} + \boldsymbol{\beta}^T\mathbf{X}^T\mathbf{X}\boldsymbol{\beta}\\[10pt]
&=\mathbf{y}^T\mathbf{y} - 2\boldsymbol{\beta}^T\mathbf{X}^T\mathbf{y} + \boldsymbol{\beta}^T\mathbf{X}^T\mathbf{X}\boldsymbol{\beta}
\end{aligned}
$$

## Recap

-   Evaluated models using RMSE and $R^2$

-   Used analysis of variance to partition variability in the response variable
