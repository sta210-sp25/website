---
title: "Properties of estimators"
author: "Prof. Maria Tackett"
date: "2024-09-26"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 221 - Fall 2024](https://sta221-fa24.netlify.app)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
filters:
  - parse-latex
bibliography: references.bib
---

```{r setup}
#| include: false

library(countdown)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.618,
  fig.retina = 3,
  dpi = 300,
  out.width = "80%",
  fig.align = "center"
)

options(scipen=999)
```

## Announcements

-   Project

    -   Research questions due **TODAY**

    -   Proposal due Thursday, October 3 at 11:59pm

-   Lab 03 due Thursday, October 3 at 11:59pm

-   HW 02 due Thursday, October 3 at 11:59pm (released after class)

-   [Statistics experience](https://sta221-fa24.netlify.app/hw/stats-experience) due **Tue, Nov 26 at 11:59pm**

## Topics

-   Compute and interpret confidence interval for a single coefficient

-   Properties of $\hat{\boldsymbol{\beta}}$

-   Define "linear" model

## Computing setup

```{r packages}
#| echo: true
#| message: false

# load packages
library(tidyverse)  
library(tidymodels)  
library(knitr)       
library(kableExtra)  
library(patchwork)   

# set default theme in ggplot2
ggplot2::theme_set(ggplot2::theme_bw())
```

## Data: NCAA Football expenditures {.midi}

Today's data come from [Equity in Athletics Data Analysis](https://ope.ed.gov/athletics/#/datafile/list) and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a [March 2022 Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-03-29/readme.md).

We will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :

-   `total_exp_m`: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)

-   `enrollment_th`: Total student enrollment in the 2019 - 2020 academic year (in thousands)

-   `type`: institution type (Public or Private)

```{r}
#| include: false
#| eval: false

## code to make data set for these notes

sports <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-29/sports.csv') 

# filter data to only include D1 football for the year 2019

sports |>
  filter(sports == "Football", 
         classification_name == "NCAA Division I-FBS", year == 2019) |>
  mutate(type = if_else(sector_name == "Private nonprofit, 4-year or above", "Private", "Public"), 
         enrollment_th = ef_total_count / 1000,
         total_exp_m = total_exp_menwomen/ 1000000) |>
  select(year, institution_name, city_txt, state_cd, zip_text, type,
         enrollment_th, 
         total_exp_m) |> 
  write_csv("data/ncaa-football-exp.csv")


```

```{r}
#| echo: false
football <- read_csv("data/ncaa-football-exp.csv")
```

```{}
```

## Regression model

```{r}
#| echo: true
exp_fit <- lm(total_exp_m ~ enrollment_th + type, data = football)
tidy(exp_fit) |>
  kable(digits = 3)
```

## Inference for $\beta_j$ {.midi}

We often want to conduct inference on individual model coefficients

-   **Hypothesis test:** Is there a linear relationship between the response and $x_j$?

-   **Confidence interval**: What is a plausible range of values $\beta_j$ can take?

# Confidence interval for $\beta_j$

## Confidence interval for $\beta_j$ {.midi}

::: incremental
-   A plausible range of values for a population parameter is called a **confidence interval**

-   Using only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net

    -   We can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish

    -   Similarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter
:::

## What "confidence" means {.midi}

::: incremental
-   We will construct $C\%$ confidence intervals.

    -   The confidence level impacts the width of the interval

<br>

-   "Confident" means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate $C\%$ CIs for the coefficient of $x_j$, then $C\%$ of those intervals will contain the true value of the coefficient $\beta_j$

<br>

-   Balance precision and accuracy when selecting a confidence level
:::

## Confidence interval for $\beta_j$

$$
\text{Estimate} \pm \text{ (critical value) } \times \text{SE}
$$

<br>

. . .

$$
\hat{\beta}_1 \pm t^* \times SE({\hat{\beta}_j})
$$

where $t^*$ is calculated from a $t$ distribution with $n-p-1$ degrees of freedom

## Computing $t^*$ in R

::: {.fragment fragment-index="1"}
```{r}
#| echo: true

# confidence level: 95%
qt(0.975, df = nrow(football) - 2 - 1)
```
:::

<br>

::: {.fragment fragment-index="2"}
```{r}
# confidence level: 90%
qt(0.95, df = nrow(football) - 2 - 1)
```
:::

<br>

::: {.fragment fragment-index="3"}
```{r}
# confidence level: 99%
qt(0.995, df = nrow(football) - 2 - 1)
```
:::

## 95% CI for coefficient of enrollment

```{r}
#| echo: false
tidy(exp_fit) |> 
  kable(digits = 3)
```

<br>

. . .

$$
\hat{\beta}_j \pm t^* \times SE(\hat{\beta}_j)
$$

. . .

$$
0.7804 \pm 1.9793 \times 0.1103
$$

. . .

$$
[0.562, 0.999]
$$

## Interpreting the CI

<!--# Make Ed Discussion post-->

<!--# Best interpretation: Interpretation: We are 95% confident that for each additional 1,000 students enrolled, the institution's expenditures on football will be greater by $562,000 to $999,000, on average, holding institution type constant.-->

## Computing CI in R

```{r}
#| echo: true
#| code-line-numbers: "1"

tidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |> 
  kable(digits = 3)
```

# Properties of $\hat{\boldsymbol{\beta}}$ 

## Motvation

-   We have discussed how to use least squares to find an estimator of $\hat{\boldsymbol{\beta}}$

-   How do we know whether our least squares estimator is a "good" estimator?

-   When we consider what makes an estimator "good", we'll look at three criteria:

    -   Bias

    -   Variance

    -   Mean squared error

-   We'll take a look at these over the course of a few lectures and motivate why we might prefer using least squares to compute $\hat{\boldsymbol{\beta}}$ versus other methods

## Bias and variance

Suppose you are throwing darts at a target

::: columns
::: {.column width="50%"}
<!--# find image of dart-->
:::

::: {.column width="50%"}
-   **Unbiased**: Darts spread around the target

-   **Biased**: Darts systematically away from the target

-   **Variance**: Darts could be widely spread (high variance) or generally clustered together (low variance)
:::
:::

## Bias and variance

-   **Ideal scenario**: Darts are clustered around the target (unbiaseds and low variance)

-   **Worst case scenario**: Darts are widely spread out and systematically far from the target (high bias and high variance)

-   **Acceptable scenario:** There's some tradeoff between the bias and variance. For example, it may be acceptable for the darts to be clustered around a point that is close to the target (low bias and low variance)

## Bias and variance in estimator

I Each time we take a sample, we compute the MLE for the
parameters of interest. (We shoot an arrow at the target.)
I Suppose we could take many independent samples over and
over again and compute the MLE in each.
I Ideally, the collection of MLE values are centered at the true
parameter. (We are unbiased shooters.)
I Even better, the collection of MLE values are clustered around
the true parameter. (We are unbiased shooters with low
variance.)
I It would be bad news if the MLE values tended not to estimate
the true parameter and were diâ†µusely spread. (We are biased
shooters with high variance.

<!--# show distribution of beta-hat-->

## $E(\hat{\boldsymbol{\beta}})$ 
