---
title: "HW 04: Logistic regression"

bibliography: references.bib
---

::: callout-important
## Due date

This assignment is due on **Thursday, November 21 at 11:59pm.**
:::

# Introduction

<!--# Update-->

# Learning goals

In this assignment, you will…

<!--# Update-->

# Getting started

-   Go to the [sta221-fa24](https://www.github.com/sta221-fa24) organization on GitHub. Click on the repo with the prefix **hw-04**. It contains the starter documents you need to complete the lab.

-   Clone the repo and start a new project in RStudio. See the [Lab 01 instructions](https://sta221-fa24.netlify.app/labs/lab-01#clone-the-repo-start-new-rstudio-project) for details on cloning a repo and starting a new project in R.

# Packages

The following packages are used in this assignment:

```{r}
#| eval: false

library(tidyverse)
library(tidymodels)
library(knitr)

# load other packages as needed
```

# Conceptual exercises

## Instructions

The conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\
\
**You may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.**

## Exercise 1

In the 2014 article [“The Biggest Predictor of How Long You’ll Be Unemployed Is When You Lose Your Job”](https://fivethirtyeight.com/features/the-biggest-predictor-of-how-long-youll-be-unemployed-is-when-you-lose-your-job/), author Ben Casselman analyzes the relationship between numerous factors such as age, race, and education and the odds an adult is unemployed for over a year.

Casselman fits a logistic regression model using the unemployment rate at the time the person lost their job to predict whether an adult is unemployed for over a year. He states the following from the model:

> *“A one-point increase in the unemployment rate raises an individual’s odds of becoming long-term unemployed by 35 percent.”*

What is the coefficient for unemployment rate in this model? Show how you calculated the answer.

## Exercise 2

<!--# Adapted from Gelman and Hill pg. 105 #3-->

You would like to study how well the combined earnings for a child's parents predicts high school graduate. Suppose the probability a child graduates from high school is 27% for children whose parents earn no income and is 88% for children whose parents earn \$60,000 combined income.

Write the equation for the logistic regression model with the single predictor variable `income` that is consistent with the information above. You can assume income is measured in tens of thousands of dollars.

## Exercise 3

*In the paper [“Employing Standardized Risk Assessment in Pretrial Release Decisions: Association With Criminal Justice Outcomes and Racial Equity”](https://web-s-ebscohost-com.proxy.lib.duke.edu/ehost/pdfviewer/pdfviewer?vid=0&sid=221ae3cd-b01e-4432-a4dc-4b259e895086%40redis)* Marlowe et al. ([2020](https://sta210-fa22.netlify.app/hw/hw-04#ref-marlowe2020)) *analyze the risk predictions produced by a black-box algorithm used to determine whether a defendant is considered “high risk” of being rearrested if they are released while awaiting trial. Such algorithms are used by judges in some states to help determine whether or not defendants are released while awaiting trial.*

*The authors examine the algorithm’s risk predictions and whether a person was rearrested for over 500 defendants released pretrial in a southern state. For each person, the algorithm produced one of the following predictions: “High Risk” or “Low Risk”. The observed outcome was “Rearrested” or “Not Rearrested”. Below are some results from the analysis:*

-   *Sensitivity: 86%*
-   *Specificity: 24%*
-   *Positive predictive power: 57%*
-   *Negative predictive power: 60%*

::: callout-tip
-   **Positive Predictive Power**: P(Y = 1 \| Y classified as 1 from the model)

-   **Negative Predictive Power**: P(Y = 0 \| Y classified as 0 from the model)
:::

a.  Explain what each of the following mean in the context of the analysis:

    -   Sensitivity

    -   Specificity

    -   Positive predictive power

    -   Negative predictive power

b.  What is the false positive rate? What does this value mean in the context of the analysis?

c.  The AUC for this algorithm is 0.55. Based on this value, do you think this algorithm a good fit for the population examined in the paper? Why or why not?

## Exercise 4

The 2016 article [“Tea consumption reduces the incidence of neurocognitive disorders: Findings from the Singapore longitudinal aging study”](https://link.springer.com/article/10.1007/s12603-016-0687-0) ([Feng et al. 2016](https://sta210-fa22.netlify.app/hw/hw-04#ref-feng2016)) examined the association between tea consumption habits and neurocognitive disorders (NCD), such as Alzheimer’s disease, in adults age 55 and older. Portions of the abstract are below:

> [Objectives]{.underline}
>
> *To examine the relationships between tea consumption habits and incident neurocognitive disorders (NCD) and explore potential effect modification by gender and the apolipoprotein E (APOE) genotype.*
>
> [Participants]{.underline}

> *957 community-living Chinese elderly who were cognitively intact at baseline.*

> [Measurements]{.underline}

> *We collected tea consumption information at baseline from 2003 to 2005 and ascertained incident cases of neurocognitive disorders (NCD) from 2006 to 2010. Odds ratio (OR) of association were calculated in logistic regression models that adjusted for potential confounders.*

> [Results]{.underline}

> *A total of 72 incident NCD cases were identified from the cohort. Tea intake was associated with lower risk of incident NCD, independent of other risk factors. Reduced NCD risk was observed for both green tea (OR=0.43) and black/oolong tea (OR=0.53) and appeared to be influenced by the changing of tea consumption habit at follow-up. Using consistent nontea consumers as the reference, only consistent tea consumers had reduced risk of NCD (OR=0.39). Stratified analyses indicated that tea consumption was associated with reduced risk of NCD among females (OR=0.32) and APOE e4 carriers (OR=0.14) but not males and non APOE e4 carriers.*

a.  The odds ratios reported in the abstract are the adjusted odds ratios, i.e., the odds ratios after adjusting for potential confounders such as age, pre-existing health conditions, diet, and behavioral factors. Interpret the following odds ratios from the abstract. Write the interpretations in the context of the data.

    -   OR = 0.39

    -   OR = 0.32

b.  An [online article](https://www.womansworld.com/posts/health/tea-cuts-dementia-risk) based on the results of Feng et al. states the following:

    > *“And for people who carry a gene that puts them at higher risk for Alzheimer’s disease (the APOE e4 gene), enjoying the beverage is even more important: Daily tea consumption could reduce their risk of cognitive decline by up to 86 percent.”*

    Is this statement supported by the results of the study? Briefly explain why or why not.

<!--# START HERE--->

# Applied exercises

## Instructions

The applied exercises are focused on applying the concepts to analyze data.

**All work for the applied exercises must be typed in your Quarto document following a reproducible workflow.**

Write all narrative using complete sentences and include informative axis labels / titles on visualizations.

## Data: SAT

This data set contains the average SAT score (out of 1600) and other variables that may be associated with SAT performance for each of the 50 U.S. states. The data is based on test takers for the 1982 exam. We will use the following variables:

-   **`SAT`**: average total SAT score

-   **`Takers`**: percentage of high school seniors who took exam

-   **`Income`**: median income of families of test-takers (\$ hundreds)

-   **`Years`**: average number of years test-takers had formal education in social sciences, natural sciences, and humanities

-   **`Public`**: percentage of test-takers who attended public high schools

-   **`Expend`**: total state expenditure on high schools (\$ hundreds per student)

-   **`Rank`**: median percentile rank of test-takers within their high school classes

The data are in the file `sat-1982.csv` in the `data` folder.

## Exercise 5

a.  Fit a main effects model using `SAT` as the response and all other variables (except State) as the predictors. Neatly display the model using 3 digits.
b.  Are there any influential observations in the data set? Briefly explain showing any work or output used to make the determination.
c.  Consider the observation with the highest value for Cook's distance. What is the value of leverage for this observation? Would this be considered large leverage? Briefly explain showing any work or output used to make the determination.

## Exercise 6

a.  Compute the Variance Inflation Factors (VIF) for the model from the previous exercise.
b.  Does this model have any issues with multicollinearity? If so, what predictors appear to be collinear?
c.  If multicollinearity is present, select a strategy to fit a model that does not have an issue with multicollinearity.
    -   Briefly describe your strategy.
    -   Select a final model.
    -   Briefly explain your selection, showing any work and output used to choose a model.

## Data: **2000 U.S. Presidential Election**

We will examine data about the [2000 U.S. presidential election](https://en.wikipedia.org/wiki/2000_United_States_presidential_election) between George W. Bush and Al Gore. It was one of the closest elections in history that ultimately came down to the state of Florida. One county in particular, Palm Beach County, was at the center of the controversy due to the design of their ballots - the infamous [butterfly ballots](http://news.bbc.co.uk/2/hi/in_depth/americas/2000/us_elections/glossary/a-b/1037172.stm). It is believed that many people who intended to vote for Al Gore accidentally voted for Pat Buchanan due to how the spots to mark the candidate were arranged next to the names.

The variables in the data are

-   `County`: County name

-   `Bush2000`: Number of votes for George W. Bush

-   `Buchanan2000`: Number of votes for Pat Buchanan

The data are available in the file `florida-votes-2000.csv` in the `data` folder of your repo.

## Exercise 7

The goal is to fit a model that uses the number of votes for Bush to predict the number of votes for Buchanan. Using this model, we’ll investigate whether the data support the claim that votes for Gore may have accidentally gone to Buchanan.

a.  Visualize the relationship between the number of votes for Buchanan versus the number of votes for Bush. Describe what you observe in the visualization, including a description of the relationship between the votes for Buchanan and votes for Bush.
b.  What is the county with the extreme outlier number of votes for Buchanan? Create a new data frame that doesn’t include the outlying county. **You will use this updated data frame for the remainder of this exercise and Exercise 8.**
c.  Fit a model to predict the number of votes for Buchanan based on the number of votes for Bush in the county.
    -   Make a plot of the standardized residuals versus the fitted values.
    -   Is the constant variance condition satisfied? Briefly explain.

## Exercise 8

Now let's consider potential models with transformations on the response and/or predictor variables. The four candidate models are the following:

| Model                      | Response variable | Predictor variable |
|----------------------------|-------------------|--------------------|
| 1 (from previous exercise) | Buchanan2000      | Bush2000           |
| 2                          | log(Buchanan2000) | Bush2000           |
| 3                          | Buchanan2000      | log(Bush2000)      |
| 4                          | log(Buchanan2000) | log(Bush2000)      |

Which model best fits the data? Briefly explain, showing any work and output used to determine the response. **(Note: Use the data set without the outlying county to find the candidate models.)**

## Exercise 9

Now we will use the model to predict the expected number of Buchanan votes for the outlier county.

Suppose the observed value of the predictor for this county (a new observation) is $x_0$. We define $\mathbf{x}_0^T = [1, x_0]$

Then the predicted response is

$$
\hat{y}_0 = \mathbf{x}_0^T\hat{\boldsymbol{\beta}}
$$

Where $\hat{\boldsymbol{\beta}}$ is the vector of estimated model coefficients.

Just as there is uncertainty in our model coefficients, there is uncertainty in our predictions as well. We use a confidence interval to quantify the uncertainty for a model coefficient, and we can use a **prediction interval** to quantify the uncertainty in the prediction for a new observation.

The $C\%$ prediction interval for the new observation is

$$
\hat{y}_0 \pm t^*_{n - p - 1}\sqrt{\hat{\sigma}^2_\epsilon(1 + \mathbf{x}_0^T(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{x}_0)}
$$

where $t^*_{n-p-1}$ is the critical value obtained from the $t$ distribution with $n - p - 1$ degrees of freedom, $\mathbf{X}$ is the design matrix for the model, and $\hat{\sigma}^2_\epsilon$ is the estimated variability about the regression line.

a.  Use the model you chose in the previous exercise to compute the predicted number of votes for Buchanan in the outlying county identified in Exercise 7. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).

b.  Compute the 95% prediction interval for this county. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).

c.  It is assumed that some of the votes for Buchanan in that county were actually intended to be for Gore. Based on your results in the previous question, does your model support this claim?

    -   If no, briefly explain.

    -   If yes, about how many votes were possibly intended for Gore? Show any calculations and output used to determine your answer. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).

# Submission

::: callout-warning
Before you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.

Remember -- you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.

If you write your responses to conceptual exercises by hand, you will need to combine your written work to the completed PDF for the applied exercises before submitting on Gradescope.

Instructions to combine PDFs:

-   Preview (Mac): [support.apple.com/guide/preview/combine-pdfs-prvw43696/mac](https://support.apple.com/guide/preview/combine-pdfs-prvw43696/mac)

-   Adobe (Mac or PC): help[.adobe.com/acrobat/using/merging-files-single-pdf.html](https://helpx.adobe.com/acrobat/using/merging-files-single-pdf.html)

    -   Get free access to Adobe Acrobat as a Duke student: [oit.duke.edu/help/articles/kb0030141/](https://oit.duke.edu/help/articles/kb0030141/)
:::

To submit your assignment:

-   Access Gradescope through the menu on the [STA 221 Canvas site.](https://canvas.duke.edu/courses/38867)

-   Click on the assignment, and you’ll be prompted to submit it.

-   Mark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be “checked”).

-   Select the first page of your .PDF submission to be associated with the *“Workflow & formatting”* section.

# Grading

| Component             | Points |
|-----------------------|--------|
| Ex 1                  | 3      |
| Ex 2                  | 9      |
| Ex 3                  | 9      |
| Ex 4                  | 3      |
| Ex 5                  | 5      |
| Ex 6                  | 5      |
| Ex 7                  | 5      |
| Ex 8                  | 3      |
| Ex 9                  | 5      |
| Workflow & formatting | 3      |

The "Workflow & formatting" grade is to assess the reproducible workflow and document format for the applied exercises. This includes having at least 3 informative commit messages, a neatly organized document with readable code and your name and the date updated in the YAML.
