[
  {
    "objectID": "project-old.html",
    "href": "project-old.html",
    "title": "Final project",
    "section": "",
    "text": "Project proposal\n\ndue Friday, October 27 (Tuesday labs)\ndue Sunday, October 29 (Thursday labs)\n\nDraft report + peer review\n\ndue Tuesday, November 14 (Tuesday labs)\ndue Thursday, November 16 (Thursday labs)\n\nRound 1 submission (optional) due Friday, December 1\nPresentation + Presentation comments\n\nTuesday, December 5 (Tuesday labs)\nThursday, December 7 (Thursday labs)\n\nWritten report due Wednesday, December 13\nReproducibility + organization due Wednesday, December 13"
  },
  {
    "objectID": "project-old.html#timeline",
    "href": "project-old.html#timeline",
    "title": "Final project",
    "section": "",
    "text": "Project proposal\n\ndue Friday, October 27 (Tuesday labs)\ndue Sunday, October 29 (Thursday labs)\n\nDraft report + peer review\n\ndue Tuesday, November 14 (Tuesday labs)\ndue Thursday, November 16 (Thursday labs)\n\nRound 1 submission (optional) due Friday, December 1\nPresentation + Presentation comments\n\nTuesday, December 5 (Tuesday labs)\nThursday, December 7 (Thursday labs)\n\nWritten report due Wednesday, December 13\nReproducibility + organization due Wednesday, December 13"
  },
  {
    "objectID": "project-old.html#introduction",
    "href": "project-old.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The four primary deliverables for the final project are\n\na written, reproducible report detailing your analysis\na GitHub repository corresponding to your report\nslides and an in-person presentation\nformal peer review on another team’s work and presentation feedback"
  },
  {
    "objectID": "project-old.html#project-proposal",
    "href": "project-old.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\n\n\n\n\n\n\nDue dates\n\n\n\n\nFriday, October 27 (Tuesday labs)\nSunday, October 29 (Thursday labs)\n\n\n\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing for the project, do some preliminary exploratory data analysis, and begin to think about a modeling strategy . If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point. It may also help to think of topics you’re interested in investigating and find data sets on those topics.\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\nThe introduction section includes\n\nan introduction to the subject matter you’re investigating (citing any relevant literature)\nthe motivation for your research question (citing any relevant literature)\nthe primary research question you are interested in exploring\nyour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\nThe data description section includes\n\nthe source of the data set\na description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\na description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\nIn this section, you will begin to explore the data. This includes using narrative, visualizations and summary statistics to describe the following:\n\ndistribution of the response variable\ndistributions of one potential quantitative predictor variable and one potential categorical predictor variable\nthe relationships between the response variable and each of the predictors from the previous step\na potential interaction effect you’re interested in exploring (it doesn’t have to be an interaction with the two predictors from above)\n\nThese steps are to help get you started on exploratory data analysis and will not be the complete EDA for the final report. The requirements above are minimum requirements, but your group is welcome to include more at this stage.\nIn this section, you will also describe any data cleaning you need to do to prepare for modeling, such as imputing missing values, collapsing levels for categorical predictors, creating new variables, summarizing data, etc.\n\n\nSection 4: Analysis approach\nIn this section, you will provide a brief overview of your analysis approach. This includes\n\na description of the response variable and list of all potential predictors\nregression model technique (multiple linear regression or logistic regression)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\n\n\n\n\n\n\nImportant\n\n\n\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file. Put the data set and the data dictionary in the data folder.\nSubmit the PDF of the proposal to Gradescope. Mark all pages of the document.\n\n\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages; it may not exceed 5 pages.\nThe proposal is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (14 - 15 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as descrbied above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (11 - 13 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (8 - 10 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (7 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-old.html#draft-report-peer-review",
    "href": "project-old.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Draft report + peer review",
    "text": "Draft report + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\n\n\n\n\n\n\nDue dates\n\n\n\nDraft is due in your project GitHub repo at 9am on\n\nTuesday, November 14 (Tuesday labs)\nThursday, November 16 (Thursday labs)\n\n\n\nWrite the draft in the written-report.qmd file in your project repo. You do not need to submit the draft on Gradescope.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written-report.qmd file in our GitHub repo by the deadline.\n\n\n\nPeer review\n\n\n\n\n\n\nImportant\n\n\n\nPeer review comments are due in GitHub at 11:59pm on\n\nWednesday, November 15 (Tuesday labs)\nFriday, November 17 (Thursday labs)\n\n\n\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’s projects to review. Each team should push their draft to their GitHub repo by the 9am on the day their lab’s draft is due. The lab that week will be dedicate to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nPeer review assignments\n\n\n\nClick here to see which project your team is reviewing. You’ll spend about 30 minutes reviewing each project.\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Fill out this issue. You will answer the the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods and analysis approach used.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions."
  },
  {
    "objectID": "project-old.html#written-report",
    "href": "project-old.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\n\n\n\n\n\n\nNote\n\n\n\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the variables in the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics, conditions, and diagnostics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. The model conditions and diagnostics are thoroughly and accurately assessed for their model. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted and labeled. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.\n\n\nSubmission\n\n\n\n\n\n\nImportant\n\n\n\nThe written report is due on Wednesday, December 13 at 11:59pm.\nTo submit your report, written-report.qmd and the rendered written-report.pdf to your team’s GitHub repo by the deadline. You will not submit the report on Gradescope.\nThe version of the report in the repo by Wednesday, December 13 will be the one that is graded."
  },
  {
    "objectID": "project-old.html#round1-submission",
    "href": "project-old.html#round1-submission",
    "title": "Final project",
    "section": "Round 1 submission (optional)",
    "text": "Round 1 submission (optional)\n\n\n\n\n\n\nDue date\n\n\n\nFriday, December 1 at 11:59pm on GitHub (all teams)\nReports submitted after this date will not receive preliminary feedback.\n\n\nThe Round 1 submission is an opportunity to receive detailed feedback on your analysis and written report before the final submission. Therefore, to make the feedback most useful, you must submit a complete written report to receive feedback. You will also be notified of the grade you would receive at that point. You will have the option to keep the grade (and thus you don’t need to turn in an updated report) or resubmit the written report by the final submission deadline to receive a new grade.\n\nTo submit the Round 1 submission:\n\nPush the updated written-report.qmd and written-report.pdf to your GitHub repo.\nOpen an issue with the title “Round 1 Submission”. You can use the template issue in the GitHub repo. Make sure I am tagged in the issue (@matackett), so I receive an email notification of your Round 1 submission. See Creating an issue from a repository for instructions on opening an issue. Please ask a member of the teaching team for assistance if you need help opening the issue.\n\n\n\n\n\n\n\nNote\n\n\n\nNote that this is optional, so there is nograde penalty for not turning in a Round 1 submission. Due to time constraints at the end of the semester, only high-level feedback will be given for the reports submitted at the final written report deadline on December 13."
  },
  {
    "objectID": "project-old.html#presentation",
    "href": "project-old.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs December 5 & 7.\n\nClick here for the presentation order.\n\n\nIn addition to the written report, your team will also do an in-person presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\n\n\nThe presentation must be no longer than 6 minutes. It is fine if the presentation is shorter than 6 minutes, but it cannot exceed 6 minutes due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4: Final model\nSlide 5: Interesting findings from the model\nSlide 6: Conclusions + future work\n\n\n\nGrading criteria\nThe presentation grade will be based on the following criteira:\n\nContent: The group told a unified story using the appropriate regression analysis.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nProfessionalism: The group’s communication style was clear and professional.\nTime Management: Team divided the time well and stayed within the 6 minute time limit, with each team member making a meaning contribution to the presentation. (assessed by the teaching team only).\n\n80% of the presentation grade will be the average of the teaching scores and 20% will be the average of the peer scores.\n\n\n\n\n\n\nImportant\n\n\n\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\nSlides must be submitted by the start of your lab on December 5 or 7. You will not submit the slides on Gradescope."
  },
  {
    "objectID": "project-old.html#presentation-comments",
    "href": "project-old.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to find the teams you’re scoring and a link to the feedback form.\nThis portion of the project will be assessed individually.\n\n\n\nYou will provide feedback on two teams’ presentations. You can find your assigned teams and the link to the feedback from here. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day (December 5 for Tuesday labs, December 7 for Thursday labs)."
  },
  {
    "objectID": "project-old.html#reproducibility-organization",
    "href": "project-old.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\n\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.\n\n\n\n\n\n\nImportant\n\n\n\nThe repo must be ready for grading by Wednesday, December 13 at 11:59pm."
  },
  {
    "objectID": "project-old.html#peer-teamwork-evaluation",
    "href": "project-old.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly."
  },
  {
    "objectID": "project-old.html#overall-grading",
    "href": "project-old.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nProject proposal\n15 pts\n\n\nDraft report + peer review\n15 pts\n\n\nPresentation\n20 pts\n\n\nPresentation comments\n5 pts\n\n\nWritten report\n40 pts\n\n\nReproducibility + organization\n5 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-old.html#late-work-policy",
    "href": "project-old.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "Research questions due Thursday, September 26\nProject proposal due Thursday, October 3\nExploratory data analysis due Thursday, October 31\nPresentation + Presentation comments Monday, November 11 (in lab)\nAnalysis draft + peer review Monday, November 25 (peer review in lab)\nRound 1 submission (optional) due Friday, December 6\nWritten report due Thursday, December 12 at 9pm\nReproducibility + organization due Thursday, December 12 at 9pm",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-milestones",
    "href": "project.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research questions due Thursday, September 26\nProject proposal due Thursday, October 3\nExploratory data analysis due Thursday, October 31\nPresentation + Presentation comments Monday, November 11 (in lab)\nAnalysis draft + peer review Monday, November 25 (peer review in lab)\nRound 1 submission (optional) due Friday, December 6\nWritten report due Thursday, December 12 at 9pm\nReproducibility + organization due Thursday, December 12 at 9pm",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the final deliverables.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#research-questions",
    "href": "project.html#research-questions",
    "title": "Final project",
    "section": "Research questions",
    "text": "Research questions\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing potential research questions; you do not need to have a data set identified at this point.\nDevelop three potential research questions. Include the following for each question:\n\nA statement of the research question.\nThe target population of interest for this question.\nA statement about your motivation for investigating this research question and why this question is important.\nIdeas about the type of data you might use to answer this question. Note: These are your ideas about the type of data you could use. You do not need to have a data set at this point.\n\n\nSubmission\nWrite your responses in research-questions.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, September 26 at 11:59pm.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research questions. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Questions milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\n\nDescription of data cleaning you need to do to prepare for analysis (can focus on the response variable for now), such as joining data sets, imputing missing values, variable transformation, creating a new variable, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, October 3 at 11:59pm.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#eda",
    "href": "project.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, October 31 at 11:59pm.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about about 4 - 6 pages.\n\n\n\n\n\n\nTip\n\n\n\nYou can suppress code, warnings, and messages by including the following in the YAML:\nexecute: \n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (14 - 15 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (11 - 13 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (8 - 10 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (7 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation",
    "href": "project.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs on November 11. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on November 11. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation-comments",
    "href": "project.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day, November 11.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#draft-report-peer-review",
    "href": "project.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\n\n\n\n\n\n\nImportant\n\n\n\nThe draft report is due in your GitHub repo by November 25 at 9am.\n\n\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\n\n\n\nPeer review\n\n\n\n\n\n\nImportant\n\n\n\nPeer review comments are due in GitHub on November 26 at 11:59pm.\n\n\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 221 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by the 9am on the day their lab’s draft is due. The lab that week will be dedicate to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review. –&gt;\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Fill out this issue. You will answer the the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods and analysis approach used.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#round1-submission",
    "href": "project.html#round1-submission",
    "title": "Final project",
    "section": "Round 1 submission (optional)",
    "text": "Round 1 submission (optional)\n\n\n\n\n\n\nImportant\n\n\n\nThe Round 1 submission is due on Friday, December 6 at 11:59pm. Reports submitted after this date will not receive preliminary feedback.\n\n\nThe Round 1 submission is an opportunity to receive detailed feedback on your analysis and Written report before the final submission. Therefore, to make the feedback most useful, you must submit a complete written report to receive feedback. You will also be notified of the grade you would receive at that point. You will have the option to keep the grade (and thus you don’t need to turn in an updated report) or resubmit the written report by the final submission deadline to receive a new grade.\n\nTo submit the Round 1 submission:\n\nPush the updated `written-report.qmd` and `written-report.pdf` to your GitHub repo.\nOpen an issue with the title “Round 1 Submission”. You can use the template issue in the GitHub repo. Make sure I am tagged in the issue (@matackett), so I receive an email notification of your Round 1 submission. See Creating an issue from a repository for instructions on opening an issue. Please ask a member of the teaching team for assistance if you need help opening the issue.\n\nNote that this is optional, so there is no grade penalty for not turning in a Round 1 submission. Due to time constraints at the end of the semester, only high-level feedback will be given for the reports submitted at the final written report deadline on December 12.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#written-report",
    "href": "project.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nThe written report is due on Thursday, December 12 at 9pm.\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\n\n\nResults\n\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#reproducibility-organization",
    "href": "project.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#peer-teamwork-evaluation",
    "href": "project.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#overall-grading",
    "href": "project.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch question\n3 pts\n\n\nProject proposal\n10 pts\n\n\nExploratory data analysis\n15 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n15 pts\n\n\nWritten report\n40 pts\n\n\nReproducibility + organization\n5 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#late-work-policy",
    "href": "project.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nFiveThirtyEight data\nTidyTuesday\nData Is Plural\nR Data Sources for Regression Analysis\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "math-rules.html",
    "href": "math-rules.html",
    "title": "Math rules",
    "section": "",
    "text": "This page contains mathematical rules we’ll use in this course that may be beyond what is covered in a linear algebra course.\n\n\n\n\nLet \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\nThe gradient of \\(\\mathbf{x}^T\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{z} = \\mathbf{z}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\nThen the gradient of \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^T \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\n\\]\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\n\n\n\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]\n\n\n\n\n\n\nThe expected value of a random variable \\(\\mathbf{X}\\) is a weighted average, i.e., the mean value of the possible values a random variable can take weighted by the probability of the outcomes.\nLet \\(f_X(x)\\) be the probability distribution of \\(X\\). If \\(X\\) is continuous then\n\\[\nE(X) = \\int_{-\\infty}^{\\infty}xf_X(x)dx\n\\]\nIf \\(X\\) is discrete then\n\\[\nE(X) = \\sum_{x \\in X}xf_X(x) = \\sum_{x\\in X}xP(X = x)\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nE(aX + b) = E(aX) + E(b) = aE(X) + b\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\), \\(b\\), and \\(c\\) be constants. For any functions \\(g_1(x)\\) and \\(g_2(x)\\), then\n\\[E(ag_1(X) + bg_2(X) + c) = aE(g_1(X)) + bE(g_2(X)) + c\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Ab}) = \\mathbf{A}E(\\mathbf{b})\n\\]\n\n\n\n\n\n\nThe variance of a random variable \\(X\\) is a measure of the spread of a distribution about its mean.\n\\[\nVar(X) = E[(X - E(X))^2] = E(X^2) - E(X)^2\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nVar(aX + b) = a^2Var(X)\n\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen\n\\[\nVar(\\mathbf{b}) = E[(\\mathbf{b} - E(\\mathbf{b}))(\\mathbf{b} - E(\\mathbf{b}))^T]\n\\]\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\n\\begin{aligned}\nVar(\\mathbf{Ab}) &= E[(\\mathbf{Ab} - E(\\mathbf{Ab}))(\\mathbf{Ab} - E(\\mathbf{Ab}))^T]\\\\& = \\mathbf{A}Var(\\mathbf{b})\\mathbf{A}^T\n\\end{aligned}\n\\]\n\n\n\n\n\n\nLet \\(X\\) be a random variable, such that \\(X \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(X = x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(x - \\mu)^2}\\Big\\}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#matrix-calculus",
    "href": "math-rules.html#matrix-calculus",
    "title": "Math rules",
    "section": "",
    "text": "Let \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\nThe gradient of \\(\\mathbf{x}^T\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{z} = \\mathbf{z}\n\\]\n\n\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\nThen the gradient of \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^T \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\n\\]\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\n\n\n\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#expected-value",
    "href": "math-rules.html#expected-value",
    "title": "Math rules",
    "section": "",
    "text": "The expected value of a random variable \\(\\mathbf{X}\\) is a weighted average, i.e., the mean value of the possible values a random variable can take weighted by the probability of the outcomes.\nLet \\(f_X(x)\\) be the probability distribution of \\(X\\). If \\(X\\) is continuous then\n\\[\nE(X) = \\int_{-\\infty}^{\\infty}xf_X(x)dx\n\\]\nIf \\(X\\) is discrete then\n\\[\nE(X) = \\sum_{x \\in X}xf_X(x) = \\sum_{x\\in X}xP(X = x)\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nE(aX + b) = E(aX) + E(b) = aE(X) + b\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\), \\(b\\), and \\(c\\) be constants. For any functions \\(g_1(x)\\) and \\(g_2(x)\\), then\n\\[E(ag_1(X) + bg_2(X) + c) = aE(g_1(X)) + bE(g_2(X)) + c\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Ab}) = \\mathbf{A}E(\\mathbf{b})\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#variance",
    "href": "math-rules.html#variance",
    "title": "Math rules",
    "section": "",
    "text": "The variance of a random variable \\(X\\) is a measure of the spread of a distribution about its mean.\n\\[\nVar(X) = E[(X - E(X))^2] = E(X^2) - E(X)^2\n\\]\n\n\n\n\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants. Then\n\\[\nVar(aX + b) = a^2Var(X)\n\\]\n\n\n\n\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\nThen\n\\[\nVar(\\mathbf{b}) = E[(\\mathbf{b} - E(\\mathbf{b}))(\\mathbf{b} - E(\\mathbf{b}))^T]\n\\]\n\n\n\n\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\n\\begin{aligned}\nVar(\\mathbf{Ab}) &= E[(\\mathbf{Ab} - E(\\mathbf{Ab}))(\\mathbf{Ab} - E(\\mathbf{Ab}))^T]\\\\& = \\mathbf{A}Var(\\mathbf{b})\\mathbf{A}^T\n\\end{aligned}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "math-rules.html#probability-distributions",
    "href": "math-rules.html#probability-distributions",
    "title": "Math rules",
    "section": "",
    "text": "Let \\(X\\) be a random variable, such that \\(X \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(X = x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(x - \\mu)^2}\\Big\\}\n\\]",
    "crumbs": [
      "Math rules"
    ]
  },
  {
    "objectID": "slides/18-prob-odds.html#announcements",
    "href": "slides/18-prob-odds.html#announcements",
    "title": "Probabilites, odds, odds ratios",
    "section": "Announcements",
    "text": "Announcements\n\nHW 03 due TODAY 11:59pm\nProject: Exploratory data analysis due TODAY at 11:59pm\nTuesday, November 5: Wellness Day (no lecture)\nLooking ahead\n\nProject presentations November 11\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/18-prob-odds.html#topics",
    "href": "slides/18-prob-odds.html#topics",
    "title": "Probabilites, odds, odds ratios",
    "section": "Topics",
    "text": "Topics\n\nLogistic regression for binary response variable\nRelationship between odds and probabilities\nOdds ratios and connection to logistic model"
  },
  {
    "objectID": "slides/18-prob-odds.html#computational-setup",
    "href": "slides/18-prob-odds.html#computational-setup",
    "title": "Probabilites, odds, odds ratios",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data) #contains data set\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/18-prob-odds.html#types-of-outcome-variables",
    "href": "slides/18-prob-odds.html#types-of-outcome-variables",
    "title": "Probabilites, odds, odds ratios",
    "section": "Types of outcome variables",
    "text": "Types of outcome variables\nQuantitative outcome variable:\n\nSales price of a house in Duke Forest\nModel: Expected sales price given the number of bedrooms, lot size, etc.\n\n\nCategorical outcome variable:\n\nIndicator of being high risk of getting coronary heart disease in the next 10 years\nModel: Probability an adult is high risk of heart disease in the next 10 years given their age, total cholesterol, etc."
  },
  {
    "objectID": "slides/18-prob-odds.html#models-for-categorical-outcomes",
    "href": "slides/18-prob-odds.html#models-for-categorical-outcomes",
    "title": "Probabilites, odds, odds ratios",
    "section": "Models for categorical outcomes",
    "text": "Models for categorical outcomes\n\n\nLogistic regression\n2 Outcomes\n1: Yes, 0: No\n\nMultinomial logistic regression (in STA 310)\n3+ Outcomes\n1: Democrat, 2: Republican, 3: Independent"
  },
  {
    "objectID": "slides/18-prob-odds.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/18-prob-odds.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Probabilites, odds, odds ratios",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 6\n     Age Sleep7 Sleep           SmokeLife SmokeDaily MarijuaEver\n   &lt;int&gt;  &lt;int&gt; &lt;fct&gt;           &lt;fct&gt;     &lt;fct&gt;            &lt;int&gt;\n 1    16      1 8 hours         Yes       Yes                  1\n 2    17      0 5 hours         Yes       Yes                  1\n 3    18      0 5 hours         Yes       Yes                  1\n 4    17      1 7 hours         Yes       No                   1\n 5    15      0 4 or less hours No        No                   0\n 6    17      0 6 hours         No        No                   0\n 7    17      1 7 hours         No        No                   0\n 8    16      1 8 hours         Yes       No                   0\n 9    16      1 8 hours         No        No                   0\n10    18      0 4 or less hours Yes       Yes                  1\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/18-prob-odds.html#plot-the-data",
    "href": "slides/18-prob-odds.html#plot-the-data",
    "title": "Probabilites, odds, odds ratios",
    "section": "Plot the data",
    "text": "Plot the data\n\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")"
  },
  {
    "objectID": "slides/18-prob-odds.html#lets-fit-a-linear-regression-model",
    "href": "slides/18-prob-odds.html#lets-fit-a-linear-regression-model",
    "title": "Probabilites, odds, odds ratios",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/18-prob-odds.html#lets-use-proportions",
    "href": "slides/18-prob-odds.html#lets-use-proportions",
    "title": "Probabilites, odds, odds ratios",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/18-prob-odds.html#what-happens-if-we-zoom-out",
    "href": "slides/18-prob-odds.html#what-happens-if-we-zoom-out",
    "title": "Probabilites, odds, odds ratios",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/18-prob-odds.html#lets-try-another-model",
    "href": "slides/18-prob-odds.html#lets-try-another-model",
    "title": "Probabilites, odds, odds ratios",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/18-prob-odds.html#the-code",
    "href": "slides/18-prob-odds.html#the-code",
    "title": "Probabilites, odds, odds ratios",
    "section": "The code",
    "text": "The code\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)"
  },
  {
    "objectID": "slides/18-prob-odds.html#different-types-of-models",
    "href": "slides/18-prob-odds.html#different-types-of-models",
    "title": "Probabilites, odds, odds ratios",
    "section": "Different types of models",
    "text": "Different types of models\n\n\n\n\n\n\n\n\nMethod\nOutcome\nModel\n\n\n\n\nLinear regression\nQuantitative\n\\(y_i = \\beta_0 + \\beta_1~ x_i\\)\n\n\nLinear regression (transform Y)\nQuantitative\n\\(\\log(y_i) = \\beta_0 + \\beta_1~ x_i\\)\n\n\nLogistic regression\nBinary\n\\(\\log\\big(\\frac{\\pi_i}{1-\\pi_i}\\big) = \\beta_0 + \\beta_1 ~ x_i\\)"
  },
  {
    "objectID": "slides/18-prob-odds.html#linear-vs.-logistic-regression",
    "href": "slides/18-prob-odds.html#linear-vs.-logistic-regression",
    "title": "Probabilites, odds, odds ratios",
    "section": "Linear vs. logistic regression",
    "text": "Linear vs. logistic regression\n\nState whether a linear regression model or logistic regression model is more appropriate for each scenario.\n\nUse age and education to predict if a randomly selected person will vote in the next election.\nUse budget and run time (in minutes) to predict a movie’s total revenue.\nUse age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year."
  },
  {
    "objectID": "slides/18-prob-odds.html#binary-response-variable",
    "href": "slides/18-prob-odds.html#binary-response-variable",
    "title": "Probabilites, odds, odds ratios",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes}, 0: \\text{ no}\\)\n\\(\\pi\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{\\pi}{1-\\pi}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\): log odds\nGo from \\(\\pi\\) to \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/18-prob-odds.html#odds",
    "href": "slides/18-prob-odds.html#odds",
    "title": "Probabilites, odds, odds ratios",
    "section": "Odds",
    "text": "Odds\n\nSuppose there is a 70% chance it will rain tomorrow\n\nProbability it will rain is \\(\\mathbf{p = 0.7}\\)\nProbability it won’t rain is \\(\\mathbf{1 - p = 0.3}\\)\nOdds it will rain are 7 to 3, 7:3, \\(\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}\\)"
  },
  {
    "objectID": "slides/18-prob-odds.html#are-teenagers-getting-enough-sleep",
    "href": "slides/18-prob-odds.html#are-teenagers-getting-enough-sleep",
    "title": "Probabilites, odds, odds ratios",
    "section": "Are teenagers getting enough sleep?",
    "text": "Are teenagers getting enough sleep?\n\nsleep |&gt;\n  count(Sleep7) |&gt;\n  mutate(p = round(n / sum(n), 3))\n\n# A tibble: 2 × 3\n  Sleep7     n     p\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1      0   150 0.336\n2      1   296 0.664\n\n\n\n\\(P(\\text{7+ hours of sleep}) = P(Y = 1) = p = 0.664\\)\n\n\n\\(P(\\text{&lt; 7 hours of sleep}) = P(Y = 0) = 1 - p = 0.336\\)\n\n\n\\(P(\\text{odds of 7+ hours of sleep}) = \\frac{0.664}{0.336} = 1.976\\)"
  },
  {
    "objectID": "slides/18-prob-odds.html#from-odds-to-probabilities",
    "href": "slides/18-prob-odds.html#from-odds-to-probabilities",
    "title": "Probabilites, odds, odds ratios",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nodds\n\\[\\omega = \\frac{\\pi}{1-\\pi}\\]\n\nprobability\n\\[\\pi = \\frac{\\omega}{1 + \\omega}\\]"
  },
  {
    "objectID": "slides/18-prob-odds.html#risk-of-coronary-heart-disease",
    "href": "slides/18-prob-odds.html#risk-of-coronary-heart-disease",
    "title": "Probabilites, odds, odds ratios",
    "section": "Risk of coronary heart disease",
    "text": "Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease. These notes focus on the following variables:\n\nhigh_risk:\n\n1: High risk of having heart disease in next 10 years\n0: Not high risk of having heart disease in next 10 year\n\neducation: 1 = Some High School, 2 = High School or GED, 3 = Some College or Vocational School, 4 = College"
  },
  {
    "objectID": "slides/18-prob-odds.html#high-risk-vs.-education",
    "href": "slides/18-prob-odds.html#high-risk-vs.-education",
    "title": "Probabilites, odds, odds ratios",
    "section": "High risk vs. education",
    "text": "High risk vs. education\n\n\n\n\n\nEducation\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403"
  },
  {
    "objectID": "slides/18-prob-odds.html#compare-the-odds-for-two-groups",
    "href": "slides/18-prob-odds.html#compare-the-odds-for-two-groups",
    "title": "Probabilites, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nEducation\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403\n\n\n\n\n\n\n\nWe want to compare the risk of heart disease for those with a High School diploma/GED and those with a college degree.\nWe’ll use the odds to compare the two groups\n\n\\[\n\\text{odds} = \\frac{P(\\text{success})}{P(\\text{failure})} = \\frac{\\text{# of successes}}{\\text{# of failures}}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds.html#compare-the-odds-for-two-groups-1",
    "href": "slides/18-prob-odds.html#compare-the-odds-for-two-groups-1",
    "title": "Probabilites, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nEducation\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403\n\n\n\n\n\n\nOdds of being high risk for the High school or GED group: \\(\\frac{147}{1106} = 0.133\\)\nOdds of being high risk for the College group: \\(\\frac{70}{403} = 0.174\\)\nBased on this, we see those with a college degree had higher odds of being high risk for heart disease than those with a high school diploma or GED."
  },
  {
    "objectID": "slides/18-prob-odds.html#odds-ratio-or",
    "href": "slides/18-prob-odds.html#odds-ratio-or",
    "title": "Probabilites, odds, odds ratios",
    "section": "Odds ratio (OR)",
    "text": "Odds ratio (OR)\n\n\n\n\n\nEducation\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403\n\n\n\n\n\nLet’s summarize the relationship between the two groups. To do so, we’ll use the odds ratio (OR).\n\\[\nOR = \\frac{\\text{odds}_1}{\\text{odds}_2} = \\frac{\\omega_1}{\\omega_2}\n\\]"
  },
  {
    "objectID": "slides/18-prob-odds.html#or-college-vs.-high-school-or-ged",
    "href": "slides/18-prob-odds.html#or-college-vs.-high-school-or-ged",
    "title": "Probabilites, odds, odds ratios",
    "section": "OR: College vs. High school or GED",
    "text": "OR: College vs. High school or GED\n\n\n\n\n\nEducation\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403\n\n\n\n\n\n\\[OR = \\frac{\\text{odds}_{College}}{\\text{odds}_{HS}} = \\frac{0.174}{0.133} = \\mathbf{1.308}\\]\n\nThe odds of being high risk for heart disease are 1.30 times higher for those with a college degree than those with a high school diploma or GED."
  },
  {
    "objectID": "slides/18-prob-odds.html#or-college-vs.-some-high-school",
    "href": "slides/18-prob-odds.html#or-college-vs.-some-high-school",
    "title": "Probabilites, odds, odds ratios",
    "section": "OR: College vs. Some high school",
    "text": "OR: College vs. Some high school\n\n\n\n\n\nEducation\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403\n\n\n\n\n\n\\[OR = \\frac{\\text{odds}_{College}}{\\text{odds}_{Some HS}} = \\frac{70/403}{323/1397} = 0.751\\]\n\nThe odds of being high risk for having heart disease for those with a college degree are 0.751 times the odds of being high risk for heart disease for those with some high school."
  },
  {
    "objectID": "slides/18-prob-odds.html#more-natural-interpretation",
    "href": "slides/18-prob-odds.html#more-natural-interpretation",
    "title": "Probabilites, odds, odds ratios",
    "section": "More natural interpretation",
    "text": "More natural interpretation\n\nIt’s more natural to interpret the odds ratio with a statement with the odds ratio greater than 1.\nThe odds of being high risk for heart disease are 1.33 times higher for those with some high school than those with a college degree."
  },
  {
    "objectID": "slides/18-prob-odds.html#making-the-table-1",
    "href": "slides/18-prob-odds.html#making-the-table-1",
    "title": "Probabilites, odds, odds ratios",
    "section": "Making the table 1",
    "text": "Making the table 1\nFirst, rename the levels of the categorical variables:\n\nheart_disease &lt;- heart_disease |&gt;\n  mutate(\n    high_risk_names = if_else(high_risk == \"1\", \"High risk\", \"Not high risk\"),\n    education_names = case_when(\n      education == \"1\" ~ \"Some high school\",\n      education == \"2\" ~ \"High school or GED\",\n      education == \"3\" ~ \"Some college or vocational school\",\n      education == \"4\" ~ \"College\"\n    ),\n    education_names = fct_relevel(education_names, \"Some high school\", \"High school or GED\", \"Some college or vocational school\", \"College\")\n  )"
  },
  {
    "objectID": "slides/18-prob-odds.html#making-the-table-2",
    "href": "slides/18-prob-odds.html#making-the-table-2",
    "title": "Probabilites, odds, odds ratios",
    "section": "Making the table 2",
    "text": "Making the table 2\nThen, make the table:\n\nheart_disease |&gt;\n  count(education_names, high_risk_names) |&gt;\n  pivot_wider(names_from = high_risk_names, values_from = n) |&gt;\n  kable(col.names = c(\"Education\", \"High risk\", \"Not high risk\"))"
  },
  {
    "objectID": "slides/18-prob-odds.html#deeper-look-into-the-code",
    "href": "slides/18-prob-odds.html#deeper-look-into-the-code",
    "title": "Probabilites, odds, odds ratios",
    "section": "Deeper look into the code",
    "text": "Deeper look into the code\n\nheart_disease |&gt;\n  count(education_names, high_risk_names)\n\n# A tibble: 8 × 3\n  education_names                   high_risk_names     n\n  &lt;fct&gt;                             &lt;chr&gt;           &lt;int&gt;\n1 Some high school                  High risk         323\n2 Some high school                  Not high risk    1397\n3 High school or GED                High risk         147\n4 High school or GED                Not high risk    1106\n5 Some college or vocational school High risk          88\n6 Some college or vocational school Not high risk     601\n7 College                           High risk          70\n8 College                           Not high risk     403"
  },
  {
    "objectID": "slides/18-prob-odds.html#deeper-look-into-the-code-1",
    "href": "slides/18-prob-odds.html#deeper-look-into-the-code-1",
    "title": "Probabilites, odds, odds ratios",
    "section": "Deeper look into the code",
    "text": "Deeper look into the code\n\nheart_disease |&gt;\n  count(education_names, high_risk_names) |&gt;\n  pivot_wider(names_from = high_risk_names, values_from = n)\n\n# A tibble: 4 × 3\n  education_names                   `High risk` `Not high risk`\n  &lt;fct&gt;                                   &lt;int&gt;           &lt;int&gt;\n1 Some high school                          323            1397\n2 High school or GED                        147            1106\n3 Some college or vocational school          88             601\n4 College                                    70             403"
  },
  {
    "objectID": "slides/18-prob-odds.html#deeper-look-into-the-code-2",
    "href": "slides/18-prob-odds.html#deeper-look-into-the-code-2",
    "title": "Probabilites, odds, odds ratios",
    "section": "Deeper look into the code",
    "text": "Deeper look into the code\n\nheart_disease |&gt;\n  count(education_names, high_risk_names) |&gt;\n  pivot_wider(names_from = high_risk_names, values_from = n) |&gt;\n  kable()\n\n\n\n\neducation_names\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403"
  },
  {
    "objectID": "slides/18-prob-odds.html#deeper-look-into-the-code-3",
    "href": "slides/18-prob-odds.html#deeper-look-into-the-code-3",
    "title": "Probabilites, odds, odds ratios",
    "section": "Deeper look into the code",
    "text": "Deeper look into the code\n\nheart_disease |&gt;\n  count(education_names, high_risk_names) |&gt;\n  pivot_wider(names_from = high_risk_names, values_from = n) |&gt;\n  kable(col.names = c(\"Education\", \"High risk\", \"Not high risk\"))\n\n\n\n\nEducation\nHigh risk\nNot high risk\n\n\n\n\nSome high school\n323\n1397\n\n\nHigh school or GED\n147\n1106\n\n\nSome college or vocational school\n88\n601\n\n\nCollege\n70\n403"
  },
  {
    "objectID": "slides/18-prob-odds.html#recap",
    "href": "slides/18-prob-odds.html#recap",
    "title": "Probabilites, odds, odds ratios",
    "section": "Recap",
    "text": "Recap\n\nIntroduced logistic regression for binary response variable\nShowed the relationship between odds and probabilities\nIntroduced odds ratios and their connection to logistic model\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#announcements",
    "href": "slides/05-slr-matrix-contd.html#announcements",
    "title": "SLR: Matrix representation",
    "section": "Announcements",
    "text": "Announcements\n\nLab 01 due on Thursday, September 12 at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + mark pages for each question\n\nHW 01 will be assigned on Thursday"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#topics",
    "href": "slides/05-slr-matrix-contd.html#topics",
    "title": "SLR: Matrix representation",
    "section": "Topics",
    "text": "Topics\n\nMatrix representation of simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#slr-in-matrix-form",
    "href": "slides/05-slr-matrix-contd.html#slr-in-matrix-form",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\nSuppose we have \\(n\\) observations, a quantitative response variable, and a single predictor\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_1 \\\\\n\\vdots &  \\vdots \\\\\n1 &  x_n\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\n\n\\(\\mathbf{y}\\): \\(n\\times 1\\) vector of responses\n\\(\\mathbf{X}\\): \\(n \\times 2\\) design matrix\n\\(\\boldsymbol{\\beta}\\): \\(2 \\times 1\\) vector of coefficients\n\\(\\boldsymbol{\\epsilon}\\): \\(n \\times 1\\) vector of error terms"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nGoal: Find \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimizes the sum of squared residuals \\[\n\\begin{aligned}\nSSR = \\sum_{i=1}^n e_i^2 = \\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-1",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-1",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\n\\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&\\class{fragment}{= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})}\\\\[10pt]\n&\\class{fragment}{=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}}\\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-2",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-2",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\n\\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-3",
    "href": "slides/05-slr-matrix-contd.html#minimize-sum-of-squared-residuals-3",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nThe estimate of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimizes SSR is the one such that\n\\[\n\\nabla_{\\boldsymbol{\\beta}} SSR = \\nabla_{\\boldsymbol{\\beta}}( \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}) = 0\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-operations",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-operations",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector operations",
    "text": "Side note: Vector operations\nLet \\(\\mathbf{x} = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\x_k\\end{bmatrix}\\)be a \\(k \\times 1\\) vector and \\(f(\\mathbf{x})\\) be a function of \\(\\mathbf{x}\\).\n\nThen \\(\\nabla_\\mathbf{x}f\\), the gradient of \\(f\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x}f = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_k}\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-operations-1",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-operations-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector operations",
    "text": "Side note: Vector operations\nThe Hessian matrix, \\(\\nabla_\\mathbf{x}^2f\\) is a \\(k \\times k\\) matrix of partial second derivatives\n\\[\n\\nabla_{\\mathbf{x}}^2f = \\begin{bmatrix} \\frac{\\partial^2f}{\\partial x_1^2} & \\frac{\\partial^2f}{\\partial x_1 \\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_1\\partial x_k} \\\\\n\\frac{\\partial^2f}{\\partial\\ x_2 \\partial x_1} & \\frac{\\partial^2f}{\\partial x_2^2} & \\dots & \\frac{\\partial^2f}{\\partial x_2 \\partial x_k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2f}{\\partial x_k\\partial x_1} & \\frac{\\partial^2f}{\\partial x_k\\partial x_2} & \\dots & \\frac{\\partial^2f}{\\partial x_k^2} \\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-operations-2",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-operations-2",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector operations",
    "text": "Side note: Vector operations\n\n\n\nProposition 1\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{z}\\) be a \\(k \\times 1\\) vector, such that \\(\\mathbf{z}\\) is not a function of \\(\\mathbf{x}\\) .\nThe gradient of \\(\\mathbf{x}^T\\mathbf{z}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{z} = \\mathbf{z}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-proposition-1",
    "href": "slides/05-slr-matrix-contd.html#side-note-proposition-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Proposition 1",
    "text": "Side note: Proposition 1\n\\[\n\\begin{aligned}\n\\mathbf{x}^T\\mathbf{z} &= \\class{fragment}{\\begin{bmatrix}x_1 & x_2 & \\dots &x_k\\end{bmatrix}\n\\begin{bmatrix}z_1 \\\\ z_2 \\\\ \\vdots \\\\z_k\\end{bmatrix}} \\\\[10pt]\n&\\class{fragment}{= x_1z_1 + x_2z_2 + \\dots + x_kz_k} \\\\\n&\\class{fragment}{= \\sum_{i=1}^k x_iz_i}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-proposition-1-1",
    "href": "slides/05-slr-matrix-contd.html#side-note-proposition-1-1",
    "title": "SLR: Matrix representation",
    "section": "Side note: Proposition 1",
    "text": "Side note: Proposition 1\n\\[\n\\nabla_\\mathbf{x}\\hspace{1mm}\\mathbf{x}^T\\mathbf{z} = \\class{fragment}{\\begin{bmatrix}\\frac{\\partial \\mathbf{x}^T\\mathbf{z}}{\\partial x_1} \\\\ \\frac{\\partial \\mathbf{x}^T\\mathbf{z}}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial \\mathbf{x}^T\\mathbf{z}}{\\partial x_k}\\end{bmatrix}}  \n= \\class{fragment}{\\begin{bmatrix}\\frac{\\partial}{\\partial x_1} (x_1z_1 + x_2z_2 + \\dots + x_kz_k) \\\\ \\frac{\\partial}{\\partial x_2} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\\\ \\vdots \\\\ \\frac{\\partial}{\\partial x_k} (x_1z_1 + x_2z_2 + \\dots + x_kz_k)\\end{bmatrix}}\n= \\class{fragment}{\\begin{bmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_k\\end{bmatrix} = \\mathbf{z}}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#side-note-vector-matrix-operations",
    "href": "slides/05-slr-matrix-contd.html#side-note-vector-matrix-operations",
    "title": "SLR: Matrix representation",
    "section": "Side note: Vector + matrix operations",
    "text": "Side note: Vector + matrix operations\n\n\n\nProposition 2\n\n\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\) .\nThen the gradient of \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = (\\mathbf{A}\\mathbf{x} + \\mathbf{A}^T \\mathbf{x}) = (\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\n\\]\nIf \\(\\mathbf{A}\\) is symmetric, then\n\\[\n(\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n\n\n\n\nProof in HW 01"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#find-the-least-squares-estimators",
    "href": "slides/05-slr-matrix-contd.html#find-the-least-squares-estimators",
    "title": "SLR: Matrix representation",
    "section": "Find the least squares estimators",
    "text": "Find the least squares estimators\n\\[\n\\begin{aligned}\n\\nabla_{\\boldsymbol{\\beta}} SSR &= \\nabla_{\\boldsymbol{\\beta}}( \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta})  \\\\[10pt]\n& \\class{fragment}{= \\nabla_\\boldsymbol{\\beta} \\hspace{1mm} \\mathbf{y}^T\\mathbf{y} - 2\\nabla_\\boldsymbol{\\beta} \\hspace{1mm} \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\nabla_\\boldsymbol{\\beta} \\hspace{1mm} \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}} \\\\[10pt]\n&\\class{fragment}{= 0 - 2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}}\\class{fragment}{=0} \\\\[10pt]\n&\\class{fragment}{\\Rightarrow \\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}} \\\\[10pt]\n&\\class{fragment}{\\Rightarrow   (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}} \\\\[10pt]\n&\\class{fragment}{\\color{#993399}{\\Rightarrow \\hat{\\boldsymbol{\\beta}} =  (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#did-we-find-a-minimum",
    "href": "slides/05-slr-matrix-contd.html#did-we-find-a-minimum",
    "title": "SLR: Matrix representation",
    "section": "Did we find a minimum?",
    "text": "Did we find a minimum?\n\\[\n\\begin{aligned}\n\\nabla^2_{\\boldsymbol{\\beta}} SSR &= \\nabla_{\\boldsymbol{\\beta}} (-2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&\\class{fragment}{=-2\\nabla_{\\boldsymbol{\\beta}}\\mathbf{X}^T\\mathbf{y} + 2\\nabla_{\\boldsymbol{\\beta}}(\\mathbf{X}^T\\mathbf{X}\\mathbf{\\beta})} \\\\[10pt]\n&\\class{fragment}{\\propto \\mathbf{X}^T\\mathbf{X}}\\class{fragment}{ &gt; 0}\n\\end{aligned}\n\\]\n\nShow the details in HW 01"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#predicted-fitted-values",
    "href": "slides/05-slr-matrix-contd.html#predicted-fitted-values",
    "title": "SLR: Matrix representation",
    "section": "Predicted (fitted) values",
    "text": "Predicted (fitted) values\nNow that we have \\(\\hat{\\boldsymbol{\\beta}}\\), let’s predict values of \\(\\mathbf{y}\\) using the model\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\underbrace{\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T}_{\\mathbf{H}}\\mathbf{y} = \\mathbf{H}\\mathbf{y}\n\\]\n\nHat matrix: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\)\n\n\n\n\\(\\mathbf{H}\\) is an \\(n\\times n\\) matrix\nMaps vector of observed values \\(\\mathbf{y}\\) to a vector of fitted values \\(\\hat{\\mathbf{y}}\\)\nIt is only a function of \\(\\mathbf{X}\\) not \\(\\mathbf{y}\\)"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#residuals",
    "href": "slides/05-slr-matrix-contd.html#residuals",
    "title": "SLR: Matrix representation",
    "section": "Residuals",
    "text": "Residuals\nRecall that the residuals are the difference between the observed and predicted values\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{y} - \\hat{\\mathbf{y}}\\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}} \\\\[10pt]\n&\\class{fragment}{ = \\mathbf{y} - \\mathbf{H}\\mathbf{y}} \\\\[20pt]\n\\class{fragment}{\\color{#993399}{\\mathbf{e}}} &\\class{fragment}{\\color{#993399}{=(\\mathbf{I} - \\mathbf{H})\\mathbf{y}}} \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-slr-matrix-contd.html#recap",
    "href": "slides/05-slr-matrix-contd.html#recap",
    "title": "SLR: Matrix representation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced matrix representation for simple linear regression\n\nModel from\nLeast square estimate\nPredicted (fitted) values\nResiduals\n\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#announcements",
    "href": "slides/06-mlr-pt2.html#announcements",
    "title": "Multiple linear regression (MLR)",
    "section": "Announcements",
    "text": "Announcements\n\nLab 01 due on TODAY at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + mark pages for each question\n\nHW 01 due Thursday, September 19 at 11:59pm\n\nWill be released after class\n\nTeam labs start on Monday"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#homework",
    "href": "slides/06-mlr-pt2.html#homework",
    "title": "Multiple linear regression (MLR)",
    "section": "Homework",
    "text": "Homework\nHomework will generally be split into two sections:\n\n1️⃣ Conceptual exercises\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#homework-1",
    "href": "slides/06-mlr-pt2.html#homework-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Homework",
    "text": "Homework\n2️⃣ Applied exercises\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#topics",
    "href": "slides/06-mlr-pt2.html#topics",
    "title": "Multiple linear regression (MLR)",
    "section": "Topics",
    "text": "Topics\n\nCategorical predictors and interaction terms\nAssess model fit using RSME and \\(R^2\\)\nCompare models using \\(Adj. R^2\\)\nIntroduce LaTex"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#computing-setup",
    "href": "slides/06-mlr-pt2.html#computing-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#data-peer-to-peer-lender",
    "href": "slides/06-mlr-pt2.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#variables",
    "href": "slides/06-mlr-pt2.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#response-vs.-predictors",
    "href": "slides/06-mlr-pt2.html#response-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\nGoal: Use these predictors in a single model to understand variability in interest rate."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#model-fit-in-r",
    "href": "slides/06-mlr-pt2.html#model-fit-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/06-mlr-pt2.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nHow might we include a categorical predictor with \\(k\\) levels in the design matrix, \\(\\mathbf{X}\\) ?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables",
    "href": "slides/06-mlr-pt2.html#indicator-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables",
    "text": "Indicator variables\nSuppose we want to predict the amount of sleep a Duke student gets based on whether they are in Pratt (Pratt Yes/ No are the only two options). Consider the model\n\\[\nSleep_i = \\beta_0 + \\beta_1\\mathbf{1}(Pratt_i = \\texttt{Yes}) + \\beta_2\\mathbf{1}(Pratt_i = \\texttt{No})\n\\]\n\n\nWrite out the design matrix for this hypothesized linear model.\nDemonstrate that the design matrix is not of full column rank (that is, affirmatively provide one of the columns in terms of the others).\nUse this intuition to explain why when we include categorical predictors, we cannot include both indicators for every level of the variable and an intercept."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-1",
    "href": "slides/06-mlr-pt2.html#indicator-variables-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(k\\) levels\nWe can make \\(k\\) indicator variables from the data - one indicator for each level\nAn indicator (dummy) variable takes values 1 or 0\n\n1 if the observation belongs to that level\n0 if the observation does not belong to that level"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-for-verified_income",
    "href": "slides/06-mlr-pt2.html#indicator-variables-for-verified_income",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables for verified_income",
    "text": "Indicator variables for verified_income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(\n    not_verified = if_else(verified_income == \"Not Verified\", 1, 0),\n    source_verified = if_else(verified_income == \"Source Verified\", 1, 0),\n    verified = if_else(verified_income == \"Verified\", 1, 0)\n  )\n\n\n\n\n# A tibble: 3 × 4\n  verified_income not_verified source_verified verified\n  &lt;fct&gt;                  &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;\n1 Not Verified               1               0        0\n2 Verified                   0               0        1\n3 Source Verified            0               1        0"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#indicator-variables-in-the-model",
    "href": "slides/06-mlr-pt2.html#indicator-variables-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables in the model",
    "text": "Indicator variables in the model\n\nWe will use \\(k-1\\) of the indicator variables in the model.\nThe baseline is the category that doesn’t have a term in the model.\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant.\n\n\n\nloan50 |&gt;\n  select(verified_income, source_verified, verified) |&gt;\n  slice(1, 3, 6)\n\n# A tibble: 3 × 3\n  verified_income source_verified verified\n  &lt;fct&gt;                     &lt;dbl&gt;    &lt;dbl&gt;\n1 Not Verified                  0        0\n2 Verified                      0        1\n3 Source Verified               1        0\n\n\n\nTake a look at the design matrix in AE 02"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interpreting-verified_income",
    "href": "slides/06-mlr-pt2.html#interpreting-verified_income",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\n\n\nThe baseline level is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant.\n\n\n\n\n\nWhat is the expected interest rate for someone whose income is Verified, who has a debt-to-income ratio of 0 and annual income of $0?"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interaction-terms-1",
    "href": "slides/06-mlr-pt2.html#interaction-terms-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interest-rate-vs.-annual-income",
    "href": "slides/06-mlr-pt2.html#interest-rate-vs.-annual-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Interest rate vs. annual income",
    "text": "Interest rate vs. annual income\nThe lines are not parallel indicating there is a potential interaction effect. The slope of annual income differs based on the income verification."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interaction-term-in-model",
    "href": "slides/06-mlr-pt2.html#interaction-term-in-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_fit_2 &lt;- lm(interest_rate ~ debt_to_income + verified_income + annual_income_th + verified_income * annual_income_th,\n      data = loan50)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.560\n2.034\n4.700\n0.000\n\n\ndebt_to_income\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n3.577\n2.539\n1.409\n0.166\n\n\nverified_incomeVerified\n9.923\n3.654\n2.716\n0.009\n\n\nannual_income_th\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th\n-0.032\n0.033\n-0.979\n0.333"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#interpreting-interaction-terms",
    "href": "slides/06-mlr-pt2.html#interpreting-interaction-terms",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#rmse-r2",
    "href": "slides/06-mlr-pt2.html#rmse-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "RMSE & \\(R^2\\)",
    "text": "RMSE & \\(R^2\\)\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#comparing-models",
    "href": "slides/06-mlr-pt2.html#comparing-models",
    "title": "Multiple linear regression (MLR)",
    "section": "Comparing models",
    "text": "Comparing models\n\n\nWhen comparing models, do we prefer the model with the lower or higher RMSE?\nThough we use \\(R^2\\) to assess the model fit, it is generally unreliable for comparing models with different number of predictors. Why?\n\n\\(R^2\\) will stay the same or increase as we add more variables to the model . Let’s show why this is true.\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#adjusted-r2",
    "href": "slides/06-mlr-pt2.html#adjusted-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#r2-and-adjusted-r2",
    "href": "slides/06-mlr-pt2.html#r2-and-adjusted-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n\n\\[R^2_{adj} = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#using-r2-and-adjusted-r2",
    "href": "slides/06-mlr-pt2.html#using-r2-and-adjusted-r2",
    "title": "Multiple linear regression (MLR)",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables\n\n\n\n📋 https://sta221-fa24.netlify.app/ae/ae-02-mlr"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#latex-in-this-class",
    "href": "slides/06-mlr-pt2.html#latex-in-this-class",
    "title": "Multiple linear regression (MLR)",
    "section": "Latex in this class",
    "text": "Latex in this class\nFor this class you will need to be able to…\n\nProperly write mathematical symbols, e.g., \\(\\beta_1\\) not B1, \\(R^2\\) not R2\nWrite basic regression equations, e.g., \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\nWrite matrix equations: \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\nWrite hypotheses (we’ll start this next week), e.g., \\(H_0: \\beta = 0\\)\n\nYou are welcome to but not required to write math proofs using LaTex."
  },
  {
    "objectID": "slides/06-mlr-pt2.html#recap",
    "href": "slides/06-mlr-pt2.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nInterpreted categorical predictors and interaction terms\nAssessed model fit using RSME and \\(R^2\\)\nCompared models using \\(Adj. R^2\\)\nIntroduced LaTex"
  },
  {
    "objectID": "slides/06-mlr-pt2.html#next-class",
    "href": "slides/06-mlr-pt2.html#next-class",
    "title": "Multiple linear regression (MLR)",
    "section": "Next class",
    "text": "Next class\n\nGeometric interpretation\nInference for regression\nSee Sep 17 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/19-logistic-regression.html#announcements",
    "href": "slides/19-logistic-regression.html#announcements",
    "title": "Logistic Regression",
    "section": "Announcements",
    "text": "Announcements\n\nLab 05 due TODAY 11:59pm\nMonday, November 11: Project presentations\nLooking ahead\n\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/19-logistic-regression.html#topics",
    "href": "slides/19-logistic-regression.html#topics",
    "title": "Logistic Regression",
    "section": "Topics",
    "text": "Topics\n\nLogistic regression for binary response variable\nUse logistic regression model to calculate predicted odds and probabilities\nInterpret the coefficients of a logistic regression model with\n\na single categorical predictor\na single quantitative predictor\nmultiple predictors"
  },
  {
    "objectID": "slides/19-logistic-regression.html#computational-setup",
    "href": "slides/19-logistic-regression.html#computational-setup",
    "title": "Logistic Regression",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data) #contains data set\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/19-logistic-regression.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/19-logistic-regression.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Logistic Regression",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 6\n     Age Sleep7 Sleep           SmokeLife SmokeDaily MarijuaEver\n   &lt;int&gt;  &lt;int&gt; &lt;fct&gt;           &lt;fct&gt;     &lt;fct&gt;            &lt;int&gt;\n 1    16      1 8 hours         Yes       Yes                  1\n 2    17      0 5 hours         Yes       Yes                  1\n 3    18      0 5 hours         Yes       Yes                  1\n 4    17      1 7 hours         Yes       No                   1\n 5    15      0 4 or less hours No        No                   0\n 6    17      0 6 hours         No        No                   0\n 7    17      1 7 hours         No        No                   0\n 8    16      1 8 hours         Yes       No                   0\n 9    16      1 8 hours         No        No                   0\n10    18      0 4 or less hours Yes       Yes                  1\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-fit-a-linear-regression-model",
    "href": "slides/19-logistic-regression.html#lets-fit-a-linear-regression-model",
    "title": "Logistic Regression",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-use-proportions",
    "href": "slides/19-logistic-regression.html#lets-use-proportions",
    "title": "Logistic Regression",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/19-logistic-regression.html#what-happens-if-we-zoom-out",
    "href": "slides/19-logistic-regression.html#what-happens-if-we-zoom-out",
    "title": "Logistic Regression",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-try-another-model",
    "href": "slides/19-logistic-regression.html#lets-try-another-model",
    "title": "Logistic Regression",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/19-logistic-regression.html#binary-response-variable",
    "href": "slides/19-logistic-regression.html#binary-response-variable",
    "title": "Logistic Regression",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes}, 0: \\text{ no}\\)\n\\(\\pi\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{\\pi}{1-\\pi}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\): log odds\nGo from \\(\\pi\\) to \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/19-logistic-regression.html#from-odds-to-probabilities",
    "href": "slides/19-logistic-regression.html#from-odds-to-probabilities",
    "title": "Logistic Regression",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\nLogistic model: log odds = \\(\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\mathbf{X}\\boldsymbol{\\beta}\\)\nOdds = \\(\\exp\\big\\{\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\big\\} = \\frac{\\pi}{1-\\pi}\\)\nCombining (1) and (2) with what we saw earlier\n\n\n\\[\\text{probability} = \\pi = \\frac{\\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#sigmoid-function",
    "href": "slides/19-logistic-regression.html#sigmoid-function",
    "title": "Logistic Regression",
    "section": "Sigmoid Function",
    "text": "Sigmoid Function\nWe call this function relating the probability to the predictors a sigmoid function, \\[\n\\sigma(x) = \\frac{\\exp\\{x\\}}{1 + \\exp\\{x\\}}= \\frac{1}{1+\\text{exp}\\{-x\\}}.\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#sigmoid-function-1",
    "href": "slides/19-logistic-regression.html#sigmoid-function-1",
    "title": "Logistic Regression",
    "section": "Sigmoid Function",
    "text": "Sigmoid Function"
  },
  {
    "objectID": "slides/19-logistic-regression.html#logistic-regression-model",
    "href": "slides/19-logistic-regression.html#logistic-regression-model",
    "title": "Logistic Regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\nLogit form: \\[\\text{logit}(\\pi) = \\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\mathbf{X}\\boldsymbol{\\beta}\\]\n\nProbability form:\n\\[\n\\pi = \\frac{\\exp\\{\\mathbf{X}\\boldsymbol{\\beta}\\}}{1 + \\exp\\{\\mathbf{X}\\boldsymbol{\\beta} \\}}  \n\\]\n\n\nLogit and sigmoid link functions are inverses of each other.\n\n\n\n\n\n\nNote\n\n\nMore on link functions later, if time permits"
  },
  {
    "objectID": "slides/19-logistic-regression.html#goal",
    "href": "slides/19-logistic-regression.html#goal",
    "title": "Logistic Regression",
    "section": "Goal",
    "text": "Goal\nWe want to use our data to estimate \\(\\boldsymbol{\\beta}\\) (find \\(\\hat{\\boldsymbol{\\beta}}\\)) and obtain the model:\n\\[\n\\hat\\pi = \\frac{\\exp\\{\\mathbf{X}\\hat{\\boldsymbol\\beta}\\}}{ 1 + \\exp\\{\\mathbf{X}\\hat{\\boldsymbol\\beta}\\}}\n\\]\nIn this modeling scheme, one typically finds \\(\\hat{\\boldsymbol{\\beta}}\\) by maximizing the likelihood function."
  },
  {
    "objectID": "slides/19-logistic-regression.html#linear-regression-vs.-logistic-regression",
    "href": "slides/19-logistic-regression.html#linear-regression-vs.-logistic-regression",
    "title": "Logistic Regression",
    "section": "Linear Regression vs. Logistic Regression",
    "text": "Linear Regression vs. Logistic Regression\n\n\nLinear regression:\n\nQuantitative outcome\n\\(y_i = x_i^\\top \\boldsymbol{\\beta} + \\epsilon_i\\)\n\\(E[Y_i] = x_i^\\top \\boldsymbol{\\beta}\\)\nEstimate \\(\\boldsymbol\\beta\\)\nUse \\(\\hat{\\boldsymbol\\beta}\\) to predict \\(\\hat y_i\\)\n\n\nLogistic regression:\n\nBinary outcome\n\\(\\log\\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = x_i^\\top \\boldsymbol{\\beta}\\)\n\\(E[Y_i] = \\pi_i\\)\nEstimate \\(\\boldsymbol\\beta\\)\nUse \\(\\hat{\\boldsymbol\\beta}\\) to predict \\(\\hat \\pi_i\\)"
  },
  {
    "objectID": "slides/19-logistic-regression.html#likelihood-function-for-boldsymbolbeta",
    "href": "slides/19-logistic-regression.html#likelihood-function-for-boldsymbolbeta",
    "title": "Logistic Regression",
    "section": "Likelihood function for \\(\\boldsymbol{\\beta}\\)",
    "text": "Likelihood function for \\(\\boldsymbol{\\beta}\\)\n\n\\(P(Y_i = 1) = \\pi_i\\). What likelihood function should we use?\n\n\n\n\\(f(y_i | x_i, \\boldsymbol{\\beta}) = \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}\\)\n\n\n\n\n\\(Y_i\\)’s are independent, so\n\n\\[f(y_1, \\dots, y_n) = \\prod_{i=1}^n \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#likelihood",
    "href": "slides/19-logistic-regression.html#likelihood",
    "title": "Logistic Regression",
    "section": "Likelihood",
    "text": "Likelihood\nThe likelihood function for \\(\\boldsymbol\\beta\\) is\n\\[\n\\begin{aligned}\nL&(\\boldsymbol\\beta| x_1, \\dots, x_n, y_1, \\dots, y_n) \\\\[5pt]\n&=  \\prod_{i=1}^n \\pi_i^{y_i} (1-\\pi_i)^{1-y_i} \\\\[10pt]\n\\end{aligned}\n\\] \n\nWe will use the log-likelihood function to find the MLEs"
  },
  {
    "objectID": "slides/19-logistic-regression.html#log-likelihood",
    "href": "slides/19-logistic-regression.html#log-likelihood",
    "title": "Logistic Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nThe log-likelihood function for \\(\\boldsymbol\\beta\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\boldsymbol\\beta | x_1, \\dots, x_n, y_1, \\dots, y_n)\n  \\\\[8pt]\n& = \\sum_{i=1}^n\\log(\\pi_i^{y_i}(1-\\pi_i)^{1-y_i})\\\\\n&= \\sum_{i=1}^n\\left(y_i\\log (\\pi_i) + (1-y_i)\\log(1-\\pi_i)\\right)\\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#log-likelihood-1",
    "href": "slides/19-logistic-regression.html#log-likelihood-1",
    "title": "Logistic Regression",
    "section": "Log-likelihood",
    "text": "Log-likelihood\nPlugging in \\(\\pi_i = \\frac{\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}{1+\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}\\) and simplifying, we get:\n\\[\n\\begin{aligned}\\log &L(\\boldsymbol\\beta | x_1, \\dots, x_n, y_1, \\dots, y_n) \\\\\n&= \\sum_{i=1}^n y_i x_i^\\top \\boldsymbol\\beta - \\sum_{i=1}^n \\log(1+ \\exp\\{x_i^\\top \\beta\\})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#finding-the-mle",
    "href": "slides/19-logistic-regression.html#finding-the-mle",
    "title": "Logistic Regression",
    "section": "Finding the MLE",
    "text": "Finding the MLE\n\nTaking the derivative:\n\n\\[\n\\begin{aligned}\n\\frac{\\partial \\log L}{\\partial \\boldsymbol\\beta} =\\sum_{i=1}^n y_i x_i^\\top\n&- \\sum_{i=1}^n \\frac{\\exp\\{x_i^\\top \\boldsymbol\\beta\\} x_i^\\top}{1+\\exp\\{x_i^\\top \\boldsymbol\\beta\\}}\n\\end{aligned}\n\\]\n\n\nIf we set this to zero, there is no closed form solution.\n\n\n\n\nR uses numerical approximation to find the MLE."
  },
  {
    "objectID": "slides/19-logistic-regression.html#risk-of-coronary-heart-disease",
    "href": "slides/19-logistic-regression.html#risk-of-coronary-heart-disease",
    "title": "Logistic Regression",
    "section": "Risk of coronary heart disease",
    "text": "Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk: 1 = High risk of having heart disease in next 10 years, 0 = Not high risk of having heart disease in next 10 years\nage: Age at exam time (in years)\neducation: 1 = Some High School, 2 = High School or GED, 3 = Some College or Vocational School, 4 = College"
  },
  {
    "objectID": "slides/19-logistic-regression.html#data-heart_disease",
    "href": "slides/19-logistic-regression.html#data-heart_disease",
    "title": "Logistic Regression",
    "section": "Data: heart_disease",
    "text": "Data: heart_disease\n\n\n# A tibble: 4,135 × 3\n     age education high_risk\n   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;    \n 1    39 4         0        \n 2    46 2         0        \n 3    48 1         0        \n 4    61 3         1        \n 5    46 3         0        \n 6    43 2         0        \n 7    63 1         1        \n 8    45 2         0        \n 9    52 1         0        \n10    43 1         0        \n# ℹ 4,125 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression.html#high-risk-vs.-age",
    "href": "slides/19-logistic-regression.html#high-risk-vs.-age",
    "title": "Logistic Regression",
    "section": "High risk vs. age",
    "text": "High risk vs. age\n\nggplot(heart_disease, aes(x = high_risk, y = age)) +\n  geom_boxplot(fill = \"steelblue\") +\n  labs(x = \"High risk - 1: yes, 0: no\",\n       y = \"Age\", \n       title = \"Age vs. High risk of heart disease\")"
  },
  {
    "objectID": "slides/19-logistic-regression.html#lets-fit-the-model",
    "href": "slides/19-logistic-regression.html#lets-fit-the-model",
    "title": "Logistic Regression",
    "section": "Let’s fit the model",
    "text": "Let’s fit the model\n\n\nheart_edu_age_fit &lt;- glm(high_risk ~ age + education, \n                         data  = heart_disease, \n                         family = \"binomial\")\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\Big) =& -5.385 + 0.073 \\times \\text{age} - 0.242\\times \\text{education}_2 \\\\\n&- 0.235\\times\\text{education}_3 - 0.020 \\times\\text{education}_4\n\\end{aligned}\n\\] where \\(\\hat{\\pi}\\) is the predicted probability of being high risk of having heart disease in the next 10 years"
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of log-odds",
    "text": "Interpretation in terms of log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\neducation4: The log-odds of being high risk for heart disease are expected to be 0.020 less for those with a college degree compared to those with some high school, holding age constant.\n\n\n\n\n\n\n\nWarning\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds-1",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-log-odds-1",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of log-odds",
    "text": "Interpretation in terms of log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\nage: For each additional year in age, the log-odds of being high risk for heart disease are expected to increase by 0.073, holding education level constant.\n\n\n\n\n\n\n\nWarning\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of odds",
    "text": "Interpretation in terms of odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\neducation4: The odds of being high risk for heart disease for those with a college degree are expected to be 0.98 (exp{-0.020}) times the odds for those with some high school, holding age constant.\n\n\n\n\n\n\nNote\n\n\nIn logistic regression with 2+ predictors, \\(exp\\{\\hat{\\beta}_j\\}\\) is often called the adjusted odds ratio (AOR)."
  },
  {
    "objectID": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds-1",
    "href": "slides/19-logistic-regression.html#interpretation-in-terms-of-odds-1",
    "title": "Logistic Regression",
    "section": "Interpretation in terms of odds",
    "text": "Interpretation in terms of odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-5.385\n0.308\n-17.507\n0.000\n\n\nage\n0.073\n0.005\n13.385\n0.000\n\n\neducation2\n-0.242\n0.112\n-2.162\n0.031\n\n\neducation3\n-0.235\n0.134\n-1.761\n0.078\n\n\neducation4\n-0.020\n0.148\n-0.136\n0.892\n\n\n\n\n\n\nage: For each additional year in age, the odds being high risk for heart disease are expected to multiply by a factor of 1.08 (exp(0.073)), holding education level constant.\nAlternate interpretation: For each additional year in age, the odds of being high risk for heart disease are expected to increase by 8%.\n\n\n\n\n\n\nNote\n\n\nIn logistic regression with 2+ predictors, \\(exp\\{\\hat{\\beta}_j\\}\\) is often called the adjusted odds ratio (AOR)."
  },
  {
    "objectID": "slides/19-logistic-regression.html#introduction-to-glms",
    "href": "slides/19-logistic-regression.html#introduction-to-glms",
    "title": "Logistic Regression",
    "section": "Introduction to GLMs",
    "text": "Introduction to GLMs\n\n\nWider class of models.\nResponse variable does not have to be continuous and/or normal.\nVariance does not have to be constant\nStill need to specify distribution of outcome variable (randomness).\nDoes not require a linear relationship between response and explanatory variable. Instead, assumes linear relationship between the transformed expected response (ex. \\(\\text{logit}(\\pi_i)\\)) and predictors."
  },
  {
    "objectID": "slides/19-logistic-regression.html#generalization-of-linear-model",
    "href": "slides/19-logistic-regression.html#generalization-of-linear-model",
    "title": "Logistic Regression",
    "section": "Generalization of Linear Model",
    "text": "Generalization of Linear Model\n\nLinear model\n\\(E[Y_i] = \\mu_i = x_i^\\top\\boldsymbol\\beta\\).\n\\(Y_i \\overset{ind}{\\sim} N(\\mu_i, \\sigma^2)\\).\n\n\n\nGLM\n\\(g\\left(E[Y_i]\\right) = g(\\mu_i)  = x_i^\\top \\beta\\). Alternatively, \\(\\mu_i \\sim g^{-1}(x_i^\\top \\beta)\\).\n\\(Y_i \\overset{ind}{\\sim} f(\\mu_i)\\).\n\n\n\n\n\n\n\n\n\nNote\n\n\nWe call \\(g\\) a link function"
  },
  {
    "objectID": "slides/19-logistic-regression.html#examples-of-link-functions",
    "href": "slides/19-logistic-regression.html#examples-of-link-functions",
    "title": "Logistic Regression",
    "section": "Examples of link functions",
    "text": "Examples of link functions\nLinear regression\n\\(g(\\mu_i) = \\mu_i\\) and \\(Y_i\\sim N(\\mu_i,\\sigma^2)\\).\n\nLogistic regression\n\\(g(\\pi_i) = \\text{logit}(\\pi_i)\\) (note, \\(E[Y_i] = \\pi_i\\)). \\(Y_i \\sim \\text{Bernoulli}(\\pi_i)\\). Alternatively, \\(\\pi_i = \\sigma(x_i^\\top\\boldsymbol\\beta)\\) where \\(\\sigma\\) is the sigmoid function.\n\n\nProbit model\n\\(\\pi_i = \\Phi(x_i^\\top\\boldsymbol\\beta)\\), where \\(\\Phi\\) is the cdf of standard normal. \\(Y_i \\sim \\text{Bernoulli}(\\pi_i)\\). \\(g(\\pi_i) = \\Phi^{-1}(\\pi_i)\\) is called a probit link."
  },
  {
    "objectID": "slides/19-logistic-regression.html#predicted-log-odds",
    "href": "slides/19-logistic-regression.html#predicted-log-odds",
    "title": "Logistic Regression",
    "section": "Predicted log odds",
    "text": "Predicted log odds\n\nheart_disease_aug = \n  augment(heart_edu_age_fit) \nheart_disease_aug|&gt; select(.fitted, .resid)|&gt;\n  head(6)\n\n# A tibble: 6 × 2\n  .fitted .resid\n    &lt;dbl&gt;  &lt;dbl&gt;\n1   -2.55 -0.388\n2   -2.26 -0.446\n3   -1.87 -0.536\n4   -1.15  1.69 \n5   -2.25 -0.448\n6   -2.48 -0.402\n\n\n\nFor observation 1\n\\[\\text{predicted odds} = \\hat{\\omega} = \\frac{\\hat{\\pi}}{1-\\hat{\\pi}} = \\exp\\{-2.548\\} = 0.078\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#predicted-probabilities",
    "href": "slides/19-logistic-regression.html#predicted-probabilities",
    "title": "Logistic Regression",
    "section": "Predicted probabilities",
    "text": "Predicted probabilities\n\nheart_disease_aug$predicted_prob &lt;- \n  predict.glm(heart_edu_age_fit, heart_disease, type = \"response\")\nheart_disease_aug|&gt;\n  select(.fitted,predicted_prob) |&gt;\n  head(6)\n\n# A tibble: 6 × 2\n  .fitted predicted_prob\n    &lt;dbl&gt;          &lt;dbl&gt;\n1   -2.55         0.0726\n2   -2.26         0.0948\n3   -1.87         0.134 \n4   -1.15         0.240 \n5   -2.25         0.0954\n6   -2.48         0.0775\n\n\n\nFor observation 1\n\\[\\text{predicted probability} = \\hat{\\pi} = \\frac{\\exp\\{-2.548\\}}{1 + \\exp\\{-2.548\\}} = 0.073\\]"
  },
  {
    "objectID": "slides/19-logistic-regression.html#predicted-classes",
    "href": "slides/19-logistic-regression.html#predicted-classes",
    "title": "Logistic Regression",
    "section": "Predicted classes",
    "text": "Predicted classes\n\n# Convert probabilities to binary predictions (0 or 1)\nheart_disease_aug &lt;- heart_disease_aug |&gt;\n  mutate(predicted_class =  ifelse(predicted_prob &gt; 0.5, 1, 0))\nheart_disease_aug |&gt;\n  select(predicted_prob, predicted_class) \n\n# A tibble: 4,135 × 2\n   predicted_prob predicted_class\n            &lt;dbl&gt;           &lt;dbl&gt;\n 1         0.0726               0\n 2         0.0948               0\n 3         0.134                0\n 4         0.240                0\n 5         0.0954               0\n 6         0.0775               0\n 7         0.317                0\n 8         0.0887               0\n 9         0.172                0\n10         0.0967               0\n# ℹ 4,125 more rows"
  },
  {
    "objectID": "slides/19-logistic-regression.html#observed-vs.-predicted",
    "href": "slides/19-logistic-regression.html#observed-vs.-predicted",
    "title": "Logistic Regression",
    "section": "Observed vs. predicted",
    "text": "Observed vs. predicted\n\nWhat does the following table show?\n\n\nheart_disease_aug|&gt;\n  count(high_risk, predicted_class)\n\n# A tibble: 2 × 3\n  high_risk predicted_class     n\n  &lt;fct&gt;               &lt;dbl&gt; &lt;int&gt;\n1 0                       0  3507\n2 1                       0   628\n\n\n\n\nThe predicted_class is the class with the probability of occurring higher than 0.5. What is a limitation to using this method to determine the predicted class?"
  },
  {
    "objectID": "slides/19-logistic-regression.html#recap-1",
    "href": "slides/19-logistic-regression.html#recap-1",
    "title": "Logistic Regression",
    "section": "Recap",
    "text": "Recap\n\nReviewed the relationship between odds and probabilities\nIntroduced logistic regression for binary response variable\nInterpreted the coefficients of a logistic regression model with multiple predictors\nIntroduced generalized linear model\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/12-exam-01-review.html#announcements",
    "href": "slides/12-exam-01-review.html#announcements",
    "title": "Exam 01 review",
    "section": "Announcements",
    "text": "Announcements\n\nProject Proposal due TODAY at 11:59pm\nLab 03 due TODAY at 11:59pm\nHW 02 due TODAY at 11:59pm\nExam 01: Tuesday, October 8 (in class + take-home)\n\nLecture recordings available until the start of the in-class exam (Link on side bar of webpage)\nMonday’s lab: Exam office hours\nNo office hours while take-home exam is out"
  },
  {
    "objectID": "slides/12-exam-01-review.html#exam-01",
    "href": "slides/12-exam-01-review.html#exam-01",
    "title": "Exam 01 review",
    "section": "Exam 01",
    "text": "Exam 01\n\n20s% of final course grade\n50 points total\n\nin-class: 35-40 points\ntake-home: 10 - 15 points\n\nIn-class: 75 minutes during Tuesday, October 8 lecture\nTake-home: due October 10 at 11:30am (we will have class Thursday)\nIf you miss any part of the exam for an excused absence (with academic dean’s note), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/12-exam-01-review.html#content-weeks-1---6",
    "href": "slides/12-exam-01-review.html#content-weeks-1---6",
    "title": "Exam 01 review",
    "section": "Content: Weeks 1 - 6",
    "text": "Content: Weeks 1 - 6\n\n\n\nExploratory data analysis\nFitting and interpreting linear regression models\nModel assessment and comparison\nANOVA\nCategorical + interaction terms\nInference for model coefficients\n\n\n\nMatrix representation of regression\nHat matrix\nFinding the least-squares estimator (no geometric interpretation)\nAssumptions for least-squares regression\nProperties of the least-squares estimator"
  },
  {
    "objectID": "slides/12-exam-01-review.html#outline-of-in-class-portion",
    "href": "slides/12-exam-01-review.html#outline-of-in-class-portion",
    "title": "Exam 01 review",
    "section": "Outline of in-class portion",
    "text": "Outline of in-class portion\n\nClosed-book, closed-note.\n8 questions, some with multiple parts\nQuestion types:\n\nShort answer (show work / explain response)\nTrue/ False.\n\nIf false, write 1 - 2 sentence justification about why it is false.\n\nDerivations\n\nWill be provided all relevant R output and a page of math rules \nJust need a pencil or pen. No calculator permitted on exam."
  },
  {
    "objectID": "slides/12-exam-01-review.html#outline-of-take-home-portion",
    "href": "slides/12-exam-01-review.html#outline-of-take-home-portion",
    "title": "Exam 01 review",
    "section": "Outline of take-home portion",
    "text": "Outline of take-home portion\n\nReleased: Tuesday, October 8 ~ 1pm\nDue: Thursday, October 10 at 11:30 (we will have class Thursday)\nSimilar in format to a lab/ HW\n\nWill receive Exam questions in README of GitHub repo\nFormatting + using a reproducible workflow will be part of grade\n\nSubmit a PDF of responses to GitHub"
  },
  {
    "objectID": "slides/16-variable-transformations.html#announcements",
    "href": "slides/16-variable-transformations.html#announcements",
    "title": "Variable transformations",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due TODAY at 11:59pm on Canvas\nLab 04 due TODAY at 11:59pm\nTeam Feedback (from TEAMMATES) due TODAY at 11:59pm\nMid semester survey (strongly encouraged!) by TODAY at 11:59pm\nHW 03 due Thursday October 31 at 11:59pm (released after class)\nLooking ahead\n\nProject: Exploratory data analysis due October 31\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/16-variable-transformations.html#exam-weighting",
    "href": "slides/16-variable-transformations.html#exam-weighting",
    "title": "Variable transformations",
    "section": "Exam weighting",
    "text": "Exam weighting\n\nNo curves on individual exam grades\nExams will be weighted to reflect significant progress throughout semester. There are 2 scenarios:\n\nIf Exam 02 score is at least 5 (out of 50) points greater than the Exam 01 score (before corrections), Exam 01 is 13% and Exam 02 is 27% of the final course grade\nOtherwise, the exams are 20% each as stated in the syllabus."
  },
  {
    "objectID": "slides/16-variable-transformations.html#computing-set-up",
    "href": "slides/16-variable-transformations.html#computing-set-up",
    "title": "Variable transformations",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(Sleuth3) #for data set\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/16-variable-transformations.html#topics",
    "href": "slides/16-variable-transformations.html#topics",
    "title": "Variable transformations",
    "section": "Topics",
    "text": "Topics\n\nVariable transformations"
  },
  {
    "objectID": "slides/16-variable-transformations.html#data-respiratory-rate-vs.-age",
    "href": "slides/16-variable-transformations.html#data-respiratory-rate-vs.-age",
    "title": "Variable transformations",
    "section": "Data: Respiratory Rate vs. Age",
    "text": "Data: Respiratory Rate vs. Age\n\nA high respiratory rate can potentially indicate a respiratory infection in children. In order to determine what indicates a “high” rate, we first want to understand the relationship between a child’s age and their respiratory rate.\nThe data contain the respiratory rate for 618 children ages 15 days to 3 years. It was obtained from the Sleuth3 R package and is originally form a 1994 publication “Reference Values for Respiratory Rate in the First 3 Years of Life”.\nVariables:\n\nAge: age in months\nRate: respiratory rate (breaths per minute)"
  },
  {
    "objectID": "slides/16-variable-transformations.html#rate-vs.-age",
    "href": "slides/16-variable-transformations.html#rate-vs.-age",
    "title": "Variable transformations",
    "section": "Rate vs. Age",
    "text": "Rate vs. Age"
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-1-rate-vs.-age",
    "href": "slides/16-variable-transformations.html#model-1-rate-vs.-age",
    "title": "Variable transformations",
    "section": "Model 1: Rate vs. Age",
    "text": "Model 1: Rate vs. Age\n\nresp_fit &lt;- lm(Rate ~ Age, data = respiratory)\n\ntidy(resp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n47.052\n0.504\n93.317\n0\n\n\nAge\n-0.696\n0.029\n-23.684\n0"
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-1-residuals",
    "href": "slides/16-variable-transformations.html#model-1-residuals",
    "title": "Variable transformations",
    "section": "Model 1: Residuals",
    "text": "Model 1: Residuals"
  },
  {
    "objectID": "slides/16-variable-transformations.html#consider-different-transformations",
    "href": "slides/16-variable-transformations.html#consider-different-transformations",
    "title": "Variable transformations",
    "section": "Consider different transformations…",
    "text": "Consider different transformations…"
  },
  {
    "objectID": "slides/16-variable-transformations.html#identifying-a-need-to-transform-y",
    "href": "slides/16-variable-transformations.html#identifying-a-need-to-transform-y",
    "title": "Variable transformations",
    "section": "Identifying a need to transform Y",
    "text": "Identifying a need to transform Y\n\n\nTypically, a “fan-shaped” residual plot indicates the need for a transformation of the response variable Y\n\nThere are multiple ways to transform a variable, e.g., Y, 1/Y, log⁡(Y)\nlog⁡(Y) the most straightforward to interpret, so we use that transformation when possible\n\n\n\n\nWhen building a model:\n\nChoose a transformation and build the model on the transformed data\nReassess the residual plots\nIf the residuals plots did not sufficiently improve, try a new transformation!"
  },
  {
    "objectID": "slides/16-variable-transformations.html#log-transformation-on-y",
    "href": "slides/16-variable-transformations.html#log-transformation-on-y",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\n\nIf we apply a log transformation to the response variable, we want to estimate the parameters for the statistical model\n\n\\[\n\\log(y_i) = \\beta_0+ \\beta_1 x_{i1} + \\dots +\\beta_px_{ip} + \\epsilon_i, \\hspace{10mm} \\epsilon \\sim N(0,\\sigma^2_\\epsilon)\n\\]\n\nThe regression equation is\n\n\\[\\widehat{\\log(y_i)} = \\hat{\\beta}_0+ \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_px_{ip}\\]"
  },
  {
    "objectID": "slides/16-variable-transformations.html#log-transformation-on-y-1",
    "href": "slides/16-variable-transformations.html#log-transformation-on-y-1",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\nWe want to interpret the model in terms of the original variable \\(Y\\), not \\(\\log(Y)\\), so we need to write the regression equation in terms of \\(Y\\)\n\\[\\begin{align}\\hat{y_i} &= \\exp\\{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_Px_{ip}\\}\\\\ &= \\exp\\{\\hat{\\beta}_0\\}\\exp\\{\\hat{\\beta}_1x_{i1}\\}\\dots\\exp\\{\\hat{\\beta}_px_{ip}\\}\\end{align}\\]\n\n\n\n\n\n\nNote\n\n\nThe predicted value \\(\\hat{y_i}\\) is the predicted median of \\(Y\\). Note, when the distribution of \\(y_i|x_1, \\ldots, x_p\\) is symmetric, then the median equals the mean. (See notes at the end for more details)"
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-interpretation",
    "href": "slides/16-variable-transformations.html#model-interpretation",
    "title": "Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\\begin{align}\\hat{y_i} &= \\exp\\{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{1p} + \\dots + \\hat{\\beta}_Px_{ip}\\}\\\\ &= \\exp\\{\\hat{\\beta}_0\\}\\exp\\{\\hat{\\beta}_1x_{i1}\\}\\dots\\exp\\{\\hat{\\beta}_px_{ip}\\}\\end{align}\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = x_{ip} =0\\), \\(y_i\\) is expected to be \\(\\exp\\{\\hat{\\beta}_0\\}\\)\nSlope: For every one unit increase in \\(x_{ij}\\), \\(y_{i}\\) is expected to multiply by a factor of \\(\\exp\\{\\hat{\\beta}_j\\}\\), holding all else constant\n\n\nWhy is the interpretation in terms of a multiplicative change?"
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-2-lograte-vs.-age",
    "href": "slides/16-variable-transformations.html#model-2-lograte-vs.-age",
    "title": "Variable transformations",
    "section": "Model 2: log(Rate) vs. Age",
    "text": "Model 2: log(Rate) vs. Age\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3.845\n0.013\n304.500\n0\n\n\nAge\n-0.019\n0.001\n-25.839\n0\n\n\n\n\n\n\n\n\nInterpret the intercept in terms of (1) log(Rate) and (2) Rate.\nInterpret the effect of Age in terms of (1) log(Rate) and (2) Rate."
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-2-residuals",
    "href": "slides/16-variable-transformations.html#model-2-residuals",
    "title": "Variable transformations",
    "section": "Model 2: Residuals",
    "text": "Model 2: Residuals"
  },
  {
    "objectID": "slides/16-variable-transformations.html#compare-residual-plots",
    "href": "slides/16-variable-transformations.html#compare-residual-plots",
    "title": "Variable transformations",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/16-variable-transformations.html#log-transformation-on-x",
    "href": "slides/16-variable-transformations.html#log-transformation-on-x",
    "title": "Variable transformations",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\n\nTry a transformation on \\(X\\) if the scatterplot shows some curvature but the variance is constant for all values of \\(X\\)"
  },
  {
    "objectID": "slides/16-variable-transformations.html#rate-vs.-logage",
    "href": "slides/16-variable-transformations.html#rate-vs.-logage",
    "title": "Variable transformations",
    "section": "Rate vs. log(Age)",
    "text": "Rate vs. log(Age)"
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-with-transformation-on-x",
    "href": "slides/16-variable-transformations.html#model-with-transformation-on-x",
    "title": "Variable transformations",
    "section": "Model with Transformation on \\(X\\)",
    "text": "Model with Transformation on \\(X\\)\nSuppose we have the following regression equation:\n\\[\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\log(x_i)\\]\n\n\n\nIntercept: When \\(x_i = 1\\) \\((\\log(x_i) = 0)\\), \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\) (i.e. the mean of \\(y_i\\) is \\(\\hat{\\beta}_0\\))\nSlope: When \\(x_i\\) is multiplied by a factor of \\(\\mathbf{C}\\), the mean of \\(y_i\\) is expected to change by \\(\\hat{\\beta}_1\\log(C)\\) units\n\nExample: when \\(x_i\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_1\\log(2)\\) units"
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-3-rate-vs.-logage",
    "href": "slides/16-variable-transformations.html#model-3-rate-vs.-logage",
    "title": "Variable transformations",
    "section": "Model 3: Rate vs. log(Age)",
    "text": "Model 3: Rate vs. log(Age)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n50.135\n0.632\n79.330\n0\n\n\nlog_age\n-5.982\n0.263\n-22.781\n0\n\n\n\n\n\n\n\nInterpret the slope and intercept in the context of the data."
  },
  {
    "objectID": "slides/16-variable-transformations.html#model-3-residuals",
    "href": "slides/16-variable-transformations.html#model-3-residuals",
    "title": "Variable transformations",
    "section": "Model 3: Residuals",
    "text": "Model 3: Residuals"
  },
  {
    "objectID": "slides/16-variable-transformations.html#choose-a-model",
    "href": "slides/16-variable-transformations.html#choose-a-model",
    "title": "Variable transformations",
    "section": "Choose a model",
    "text": "Choose a model\nRecall the goal of the analysis:\nIn order to determine what indicates a “high” rate, we first want to understand the relationship between a child’s age and their respiratory rate.\n\n\nWhich is the preferred metric to compare the models - \\(R^2\\) or RMSE?"
  },
  {
    "objectID": "slides/16-variable-transformations.html#compare-models",
    "href": "slides/16-variable-transformations.html#compare-models",
    "title": "Variable transformations",
    "section": "Compare models",
    "text": "Compare models\n\n\n\n\n\n\n\n\nRate vs. Age\nlog(Rate) vs. Age\nRate vs. log(Age)\n\n\n\n\n0.477\n0.52\n0.457\n\n\n\n\n\nWhich model would you choose?"
  },
  {
    "objectID": "slides/16-variable-transformations.html#learn-more",
    "href": "slides/16-variable-transformations.html#learn-more",
    "title": "Variable transformations",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/16-variable-transformations.html#recap",
    "href": "slides/16-variable-transformations.html#recap",
    "title": "Variable transformations",
    "section": "Recap",
    "text": "Recap\n\nIntroduced variable transformations\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/15-multicollinearity.html#announcements",
    "href": "slides/15-multicollinearity.html#announcements",
    "title": "Multicollinearity",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Thursday at 11:59pm on Canvas\nLab 04 due Thursday at 11:59pm\nTeam Feedback (from TEAMMATES) due Thursday at 11:59pm\nMid semester survey (strongly encouraged!) by Thursday at 11:59pm\nLooking ahead\n\nProject: Exploratory data analysis due October 31\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/15-multicollinearity.html#spring-2025-statistics-classes",
    "href": "slides/15-multicollinearity.html#spring-2025-statistics-classes",
    "title": "Multicollinearity",
    "section": "Spring 2025 statistics classes",
    "text": "Spring 2025 statistics classes\n\nSTA 230, STA 231 or STA 240: Probability\nSTA 310: Generalized Linear Models\nSTA 323: Statistical Computing\nSTA 360: Bayesian Inference and Modern Statistical Methods\nSTA 432: Theory and Methods of Statistical Learning and Inference"
  },
  {
    "objectID": "slides/15-multicollinearity.html#computing-set-up",
    "href": "slides/15-multicollinearity.html#computing-set-up",
    "title": "Multicollinearity",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally) #for pairwise plot matrix\n\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/15-multicollinearity.html#topics",
    "href": "slides/15-multicollinearity.html#topics",
    "title": "Multicollinearity",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/15-multicollinearity.html#data-trail-users",
    "href": "slides/15-multicollinearity.html#data-trail-users",
    "title": "Multicollinearity",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005 to\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/15-multicollinearity.html#variables",
    "href": "slides/15-multicollinearity.html#variables",
    "title": "Multicollinearity",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/15-multicollinearity.html#eda-relationship-between-predictors",
    "href": "slides/15-multicollinearity.html#eda-relationship-between-predictors",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\nWe can create a pairwise plot matrix using the ggpairs function from the GGally R package\n\nrail_trail |&gt;\n  select(hightemp, avgtemp, season, precip) |&gt;\n  ggpairs()"
  },
  {
    "objectID": "slides/15-multicollinearity.html#eda-relationship-between-predictors-1",
    "href": "slides/15-multicollinearity.html#eda-relationship-between-predictors-1",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\n\n\nWhat might be a potential concern with a model that uses high temperature, average temperature, season, and precipitation to predict volume?"
  },
  {
    "objectID": "slides/15-multicollinearity.html#multicollinearity-1",
    "href": "slides/15-multicollinearity.html#multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nIdeally there is no linear relationship (dependence) between the predictors\n\nThis is generally not the case in practice but is often not a major issue\n\nMulticollinearity: there are near-linear dependencies between predictors"
  },
  {
    "objectID": "slides/15-multicollinearity.html#common-sources-of-multicollinearity",
    "href": "slides/15-multicollinearity.html#common-sources-of-multicollinearity",
    "title": "Multicollinearity",
    "section": "Common sources of multicollinearity",
    "text": "Common sources of multicollinearity\n\n\nDependencies that generally occur in the population\nHow the model is defined and the variables that are included\nSample comes from only a subspace of the region of predictors\nThere are more predictor variables than observations"
  },
  {
    "objectID": "slides/15-multicollinearity.html#detecting-multicollinearity",
    "href": "slides/15-multicollinearity.html#detecting-multicollinearity",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nVariance Inflation Factor (VIF): measure of multicollinearity in the regression model\n\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by a linear combination of all the other predictors"
  },
  {
    "objectID": "slides/15-multicollinearity.html#detecting-multicollinearity-1",
    "href": "slides/15-multicollinearity.html#detecting-multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nCommon practice uses threshold \\(VIF &gt; 10\\) as indication of concerning multicollinearity\nVariables with similar values of VIF are typically the ones correlated with each other\nUse the vif() function in the rms R package to calculate VIF"
  },
  {
    "objectID": "slides/15-multicollinearity.html#effects-of-multicollinearity",
    "href": "slides/15-multicollinearity.html#effects-of-multicollinearity",
    "title": "Multicollinearity",
    "section": "Effects of multicollinearity",
    "text": "Effects of multicollinearity\n\n\nLarge variance \\((\\hat{\\sigma}^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1})\\) in the model coefficients\n\nDifferent combinations of coefficient estimates produce equally good model fits\n\nUnreliable statistical inference results\n\nMay conclude coefficients are not statistically significant when there is, in fact, a relationship between the predictors and response\n\nInterpretation of coefficient is no longer “holding all other variables constant”, since this would be impossible for correlated predictors"
  },
  {
    "objectID": "slides/15-multicollinearity.html#dealing-with-multicollinearity",
    "href": "slides/15-multicollinearity.html#dealing-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/15-multicollinearity.html#recap",
    "href": "slides/15-multicollinearity.html#recap",
    "title": "Multicollinearity",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multicollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it\n\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#announcements",
    "href": "slides/14-model-diagnostics.html#announcements",
    "title": "Model diagnostics",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Thursday, October 24 at 11:59pm on Canvas\nLabs resume on Monday\nProject: Exploratory data analysis due October 31\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#computing-set-up",
    "href": "slides/14-model-diagnostics.html#computing-set-up",
    "title": "Model diagnostics",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)   \nlibrary(viridis)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#topics",
    "href": "slides/14-model-diagnostics.html#topics",
    "title": "Model diagnostics",
    "section": "Topics",
    "text": "Topics\n\nReview: Maximum likelihood estimation\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#likelihood",
    "href": "slides/14-model-diagnostics.html#likelihood",
    "title": "Model diagnostics",
    "section": "Likelihood",
    "text": "Likelihood\n\n\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values). \nNote that this is not the same as the probability function.\n\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood function: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#maximum-likelihood-estimation-1",
    "href": "slides/14-model-diagnostics.html#maximum-likelihood-estimation-1",
    "title": "Model diagnostics",
    "section": "Maximum likelihood estimation",
    "text": "Maximum likelihood estimation\n\nMaximum likelihood estimation is the process of finding the values of the parameters that maximize the likelihood function , i.e., the values that are most likely given the observed data.\nThere are three primary ways to find the maximum likelihood estimator\n\nApproximate using a graph\nUsing calculus\nNumerical approximation"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#simple-linear-regression-model",
    "href": "slides/14-model-diagnostics.html#simple-linear-regression-model",
    "title": "Model diagnostics",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\nSuppose we have the simple linear regression (SLR) model\n\\[\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are independently and identically distributed.\n\n\nWe can write this model in the form below and use this to find the MLE\n\\[\ny_i | x_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2_{\\epsilon})\n\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#likelihood-for-slr",
    "href": "slides/14-model-diagnostics.html#likelihood-for-slr",
    "title": "Model diagnostics",
    "section": "Likelihood for SLR",
    "text": "Likelihood for SLR\nThe likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\nL&(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n) \\\\[5pt]\n&= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma_\n\\epsilon^2}}\\exp\\Big\\{{-\\frac{1}{2\\sigma_\\epsilon^2}(y_i - [\\beta_0 + \\beta_1x_i])^2}\\Big\\} \\\\[10pt]\n& = (2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#log-likelihood-for-slr",
    "href": "slides/14-model-diagnostics.html#log-likelihood-for-slr",
    "title": "Model diagnostics",
    "section": "Log-likelihood for SLR",
    "text": "Log-likelihood for SLR\nThe log-likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n)\n  \\\\[8pt]\n& = -\\frac{n}{2}\\log(2\\pi\\sigma^2_{\\epsilon}) -\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\n\\end{aligned}\n\\]\n\n\nWe will use the log-likelihood function to find the MLEs"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#mle-for-beta_0beta_1-sigma2_epsilon",
    "href": "slides/14-model-diagnostics.html#mle-for-beta_0beta_1-sigma2_epsilon",
    "title": "Model diagnostics",
    "section": "MLE for \\(\\beta_0,\\beta_1, \\sigma^2_{\\epsilon}\\)",
    "text": "MLE for \\(\\beta_0,\\beta_1, \\sigma^2_{\\epsilon}\\)\n\\[\n\\tilde{\\beta}_0 = \\frac{1}{n}\\sum_{i=1}^ny_i  - \\frac{1}{n}\\tilde{\\beta}_1\\sum_{i=1}^n x_i\n\\]\n\n\\[\n\\tilde{\\beta}_1 = \\frac{\\sum_{i=1}^n y_i(x_i - \\bar{x})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\n\\]\n\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{\\sum_{i=1}^n(y_i - \\tilde{\\beta}_0 - \\tilde{\\beta}_1x_i)^2}{n} = \\frac{\\sum_{i=1}^ne_i^2}{n}\n\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#mle-for-linear-regression-in-matrix-form",
    "href": "slides/14-model-diagnostics.html#mle-for-linear-regression-in-matrix-form",
    "title": "Model diagnostics",
    "section": "MLE for linear regression in matrix form",
    "text": "MLE for linear regression in matrix form\n\\[\nL(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon} | \\mathbf{X}, \\mathbf{y}) = \\frac{1}{(2\\pi)^{n/2}\\sigma^n_{\\epsilon}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\Big\\}\n\\]\n\n\\[\n\\log L(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon | \\mathbf{X}, \\mathbf{y}) = -\\frac{n}{2}\\log(2\\pi) - n \\log(\\sigma_{\\epsilon}) - \\frac{1}{2\\sigma^2_{\\epsilon}}(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{\\beta})\n\\]\n\n\n\n\nFor a fixed value of \\(\\sigma_\\epsilon\\) , we know that \\(\\log L\\) is maximized when what is true about \\((\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\) ?\nWhat does this tell us about the relationship between the MLE and least-squares estimator for \\(\\boldsymbol{\\beta}\\)?"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#why-maximum-likelihood-estimation",
    "href": "slides/14-model-diagnostics.html#why-maximum-likelihood-estimation",
    "title": "Model diagnostics",
    "section": "Why maximum likelihood estimation?",
    "text": "Why maximum likelihood estimation?\n\n“Maximum likelihood estimation is, by far, the most popular technique for deriving estimators.” (Casella and Berger 2024, 315)\nMLEs have nice statistical properties. They are\n\nConsistent\nEfficient - Have the smallest MSE among all consistent estimators\nAsymptotically normal"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#putting-it-all-together",
    "href": "slides/14-model-diagnostics.html#putting-it-all-together",
    "title": "Model diagnostics",
    "section": "Putting it all together",
    "text": "Putting it all together\n\n\nThe MLE \\(\\tilde{\\boldsymbol{\\beta}}\\) is equivalent to the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) , when the errors follow independent and identical normal distributions\nThis means the least-squares estimator \\(\\hat{\\mathbf{\\boldsymbol{\\beta}}}\\) inherits all the nice properties of MLEs\n\nConsistency\nEfficiency - minimum variance among all consistent estimators\nAsymptotically normal"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#putting-it-all-together-1",
    "href": "slides/14-model-diagnostics.html#putting-it-all-together-1",
    "title": "Model diagnostics",
    "section": "Putting it all together",
    "text": "Putting it all together\n\nFrom previous work, we also know \\(\\hat{\\boldsymbol{\\beta}}\\) is unbiased and thus the MLE \\(\\tilde{\\boldsymbol{\\beta}}\\) is unbiased\nNote that the MLE \\(\\tilde{\\sigma}^2_{\\epsilon}\\) is asymptotically unbiased\n\nThe estimate from least-squares \\(\\hat{\\sigma}_{\\epsilon}^2\\) is unbiased"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#data-duke-lemurs",
    "href": "slides/14-model-diagnostics.html#data-duke-lemurs",
    "title": "Model diagnostics",
    "section": "Data: Duke lemurs",
    "text": "Data: Duke lemurs\nToday’s data contains a subset of the original Duke Lemur data set available in the TidyTuesday GitHub repo. This data includes information on “young adult” lemurs from the Coquerel’s sifaka species (PCOQ), the largest species at the Duke Lemur Center. The analysis will focus on the following variables:\n\nage_at_wt_mo: Age in months: Age of the animal when the weight was taken, in months (((Weight_Date-DOB)/365)*12)\nweight_g: Weight: Animal weight, in grams. Weights under 500g generally to nearest 0.1-1g; Weights &gt;500g generally to the nearest 1-20g.\n\nThe goal of the analysis is to use the age of the lemurs to understand variability in the weight."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#eda",
    "href": "slides/14-model-diagnostics.html#eda",
    "title": "Model diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#fit-model",
    "href": "slides/14-model-diagnostics.html#fit-model",
    "title": "Model diagnostics",
    "section": "Fit model",
    "text": "Fit model\n\nlemurs_fit &lt;- lm(weight_g ~ age_at_wt_mo, data = lemurs)\n\ntidy(lemurs_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n3133.284\n353.499\n8.864\n0.000\n\n\nage_at_wt_mo\n19.558\n10.083\n1.940\n0.056"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-conditions",
    "href": "slides/14-model-diagnostics.html#model-conditions",
    "title": "Model diagnostics",
    "section": "Model conditions",
    "text": "Model conditions\n\n\nLinearity\nConstant variance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-conditions-1",
    "href": "slides/14-model-diagnostics.html#model-conditions-1",
    "title": "Model diagnostics",
    "section": "Model conditions",
    "text": "Model conditions\n\n\nNormality\nIndependence"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-diagnostics-1",
    "href": "slides/14-model-diagnostics.html#model-diagnostics-1",
    "title": "Model diagnostics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nlemurs_aug &lt;- augment(lemurs_fit)\n\nlemurs_aug |&gt; slice(1:10)\n\n# A tibble: 10 × 8\n   weight_g age_at_wt_mo .fitted .resid   .hat .sigma    .cooksd .std.resid\n      &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1     3400         32.0   3758. -358.  0.0158   516. 0.00396       -0.703 \n 2     4143         46.2   4037.  106.  0.0655   517. 0.00159        0.213 \n 3     3581         43.1   3977. -396.  0.0414   515. 0.0134        -0.787 \n 4     3620         33.0   3778. -158.  0.0141   517. 0.000690      -0.310 \n 5     3720         32.4   3768.  -47.9 0.0149   517. 0.0000668     -0.0940\n 6     3540         35.4   3825. -285.  0.0134   516. 0.00212       -0.559 \n 7     4440         37.3   3863.  577.  0.0161   513. 0.0105         1.13  \n 8     4440         32.6   3770.  670.  0.0147   511. 0.0129         1.31  \n 9     3770         31.8   3754.   15.6 0.0162   517. 0.00000767     0.0305\n10     3920         31.9   3757.  163.  0.0159   517. 0.000828       0.320"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#model-diagnostics-in-r",
    "href": "slides/14-model-diagnostics.html#model-diagnostics-in-r",
    "title": "Model diagnostics",
    "section": "Model diagnostics in R",
    "text": "Model diagnostics in R\nUse the augment() function in the broom package to output the model diagnostics (along with the predicted values and residuals)\n\nresponse and predictor variables in the model\n.fitted: predicted values\n.se.fit: standard errors of predicted values\n.resid: residuals\n.hat: leverage\n.sigma: estimate of residual standard deviation when the corresponding observation is dropped from model\n.cooksd: Cook’s distance\n.std.resid: standardized residuals"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#influential-point",
    "href": "slides/14-model-diagnostics.html#influential-point",
    "title": "Model diagnostics",
    "section": "Influential Point",
    "text": "Influential Point\nAn observation is influential if removing has a noticeable impact on the regression coefficients"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#influential-points",
    "href": "slides/14-model-diagnostics.html#influential-points",
    "title": "Model diagnostics",
    "section": "Influential points",
    "text": "Influential points\n\n\nInfluential points have a noticeable impact on the coefficients and standard errors used for inference\nThese points can sometimes be identified in a scatterplot if there is only one predictor variable\n\nThis is often not the case when there are multiple predictors\n\nWe will use measures to quantify an individual observation’s influence on the regression model\n\nleverage, standardized & studentized residuals, and Cook’s distance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#hat-matrix",
    "href": "slides/14-model-diagnostics.html#hat-matrix",
    "title": "Model diagnostics",
    "section": "Hat matrix",
    "text": "Hat matrix\n\n\nRecall the hat matrix \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\)\nWe’ve seen that \\(\\mathbf{H}\\) is used to compute \\(Var(\\hat{\\mathbf{y}}) = \\sigma^2_{\\epsilon}\\mathbf{H}\\) and \\(Var(\\mathbf{e}) = \\sigma^2_{\\epsilon}(\\mathbf{I} - \\mathbf{H})\\)\nAn element of \\(\\mathbf{H}\\), \\(h_{ij}\\), is the leverage of the observation \\(y_i\\) on the fitted values \\(\\hat{y}_{j}\\)"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#leverage-1",
    "href": "slides/14-model-diagnostics.html#leverage-1",
    "title": "Model diagnostics",
    "section": "Leverage",
    "text": "Leverage\n\n\nWe focus on the diagonal elements\n\\[\nh_{ii} = \\mathbf{x}_i^T(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{x}_i\n\\]such that \\(\\mathbf{x}^T_i\\) is the \\(i^{th}\\) row of \\(\\mathbf{X}\\)\n\\(h_{ii}\\) is the leverage: a measure of the distance of the \\(i^{th}\\) observation from the center (or centroid) of the \\(x\\) space\nObservations with large values of \\(h_{ii}\\) are far away from the typical value (or combination of values) of the predictors in the data"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#large-leverage",
    "href": "slides/14-model-diagnostics.html#large-leverage",
    "title": "Model diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\n\n\nThe sum of the leverages for all points is \\(p + 1\\), where \\(p\\) is the number of predictors in the model . More specifically\n\\[\n\\sum_{i=1}^n h_{ii} = \\text{rank}(\\mathbf{H}) = \\text{rank}(\\mathbf{X}) = p+1\n\\]\nThe average value of leverage, \\(h_{ii}\\), is \\(\\bar{h} =  \\frac{(p+1)}{n}\\)\nAn observation has large leverage if \\[h_{ii} &gt; \\frac{2(p+1)}{n}\\]"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#lemurs-leverage",
    "href": "slides/14-model-diagnostics.html#lemurs-leverage",
    "title": "Model diagnostics",
    "section": "Lemurs: Leverage",
    "text": "Lemurs: Leverage\n\nh_threshold &lt;- 2 * 2 / nrow(lemurs)\nh_threshold\n\n[1] 0.05263158\n\n\n\n\nlemurs_aug |&gt;\n  filter(.hat &gt; h_threshold)\n\n# A tibble: 7 × 8\n  weight_g age_at_wt_mo .fitted .resid   .hat .sigma .cooksd .std.resid\n     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     4143         46.2   4037.  106.  0.0655   517. 0.00159     0.213 \n2     4313         58.2   4272.   41.1 0.229    517. 0.00123     0.0910\n3     4640         54.9   4208.  432.  0.173    514. 0.0895      0.925 \n4     3677         47.4   4061. -384.  0.0770   515. 0.0253     -0.778 \n5     4319         58.2   4272.   47.1 0.229    517. 0.00161     0.104 \n6     3610         47.4   4061. -451.  0.0770   514. 0.0348     -0.914 \n7     3597         48.6   4084. -487.  0.0889   514. 0.0480     -0.992 \n\n\n\n\n\nWhy do you think these points have large leverage?"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#lets-look-at-the-data",
    "href": "slides/14-model-diagnostics.html#lets-look-at-the-data",
    "title": "Model diagnostics",
    "section": "Let’s look at the data",
    "text": "Let’s look at the data"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#large-leverage-1",
    "href": "slides/14-model-diagnostics.html#large-leverage-1",
    "title": "Model diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\nIf there is point with high leverage, ask\n\n❓ Is there a data entry error?\n❓ Is this observation within the scope of individuals for which you want to make predictions and draw conclusions?\n❓ Is this observation impacting the estimates of the model coefficients? (Need more information!)\n\n\nJust because a point has high leverage does not necessarily mean it will have a substantial impact on the regression. Therefore we need to check other measures."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#scaled-residuals-1",
    "href": "slides/14-model-diagnostics.html#scaled-residuals-1",
    "title": "Model diagnostics",
    "section": "Scaled residuals",
    "text": "Scaled residuals\n\n\nWhat is the best way to identify outlier points that don’t fit the pattern from the regression line?\n\nLook for points that have large residuals\n\nWe can rescale residuals and put them on a common scale to more easily identify “large” residuals\nWe will consider two types of scaled residuals: standardized residuals and studentized residuals"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#standardized-residuals",
    "href": "slides/14-model-diagnostics.html#standardized-residuals",
    "title": "Model diagnostics",
    "section": "Standardized residuals",
    "text": "Standardized residuals\n\n\nThe variance of the residuals can be estimated by the mean squared residuals (MSR) \\(= \\frac{SSR}{n - p - 1} = \\hat{\\sigma}^2_{\\epsilon}\\)\nWe can use MSR to compute standardized residuals\n\\[\nstd.res_i = \\frac{e_i}{\\sqrt{MSR}}\n\\]\nStandardized residuals are produced by augment() in the column .std.resid"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#studentized-residuals",
    "href": "slides/14-model-diagnostics.html#studentized-residuals",
    "title": "Model diagnostics",
    "section": "Studentized residuals",
    "text": "Studentized residuals\n\n\nMSR is an approximation of the variance of the residuals.\nThe variance of the residuals is \\(Var(\\mathbf{e}) = \\sigma^2_{\\epsilon}(\\mathbf{I} - \\mathbf{H})\\)\n\nThe variance of the \\(i^{th}\\) residual is \\(Var(e_i) = \\sigma^2_{\\epsilon}(1 - h_{ii})\\)\n\nThe studentized residual is the residual rescaled by the more exact calculation for variance\n\n\n\\[\nr_i = \\frac{e_{i}}{\\sqrt{\\hat{\\sigma}^2_{\\epsilon}(1 - h_{ii})}}\n\\]\n\nStandardized and studentized residuals provide similar information about which points are outliers in the response."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#using-standardized-residuals",
    "href": "slides/14-model-diagnostics.html#using-standardized-residuals",
    "title": "Model diagnostics",
    "section": "Using standardized residuals",
    "text": "Using standardized residuals\nWe can examine the standardized residuals directly from the output from the augment() function\n\n\nAn observation is a potential outlier if its standardized residual is beyond \\(\\pm 3\\)"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#digging-in-to-the-data",
    "href": "slides/14-model-diagnostics.html#digging-in-to-the-data",
    "title": "Model diagnostics",
    "section": "Digging in to the data",
    "text": "Digging in to the data\nLet’s look at the value of the response variable to better understand potential outliers"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#motivating-cooks-distance",
    "href": "slides/14-model-diagnostics.html#motivating-cooks-distance",
    "title": "Model diagnostics",
    "section": "Motivating Cook’s Distance",
    "text": "Motivating Cook’s Distance\n\nAn observation’s influence on the regression line depends on\n\nHow close it lies to the general trend of the data\nIts leverage\n\nCook’s Distance is a statistic that includes both of these components to measure an observation’s overall impact on the model"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#cooks-distance-1",
    "href": "slides/14-model-diagnostics.html#cooks-distance-1",
    "title": "Model diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance for the \\(i^{th}\\) observation is\n\\[\nD_i = \\frac{r^2_i}{p + 1}\\Big(\\frac{h_{ii}}{1 - h_{ii}}\\Big)\n\\]\n\nThis measure is a combination of\n\nHow well the model fits the \\(i^{th}\\) observation (magnitude of residuals)\nHow far the \\(i^{th}\\) observation is from the rest of the data (where the point is in the \\(x\\) space)"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#using-cooks-distance",
    "href": "slides/14-model-diagnostics.html#using-cooks-distance",
    "title": "Model diagnostics",
    "section": "Using Cook’s Distance",
    "text": "Using Cook’s Distance\n\nAn observation with large value of \\(D_i\\) is said to have a strong influence on the predicted values\nGeneral thresholds .An observation with\n\n\\(D_i &gt; 0.5\\) is moderately influential\n\\(D_i &gt; 1\\) is very influential"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#cooks-distance-2",
    "href": "slides/14-model-diagnostics.html#cooks-distance-2",
    "title": "Model diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s Distance is in the column .cooksd in the output from the augment() function"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#using-these-measures",
    "href": "slides/14-model-diagnostics.html#using-these-measures",
    "title": "Model diagnostics",
    "section": "Using these measures",
    "text": "Using these measures\n\nStandardized residuals, leverage, and Cook’s Distance should all be examined together\nExamine plots of the measures to identify observations that are outliers, high leverage, and may potentially impact the model."
  },
  {
    "objectID": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "href": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "title": "Model diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nFirst consider if the outlier is a result of a data entry error.\nIf not, you may consider dropping an observation if it’s an outlier in the predictor variables if…\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. Mention this in the write up of the results and be careful to avoid extrapolation when making predictions"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "href": "slides/14-model-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "title": "Model diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nIt is generally not good practice to drop observations that ar outliers in the value of the response variable\n\nThese are legitimate observations and should be in the model\nYou can try transformations or increasing the sample size by collecting more data\n\nA general strategy when there are influential points is to fit the model with and without the influential points and compare the outcomes"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#recap",
    "href": "slides/14-model-diagnostics.html#recap",
    "title": "Model diagnostics",
    "section": "Recap",
    "text": "Recap\n\nReviewed Maximum likelihood estimation\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/14-model-diagnostics.html#references",
    "href": "slides/14-model-diagnostics.html#references",
    "title": "Model diagnostics",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 221 - Fall 2024\n\n\n\n\nCasella, George, and Roger Berger. 2024. Statistical Inference. CRC Press."
  },
  {
    "objectID": "slides/08-inference.html#announcements",
    "href": "slides/08-inference.html#announcements",
    "title": "Inference for regression",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due on TODAY at 11:59pm\nHW 01 due TODAY at 11:59pm\nStatistics experience due Tue, Nov 26 at 11:59pm"
  },
  {
    "objectID": "slides/08-inference.html#statistics-experience",
    "href": "slides/08-inference.html#statistics-experience",
    "title": "Inference for regression",
    "section": "Statistics experience",
    "text": "Statistics experience\nGoal: Engage with statistics / data science outside the classroom and connect your experience with what you’re learning in the course.\nWhat: Have a statistics experience + create a slide reflecting on the experience. Counts as a homework grade.\nWhen: Must do the activity this semester. Reflection due Tuesday, November 26 at 11:59pm\nFor more info: sta221-fa24.netlify.app/hw/stats-experience"
  },
  {
    "objectID": "slides/08-inference.html#reminder-course-policies-about-assignments",
    "href": "slides/08-inference.html#reminder-course-policies-about-assignments",
    "title": "Inference for regression",
    "section": "Reminder: course policies about assignments",
    "text": "Reminder: course policies about assignments\n\nLate work\n\nHW and labs accepted up to 2 days late.\n5% deduction for each 24-hour period the assignment is late.\n\nOne time late waiver\n\nCan use on HW and individual labs\n\nLowest HW and lowest lab grade dropped at the end of the semester."
  },
  {
    "objectID": "slides/08-inference.html#reminder-course-policies-about-assignments-1",
    "href": "slides/08-inference.html#reminder-course-policies-about-assignments-1",
    "title": "Inference for regression",
    "section": "Reminder: course policies about assignments",
    "text": "Reminder: course policies about assignments\n\nRead the feedback on Gradescope carefully! If you have questions about the comments, ask a member of the teaching team during office hours or before/after class.\nRegrade requests\n\nOpened 1 day after assignment is returned and due within 1 week\nOnly submit regrade request if there is an error in the grading not to dispute points or ask questions about grading.\nProf. Tackett or Kat (Head TA) will regrade the entire exercise being disputed, which could potentially result in a lower grade."
  },
  {
    "objectID": "slides/08-inference.html#poll-office-hours-availability",
    "href": "slides/08-inference.html#poll-office-hours-availability",
    "title": "Inference for regression",
    "section": "Poll: Office hours availability",
    "text": "Poll: Office hours availability"
  },
  {
    "objectID": "slides/08-inference.html#topics",
    "href": "slides/08-inference.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient"
  },
  {
    "objectID": "slides/08-inference.html#computing-setup",
    "href": "slides/08-inference.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/08-inference.html#data-ncaa-football-expenditures",
    "href": "slides/08-inference.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/08-inference.html#univariate-eda",
    "href": "slides/08-inference.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/08-inference.html#bivariate-eda",
    "href": "slides/08-inference.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/08-inference.html#regression-model",
    "href": "slides/08-inference.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect the institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/08-inference.html#from-sample-to-population",
    "href": "slides/08-inference.html#from-sample-to-population",
    "title": "Inference for regression",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor every additional 1,000 students, we expect the institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant.\n\n\n\n\nThis estimate is valid for the single sample of 127 higher education institutions in the 2019 - 2020 academic year.\nBut what if we’re not interested quantifying the relationship between student enrollment, institution type, and football expenditures for this single sample?\nWhat if we want to say something about the relationship between these variables for all colleges and universities with football programs and across different years?"
  },
  {
    "objectID": "slides/08-inference.html#statistical-inference",
    "href": "slides/08-inference.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/08-inference.html#inference-for-linear-regression",
    "href": "slides/08-inference.html#inference-for-linear-regression",
    "title": "Inference for regression",
    "section": "Inference for linear regression",
    "text": "Inference for linear regression\n\nInference based on ANOVA\n\nHypothesis test for the statistical significance of the overall regression model\nHypothesis test for a subset of coefficients\n\nInference for a single coefficient \\(\\beta_j\\)\n\nHypothesis test for a coefficient \\(\\beta_j\\)\nConfidence interval for a coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/08-inference.html#linear-regression-model",
    "href": "slides/08-inference.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\begin{aligned}\n\\mathbf{y} &= Model + Error \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\n\n\n\nWe have discussed multiple ways to find the least squares estimates of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}\\)\n\nNone of these approaches depend on the distribution of \\(\\boldsymbol{\\epsilon}\\)\n\nNow we will use statistical inference to draw conclusions about \\(\\boldsymbol{\\beta}\\) that depend on particular assumptions about the distribution of \\(\\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/08-inference.html#linear-regression-model-1",
    "href": "slides/08-inference.html#linear-regression-model-1",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{8mm} \\boldsymbol{\\epsilon} \\sim N(0, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\end{aligned}\n\\]\nsuch that the errors are independent and normally distributed.\n\n\nIndependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nNormally distributed: Tell us the shape of the distribution of residuals\n\n\nWhat else do we know about the distribution of the residuals based on this equation?"
  },
  {
    "objectID": "slides/08-inference.html#describing-random-phenomena",
    "href": "slides/08-inference.html#describing-random-phenomena",
    "title": "Inference for regression",
    "section": "Describing random phenomena",
    "text": "Describing random phenomena\n\n\nThere is some uncertainty in the residuals (and the predicted responses), so we use mathematical models to describe that uncertainty.\nSome terminology:\n\nSample space: Set of all possible outcomes\nRandom variable: Function (mapping) from the sample space onto real numbers\nEvent: Subset of the sample space, i.e., a set of possible outcomes (possible values the random variable can take)\nProbability distribution function: Mathematical function that produces probability of occurrences for events in the sample space"
  },
  {
    "objectID": "slides/08-inference.html#example",
    "href": "slides/08-inference.html#example",
    "title": "Inference for regression",
    "section": "Example",
    "text": "Example\nSuppose we are tossing 2 fair coins with sides heads (H) and tails (T)\n\n\nSample space: {HH, HT, TH, TT}\nRandom variable: \\(X\\) : The number of heads in two coin tosses\nEvent: We flip two coins and get 1 head\nProbability distribution function: \\[P(X = x_i) = {2 \\choose x_i}0.5^{x_i}{0.5}^{2-x_i}\\]\nNow we can find \\[P(X = 1) = {2 \\choose 1}0.5^1{0.5}^{2-1} = 0.5\\]"
  },
  {
    "objectID": "slides/08-inference.html#mathematical-representation",
    "href": "slides/08-inference.html#mathematical-representation",
    "title": "Inference for regression",
    "section": "Mathematical representation",
    "text": "Mathematical representation\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/08-inference.html#expected-value-of-mathbfy",
    "href": "slides/08-inference.html#expected-value-of-mathbfy",
    "title": "Inference for regression",
    "section": "Expected value of \\(\\mathbf{y}\\)",
    "text": "Expected value of \\(\\mathbf{y}\\)\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(E(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/08-inference.html#variance",
    "href": "slides/08-inference.html#variance",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of independent random variables.\n\n\nThen \\(Var(\\mathbf{b}) = \\begin{bmatrix}Var(b_1) & 0 & \\dots & 0 \\\\ 0 & Var(b_2) & \\dots & 0 \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ 0 & 0 & \\dots & Var(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(Var(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/08-inference.html#assumptions-of-regression",
    "href": "slides/08-inference.html#assumptions-of-regression",
    "title": "Inference for regression",
    "section": "Assumptions of regression",
    "text": "Assumptions of regression\n\n\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another."
  },
  {
    "objectID": "slides/08-inference.html#estimating-sigma2_epsilon",
    "href": "slides/08-inference.html#estimating-sigma2_epsilon",
    "title": "Inference for regression",
    "section": "Estimating \\(\\sigma^2_{\\epsilon}\\)",
    "text": "Estimating \\(\\sigma^2_{\\epsilon}\\)\n\nOnce we fit the model, we can use the residuals to estimate \\(\\sigma_{\\epsilon}^2\\)\n\\(\\hat{\\sigma}^2_{\\epsilon}\\) is needed for hypothesis testing and constructing confidence intervals for regression\n\n\\[\n\\hat{\\sigma}^2_\\epsilon = \\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-p-1} = \\frac{\\sum_\\limits{i=1}^ne_i^2}{n - p - 1} = \\frac{SSR}{n - p - 1}\n\\]\n\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) is a measure of the average distance between the observations and regression line\n\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#inference-for-beta_j",
    "href": "slides/08-inference.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?\n\n\nBut first we need to understand the distribution of \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "slides/08-inference.html#sampling-distribution-of-hatbeta",
    "href": "slides/08-inference.html#sampling-distribution-of-hatbeta",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}\\)\n\nA sampling distribution is the probability distribution of a statistic based on a large number of random samples of size \\(n\\) from a population\nThe sampling distribution of \\(\\hat{\\boldsymbol{\\beta}}\\) is the probability distribution of the estimated coefficients if we repeatedly took samples of size \\(n\\) and fit the regression model\n\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\]\n\nThe estimated coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) are normally distributed with\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\hspace{10mm} Var(\\hat{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\boldsymbol{X}^T\\boldsymbol{X})^{-1}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/08-inference.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/08-inference.html#steps-for-a-hypothesis-test",
    "href": "slides/08-inference.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion."
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\nWe will generally test the hypotheses:\n\\[\n\\begin{aligned}\n&H_0: \\beta_j = 0 \\\\\n&H_a: \\beta_j \\neq 0\n\\end{aligned}\n\\]\n\nState these hypotheses in words."
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\n\\text{Test Statstic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\nIf \\(\\sigma^2_{\\epsilon}\\) was known, the test statistic would be\n\\[Z = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\sigma^2_\\epsilon C_{jj}}} ~\\sim ~ N(0, 1)\n\\]\n\n\nIn general, \\(\\sigma^2_{\\epsilon}\\) is not known, so we use \\(\\hat{\\sigma}_{\\epsilon}^2\\) to calculate \\(SE(\\hat{\\beta}_j)\\)\n\\[T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n\\]"
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic-1",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-test-statistic-1",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\n\nThe test statistic \\(T\\) follows a \\(t\\) distribution with \\(n - p -1\\) degrees of freedom.\nWe need to account for the additional variability introduced by calculating \\(SE(\\hat{\\beta}_j)\\) using an estimated value instead of a constant"
  },
  {
    "objectID": "slides/08-inference.html#t-vs.-n01",
    "href": "slides/08-inference.html#t-vs.-n01",
    "title": "Inference for regression",
    "section": "t vs. N(0,1)",
    "text": "t vs. N(0,1)\n\n\nFigure 1: Standard normal vs. t distributions"
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): P-value",
    "text": "Hypothesis test for \\(\\beta_j\\): P-value\nThe p-value is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n- p - 1\\) degrees of freedom\n\n\nWhy do we take into account “extreme” on both the high and low ends?"
  },
  {
    "objectID": "slides/08-inference.html#understanding-the-p-value",
    "href": "slides/08-inference.html#understanding-the-p-value",
    "title": "Inference for regression",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/08-inference.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/08-inference.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\nThere are two parts to the conclusion\n\nMake a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( \\(\\alpha\\) level)\n\nIf \\(\\text{P-value} &lt; \\alpha\\): Reject \\(H_0\\)\nIf \\(\\text{P-value} \\geq \\alpha\\): Fail to reject \\(H_0\\)\n\nState the conclusion in the context of the data"
  },
  {
    "objectID": "slides/08-inference.html#recap",
    "href": "slides/08-inference.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures\nConducted inference on a single coefficient\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-05.html#goals",
    "href": "slides/lab-05.html#goals",
    "title": "Lab 05",
    "section": "Goals",
    "text": "Goals\n\nReview AE 06\nLooking ahead - project presentations\nLab 05: Expanding multiple linear regression"
  },
  {
    "objectID": "slides/lab-05.html#ae-06",
    "href": "slides/lab-05.html#ae-06",
    "title": "Lab 05",
    "section": "AE 06",
    "text": "AE 06\n\n📋 sta221-fa24.netlify.app/ae/ab-06-prob-odds\n\n\nExplore the relationship between performance rating and likelihood of promotion\nWe will review Exercises 4 and 5\n\nResponses on Google Slide"
  },
  {
    "objectID": "slides/lab-05.html#next-weeks-lab-project-presentations",
    "href": "slides/lab-05.html#next-weeks-lab-project-presentations",
    "title": "Lab 05",
    "section": "Next week’s lab: Project Presentations",
    "text": "Next week’s lab: Project Presentations\n\n5 - 8 minute presentation about your project\n\nIntroduce subject matter and research question\nHighlights from exploratory data analysis\nModeling strategy / initial modeling (if available)\nAny questions you’d like to get feedback on\n\n\nSee project instructions for more detail."
  },
  {
    "objectID": "slides/lab-05.html#lab-05-expanding-multiple-linear-regression",
    "href": "slides/lab-05.html#lab-05-expanding-multiple-linear-regression",
    "title": "Lab 05",
    "section": "Lab 05: Expanding multiple linear regression",
    "text": "Lab 05: Expanding multiple linear regression\nThis lab focuses on\n\nmodeling complex data using variable transformations, categorical predictors and interactions, and various model specifications.\nevaluating model diagnostics and conditions.\n\n🔗 https://sta221-fa24.netlify.app/labs/lab-05"
  },
  {
    "objectID": "slides/lab-05.html#reminder-tips-for-working-on-a-team",
    "href": "slides/lab-05.html#reminder-tips-for-working-on-a-team",
    "title": "Lab 05",
    "section": "Reminder: Tips for working on a team",
    "text": "Reminder: Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other.\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/02-slr.html#announcements",
    "href": "slides/02-slr.html#announcements",
    "title": "Simple linear regression",
    "section": "Announcements",
    "text": "Announcements\n\nNo labs on Mon, Sep 2 (Labor Day)\nApplication exercises start Tue, Sep 3\n\nBring fully-charged laptop or device with keyboard\nMake sure you have accepted invite to GitHub course organization\n\nSee website for resources to learn / review R\nOffice hours start Tue, Sep 3"
  },
  {
    "objectID": "slides/02-slr.html#topics",
    "href": "slides/02-slr.html#topics",
    "title": "Simple linear regression",
    "section": "Topics",
    "text": "Topics\n\nHow regression is used to understand the relationship between multiple variables\nLeast squares estimation for the slope and intercept\nInterpret the slope and intercept\nPredict the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr.html#computing-set-up",
    "href": "slides/02-slr.html#computing-set-up",
    "title": "Simple linear regression",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)        # for data wrangling\nlibrary(broom)            # for formatting regression output\nlibrary(fivethirtyeight)  # for the fandango dataset\nlibrary(knitr)            # for formatting tables\nlibrary(patchwork)        # for arranging graphs\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/02-slr.html#movie-scores",
    "href": "slides/02-slr.html#movie-scores",
    "title": "Simple linear regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/02-slr.html#data-prep",
    "href": "slides/02-slr.html#data-prep",
    "title": "Simple linear regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/02-slr.html#data-overview",
    "href": "slides/02-slr.html#data-overview",
    "title": "Simple linear regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"A…\n$ year                       &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ critics                    &lt;int&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,…\n$ audience                   &lt;int&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,…\n$ metacritic                 &lt;int&gt; 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,…\n$ metacritic_user            &lt;dbl&gt; 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8…\n$ imdb                       &lt;dbl&gt; 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4…\n$ fandango_stars             &lt;dbl&gt; 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5…\n$ fandango_ratingvalue       &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0…\n$ rt_norm                    &lt;dbl&gt; 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4…\n$ rt_user_norm               &lt;dbl&gt; 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3…\n$ metacritic_norm            &lt;dbl&gt; 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4…\n$ metacritic_user_nom        &lt;dbl&gt; 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3…\n$ imdb_norm                  &lt;dbl&gt; 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3…\n$ rt_norm_round              &lt;dbl&gt; 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0…\n$ rt_user_norm_round         &lt;dbl&gt; 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0…\n$ metacritic_norm_round      &lt;dbl&gt; 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0…\n$ metacritic_user_norm_round &lt;dbl&gt; 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5…\n$ imdb_norm_round            &lt;dbl&gt; 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5…\n$ metacritic_user_vote_count &lt;int&gt; 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54…\n$ imdb_user_vote_count       &lt;int&gt; 271107, 65709, 103660, 3136, 19560, 39373, …\n$ fandango_votes             &lt;int&gt; 14846, 12640, 12055, 1793, 1021, 397, 252, …\n$ fandango_difference        &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…"
  },
  {
    "objectID": "slides/02-slr.html#univariate-exploratory-data-analysis-eda",
    "href": "slides/02-slr.html#univariate-exploratory-data-analysis-eda",
    "title": "Simple linear regression",
    "section": "Univariate exploratory data analysis (EDA)",
    "text": "Univariate exploratory data analysis (EDA)\nThe data set contains the “Tomatometer” score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/02-slr.html#bivariate-eda",
    "href": "slides/02-slr.html#bivariate-eda",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/02-slr.html#bivariate-eda-1",
    "href": "slides/02-slr.html#bivariate-eda-1",
    "title": "Simple linear regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/02-slr.html#why-fit-a-line",
    "href": "slides/02-slr.html#why-fit-a-line",
    "title": "Simple linear regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n\n\nPrediction\n\n\nWhat is an example of a prediction question for this data set?\n\n\n\n\n\nInference\n\n\nWhat is an example of an inference question for this data set?"
  },
  {
    "objectID": "slides/02-slr.html#terminology",
    "href": "slides/02-slr.html#terminology",
    "title": "Simple linear regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, \\(Y\\): variable describing the outcome of interest\nPredictor, \\(X\\): variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/02-slr.html#regression-model",
    "href": "slides/02-slr.html#regression-model",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{f(X)} + \\epsilon \\\\[8pt]\n& = \\color{black}{E(Y|X)} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mu_{Y|X}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr.html#regression-model-1",
    "href": "slides/02-slr.html#regression-model-1",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\epsilon \\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\epsilon \\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\epsilon \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\\(E(Y|X) = \\mu_{Y|X}\\), the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/02-slr.html#regression-model-2",
    "href": "slides/02-slr.html#regression-model-2",
    "title": "Simple linear regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{f(X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{E(Y|X)} + \\color{blue}{\\epsilon}\\\\[8pt]\n&= \\color{purple}{\\mu_{Y|X}} + \\color{blue}{\\epsilon} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#determine-fx",
    "href": "slides/02-slr.html#determine-fx",
    "title": "Simple linear regression",
    "section": "Determine \\(f(X)\\)",
    "text": "Determine \\(f(X)\\)\n\nGoal: Determine \\(f(X)\\)\nHow do we determine \\(f(X)\\)\n\nMake an assumption about the functional form \\(f(X)\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-slr.html#slr-statistical-model-population",
    "href": "slides/02-slr.html#slr-statistical-model-population",
    "title": "Simple linear regression",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[\\large{Y = \\mathbf{\\beta_0 + \\beta_1 X} + \\epsilon}, \\hspace{8mm} \\epsilon \\sim N(0, \\sigma_{\\epsilon}^2)\\]\n\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error"
  },
  {
    "objectID": "slides/02-slr.html#slr-regression-equation-sample",
    "href": "slides/02-slr.html#slr-regression-equation-sample",
    "title": "Simple linear regression",
    "section": "SLR: Regression equation (sample)",
    "text": "SLR: Regression equation (sample)\n\\[\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}\\]\n\n\\(\\hat{\\beta}_1\\): Estimated (sample) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated (sample) intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!"
  },
  {
    "objectID": "slides/02-slr.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "href": "slides/02-slr.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "title": "Simple linear regression",
    "section": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/02-slr.html#residuals",
    "href": "slides/02-slr.html#residuals",
    "title": "Simple linear regression",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/02-slr.html#least-squares-line",
    "href": "slides/02-slr.html#least-squares-line",
    "title": "Simple linear regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals\n\nClick here for full calculations."
  },
  {
    "objectID": "slides/02-slr.html#properties-of-least-squares-regression",
    "href": "slides/02-slr.html#properties-of-least-squares-regression",
    "title": "Simple linear regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/02-slr.html#estimating-the-slope",
    "href": "slides/02-slr.html#estimating-the-slope",
    "title": "Simple linear regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\n\\begin{aligned} s_X = 30.1688  \\hspace{15mm} &s_Y =  20.0244 \\hspace{15mm} r  = 0.7814 \\\\[10pt]\\hat{\\beta}_1  &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\&= \\mathbf{0.5187}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#estimating-the-intercept",
    "href": "slides/02-slr.html#estimating-the-intercept",
    "title": "Simple linear regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n\n\\[\n\\begin{aligned}\\bar{x} = 60.8493 & \\hspace{15mm} \\bar{y} = 63.8767 \\hspace{15mm} \\hat{\\beta}_1 = 0.5187 \\\\[10pt]\n\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= \\mathbf{32.3142}\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/02-slr.html#interpretation",
    "href": "slides/02-slr.html#interpretation",
    "title": "Simple linear regression",
    "section": "Interpretation",
    "text": "Interpretation\n\nQuestionSubmit\n\n\n\n\nSubmit your answers to the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/62513/discussion/5181157"
  },
  {
    "objectID": "slides/02-slr.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/02-slr.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple linear regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n\n\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/02-slr.html#making-a-prediction",
    "href": "slides/02-slr.html#making-a-prediction",
    "title": "Simple linear regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= \\mathbf{68.6232}\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/02-slr.html#fit-the-model",
    "href": "slides/02-slr.html#fit-the-model",
    "title": "Simple linear regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/02-slr.html#tidy-results",
    "href": "slides/02-slr.html#tidy-results",
    "title": "Simple linear regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the data\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/02-slr.html#format-results",
    "href": "slides/02-slr.html#format-results",
    "title": "Simple linear regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/02-slr.html#prediction-1",
    "href": "slides/02-slr.html#prediction-1",
    "title": "Simple linear regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297 \n\n\n\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/02-slr.html#recap",
    "href": "slides/02-slr.html#recap",
    "title": "Simple linear regression",
    "section": "Recap",
    "text": "Recap\n\nDescribed how regression is used to understand the relationship between multiple variables\nUsed least squares to estimate the slope and intercept\nInterpreted the slope and intercept for simple linear regression\nPredicted the response given a value of the predictor"
  },
  {
    "objectID": "slides/02-slr.html#next-time",
    "href": "slides/02-slr.html#next-time",
    "title": "Simple linear regression",
    "section": "Next time",
    "text": "Next time\n\nModel assessment for simple linear regression\n\nSee Sep 3 prepare\n\nBring fully-charged laptop or device with keyboard for in-class application exercise (AE)\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-01.html#getting-started",
    "href": "slides/lab-01.html#getting-started",
    "title": "Lab 01",
    "section": "Getting started",
    "text": "Getting started\nAsk your TA if\n\nYou do not have a lab-01 repo in the GitHub course organization: github.com/sta221-fa24\nYou need help cloning the repo and starting a new RStudio project"
  },
  {
    "objectID": "slides/lab-01.html#tips-for-working-on-lab",
    "href": "slides/lab-01.html#tips-for-working-on-lab",
    "title": "Lab 01",
    "section": "Tips for working on lab",
    "text": "Tips for working on lab\n\nYou do not have to finish the lab in class, they will always be due Thursdays at 11:59pm. One work strategy is to get through portions that you think will be most challenging (which initially might be the coding component) during lab when a TA can help you on the spot and leave the narrative writing until later.\nDo not pressure each other to finish early (particularly once you start working on teams); use the time wisely to really learn the material and produce a quality report."
  },
  {
    "objectID": "slides/lab-01.html#workflow-and-formatting",
    "href": "slides/lab-01.html#workflow-and-formatting",
    "title": "Lab 01",
    "section": "Workflow and formatting",
    "text": "Workflow and formatting\nPart of the lab grade is for “workflow and formatting” assessing the reproducible workflow and document format. This includes\n\nHaving at least 3 informative commit messages (practicing version control)\n\nThere are markers in Lab 01 to help you incorporate version control in your workflow\n\nThe PDF is neatly organized document with clear exercise headings and readable code and narrative\nThe name (first and last) and date are updated at the top of the document."
  },
  {
    "objectID": "slides/lab-01.html#when-youre-done-with-lab",
    "href": "slides/lab-01.html#when-youre-done-with-lab",
    "title": "Lab 01",
    "section": "When you’re done with lab",
    "text": "When you’re done with lab\n\nMake sure all your final changes have been pushed to your GitHub repo\nSubmit your final PDF to Gradescope\n\nAccess Gradescope through the course Canvas site\nMark the pages associated with each exercise."
  },
  {
    "objectID": "slides/lab-01.html#lab-01-park-access",
    "href": "slides/lab-01.html#lab-01-park-access",
    "title": "Lab 01",
    "section": "Lab 01: Park access",
    "text": "Lab 01: Park access\nToday’s lab focuses on exploratory data analysis and simple linear regression, content from Weeks 01 and 02 in the course.\n🔗 sta221-fa24.netlify.app/labs/lab-01.html\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#announcements",
    "href": "slides/04-slr-model-assessment-contd.html#announcements",
    "title": "SLR: Model assessment cont’d",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours start this week. See schedule on Overview page of the course website or on Canvas.\nLabs resume Monday, September 09"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#topics",
    "href": "slides/04-slr-model-assessment-contd.html#topics",
    "title": "SLR: Model assessment cont’d",
    "section": "Topics",
    "text": "Topics\n\nEvaluate models using RMSE and \\(R^2\\)\nUse analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#computing-set-up",
    "href": "slides/04-slr-model-assessment-contd.html#computing-set-up",
    "title": "SLR: Model assessment cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling (includes broom, yardstick, and other packages)\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#data-houses-in-duke-forest",
    "href": "slides/04-slr-model-assessment-contd.html#data-houses-in-duke-forest",
    "title": "SLR: Model assessment cont’d",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#regression-model",
    "href": "slides/04-slr-model-assessment-contd.html#regression-model",
    "title": "SLR: Model assessment cont’d",
    "section": "Regression model",
    "text": "Regression model\n\nduke_forest_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(duke_forest_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000\n\n\n\n\n\n\n\nWe fit a model but is it any good?"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#two-statistics",
    "href": "slides/04-slr-model-assessment-contd.html#two-statistics",
    "title": "SLR: Model assessment cont’d",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#rmse",
    "href": "slides/04-slr-model-assessment-contd.html#rmse",
    "title": "SLR: Model assessment cont’d",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#analysis-of-variance-anova",
    "href": "slides/04-slr-model-assessment-contd.html#analysis-of-variance-anova",
    "title": "SLR: Model assessment cont’d",
    "section": "ANOVA",
    "text": "ANOVA\nAnalysis of Variance (ANOVA): Technique to partition variability in \\(Y\\) by the sources of variability"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#total-variability-response",
    "href": "slides/04-slr-model-assessment-contd.html#total-variability-response",
    "title": "SLR: Model assessment cont’d",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\nGoal: Quantify how much variability in price is accounted for by the model (area) and how much accounted for by factors not included in the model."
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#partition-variability-in-price",
    "href": "slides/04-slr-model-assessment-contd.html#partition-variability-in-price",
    "title": "SLR: Model assessment cont’d",
    "section": "Partition variability in price",
    "text": "Partition variability in price\nFor now, let’s focus on two observations"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#total-variability-response-1",
    "href": "slides/04-slr-model-assessment-contd.html#total-variability-response-1",
    "title": "SLR: Model assessment cont’d",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\\[\\text{Sum of Squares Total (SST)} = \\sum_{i=1}^n(y_i - \\bar{y})^2 = (n-1)s_y^2\\]"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#explained-variability-model",
    "href": "slides/04-slr-model-assessment-contd.html#explained-variability-model",
    "title": "SLR: Model assessment cont’d",
    "section": "Explained variability (Model)",
    "text": "Explained variability (Model)\n\n\\[\\text{Sum of Squares Model (SSM)} = \\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2\\]"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#unexplained-variability-residuals",
    "href": "slides/04-slr-model-assessment-contd.html#unexplained-variability-residuals",
    "title": "SLR: Model assessment cont’d",
    "section": "Unexplained variability (Residuals)",
    "text": "Unexplained variability (Residuals)\n\n\\[\\text{Sum of Squares Residuals (SSR)} = \\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2\\]"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#sum-of-squares",
    "href": "slides/04-slr-model-assessment-contd.html#sum-of-squares",
    "title": "SLR: Model assessment cont’d",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nNote\n\n\nSee Sum of Squares for mathematical details showing \\(SST = SSM + SSR\\)."
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#r2",
    "href": "slides/04-slr-model-assessment-contd.html#r2",
    "title": "SLR: Model assessment cont’d",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\\large{R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}}\\]\n\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#interpreting-r2",
    "href": "slides/04-slr-model-assessment-contd.html#interpreting-r2",
    "title": "SLR: Model assessment cont’d",
    "section": "Interpreting $R^2$",
    "text": "Interpreting $R^2$\n\nQuestionSubmit\n\n\n\nSubmit your response to the following question on Ed Discussion.\n\nThe \\(R^2\\) of the model for price from area of houses in Duke Forest is 44.5%. Which of the following is the correct interpretation of this value?\n\nArea correctly predicts 44.5% of price for houses in Duke Forest.\n44.5% of the variability in price for houses in Duke Forest can be explained by area.\n44.5% of the variability in area for houses in Duke Forest can be explained by price.\n44.5% of the time price for houses in Duke Forest can be predicted by area.\n\nDo you think this model is useful for explaining variability in the price of Duke Forest houses?\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/62513/discussion/629888"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#augmented-data-frame",
    "href": "slides/04-slr-model-assessment-contd.html#augmented-data-frame",
    "title": "SLR: Model assessment cont’d",
    "section": "Augmented data frame",
    "text": "Augmented data frame\nUse the augment() function from the broom package (part of tidymodels) to add columns for predicted values, residuals, and other observation-level model statistics\n\n\nduke_forest_aug &lt;- augment(duke_forest_fit)\nduke_forest_aug\n\n# A tibble: 98 × 8\n     price  area  .fitted  .resid   .hat  .sigma   .cooksd .std.resid\n     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 1520000  6040 1079931. 440069. 0.133  162605. 0.604         2.80  \n 2 1030000  4475  830340. 199660. 0.0435 168386. 0.0333        1.21  \n 3  420000  1745  394951.  25049. 0.0226 169664. 0.000260      0.150 \n 4  680000  2091  450132. 229868. 0.0157 168011. 0.0150        1.37  \n 5  428500  1772  399257.  29243. 0.0220 169657. 0.000345      0.175 \n 6  456000  1950  427645.  28355. 0.0182 169659. 0.000266      0.170 \n 7 1270000  3909  740072. 529928. 0.0250 160502. 0.130         3.18  \n 8  557450  2841  569744. -12294. 0.0102 169679. 0.0000277    -0.0732\n 9  697500  3924  742465. -44965. 0.0254 169620. 0.000948     -0.270 \n10  650000  2173  463209. 186791. 0.0145 168582. 0.00912       1.11  \n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#finding-rmse-in-r",
    "href": "slides/04-slr-model-assessment-contd.html#finding-rmse-in-r",
    "title": "SLR: Model assessment cont’d",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     167067.\n\n\n\n\nWhat does this value mean?"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#finding-r2-in-r",
    "href": "slides/04-slr-model-assessment-contd.html#finding-r2-in-r",
    "title": "SLR: Model assessment cont’d",
    "section": "Finding \\(R^2\\) in R",
    "text": "Finding \\(R^2\\) in R\nUse the rsq() function from the yardstick package (part of tidymodels)\n\nrsq(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.445\n\n\n\n\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\)\n\nglance(duke_forest_fit)$r.squared\n\n[1] 0.4451945"
  },
  {
    "objectID": "slides/04-slr-model-assessment-contd.html#recap",
    "href": "slides/04-slr-model-assessment-contd.html#recap",
    "title": "SLR: Model assessment cont’d",
    "section": "Recap",
    "text": "Recap\n\nEvaluated models using RMSE and \\(R^2\\)\nUsed analysis of variance to partition variability in the response variable\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-02.html#goals",
    "href": "slides/lab-02.html#goals",
    "title": "Lab 02",
    "section": "Goals",
    "text": "Goals\n\nLaTex in this course\nMeet your team!\nTeam agreement\nLab 02: Childcare costs"
  },
  {
    "objectID": "slides/lab-02.html#latex-in-this-class",
    "href": "slides/lab-02.html#latex-in-this-class",
    "title": "Lab 02",
    "section": "LaTex in this class",
    "text": "LaTex in this class\nFor this class you will need to be able to…\n\nProperly write mathematical symbols, e.g., \\(\\beta_1\\) not B1, \\(R^2\\) not R2\nWrite basic regression equations, e.g., \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\nWrite matrix equations: \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\nWrite hypotheses (we’ll start this next week), e.g., \\(H_0: \\beta = 0\\)\n\nYou are welcome to but not required to write math proofs using LaTex."
  },
  {
    "objectID": "slides/lab-02.html#writing-latex-from-ae-02",
    "href": "slides/lab-02.html#writing-latex-from-ae-02",
    "title": "Lab 02",
    "section": "Writing LaTex (from AE 02)",
    "text": "Writing LaTex (from AE 02)\nInline: Your mathematics will display within the line of text.\n\nUse $ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Inline Math.\nExample: The text The simple linear regression model is $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$ produces\nThe simple linear regression model is \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/lab-02.html#writing-latex-from-ae-02-1",
    "href": "slides/lab-02.html#writing-latex-from-ae-02-1",
    "title": "Lab 02",
    "section": "Writing LaTex (from AE 02)",
    "text": "Writing LaTex (from AE 02)\nDisplay: Your mathematics will display outside the line of text\n\nUse a $$ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Display Math.\nExample: The text The estimated regression equation is $$\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$$ produces\nThe estimated regression equation is\n\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\]\n\n\n\n\n\n\nTip\n\n\nClick here for a quick reference of LaTex code."
  },
  {
    "objectID": "slides/lab-02.html#meet-your-team",
    "href": "slides/lab-02.html#meet-your-team",
    "title": "Lab 02",
    "section": "Meet your team!",
    "text": "Meet your team!\n\nClick here to find your team.\nSit with your team."
  },
  {
    "objectID": "slides/lab-02.html#team-name-agreement",
    "href": "slides/lab-02.html#team-name-agreement",
    "title": "Lab 02",
    "section": "Team name + agreement",
    "text": "Team name + agreement\n\nCome up with a team name. You can’t have the same name as another group in the class, so be creative!\n\nYour TA will get your team name by the end of lab.\n\nFill out the team agreement. The goals of the agreement are to…\n\nGain a common understanding of the team’s goals and expectations for collaboration\nMake a plan for team communication\nMake a plan for working outside of lab"
  },
  {
    "objectID": "slides/lab-02.html#team-workflow",
    "href": "slides/lab-02.html#team-workflow",
    "title": "Lab 02",
    "section": "Team workflow",
    "text": "Team workflow\n\nOnly one team member should type at a time. There are markers in today’s lab to help you determine whose turn it is to type.\n\nEvery team member should still be engaged in discussion for all questions, even if it’s not your turn type.\n\nDon’t forget to pull to get your teammates’ updates before making changes to the .qmd file.\n\n\n\n\n\n\nImportant\n\n\nOnly one submission per team on Gradescope. Read the submission instructions carefully!"
  },
  {
    "objectID": "slides/lab-02.html#team-workflow-in-action",
    "href": "slides/lab-02.html#team-workflow-in-action",
    "title": "Lab 02",
    "section": "Team workflow, in action",
    "text": "Team workflow, in action\n\nComplete the “Workflow: Using Git and GitHub as a team” section of the lab in your teams.\nRaise your hand if you have any questions about the workflow.\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lab-02.html#tips-for-working-on-a-team",
    "href": "slides/lab-02.html#tips-for-working-on-a-team",
    "title": "Lab 02",
    "section": "Tips for working on a team",
    "text": "Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other."
  },
  {
    "objectID": "slides/lab-02.html#lab-02-childcare-costs",
    "href": "slides/lab-02.html#lab-02-childcare-costs",
    "title": "Lab 02",
    "section": "Lab 02: Childcare costs",
    "text": "Lab 02: Childcare costs\nToday’s lab focuses on using multiple linear regression (Week 03 content) to predict childcare costs for school-aged children in North Carolina.\n🔗 sta221-fa24.netlify.app/labs/lab-02.html\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may me at maria.tackett@duke.edu. If you email me, please include “STA 221” in the subject line. Barring extenuating circumstances, I will respond to STA 221 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-canvas",
    "href": "support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "ae/ae-01-slr.html",
    "href": "ae/ae-01-slr.html",
    "title": "AE 01: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-01 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\n\nThis AE will not count towards your participation grade.\nlibrary(tidyverse)    # data wrangling and visualization\nlibrary(tidymodels)   # broom and yardstick package\nlibrary(openintro)    # duke_forest dataset\nlibrary(knitr)        # format output\nlibrary(scales)       # format plot axes\nlibrary(skimr)        # quickly calculate summary statistics"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-1",
    "href": "ae/ae-01-slr.html#exercise-1",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhat are 1 - 2 observations about the distribution of price?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-2",
    "href": "ae/ae-01-slr.html#exercise-2",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nVisualize the distribution of area and calculate summary statistics.\n\n# add code here\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-3",
    "href": "ae/ae-01-slr.html#exercise-3",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat are 1 - 2 observations about the distribution of area?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-4",
    "href": "ae/ae-01-slr.html#exercise-4",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nFill in the code to visualize the relationship between price and area. What are 1 - 2 observations about the relationship between these two variables?\n\n\n\n\n\n\nImportant\n\n\n\nRemove #|eval: false after you have filled in the code!\n\n\n\nggplot(duke_forest, aes(x = ____, y = ____)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"_______\",\n    y = \"_________\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-5",
    "href": "ae/ae-01-slr.html#exercise-5",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nYou want to fit a model of the form\n\\[\nprice = \\beta_0 + \\beta_1 ~ area + \\epsilon, \\hspace{5mm} \\epsilon \\sim N(0, \\sigma^2_\\epsilon)\n\\]\nWould a model of this form be a reasonable fit for the data? Why or why not?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-6",
    "href": "ae/ae-01-slr.html#exercise-6",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nFit the linear model described in the previous exercise and neatly display the output.\nSee notes for example code.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-7",
    "href": "ae/ae-01-slr.html#exercise-7",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nInterpret the slope in the context of the data.\nInterpret the slope in terms of area increasing by 100 sqft.\nWhich interpretation do you think is more meaningful in practice?"
  },
  {
    "objectID": "ae/ae-01-slr.html#exercise-8",
    "href": "ae/ae-01-slr.html#exercise-8",
    "title": "AE 01: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nDoes it make sense to interpret the intercept? If so, interpret it in the context of the data. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-06-prob-odds.html",
    "href": "ae/ae-06-prob-odds.html",
    "title": "AE 06: Probabilities, Odds, Odds ratios",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-06 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-06-prob-odds.html#footnotes",
    "href": "ae/ae-06-prob-odds.html#footnotes",
    "title": "AE 06: Probabilities, Odds, Odds ratios",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExcerpt from Chapter 5 of Handbook of Regression Modeling in People Analytics by Keith McNulty.↩︎"
  },
  {
    "objectID": "ae/ae-03-inference.html",
    "href": "ae/ae-03-inference.html",
    "title": "AE 03: Inference",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\n\n\n\nSet up\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")\n\n\n\nData\n\n\nRegression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\n\ntidy(exp_fit)|&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\n\nHypothesis test\nWe want to conduct a hypothesis test to determine if there is a linear relationship between enrollment and football expenditures after accounting for institution type.\nWe’ll start by getting estimates for statistics we’ll need for inference.\n\n\n\n\n\n\nExercise 1\n\n\n\nWe will use the vector of responses \\(\\mathbf{y}\\) and the design matrix \\(\\mathbf{X}\\) to calculate the values needed for inference.\nGet \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the football data frame. What are their dimensions?\n\n\n\n# add code here\n\n\n\n\n\n\n\nExercise 2\n\n\n\nNext, let’s calculate \\(\\hat{\\sigma}_\\epsilon^2\\) the estimate. Use \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) from the previous exercise to calculate this value.\n\n\n\n## add code here\n\n\n\n\n\n\n\nExercise 3\n\n\n\nNow we’re ready to conduct the hypothesis test. State the null and alternative hypotheses in words and using mathematical notation.\n\n\n. . .\n\n\n\n\n\n\nExercise 4\n\n\n\nCalculate \\(SE(\\beta_j)\\), then use this value to calculate the test statistic for the hypothesis test.\n\n\n\n## add code here\n\n\n\n\n\n\n\nExercise 5\n\n\n\nNow we need to calculate p-value to help make our final conclusion.\n\nState the distribution used to calculate the p-value.\nFill in the code below to calculate the p-value. Remove #| eval: false once you’ve filled in the code.\n\n\n\n\npt([test-statistic], [df], lower.tail = FALSE)\n\n\n\n\n\n\n\nExercise 6\n\n\n\nState your conclusion in the context of the data. Use a threshold of \\(\\alpha = 0.05\\).\n\n\n. . .\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "prepare/prepare-nov5.html",
    "href": "prepare/prepare-nov5.html",
    "title": "Wellness day",
    "section": "",
    "text": "Below are suggested activities during lecture on November 5.\n\nCatch up on / review course content\nWork on Lab 05 with your team\nWork on the project presentation with your team\nWork on the statistics experience assignment\nParticipate in a DuWell Wellness Event\nParticipate in Election Day activities as you are able"
  },
  {
    "objectID": "prepare/prepare-aug29.html",
    "href": "prepare/prepare-aug29.html",
    "title": "Prepare for August 29 lecture",
    "section": "",
    "text": "📖 Read Simple Linear Regression\n✅ Complete Lab 00 tasks"
  },
  {
    "objectID": "prepare/prepare-sep3.html",
    "href": "prepare/prepare-sep3.html",
    "title": "Prepare for September 3 lecture",
    "section": "",
    "text": "📖 Read Section 4.7: Model Assessment\n✅ Go through R resource (optional)"
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, November 26 at 11:59pm on Gradescope.\nThe world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience.\n2️⃣ Make a slide reflecting on your experience.\nYou must complete both parts to receive credit. The statistics experience will count as a homework grade.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf talks\n\n2022 conference\n2021 conference\n2020 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask Professor Tackett if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask Professor Tackett to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: CURV - connecting, uplifting, and recognizing voices\nCURV is a project by Dr. Jo Hardin at Pomona College to highlight statisticians and data scientists from groups who have been historically marginalized in the discipline. \n\n\n\n\n\n\nFor this statistics experience, you can contribute to the CURV data base. If there is a scholar you would like to suggest for the data base, submit your suggestion as an issue or pull request on the CURV GitHub repo and create a sample CURV page.\nA few guidelines:\n✅ Create a draft of the CURV page for your suggested scholar. For reference, click here for the CURV page for W.E.B. Du Bois. The page must be created in a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nYou can find the Quarto documents for current scholars in the data base in the CURV GitHub repo. You can use one of these as a template to format your page.\n\n\n✅ Make a pull request to the CURV GitHub repo to add the .qmd file for your suggested scholar, OR open an issue with a link to the .qmd file for your suggested scholar. You can ask a member of the teaching team if you have questions about how to do this.\n✅ Include the URL to your pull request or issue in your one-slide reflection.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "href": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "title": "Statistics Experience",
    "section": "Part 2: Reflect on your experience",
    "text": "Part 2: Reflect on your experience\nMake one slide summarizing and reflecting on your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nDescription of the experience\n\nName and brief description of the event/podcast/competition/etc.\n\nSomething you learned\n\nWrite 2 - 4 sentences about something you learned or found particularly interesting or unexpected.\n\nConnection to STA 221\n\nWrite 2 - 4 sentences about how the experience connects to what we’ve done in the course.\n\nCitation or link to web page for event/competition/etc.\n\nNo citation needed if you do an interview.\n\n\nMake sure the slide includes the information mentioned above and is easily readable (i.e. use a reasonable font size!). Creativity on the experience and slide design is encouraged!",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#submission",
    "href": "hw/stats-experience.html#submission",
    "title": "Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the Statistics Experience assignment on Gradescope by Tuesday, November 26 at 11:59pm. Standard homework late policy applies.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, October 31 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#instructions",
    "href": "hw/hw-03.html#instructions",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-1",
    "href": "hw/hw-03.html#exercise-1",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nLet \\(x_1, \\ldots, x_n\\) be independently and identically distributed (i.i.d.) sample observations from a distribution where\n\\[\nf(x | \\theta) = \\theta x^{\\theta - 1} \\hspace{8mm} 0\\leq x\\leq 1, \\hspace{3mm} 0 &lt; \\theta &lt; \\infty\n\\]\nFind the maximum likelihood estimator (MLE) of \\(\\theta\\).",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-2",
    "href": "hw/hw-03.html#exercise-2",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nSuppose you have the linear regression model\n\\[\ny_i = \\beta x_i + \\epsilon_i \\hspace{8mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are i.i.d. and there is no intercept.\n\nFind \\(\\tilde{\\beta}\\) , the MLE of \\(\\beta\\).\nShow that the MLE is unbiased. (Note: You must show this directly and may not use the result from part(c).)\nShow mathematically how \\(\\tilde{\\beta}\\) relates to the least-squares estimator.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-3",
    "href": "hw/hw-03.html#exercise-3",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose there are \\(n\\) observations, such that each \\(y_i\\) is generated from \\(x_i\\) based on the linear model\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\hspace{8mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are i.i.d.\nThe model is reparameterized (redefined) as\n\\[\ny_i = \\beta^{\\prime}_0 + \\beta^{\\prime}_1(x_i - \\bar{x}) + \\epsilon_i\n\\]\nsuch that \\(\\epsilon_i\\) follows the same distribution as the original model.\n\nShow that the MLE of \\(\\beta^{\\prime}_1\\) is equal to the MLE of \\(\\beta_1\\).\nShow that the MLE of \\(\\beta^{\\prime}_0\\) is not equal to the MLE of \\(\\beta_0\\).\nThe predictor in the reparameterized model is mean-centered, i.e., the predictor is shifted by its mean value. Based on your responses to parts (a) and (b), what is one potential benefit for using mean-centered predictors in the model?\n\n\n\n\n\n\n\nTip\n\n\n\nYou do not need to derive the MLEs for \\(\\beta_0\\) and \\(\\beta_1\\). You may use the results from the notes.\nYou do need to show your work / explain your reasoning to get the MLEs for \\(\\beta^{\\prime}_0\\) and \\(\\beta^{\\prime}_1\\) .",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-4",
    "href": "hw/hw-03.html#exercise-4",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 4",
    "text": "Exercise 4\nSuppose we have a model of the form\n\\[\n\\log(y_i) =\\beta_0 + \\beta_1\\log(x_i) + \\epsilon_i \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nDescribe the expected change in \\(y_i\\) when \\(x_i\\) is multiplied by a constant \\(C\\). Show the work used to obtain the expected change.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#instructions-1",
    "href": "hw/hw-03.html#instructions-1",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-sat",
    "href": "hw/hw-03.html#data-sat",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Data: SAT",
    "text": "Data: SAT\nThis data set contains the average SAT score (out of 1600) and other variables that may be associated with SAT performance for each of the 50 U.S. states. The data is based on test takers for the 1982 exam. We will use the following variables:\n\nSAT: average total SAT score\nTakers: percentage of high school seniors who took exam\nIncome: median income of families of test-takers ($ hundreds)\nYears: average number of years test-takers had formal education in social sciences, natural sciences, and humanities\nPublic: percentage of test-takers who attended public high schools\nExpend: total state expenditure on high schools ($ hundreds per student)\nRank: median percentile rank of test-takers within their high school classes\n\nThe data are in the file sat-1982.csv in the data folder.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-5",
    "href": "hw/hw-03.html#exercise-5",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nFit a main effects model using SAT as the response and all other variables (except State) as the predictors. Neatly display the model using 3 digits.\nAre there any influential observations in the data set? Briefly explain showing any work or output used to make the determination.\nConsider the observation with the highest value for Cook’s distance. What is the value of leverage for this observation? Would this be considered large leverage? Briefly explain showing any work or output used to make the determination.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-6",
    "href": "hw/hw-03.html#exercise-6",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nCompute the Variance Inflation Factors (VIF) for the model from the previous exercise.\nDoes this model have any issues with multicollinearity? If so, what predictors appear to be collinear?\nIf multicollinearity is present, select a strategy to fit a model that does not have an issue with multicollinearity.\n\nBriefly describe your strategy.\nSelect a final model.\nBriefly explain your selection, showing any work and output used to choose a model.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-2000-u.s.-presidential-election",
    "href": "hw/hw-03.html#data-2000-u.s.-presidential-election",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Data: 2000 U.S. Presidential Election",
    "text": "Data: 2000 U.S. Presidential Election\nWe will examine data about the 2000 U.S. presidential election between George W. Bush and Al Gore. It was one of the closest elections in history that ultimately came down to the state of Florida. One county in particular, Palm Beach County, was at the center of the controversy due to the design of their ballots - the infamous butterfly ballots. It is believed that many people who intended to vote for Al Gore accidentally voted for Pat Buchanan due to how the spots to mark the candidate were arranged next to the names.\nThe variables in the data are\n\nCounty: County name\nBush2000: Number of votes for George W. Bush\nBuchanan2000: Number of votes for Pat Buchanan\n\nThe data are available in the file florida-votes-2000.csv in the data folder of your repo.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-7",
    "href": "hw/hw-03.html#exercise-7",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 7",
    "text": "Exercise 7\nThe goal is to fit a model that uses the number of votes for Bush to predict the number of votes for Buchanan. Using this model, we’ll investigate whether the data support the claim that votes for Gore may have accidentally gone to Buchanan.\n\nVisualize the relationship between the number of votes for Buchanan versus the number of votes for Bush. Describe what you observe in the visualization, including a description of the relationship between the votes for Buchanan and votes for Bush.\nWhat is the county with the extreme outlier number of votes for Buchanan? Create a new data frame that doesn’t include the outlying county. You will use this updated data frame for the remainder of this exercise and Exercise 8.\nFit a model to predict the number of votes for Buchanan based on the number of votes for Bush in the county.\n\nMake a plot of the standardized residuals versus the fitted values.\nIs the constant variance condition satisfied? Briefly explain.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-8",
    "href": "hw/hw-03.html#exercise-8",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow let’s consider potential models with transformations on the response and/or predictor variables. The four candidate models are the following:\n\n\n\nModel\nResponse variable\nPredictor variable\n\n\n\n\n1 (from previous exercise)\nBuchanan2000\nBush2000\n\n\n2\nlog(Buchanan2000)\nBush2000\n\n\n3\nBuchanan2000\nlog(Bush2000)\n\n\n4\nlog(Buchanan2000)\nlog(Bush2000)\n\n\n\nWhich model best fits the data? Briefly explain, showing any work and output used to determine the response. (Note: Use the data set without the outlying county to find the candidate models.)",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-9",
    "href": "hw/hw-03.html#exercise-9",
    "title": "HW 03: Multiple linear regression cont’d",
    "section": "Exercise 9",
    "text": "Exercise 9\nNow we will use the model to predict the expected number of Buchanan votes for the outlier county.\nSuppose the observed value of the predictor for this county (a new observation) is \\(x_0\\). We define \\(\\mathbf{x}_0^T = [1, x_0]\\)\nThen the predicted response is\n\\[\n\\hat{y}_0 = \\mathbf{x}_0^T\\hat{\\boldsymbol{\\beta}}\n\\]\nWhere \\(\\hat{\\boldsymbol{\\beta}}\\) is the vector of estimated model coefficients.\nJust as there is uncertainty in our model coefficients, there is uncertainty in our predictions as well. We use a confidence interval to quantify the uncertainty for a model coefficient, and we can use a prediction interval to quantify the uncertainty in the prediction for a new observation.\nThe \\(C\\%\\) prediction interval for the new observation is\n\\[\n\\hat{y}_0 \\pm t^*_{n - p - 1}\\sqrt{\\hat{\\sigma}^2_\\epsilon(1 + \\mathbf{x}_0^T(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{x}_0)}\n\\]\nwhere \\(t^*_{n-p-1}\\) is the critical value obtained from the \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom, \\(\\mathbf{X}\\) is the design matrix for the model, and \\(\\hat{\\sigma}^2_\\epsilon\\) is the estimated variability about the regression line.\n\nUse the model you chose in the previous exercise to compute the predicted number of votes for Buchanan in the outlying county identified in Exercise 7. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nCompute the 95% prediction interval for this county. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nIt is assumed that some of the votes for Buchanan in that county were actually intended to be for Gore. Based on your results in the previous question, does your model support this claim?\n\nIf no, briefly explain.\nIf yes, about how many votes were possibly intended for Gore? Show any calculations and output used to determine your answer. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "labs/lab-06.html",
    "href": "labs/lab-06.html",
    "title": "Lab 06",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-04.html",
    "href": "labs/lab-04.html",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, October 24 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-1",
    "href": "labs/lab-04.html#exercise-1",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll start with exploratory data analysis focused on the relationship between the response and predictor variables.\n\nVisualize the relationship between the response variable bill_depth_mm and predictor bill_length_mm .\nNow, visualize the relationship between bill_depth_mm and bill_length_mm by species. Use geom_smooth(method = \"lm\", se = FALSE) to add lines and more clearly visualize the relationship for each species.\nBased on these visualizations, why is it important to include species when in the model of the relationship between bill depth and length? Briefly explain.\nBased on these visualizations, would you include an interaction term between the two predictors? Briefly explain?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-2",
    "href": "labs/lab-04.html#exercise-2",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 2",
    "text": "Exercise 2\nWe will fit the main effects model using bill length and species to understand variability in the bill depth.\n\nWrite the form of the statistical (population-level) model in matrix form.\nWrite the dimensions for \\(\\mathbf{y}, \\mathbf{X}, \\boldsymbol{\\beta}, \\boldsymbol{\\epsilon}\\) specific for this problem.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-3",
    "href": "labs/lab-04.html#exercise-3",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 3",
    "text": "Exercise 3\nConsider the regression model described in Exercise 2.\n\nWrite the likelihood function \\(L(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon} | \\mathbf{y}, \\mathbf{X})\\) in matrix form.\nDescribe how each of the four model assumptions is necessary for the form of the likelihood function.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-4",
    "href": "labs/lab-04.html#exercise-4",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 4",
    "text": "Exercise 4\nBriefly explain how the process of finding the maximum likelihood estimators for the likelihood function in Exercise 3 is related to the process of finding the least-squares estimators for the model in Exercise 2.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-5",
    "href": "labs/lab-04.html#exercise-5",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 5",
    "text": "Exercise 5\nFor the next few exercises, we will compare the results of the maximum likelihood and least-squares procedures.\n\nFit the least-squares regression model described in Exercise 2. Neatly display the results using three digits.\nDescribe the estimated effect of bill length on bill depth in the context of the data.\nDescribe the estimated effect of species on bill depth in the context of the data. Include discussion about whether there is statistical evidence of a difference between species.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-6",
    "href": "labs/lab-04.html#exercise-6",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nUse matrix/vector operations to compute the maximum likelihood estimators \\(\\tilde{\\beta}\\) for the model in Exercise 2.\nHow do these estimators compare to the least-squares estimators in the previous exercise?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-7",
    "href": "labs/lab-04.html#exercise-7",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 7",
    "text": "Exercise 7\nThe maximum likelihood estimation procedure also produces an estimator for the variance about the regression line, \\(\\sigma^2_\\epsilon\\), which we can write as\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{1}{n} \\mathbf{e}^T\\mathbf{e}\n\\]\nWe know that the maximum likelihood estimator and least-squares estimator for \\(\\sigma^2_{\\epsilon}\\) are not equal. Additionally, the least-squares estimator \\(\\hat{\\sigma}^2_{\\epsilon}\\) is unbiased. We want to find a scaling factor \\(c\\) such that the maximum likelihood estimator is unbiased.\nUsing the data and regression estimates for this analysis, compute both the maximum likelihood and least-squares estimators for \\(\\sigma_{\\epsilon}^2\\), and then find \\(c\\) by solving the equation \\[ \\hat\\sigma^2_{\\epsilon} = c \\cdot \\tilde\\sigma^2_{\\epsilon} \\]You can do this last step either computationally or algebraically.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-8",
    "href": "labs/lab-04.html#exercise-8",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow we will look into the last property of the maximum likelihood estimator for \\(\\boldsymbol{\\beta}\\), and thus of least-squares estimator - asymptotic normality.\nIn words, this property says that, when the number of samples \\(n\\) is large compared to the number of predictors \\(p\\), the maximum likelihood estimator \\(\\tilde{\\boldsymbol\\beta}\\) follows a (multivariate) normal distribution \\(N\\big(\\boldsymbol\\beta, \\sigma_\\epsilon^2 (\\mathbf{X}^T\\mathbf{X})^{-1}\\big)\\). Let’s use this to construct an approximate confidence interval for \\(\\beta_j\\), the coefficient for speciesChinstrap.\n\nUse \\(\\tilde{\\sigma}^2_{\\epsilon}\\), the maximum likelihood estimator, to compute the approximate confidence interval for \\(\\beta_j\\) . The approximate 95% confidence interval may be computed as\n\n\\[\n\\tilde{\\beta}_j\\pm 2 \\times SE(\\tilde{\\beta}_j)\n\\]\n\nThen interpret this interval in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-9",
    "href": "labs/lab-04.html#exercise-9",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCompute the exact (based on the \\(t\\)-distribution) confidence interval for \\(\\beta_j\\), the coefficient of speciesChinstrap.\nCompare the center and width of the this exact interval with the one you computed in Exercise 8. Do they differ? By how much? Which one is wider, indicating more uncertainty?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-10",
    "href": "labs/lab-04.html#exercise-10",
    "title": "Lab 04: Maximum likelihood estimation",
    "section": "Exercise 10",
    "text": "Exercise 10\nTo wrap up, we have seen that both the OLS and the maximum likelihood procedures for linear regression produce the same coefficient estimates, but lead to different estimators for the variance \\(\\sigma_\\epsilon^2\\) and allow for different types of uncertainty quantification.\nBased on the work in this lab, do you think performing inference based on either method would have changed your conclusion about the the relationship between bill depth and Chinstrap species?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01: Simple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, September 12 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#learning-goals",
    "href": "labs/lab-01.html#learning-goals",
    "title": "Lab 01: Simple linear regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab, you will…\n\nBe familiar with the workflow using RStudio and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using GitHub\nBe able to produce visualizations and summary statistics to describe distributions\nBe able to fit, interpret, and evaluate simple linear regression models",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 01: Simple linear regression",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta221-fa24 organization on GitHub.\nClick on the repo with the prefix lab-01-. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\n\nSee the Lab 00 instructions if you have not set up the SSH key or configured git.\n\nIn RStudio, go to File \\(\\rightarrow\\) New Project \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#r-and-r-studio",
    "href": "labs/lab-01.html#r-and-r-studio",
    "title": "Lab 01: Simple linear regression",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\n\n\n\n\nBelow are the components of an Quarto (.qmd) file.\n\n\n\n\n\n\nYAML\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n\n\n\n\nCommitting changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you’re happy with these changes, we’ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, “updated author name”) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let’s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!\n\n\nPush changes\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-1",
    "href": "labs/lab-01.html#exercise-1",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe begin with some exploratory data analysis (EDA). As a first step, let’s get a quick summary look at the data using the glimpse function.\nViewing a summary of the data is a useful starting point for analysis, especially if there are a large number of observations or variables.\n\nglimpse(parks)\n\n\nHow many observations are in the parks data frame?\nWhat information is provided in the data about the time and location of the measurements?",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-2",
    "href": "labs/lab-01.html#exercise-2",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe predictor variable for this analysis, spend_per_resident_data, is quantitative; however, from the glimpse of the data in Exercise 1, we see its data type is chr (character) in R. We would expect it to be dbl (double), the data type for numeric data.\nWhy did spend_per_resident_data get read by R as a character data type instead of a double? Be specific.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-3",
    "href": "labs/lab-01.html#exercise-3",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nUse the code below to transform spend_per_resident_data , so that it is correctly treated as quantitative data in R. Write a brief explanation of what each numbered line of code does.\n\n1parks &lt;-\n  parks |&gt;  \n  mutate(spend_per_resident_data = \n2           str_replace(spend_per_resident_data,\"\\\\$\", \"\")) |&gt;\n  mutate(spend_per_resident_data = \n3           as.numeric(spend_per_resident_data))\n\n\n1\n\n______\n\n2\n\n______\n\n3\n\n______\n\n\n\n\n\nThis is a good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g., “Completed exercises 1 - 3”), and push every file to GitHub by clicking the checkbox next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-4",
    "href": "labs/lab-01.html#exercise-4",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nNow we’ll examine the distributions of the variables of interest.\n\nMake a histogram of spend_per_resident_data and calculate summary statistics for this variable.\nComment on the features of the distribution of this variable by describing the shape, center, spread, and presence of potential outliers.\n\n\n\n\n\n\n\nTip\n\n\n\nWhen performing data visualization, make sure that all your plots have clear and informative titles and axis labels. When investigating more complex relationships with many variables, this simple tip will save you and your readers a lot of time and confusion.\n\nSee AE 01 for example code.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-5",
    "href": "labs/lab-01.html#exercise-5",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNext let’s explore the response variable, pct_near_park_points. Visualize the distribution of the variable and calculate summary statistics. Describe the distribution pct_near_park_points.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-6",
    "href": "labs/lab-01.html#exercise-6",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nNow let’s use bivariate exploratory data analysis to look at the relationship between spend_per_resident_data and pct_near_park_points.\n\nMake a scatterplot to visualize the relationship between the two variables.\nDoes there seem to be a relationship between spending and park access? If so, what is the shape and direction of the relationship?\n\n\nThis is a another good place to render, commit, and push changes to your lab-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 4 - 6”), and push every file to GitHub by clicking the checkbox next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-7",
    "href": "labs/lab-01.html#exercise-7",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nWe have seen the mathematical formulation for simple linear regression. In particular, given a response variable \\(Y\\) and predictor variable \\(X\\), the simple linear regression model is \\[Y = \\beta_0 + \\beta_1 X + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\]\nfor some unknown regression coefficients for slope and intercept\\((\\beta_0, \\beta_1)\\). This means that the expected value of each observation lies on the regression line\n\\[ E(Y|X) = \\beta_0 + \\beta_1 X\\]\nAnswer the following questions about simple linear regression. Your response should be in general terms about simple linear, not be specific to the parks data.\n\nWhat does \\(E(Y|X) = \\beta_0 + \\beta_1X\\) mean in terms of a given value of \\(X\\)?\nWhat is the interpretation of the coefficients \\(\\beta_0\\) and \\(\\beta_1\\) in terms of the expected value of \\(Y\\)?",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-8",
    "href": "labs/lab-01.html#exercise-8",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn class we’ve seen how matrices can be used to represent the simple linear model from the previous exercise. In particular\n\\[\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\]\nRecall that the goal is to fit a model that uses spend_per_resident_data to explain variability in park_near_pct_points.Estimate regression coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) for the model using the matrix representation. Show any work and/or code used to get the answer.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-9",
    "href": "labs/lab-01.html#exercise-9",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nNow let’s fit the model using the lm() function in R.\n\nFit the model and neatly display the output using 4 digits.\nInterpret the slope in the context of the data.\nDoes it make sense of the interpret the intercept? If so, interpret the intercept in the context of the data. Otherwise, explain why not.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#exercise-10",
    "href": "labs/lab-01.html#exercise-10",
    "title": "Lab 01: Simple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nDo you think that city expenditure on residents is a useful predictor of park access? Briefly explain your response, reporting any statistics used to make your assessment.\n\nYou’re done and ready to submit your work! render, commit, and push all remaining changes. You can use the commit message “Done with Lab 1!”, and make sure you have pushed all the files to GitHub (your Git pane in RStudio should be empty) and that all documents are updated in your repo on GitHub. The PDF document you submit to Gradescope should be identical to the one in your GitHub repo.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, September 19 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-1",
    "href": "labs/lab-02.html#exercise-1",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet’s start with some exploratory data analysis. Visualize the distribution of the response variable mcsa and calculate summary statistics. Describe the distribution of this variable, including the shape, center, spread, and presence of potential outliers.\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the childcare_train for all analysis in Exercises 1 - 7.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-2",
    "href": "labs/lab-02.html#exercise-2",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nAs you can see from the data dictionary in the README of the data folder, there are many interesting potential variables that could be included in the model to predict median childcare cost for school-age children. Therefore, we will do some feature selection and feature design to choose potential predictors and construct new ones.\nAs a team, select four variables you want to use as predictors for the model. For each variable, state the variable name, definition, and a brief explanation about why your team hypothesizes this will be a relevant predictor of median childcare costs. The explanation may (but is not required to) include some short exploratory analysis.\n\nTeam Member 1: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 1- 2.\nTeam Member 2: It’s your turn! Type the team’s response to exercises 3 - 4.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-3",
    "href": "labs/lab-02.html#exercise-3",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nOnce we’ve identified potential predictor variables, we often need to transform some variables (e.g., change raw counts into proportions) or create new ones (e.g., create a categorical variable out of quantitative data) before fitting the regression model. This process is particularly useful when putting a variable in the model “as-is” may result in interpretation issues.\nChoose one of the variables selected in the previous exercise. For this variable,\n\nTransform the variable or use it to create a new variable. Be sure to save the variable to the childcare_train data frame.\nBriefly explain your reasoning for the transformation or new variable.\nUse visualizations and/or summary statistics to display the distribution of the original variable and the transformed / newly created variable. Note: This is to help ensure the transformation / new variable is what you expect.\n\nAn example using h_6to17_both_work is below. Note you cannot use this variable for your transformation / new variable.\n\n\n\n\n\n\nExample\n\n\n\nSay we believe that the amount of households with two working parents increases demand for childcare services, and hence their price. We have the column h_6to17_both_work encoding the number of such households per county. The raw population count differs across county, so having a larger value of h_6to17_both_work may reflect population size and not necessarily imply the type of such household is more prevalent in the county.\nA reasonable thing would be creating a variable encoding the proportion of households with both parents working. We could do this by creating a variable p_6to17_both_work:\n\np_6to17_both_work = h_6to17_both_work / households\n\nIn this case, we would then use p_6to17_both_work not h_6to17_both_work as a predictor in the model.\n\n\nYou may decide to transform and/or create multiple new variables; however, you will only be graded on the one of them.\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the transformed / new variable (not the original variable) in the model!",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-4",
    "href": "labs/lab-02.html#exercise-4",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nNow let’s conduct some bivariate exploratory data analysis. Visualize the relationship between the response variable and one of your predictor variables.\nWrite two distinct observations from the visualization.\n\nTeam Member 2: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 3 - 4.\nTeam Member 3: It’s your turn! Type the team’s response to exercises 5 - 6.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-5",
    "href": "labs/lab-02.html#exercise-5",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nUse the matrix form of the model to represent the regression model with the variables you selected and transformed/created in exercises 2 and 3 as the predictors. For each symbol in the model\n\ndescribe what it represents, and\nstate the dimensions.\n\nThe description and dimensions should be in the context of these data, not in general.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-6",
    "href": "labs/lab-02.html#exercise-6",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUse lm to fit the regression model you described in the previous exercise.\n\nNeatly display the model using a reasonable number of digits.\n\n\n\nInterpret the coefficient for one predictor in the model.\n\n\nTeam Member 3: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 5 - 6.\nTeam Member 4: It’s your turn! Type the team’s response to exercises 7 - 9.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-7",
    "href": "labs/lab-02.html#exercise-7",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow let’s assess the fit of the model.\n\nHow much of the variability in the childcare costs is explained by your chosen predictor variables?\n\n\n\nBased on this, do you think the model explains a significant portion of the variability in childcare costs for school-age children in North Carolina? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-8",
    "href": "labs/lab-02.html#exercise-8",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow let’s use the testing data to explore the predictive power of the model.\n\nAdd the variable you created in Exercise 3 to the testing data.\nThen, use the code below to compute the predicted childcare costs for the observations in the testing data using the predict function.\n\n\n# compute predictions\npred &lt;- predict(childcare_fit, childcare_test)\n\n# add predictions to testing data set\nchildcare_test &lt;- childcare_test |&gt;\n  mutate(pred = pred)",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-9",
    "href": "labs/lab-02.html#exercise-9",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCompute the RMSE for the test set, and compare it to the standard deviation of the response variable mcsa.\n\n\n\nHow do these values compare?\nBased on this, how would assess the predictive power of the model?\n\n\nTeam Member 4: Render, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and the rest of the team can see the completed lab.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the team’s completed lab!",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-10",
    "href": "labs/lab-02.html#exercise-10",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nIf you haven’t already, make sure you have completed the team agreement (see the instructions in [Meet your team!]).",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#footnotes",
    "href": "labs/lab-02.html#footnotes",
    "title": "Lab 02: Multiple Linear Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDon’t trust yourself to keep your hands off the keyboard? Put them in your pocket or cross your arms. No matter how silly it might feel, resist the urge to touch your keyboard until otherwise instructed!↩︎",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Lab 03: Inference for regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, October 3 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-0",
    "href": "labs/lab-03.html#exercise-0",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 0",
    "text": "Exercise 0\nThere are two penguins in the data frame that do not have reported values for flipper length or body mass and thus will not be included in any analysis. Remove these observations from the data frame, so that we have an accurate count of the number of observations used for the analysis.\n\n\n\n\n\n\nNote\n\n\n\nExericse 0 is not graded.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-1",
    "href": "labs/lab-03.html#exercise-1",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet’s begin by exploring the relationship between between flipper length and body mass, while accounting for species.\n\nVisualize the relationship between flipper length and body mass. Then describe the relationship.\nFit the main effects linear regression model (no interaction terms) between these three variables. Neatly display the results using three digits.\nInterpret the coefficient of flipper length in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-2",
    "href": "labs/lab-03.html#exercise-2",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nNow let’s look at the assumptions underlying the regression model. Consider the linear regression model\n\\[ \\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\sigma^2 \\mathbf{I}_n)  \\tag{1}\\]\nand let \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\\) be the least squares estimator. This model relies on four assumptions:\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another.\n\nFor each condition, state the components of Equation 1 that are used to represent it.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-3",
    "href": "labs/lab-03.html#exercise-3",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe can visually assess the linearity and constant variance assumptions by examining a scatterplot of the residuals versus fitted (predicted) values.\n\nCreate a scatterplot of the residuals (y-axis) versus fitted values (x-axis) for the model fit in Exercise 1.\nIf there is a linear relationship between the response and predictor variables, no discernible pattern should be present between fitted values and residuals. Does the linearity assumption appear to be satisfied?\nBriefly explain why no discernible pattern in the plot of residuals versus fitted values would indicate the linearity condition is satisfied.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-4",
    "href": "labs/lab-03.html#exercise-4",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nIf errors have constant variance, we would expect the variability the of residuals about their mean to be approximately equal as the fitted value increases. Does the constant variance assumption appear to be satisfied? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-5",
    "href": "labs/lab-03.html#exercise-5",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNext, let’s assess the assumptions about the distribution fo the residuals. Under the normality assumption, the residuals are expected to be normally distributed. Visualize the distribution of the residuals. Does the normality assumption appear to be satisfied? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-6",
    "href": "labs/lab-03.html#exercise-6",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe last assumption is that the residuals are independent of one another. Do you think it’s reasonable to assume the independence of residuals in this analysis? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-7",
    "href": "labs/lab-03.html#exercise-7",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow let’s set up the test of whether the flipper length has a statistically significant effect on body mass in this model.\n\nWrite the null and alternative hypotheses in words and in mathematical notation.\nShow how the test statistic is computed specifically for this problem. In your response, show the code to obtain each relevant quantity in the formula for the test statistic using the matrix form of the model. Do not merely refer to the values in the lm output. You must show how each value is computed using the matrix / vector calculations.\nState the distribution of the test statistic under the null hypothesis for this problem.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-8",
    "href": "labs/lab-03.html#exercise-8",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn the regression output from Exercise 1, you are provided the \\(p\\)-value for the test of significance of each individual coefficient.\n\nInterpret the p-value for the coefficient of flipper length in the context of the data.\nThen, use the p-value and a decision-making threshold of \\(\\alpha = 0.05\\) to draw a conclusion about the relationship between flipper length and body mass in this model. State your conclusion in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-9",
    "href": "labs/lab-03.html#exercise-9",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nNow let’s construct the 95% confidence interval for the coefficient of flipper length.\n\nWrite the general formula for the 95% confidence interval.\nUse R functions to compute all the quantities you need for the interval, then compute the interval.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-10",
    "href": "labs/lab-03.html#exercise-10",
    "title": "Lab 03: Inference for regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nInterpret the interval from the previous exercise in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-00.html",
    "href": "labs/lab-00.html",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "",
    "text": "Important\n\n\n\nPlease complete all today’s lab tasks before leaving lab today."
  },
  {
    "objectID": "labs/lab-00.html#rstudio",
    "href": "labs/lab-00.html#rstudio",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "RStudio",
    "text": "RStudio\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface.\n\n\n\nReserve RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers. You will log in using your NetID credentials.\nClick “Reserve STA 210” to reserve an RStudio container. Be sure you reserve the container labeled STA 210 to ensure you have the computing set up you need for the class.\n\nYou only need to reserve a container once per semester.\n\n\nOpen RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA210 to log into the Docker container. You should now see the RStudio environment."
  },
  {
    "objectID": "labs/lab-00.html#git-and-github",
    "href": "labs/lab-00.html#git-and-github",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nIn addition to R and RStudio, we will use git and GitHub for version control and collaboration.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\n\nSign up for GitHub account\nYou will need a GitHub account to access the assignments, project, and in-class exercises for the course.\n\nIf you do not have a GitHub account, go to https://github.com and sign up for an account.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for advice on choosing a username.\n\n\n\nIf you already have a GitHub account, you can move on to the next step."
  },
  {
    "objectID": "labs/lab-00.html#connect-rstudio-and-github",
    "href": "labs/lab-00.html#connect-rstudio-and-github",
    "title": "Lab 00: Welcome + Getting Started",
    "section": "Connect RStudio and GitHub",
    "text": "Connect RStudio and GitHub\nNow that you have RStudio and a GitHub account, we will configure git so that RStudio and GitHub communicate with one another.\n\nSet up your SSH Key\nYou will authenticate GitHub using SSH. Below are an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nStep 0: Open your STA 210 RStudio container.\nStep 1: Type credentials::ssh_setup_github() into the console on the bottom left of the RStudio environment.\nStep 2: R will ask “No SSH key found. Generate one now?” Click 1 for yes.\nStep 3: You will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” Click 1 for yes.\nStep 4: You may be asked to provide your username and password to log into GitHub. This would be the ones associated with your account that you set up. After entering this information, paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta221)\n\n\n\nConfigure git\nThe last thing we need to do is configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\")\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Maria Tackett\",\n  user.email = \"maria.tackett@duke.edu\")\n\nIt may look like nothing happened but you are now ready interact between GitHub and RStudio! We will begin working with RStudio and GitHub in lecture this week."
  },
  {
    "objectID": "labs/lab-05.html",
    "href": "labs/lab-05.html",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, November 7 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-1",
    "href": "labs/lab-05.html#exercise-1",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll begin by rescaling the response and some of the predictor variables.\n\nRescale the response variable total_rev_menwomen and the primary predictor variable total_exp_menwomen, so that they are in terms of $100K (100 thousand dollars). Name the new variables rev100k and exp100k, respectively.\nRescale the predictor variable ef_total_count , so it is in terms of thousands of students. Name the new variable studnets_1k.\nBriefly explain why we might we rescale these variables instead of using them in the original units.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-2",
    "href": "labs/lab-05.html#exercise-2",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nBefore modeling, let’s do some exploratory data analysis.\n\nMake a visualization of the relationship between revenue and expenditures. Use the plot to describe the relationship between the two variables.\n\n\n\nHigher values of both expenditures and revenues are associated with greater variability. Transform both variables using a log transformation, to deal with the potential violation of an assumption of linear regression. Name the variables log_exp and log_rev, respectively.\nLarger values of expenditures and revenues seem to follow a slightly different trend and are associated with two sports - football and basketball. Create an indicator variable that takes value 1 if the sport is basketball or football and 0 otherwise. Name the variable bball_football.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-3",
    "href": "labs/lab-05.html#exercise-3",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nVisualize the relationship between log_rev and log_exp.\nFrom the visualization, you may notice a lot of observations form a straight diagonal line, indicating a perfect one-to-one relationship between expenses and revenues. Provide a possible interpretation of this phenomenon.\nDo you think it is reasonable to include observations displaying this exact relationship? Briefly explain.\nCreate a new data frame filtering out the observations for which expenditures and revenues are exactly equal. Call the new data frame sports_nolinear.\n\nYou will use sports_nolinear for the remainder of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-4",
    "href": "labs/lab-05.html#exercise-4",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nUse sports_nolinear to fit a regression model with the log-transformed revenue as the response variable and the following predictors: log-transformed expenditures, student enrollment, institution type, sports type, participation in athletics for men, participation in athletics for women, the basketball/football indicator you created in a previous exercise, and the interaction between the log-transformed expenditures and the basketball/football indicator.\nNeatly display the model using 3 digits.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-5",
    "href": "labs/lab-05.html#exercise-5",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nConsider the regression model from the previous exercise.\n\nWhat type of institution and sport correspond to the intercept?\nYou’ll notice that one coefficient has a missing value. Why is the coefficient missing? What is the technical name of this phenomenon?",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-6",
    "href": "labs/lab-05.html#exercise-6",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nFor the sake of interpretability, it is useful to have a regression model in which no coefficients are missing, and the coefficients for each sport indicator represent the baseline level for such sport. To address this issue, use the code below to fit another regression model that uses the same predictors as before, making sure to drop the unnecessary variables and the intercept (by the the -1 in the formula) to achieve this.\n\nsports_fit_2 &lt;- lm(log_rev ~ -1 + sports + students_1k + sector_name +\n             sum_partic_men + sum_partic_women + log_exp + \n             log_exp*bball_football - bball_football,\n          data = sports_nolinear)\n\n\nWhy is there only one coefficient for institution type, even after the intercept was removed?\nWhich type of institution was chosen to be the baseline in this model?",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-7",
    "href": "labs/lab-05.html#exercise-7",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow that we have an interpretable model, let us assess the model fit and perform diagnostics to verify whether our linear regression assumptions are reasonable for this data.\nAs a first step, provide some overall measures of model fit and comment on whether it seems to have an acceptable predictive power on the response of interest.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-8",
    "href": "labs/lab-05.html#exercise-8",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nNext, let’s take a look at the residuals for the model.\nBecause there are multiple sports at every institution, we may be concerned the residuals within an institution are correlated with each other (thus violating the independence assumption).\nDue to the large number of institutions, we will look at randomly selected subset of 20 institutions to evaluate this.\n\nTake a random sample of 20 institutions. Use set.seed(221) to make your results reproducible.\nPlot the residuals versus fitted values, faceted by institution.\nBased on the faceted plot, do the errors appear to be correlated within institutions? Briefly explain your response.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for more detail, code, and examples of faceting in ggplot2.\nYou may need to change the size of the figure so that the faceted lot is fully visible. You can do so using the options #| fig-width and #| fig-height in the code chunk.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-9",
    "href": "labs/lab-05.html#exercise-9",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nAfter an examination of all the residuals, we notice a few things:\n\nThere seems to be two groups of observations.\nInstitutions with larger fitted values correspond to lower variance in the residuals compared to the others.\nThere are institutions with lower fitted values that have large negative residuals, potentially indicating outliers and/or influential points.\n\nWe are concerned that these observations may indicate some model misspecification (i.e., the model does not accurately reflect the trends in the data). Therefore, we take a look at the residuals a different way. We plot the standardized residual versus the fitted values, color the points based Cook’s distance, and use shape to indicate whether the sport is basketball or football.\n\nDescribe what you observe from the plot and how your observations compare to the list above.\nDo you think this model is an appropriate fit for the data or is the model misspecified? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-05.html#exercise-10",
    "href": "labs/lab-05.html#exercise-10",
    "title": "Lab 05: Expanding Multiple Linear Regression",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nBased on this model (regardless of your answer to the previous exercise), which variables seem to be useful in explaining the variability in the revenue from collegiate sports?\nInterpret the coefficient for one useful quantitative predictor in terms of the revenue (not log(revenue)).\nInterpret the coefficient for one useful categorical predictor in terms of the revenue (not log(revenue)).",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "In STA 221, students will learn how linear and logistic regression models are used to explore multivariable relationships, apply these methods to answer relevant and engaging questions using a data-driven approach, and learn the mathematical underpinnings of the models. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, analysis of variance, model diagnostics, and model selection. Regression parameter estimation via maximum likelihood least squares will also be discussed. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields.\n\n\nEither any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#pre-requisites",
    "href": "overview.html#pre-requisites",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "Either any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#teaching-assistants",
    "href": "overview.html#teaching-assistants",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\n\n\nName\nRole\nOffice Hours\n\n\n\nKat Husar\nHead TA\nLab 02L leader\nTue 1:30 - 3:30pm, Old Chem 220\n\n\n\nJon Campbell\nLab 01L leader\nTue & Thu 9 - 10am, Old Chem 025\n\n\n\nIshrit Gupta\nLab 01L helper\nFri 1- 3pm, Old Chem 203B\n\n\n\nAlan Wang\nLab 02L helper\nMon & Wed 10 - 11am, Old Chem 203B",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Simple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, September 19 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions",
    "href": "hw/hw-01.html#instructions",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-1",
    "href": "hw/hw-01.html#exercise-1",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\na. Show that the hat matrix \\(\\mathbf{H}\\) is symmetric \\((\\mathbf{H}^T = \\mathbf{H})\\) and idempotent \\((\\mathbf{H}^2 = \\mathbf{H})\\).\nb. Show that \\((\\mathbf{I} - \\mathbf{H})\\) is symmetric and idempotent.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-2",
    "href": "hw/hw-01.html#exercise-2",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet \\(\\mathbf{x}\\) be a \\(k \\times 1\\) vector and \\(\\mathbf{A}\\) be a symmetric \\(k \\times k\\) matrix, such that \\(\\mathbf{A}\\) is not a function of \\(\\mathbf{x}\\).\nShow that the gradient of \\(\\boldsymbol{x}^T\\mathbf{A}\\mathbf{x}\\) with respect to \\(\\mathbf{x}\\) is\n\\[\n\\nabla_\\mathbf{x} \\hspace{1mm} \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = 2\\mathbf{A}\\mathbf{x}\n\\]\n(Proposition 2 from class)",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-3",
    "href": "hw/hw-01.html#exercise-3",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nIn class we used the sum of squared residuals (SSR) to estimate the regression coefficients, \\(\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}\\) . To show this is the least squares estimate, we now need to show that we have, in fact, found the estimate of \\(\\boldsymbol{\\beta}\\) that minimizes the SSR (rather than maximize).\nIf the Hessian matrix \\(\\nabla_{\\boldsymbol{\\beta}}^2 SSR\\) is positive definite, then we know we have found the \\(\\hat{\\boldsymbol{\\beta}}\\) that minimizes SSR, i.e., the least squares estimator. Additionally, we have the following proposition:",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#proposition",
    "href": "hw/hw-01.html#proposition",
    "title": "HW 01: Simple linear regression",
    "section": "Proposition",
    "text": "Proposition\nA matrix \\(\\mathbf{A}\\) is positive definite if \\(\\mathbf{z}^T\\mathbf{A}\\mathbf{z} &gt; 0\\) , given \\(\\mathbf{z}\\) is a non-zero vector.\nShow that \\(\\nabla_{\\boldsymbol{\\beta}}^2 SSR\\) is positive definite.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-4",
    "href": "hw/hw-01.html#exercise-4",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nProve that the maximum value of \\(R^2\\) must be less than 1 if the data set contains observations such that there are different observed values of the response for the same value of the predictor (e.g., the dataset contains observations \\((x_i, y_i)\\) and \\((x_j, y_j)\\) such that \\(x_i = x_j\\) and \\(y_i \\neq y_j\\) ).",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions-1",
    "href": "hw/hw-01.html#instructions-1",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#data",
    "href": "hw/hw-01.html#data",
    "title": "HW 01: Simple linear regression",
    "section": "Data",
    "text": "Data\nThe datasets wi-icecover.csv and wi-air-temperature.csv contain information about ice cover and air temperature, respectively, at Lake Monona and Lake Mendota (both in Madison, Wisonsin) for days in 1886 through 2019. The data were obtained from the ntl_icecover and ntl_airtemp data frames in the lterdatasampler R package. They were originally collected by the US Long Term Ecological Research program (LTER) Network.\n\nicecover &lt;- read_csv(\"data/wi-icecover.csv\")\nairtemp &lt;- read_csv(\"data/wi-air-temperature.csv\")\n\nThe analysis will focus on the following variables:\n\nyear: year of observation\nlakeid: lake name\nice_duration: number of days between the freeze and ice breakup dates of each lake\nair_temp_avg: yearly average air temperature in Madison, WI (degrees Celsius)",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#analysis-goal",
    "href": "hw/hw-01.html#analysis-goal",
    "title": "HW 01: Simple linear regression",
    "section": "Analysis goal",
    "text": "Analysis goal\nThe goal of this analysis is to use linear regression explain variability in ice duration for lakes in Madison, WI based on air temperature. Because ice cover is impacted by various environmental factors, researchers are interested in examining the association between these two factors to better understand the changing climate.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-5",
    "href": "hw/hw-01.html#exercise-5",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s start by looking at the response variable ice_duration.\n\nCreate side-by-side boxplots to visualize the distribution of ice_duration for each lake.\nVisualize the distribution of ice duration over time for each lake.\nThere are separate measurements for each lake in the icecover data frame. In this analysis, we will combine the data from both lakes and use the average ice duration each year.\nEvaluate the analysis choice to use the average per year rather than the individual lake measurements. Some things to consider in your evaluation: Does the average accurately reflects the ice duration for lakes in Madison, WI for that year? Will there be information loss? How might that impact (or not) the analysis conclusions? Etc.\n\n\n\n\n\n\n\nTip\n\n\n\nSee the ggplot2 reference for example code and plots.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-6",
    "href": "hw/hw-01.html#exercise-6",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nNext, let’s combine the ice duration and air temperature data into a single analysis data frame.\n\nFill in the code below to create a new data frame, icecover_avg, of the average ice duration by year.\nThen join icecover_avg and airtemp to create a new data frame. The new data frame should have 134 observations.\n\nicecover_avg &lt;- icecover |&gt;\n  group_by(_____) |&gt;\n  summarise(_____) |&gt;\n  ungroup()\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou will use the new data frame with average ice duration and average air temperature for the remainder of the assignment.\n\n\n\nVisualize the relationship between the air temperature and average ice duration. Do you think a linear model would be a good fit to capture the relationship between the two variables? \n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-7",
    "href": "hw/hw-01.html#exercise-7",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nWe will fit a model using the average air temperature to explain variability in ice duration that takes the form\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nState the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\epsilon}\\) for this analysis. Your answer should have exact values given this data set.\nFind the estimated regression coefficients \\(\\hat{\\boldsymbol{\\beta}}\\) using the matrix representation of the model. Show the code used to get the answer.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-8",
    "href": "hw/hw-01.html#exercise-8",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nFit the model from the previous exercise using the lm function. Neatly display the results using 3 digits.\nInterpret the slope in the context of the data.\n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-9",
    "href": "hw/hw-01.html#exercise-9",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nCalculate \\(R^2\\) for the model in the previous exercise and interpret it in the context of the data.\nBriefly comment on the model fit based on \\(R^2\\).",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#exercise-10",
    "href": "hw/hw-01.html#exercise-10",
    "title": "HW 01: Simple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nYou are asked to use a reproducible workflow for all of your work in the class, and the goal of this question to is better understand potential real-world implications of doing (or not) so. Below are some real-life examples in which having a non-reproducible workflow resulted in errors that impacted research or public records.\n\nSource: Ostblom and Timbers (2022)\n\n\nReproducibility error\nConsequence\nSource(s)\n\n\n\n\nLimitations in Excel data formats\nLoss of 16,000 COVID case records in the UK\n(Kelion 2020)\n\n\nAutomatic formatting in Excel\nImportant genes disregarded in scientific studies\n(Ziemann, Eren, and El-Osta 2016)\n\n\nDeletion of a cell caused rows to shift\nMix-up of which patient group received the treatment\n(Wallensteen et al. 2018)\n\n\nUsing binary instead of explanatory labels\nMix-up of the intervention with the control group\n(Aboumatar and Wise 2019)\n\n\nUsing the same notation for missing data and zero values\nPaper retraction\n(Whitehouse et al. 2021)\n\n\nIncorrectly copying data in a spreadsheet\nDelay in the opening of a hospital\n(Picken 2020)\n\n\n\nChoose one of the scenarios from the table and read the linked article discussing what went wrong. Then,\n\nBriefly describe what went wrong, i.e., what part of the process of was not reproducible and what error or impact that had.\nDescribe one way the researchers could have made the process reproducible.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Multiple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Thursday, October 3 at 11:59pm.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#instructions",
    "href": "hw/hw-02.html#instructions",
    "title": "HW 02: Multiple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.\n\nYou may write the answers and associated work for conceptual exercises by hand or type them in your Quarto document.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet \\(Var(\\hat{\\mathbf{y}})\\) be the variance of the fitted (predicted) values of the response variable. Show that \\(Var(\\hat{\\mathbf{y}}) = \\sigma^2_\\epsilon \\mathbf{H}\\).",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose we fit the model \\(\\mathbf{y} = \\mathbf{X}_1\\boldsymbol{\\beta}_1 + \\boldsymbol{\\epsilon}\\) when the true model is actually given by \\(\\mathbf{y} = \\mathbf{X}_1\\boldsymbol{\\beta}_1 + \\mathbf{X}_2\\boldsymbol{\\beta}_2 + \\boldsymbol{\\epsilon}\\). Assume \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\) for both models.\n\nFind the expected value of the least-squares estimate \\(\\hat{\\boldsymbol{\\beta}}_1\\).\nUnder what conditions is the estimate \\(\\hat{\\boldsymbol{\\beta}}_1\\) unbiased?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#instructions-1",
    "href": "hw/hw-02.html#instructions-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Instructions",
    "text": "Instructions\nThe applied exercises are focused on applying the concepts to analyze data.\nAll work for the applied exercises must be typed in your Quarto document following a reproducible workflow.\nWrite all narrative using complete sentences and include informative axis labels / titles on visualizations.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#data-lego-sets",
    "href": "hw/hw-02.html#data-lego-sets",
    "title": "HW 02: Multiple linear regression",
    "section": "Data: LEGO® sets",
    "text": "Data: LEGO® sets\nThe data for Exercises 3 - 5 includes information about LEGO® sets from themes produced January 1, 2018 and September 11, 2020. The data were originally scraped from Brickset.com, an online LEGO set guide and were obtained for this assignment from Peterson and Ziegler (2021).\nYou will work with data on about 400 randomly selected LEGO sets produced during this time period. The primary variables are interest in this analysis are\n\nPieces: Number of pieces in the set from brickset.com.\nMinifigures: Number of minifigures (LEGO® people) in the set scraped from brickset.com.\nAmazon_Price: Price of the set on Amazon.com (in U.S. dollars)\nSize: General size of the interlocking bricks (Large = LEGO Duplo® sets - which include large brick pieces safe for children ages 1 to 5, Small = LEGO® sets which- include the traditional smaller brick pieces created for age groups 5 and - older, e.g., City, Friends)\n\nThe data are contained in lego-sample.csv. Use the code below to read in the data and remove any observations that have missing values for the relevant variables.\n\nlegos &lt;- read_csv(\"data/lego-sample.csv\")|&gt;\n  drop_na(Pieces, Amazon_Price, Size, Minifigures)\n\n\n\n\n\n\n\nAnalysis goal\n\n\n\nWe want to fit a multiple linear regression model to predict the price of LEGO® sets on Amazon.com based on Pieces, Size, and Minifigures.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nIn this analysis, we dropped observations that have missing values for some of the relevant variables.\n\nWhat is a disadvantage of dropping observations that have missing values, instead of using a method to impute (fill in) the missing data?\nHow might dropping these observations impact the generalizability of conclusions?\n\nFit the regression model and neatly display the results using three digits.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nWe want to understand the relationship between Pieces and Amazon_Price based on this model that also takes into the size of the blocks and number of minifigures.\nYou are convinced from the model output that there is evidence of a linear relationship between the two variables. Now you want to be more specific and test whether the slope is actually different from 0.1 ($10 increase in the price for every 100 additional pieces).\n\nWrite the null and alternative hypotheses for this test in using words and mathematical notation.\nCalculate the test statistic for this test. You may use any relevant output from the model in the previous exercise.\nWhat is the distribution of the test statistic under the null hypothesis for this problem?\nCalculate the p-value and state your conclusion in the context of the data using a threshold of \\(\\alpha = 0.05\\).\nCalculate the 95% confidence interval. Is the confidence interval consistent with your conclusion from the hypothesis test? Briefly explain.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nInstead of using the number of minifigures in the model, you decide to create an indicator variable for whether or not there are any minifigures in the set.\n\nCreate an indicator variable that takes the value “No” if there are zero minifigures in the LEGO® set, and “Yes” if there is at least one minifigure.\nYou hypothesize that the relationship between the price and number of pieces may differ based on whether or not there are minifigures in the set.\nMake a plot to visualize this potential effect. Does the relationship between price and number of pieces seem to differ based on the inclusion of minifigures? Briefly explain.\nFit a model using the number pieces, size of the blocks, the indicator for minifigures, and the interaction between pieces and the presence of minifigures to predict the price on Amazon.com.\nBased on this model, is there evidence that the effect of pieces on the price differs based on the inclusion of minifigures? Briefly explain your response, referencing any statistics used to make your determination.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#data-world-bank",
    "href": "hw/hw-02.html#data-world-bank",
    "title": "HW 02: Multiple linear regression",
    "section": "Data: World Bank",
    "text": "Data: World Bank\nThe World Bank collects “world development indicators” about the past and current development of countries. These data are made available on the World Bank’s website. It can be used to understand the relationships between these various factors and trends over time.\n\nThis analysis focuses on indicators from 2011 on 165 countries. The variables of interest are:\n\ngdp.per.capita: gross domestic product divided by midyear population. GDP is the sum of gross value added by all resident producers in the economy plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. Data are in current U.S. dollars.\nsanit.access.factor: Population access to sanitation facilities (Low, High)\nedu.expend: Government expenditure on education, total (% of government expenditure)\nlife.expect: Life expectancy at birth (in years)",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nYou fit a model using sanitation access, education expenditures, and life expectancy to understand variability in GDP. The model takes the form\n\\[\n\\begin{aligned}\\widehat{\\log(GDP)} = \\hat{\\beta}_0 &+ \\hat{\\beta}_1 ~ sanit.access.factor + \\hat{\\beta}_2 ~ edu.expend + \\hat{\\beta}_3 ~life.expect \\\\ &+ \\hat{\\beta}_4 ~ sanit.access.factor \\times life.expect\\end{aligned}\n\\]\nwhere \\(\\log(GDP)\\) is the natural log of gdp.per.capita.\nThe F output for this model is shown below.\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n4.491\n1.638\n2.742\n0.007\n\n\nsanit.access.factorhigh\n-6.993\n1.971\n-3.548\n0.001\n\n\nedu.expend\n0.097\n0.038\n2.550\n0.012\n\n\nlife.expect\n0.030\n0.029\n1.061\n0.291\n\n\nsanit.access.factorhigh:life.expect\n0.122\n0.032\n3.853\n0.000\n\n\n\n\n\n\nInterpret the coefficient of edu.expend in the context of the data. You can interpret the coefficient in terms of \\(log(GDP)\\) .\nInterpret the coefficient of sanit.access.factorhigh in the context of the data.You can interpret the coefficient in terms of \\(log(GDP)\\) .",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-7",
    "href": "hw/hw-02.html#exercise-7",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nWrite the estimated regression equation for countries with high sanitation access.\nInterpret the effect of life.expect for countries with high sanitation access in the context of the data. You can interpret the coefficient in terms of \\(log(GDP)\\) .",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-8",
    "href": "hw/hw-02.html#exercise-8",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nBelow are plots from the exploratory data analysis of the relationships between the predictor variables. Based on these plots, what appears to be a potential issue with the model from Exercise 6? Briefly explain your response.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#bonus-optional",
    "href": "hw/hw-02.html#bonus-optional",
    "title": "HW 02: Multiple linear regression",
    "section": "Bonus (optional)",
    "text": "Bonus (optional)\nUse the model from Exercise 6 to interpret the coefficients of edu.expend and sanit.access.factorhigh in term of GDP (not log(GDP)). Write your interpretations in the context of the data.\nEach interpretation is worth 1 point out of 50. The interpretation must be exactly correct to receive credit.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "prepare/prepare-sep10.html",
    "href": "prepare/prepare-sep10.html",
    "title": "Prepare for September 10 lecture",
    "section": "",
    "text": "Review class notes and readings on simple linear regression.\nWe will extend what we’ve done thus far to multiple linear regression, with 2 or more predictors."
  },
  {
    "objectID": "prepare/prepare-sep12.html",
    "href": "prepare/prepare-sep12.html",
    "title": "Prepare for September 12 lecture",
    "section": "",
    "text": "📖 Read Multiple Linear Regression\n✅ Review Vector Geometry [slides][video]1\n🎥: Watch Geometric interpretation of least squares"
  },
  {
    "objectID": "prepare/prepare-sep12.html#footnotes",
    "href": "prepare/prepare-sep12.html#footnotes",
    "title": "Prepare for September 12 lecture",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFrom Math 218: Matrices and Vectors (Summer 2024) taught by Dr. Brian Fitzpatrick at Duke University↩︎"
  },
  {
    "objectID": "prepare/prepare-sep5.html",
    "href": "prepare/prepare-sep5.html",
    "title": "Prepare for September 5 lecture",
    "section": "",
    "text": "Review linear algebra concepts (as needed)\n\nMatrices and vectors: [slides][video]\nMatrix-Vector products: [slides][video]\nVector geometry: [slides][video]\nMatrix multiplication: [slides][video]\n\n\n\n\n\n\n\nNote\n\n\n\nAll linear algebra review materials from Math 218: Matrices and Vectors (Summer 2024) taught by Dr. Brian Fitzpatrick at Duke University"
  },
  {
    "objectID": "prepare/prepare-sep19.html",
    "href": "prepare/prepare-sep19.html",
    "title": "Prepare for September 19 lecture",
    "section": "",
    "text": "📖 Read Inference for Simple Linear Regression:\n\nSections 5.1 - 5.3\nSection 5.6\nSection 5.8\nSection 5.9"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html",
    "href": "ae/ae-04-exam-01-review.html",
    "title": "AE 04: Exam 01 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#packages",
    "href": "ae/ae-04-exam-01-review.html#packages",
    "title": "AE 04: Exam 01 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#restaurant-tips",
    "href": "ae/ae-04-exam-01-review.html#restaurant-tips",
    "title": "AE 04: Exam 01 Review",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat factors are associated with the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.1\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nAge: Age of the payer\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exploratory-data-analysis",
    "href": "ae/ae-04-exam-01-review.html#exploratory-data-analysis",
    "title": "AE 04: Exam 01 Review",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\np1 &lt;- ggplot(data = tips, aes(x = Tip)) + \n  geom_histogram(color = \"white\", binwidth = 2) +\n  labs(x = \"Tips ($)\",\n       title = \"Tips at local restaurant\")\n\np2 &lt;- ggplot(data = tips, aes(x = Party)) + \n  geom_histogram(color = \"white\") +\n  labs(x = \"Party\",\n       title = \"Number of diners in party\") +\n  xlim(c(0, 7))\n\np3 &lt;- ggplot(data = tips, aes(x = Age)) + \n  geom_bar(color = \"white\") +\n  labs(x = \"\",\n       title = \"Age of Payer\") \n\np1 / (p2 + p3)\n\n\n\n\n\n\n\n\n\np4 &lt;- ggplot(data = tips, aes(x = Party, y = Tip)) + \n  geom_jitter() + \n  labs(x = \"Number of diners in party\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Party\")\n\np5 &lt;- ggplot(data = tips, aes(x = Age, y = Tip)) + \n  geom_boxplot() + \n  labs(x = \"Age of payer\", \n       y = \"Tips ($)\",\n       title = \"Tips vs. Age\")\n\np4 + p5\n\n\n\n\n\n\n\n\nWe will use the number of diners in the party and age of the payer to understand variability in the tips."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-1",
    "href": "ae/ae-04-exam-01-review.html#exercise-1",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe will start with the main effects model.\n\nHow many indicator variables for Age can we create from the data?\nHow many indicator variables for Age will be in the regression model?\nAre the responses to parts a and b equal? If not, explain why not.\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-2",
    "href": "ae/ae-04-exam-01-review.html#exercise-2",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the dimension of the design matrix \\(\\mathbf{X}\\) for the main effects model?\nCalculate the coefficient estimates \\(\\hat{\\boldsymbol{\\beta}}\\) directly from the data.\nWrite the equation of the estimated regression model.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-3",
    "href": "ae/ae-04-exam-01-review.html#exercise-3",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nCompute the following directly from the data:\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) . Interpret this value in the context of the data.\n\\(R^2\\). Interpret this value in the context of the data.\n\\(RMSE\\). Interpret this value in the context of the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-4",
    "href": "ae/ae-04-exam-01-review.html#exercise-4",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nYou decide to add an interaction effect between Age and Party to the model and fit a model of the following form:\n\\[\n\\hat{Tip}_i = \\beta_0 + \\beta_1Party_i + \\beta_2SenCit_i + \\beta_3Yadult_i + \\beta_4Party_i \\times SenCit_i + \\beta_5 Party_i \\times Yadult_i\n\\]\n\nWhich of the following is true for this model? Select all that apply.\n\nThe intercepts are the same for every level of Age.\nThe intercepts differ by Age.\nThe effect of Party is the same for every level of Age.\nThe effect of Party differs by Age.\n\nBy how much does the intercept for tables with young adult payers differ from tables with middle age payers?\nWrite the equation of the model for tables in which the payer is a senior citizen.\nSuppose you wish to test the hypotheses: \\(H_0: \\beta_5 = 0 \\text{ vs. }H_a: \\beta_5 \\neq 0\\) . State what is being tested in terms of the effect of Party."
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-5",
    "href": "ae/ae-04-exam-01-review.html#exercise-5",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe output for the model with the interaction term and 90% confidence intervals for the coefficients is shown below.\n\ntip_int_fit &lt;- lm(Tip ~ Party + Age + Party * Age, data = tips)\ntidy(tip_int_fit, conf.int = TRUE, conf.level = 0.9) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.604\n0.504\n1.199\n0.232\n-0.229\n1.438\n\n\nParty\n1.924\n0.169\n11.359\n0.000\n1.644\n2.204\n\n\nAgeSenCit\n1.033\n0.784\n1.317\n0.190\n-0.265\n2.330\n\n\nAgeYadult\n-1.203\n0.928\n-1.297\n0.197\n-2.739\n0.332\n\n\nParty:AgeSenCit\n-0.259\n0.262\n-0.986\n0.325\n-0.692\n0.175\n\n\nParty:AgeYadult\n0.199\n0.504\n0.395\n0.693\n-0.635\n1.034\n\n\n\n\n\n\nWhat does 0.784, the standard error of AgeSenCit mean in the context of the data?\nWhat does 1.317, the test statistic for AgeSenCit mean in the context of the data?\nWhat does the p-value 0.190 mean in the context of the data?\nThe 90% confidence interval corresponds to what \\(\\alpha\\)-level?\nWhat is your conclusion about the effect of AgeSenCit?"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#exercise-6",
    "href": "ae/ae-04-exam-01-review.html#exercise-6",
    "title": "AE 04: Exam 01 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe following are general questions about regression. They are not specific to the tips data set.\n\nWhat does it mean for an estimator to be the “least-squares” estimator?\nConsider the following derivation of \\(Var(\\hat{\\boldsymbol{\\beta}})\\) , the variance of the least-squares estimator:\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) & = E[(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})(\\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta})^T] \\\\\n& = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon})((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon})^T] \\\\\n& = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^TE(\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T)\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1} \\\\\n& = \\sigma^2(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\end{aligned}\n\\]\n\nExplain how to go from Line 1 to Line 2.\n\nWhat assumptions are used to go from Line 3 to Line 4?\n\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-04-exam-01-review.html#footnotes",
    "href": "ae/ae-04-exam-01-review.html#footnotes",
    "title": "AE 04: Exam 01 Review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html",
    "href": "ae/ae-05-multicollinearity.html",
    "title": "AE 05: Multicollinearity",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(rms) #calculate VIF"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-1",
    "href": "ae/ae-05-multicollinearity.html#exercise-1",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit the regression model using high temperature, average temperature, season, and precipitation to predict volume.\nAre there any coefficients that may be not what you expected?\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-2",
    "href": "ae/ae-05-multicollinearity.html#exercise-2",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nUse the formula\n\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nto calculate the VIF for avgtemp.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-3",
    "href": "ae/ae-05-multicollinearity.html#exercise-3",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 3",
    "text": "Exercise 3\nBased on the VIF from the previous exercise, does avgtemp have a linear dependency with one or more other predictors? Explain."
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-4",
    "href": "ae/ae-05-multicollinearity.html#exercise-4",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFill in the name of the model from Exercise 1 to calculate VIF for all predictors. (Remove #| eval: false after you’ve filled in the code.)\nAre there predictors with linear dependencies? If so, which ones?\n\n\nvif(____)"
  },
  {
    "objectID": "ae/ae-05-multicollinearity.html#exercise-5",
    "href": "ae/ae-05-multicollinearity.html#exercise-5",
    "title": "AE 05: Multicollinearity",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s try to deal with the mulitcollinearity by removing one of the predictors that are linearly dependent. Choose a final model using this strategy.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-mlr.html",
    "href": "ae/ae-02-mlr.html",
    "title": "AE 02: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-02 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\n\n\n\nPackages\n\nlibrary(tidyverse)   \nlibrary(tidymodels)   \nlibrary(openintro)    \nlibrary(knitr)       \n\n\n\nData\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\nWe will focus on the following variables:\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\ninterest_rate: Interest rate for the loan\n\nThe goal of this analysis is to use the annual income, debt-to-income ratio, and income verification to understand variability in the interest rate on the loan.\nWe’ll start with data prep to rescale annual income to $1000’s and recode verified_income to fix an issue with the underlying data.\n\nloan50 &lt;- loan50 |&gt;\n   mutate(annual_income_th = annual_income / 1000, \n          verified_income = \n            case_when(verified_income == \"Not Verified\" ~ \"Not Verified\",\n                      verified_income == \"Source Verified\" ~ \"Source Verified\",\n                      verified_income == \"Verified\" ~ \"Verified\"),\n          verified_income = as_factor(verified_income)\n   )                    \n\n\nglimpse(loan50)\n\nRows: 50\nColumns: 19\n$ state                   &lt;fct&gt; NJ, CA, SC, CA, OH, IN, NY, MO, FL, FL, MD, HI…\n$ emp_length              &lt;dbl&gt; 3, 10, NA, 0, 4, 6, 2, 10, 6, 3, 8, 10, 10, 2,…\n$ term                    &lt;dbl&gt; 60, 36, 36, 36, 60, 36, 36, 36, 60, 60, 36, 36…\n$ homeownership           &lt;fct&gt; rent, rent, mortgage, rent, mortgage, mortgage…\n$ annual_income           &lt;dbl&gt; 59000, 60000, 75000, 75000, 254000, 67000, 288…\n$ verified_income         &lt;fct&gt; Not Verified, Not Verified, Verified, Not Veri…\n$ debt_to_income          &lt;dbl&gt; 0.55752542, 1.30568333, 1.05628000, 0.57434667…\n$ total_credit_limit      &lt;int&gt; 95131, 51929, 301373, 59890, 422619, 349825, 1…\n$ total_credit_utilized   &lt;int&gt; 32894, 78341, 79221, 43076, 60490, 72162, 2872…\n$ num_cc_carrying_balance &lt;int&gt; 8, 2, 14, 10, 2, 4, 1, 3, 10, 4, 3, 4, 3, 2, 3…\n$ loan_purpose            &lt;fct&gt; debt_consolidation, credit_card, debt_consolid…\n$ loan_amount             &lt;int&gt; 22000, 6000, 25000, 6000, 25000, 6400, 3000, 1…\n$ grade                   &lt;fct&gt; B, B, E, B, B, B, D, A, A, C, D, A, A, A, A, E…\n$ interest_rate           &lt;dbl&gt; 10.90, 9.92, 26.30, 9.92, 9.43, 9.92, 17.09, 6…\n$ public_record_bankrupt  &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n$ loan_status             &lt;fct&gt; Current, Current, Current, Current, Current, C…\n$ has_second_income       &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ total_income            &lt;dbl&gt; 59000, 60000, 75000, 75000, 254000, 67000, 288…\n$ annual_income_th        &lt;dbl&gt; 59.0, 60.0, 75.0, 75.0, 254.0, 67.0, 28.8, 80.…\n\n\n\n\nCategorical predictors\n\n\n\n\n\n\nExercise 1\n\n\n\nLet’s take a look at the design matrix for the model with predictors debt_to_income, annual_income_th, and verified_income.\nHow does R choose the baseline level by default?\n\n\n\n## add code here\n\n[Add response here]\n\n\n\n\n\n\nExercise 2\n\n\n\nFit the model with the predictors debt_to_income, annual_income_th, verified_income , and the interaction between annual_income_th and verified_income.\nNeatly display the model results using 3 digits.\n\n\n\n# add code here\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nWrite the estimated regression equation for the people with Not Verified income.\nWrite the estimated regression equation for people with Verified income.\n\n\n\n[add response here]\n\n\n\n\n\n\nExercise 4\n\n\n\nIn general, how do\n\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?\n\n\n\n[Add response here]\n\n\nModel assessment\n\n\n\n\n\n\nExercise 5\n\n\n\nLet’s compare the original model without interaction effects to the model you fit in Exercise 2.\nCalculate \\(R^2\\) and \\(Adj. R^2\\) for each model. You can find \\(Adj. R^2\\) from the glance function:\nglance(model_name)$adj.r.squared\n\n\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + annual_income_th +\n                verified_income, data = loan50)\n\n\n# add code here\n\n\n\n\n\n\n\nExercise 6\n\n\n\nWhich model would you choose based on\n\n\\(R^2\\)?\n\\(Adj. R^2\\)?\n\n\n\n[add response here]\n\n\nLaTex\nSometimes, you will need to include mathematical notation in your document. There are two ways you can display mathematics in your document:\nInline: Your mathematics will display within the line of text.\n\nUse $ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Inline Math.\nExample: The text The simple linear regression model is $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$ produces\n\nThe simple linear regression model is \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\n\n\nDisplayed: Your mathematics will display outside the line of text\n\nUse a $$ to start and end your LaTex syntax. You can also use the menu: Insert -&gt; LaTex Math -&gt; Display Math.\nExample: The text The estimated regression equation is $$\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$$produces\n\nThe estimated regression equation is\n\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\n\\]\n\n\n\n\n\n\nTip\n\n\n\nClick here for a quick reference of LaTex code.\n\n\n\n\nSubmission\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "Below are freely available resources to learn or review the following in R: data wrangling, data visualization, Quarto basics.",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-introduction",
    "href": "computing-r-resources.html#in-depth-introduction",
    "title": "Resources for learning R",
    "section": "In-depth introduction",
    "text": "In-depth introduction\nCoursera: Data Visualization and Transformation with R by Mine Çetinkaya-Rundel and Elijah Meyer\n\nIncludes videos, readings, practice exercise, quizzes, and other resources\nYou can select content within the modules you want to complete.\nFocus on Modules 2 and 3. Review the content in Module 1 as needed.s\nClick here for instructions to register for Coursera for free as a Duke student",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-review",
    "href": "computing-r-resources.html#in-depth-review",
    "title": "Resources for learning R",
    "section": "In-depth review",
    "text": "In-depth review\nData Science with R videos by Mine Çetinkaya-Rundel and Elijah Meyer\n\nVideos from the data science Coursera course\nFocus on videos on visualizing and summarizing data\nYou need to join the Coursera course to access the files from the code along videos.\n\nLearn R: An interactive introduction to data analysis with R\n\nHands-on tutorial that can be completed within the site (no RStudio required)\nFocus on Chapters 4 - 6",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#shorter-review",
    "href": "computing-r-resources.html#shorter-review",
    "title": "Resources for learning R",
    "section": "Shorter review",
    "text": "Shorter review\nR for Data Science (2nd ed) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\nFocus on Chapters 1 - 3, 10",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nTidy Modeling with R by Max Kuhn & Julia Silge\nPosit Cheatsheets\nR workshops by Duke Center for Data and Visualization Sciences",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 221 - Regression Analysis: Theory and Applications",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nweek\ndow\ndate\ntopic\nprepare\nslides\nae\nhw\nlab\nproject\nnotes\n\n\n\n\n1\nM\nAug 26\nLab 00: Welcome + Getting Started\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nAug 27\nWelcome to STA 221!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nAug 29\nSimple linear regression (SLR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\nSep 2\nNO LAB: Labor Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 3\nSLR: Model assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 5\nSLR: Model assessment cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLR: Matrix representation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nM\nSep 9\nLab 01: Simple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 10\nSLR: Matrix representation cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 12\nMLR: Categorical predictors + Model assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 assigned, Lab 01 due\n\n\n4\nM\nSep 16\nLab 02: Multiple linear regression + Meet your team!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 17\nANOVA + Geometric interpretation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 19\nInference for regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 due, Lab 02 due\n\n\n5\nM\nSep 23\nLab 03: Inference for regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject: Develop Research question\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nSep 24\nInference for regression cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nSep 26\nProperties of estimators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 assigned, Project research questions due\n\n\n6\nM\nSep 30\nLab 03 + Project proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 1\nProperties of estimators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 3\nExam 01 Review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 due, Lab 03 due, Project proposal due\n\n\n7\nM\nOct 7\nLab :Exam office hours\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 8\nExam 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 10\nMaximum Likelihood Estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\nM\nOct 14\nNO LAB: Fall Break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 15\nNO LECTURE: Fall Break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 17\nMLR: Model diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam 01 corrections assigned\n\n\n9\nM\nOct 21\nLab 04: Maximum likelihood estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 22\nMLR: Multicollinearity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 24\nMLR: Variable transformations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam 01 corrections due, Lab 04 due, HW 03 assigned\n\n\n10\nM\nOct 28\nLab: Project exploratory data analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nOct 29\nMLR: Model comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nOct 31\nProbabilities + Odds + Odds ratios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 03 due, Project EDA due\n\n\n11\nM\nNov 4\nLab: Expanding multiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 5\nWellness Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 7\nLogistic regression (LR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 05 due\n\n\n12\nM\nNov 11\nLab: Project presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 12\nLR: Prediction + assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 14\nLR: Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 assigned\n\n\n13\nM\nNov 18\nLab: Logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 19\nLR estimation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 21\nTBD / Catch up day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 due\n\n\n14\nM\nNov 25\nProject: Draft analysis + report\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nNov 26\nProject day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nNov 28\nNO LECTURE: Thanksgiving\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\nM\nDec 2\nProject: Peer review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nDec 3\nExam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nDec 5\nExam 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam period",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "slides/lab-03.html#goals",
    "href": "slides/lab-03.html#goals",
    "title": "Lab 03",
    "section": "Goals",
    "text": "Goals\n\nTeam project\nLab 03: Palmer penguins"
  },
  {
    "objectID": "slides/lab-03.html#lab-03-palmer-penguins",
    "href": "slides/lab-03.html#lab-03-palmer-penguins",
    "title": "Lab 03",
    "section": "Lab 03: Palmer penguins",
    "text": "Lab 03: Palmer penguins\nLab 03 focuses on\n\nusing linear regression and statistical inference to draw conclusions about penguins living in Palmer Archipelago in Antarctica.\nuse the data to check conditions about the distribution of the model residuals.\n\nUse this week to get started on the lab. We will continue discussing statistical inference in this week’s lectures, so this lab will be due on Thursday, October 3, 2024.\n🔗 https://sta221-fa24.netlify.app/labs/lab-03"
  },
  {
    "objectID": "slides/lab-03.html#final-team-project",
    "href": "slides/lab-03.html#final-team-project",
    "title": "Lab 03",
    "section": "Final Team Project",
    "text": "Final Team Project\nGoal: Use the methods from STA 221 to analyze data and answer a research question developed by your team\nPrimary deliverables:\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na GitHub repository containing all work from the project\n\nSubmission: All work for the project will be submitted in your team’s GitHub repo. You will receive feedback via an Issue on GitHub to model a workflow often used in practice."
  },
  {
    "objectID": "slides/lab-03.html#final-team-project-1",
    "href": "slides/lab-03.html#final-team-project-1",
    "title": "Lab 03",
    "section": "Final team project",
    "text": "Final team project\nMilestones: There are periodic project milestones throughout the semester to help you work towards the final deliverables:\n\nResearch questions (today’s lab)\nProject proposal (next week’s lab)\nExploratory data analysis draft\nPresentation + Presentation comments\nAnalysis draft + peer review\nRound 1 submission (optional)\nWritten report\nReproducibility + organization\n\nSee the Final Project Instructions for a timeline and details for each milestone."
  },
  {
    "objectID": "slides/lab-03.html#today-research-questions",
    "href": "slides/lab-03.html#today-research-questions",
    "title": "Lab 03",
    "section": "Today: Research questions",
    "text": "Today: Research questions\nGoal: Develop three potential research questions your team may be interested in investigating.\nYou do not need to have a data set at this point\nFull instructions here: sta221-fa24.netlify.app/project#research-questions"
  },
  {
    "objectID": "slides/lab-03.html#reminder-team-workflow",
    "href": "slides/lab-03.html#reminder-team-workflow",
    "title": "Lab 03",
    "section": "Reminder: Team workflow",
    "text": "Reminder: Team workflow\n\nOnly one team member should type at a time. There are markers in today’s lab to help you determine whose turn it is to type.\n\nEvery team member should still be engaged in discussion for all questions, even if it’s not your turn type.\n\nDon’t forget to pull to get your teammates’ updates before making changes to the .qmd file.\n\n\n\n\n\n\nImportant\n\n\nOnly one submission per team on Gradescope. Read the submission instructions carefully!"
  },
  {
    "objectID": "slides/lab-03.html#reminder-tips-for-working-on-a-team",
    "href": "slides/lab-03.html#reminder-tips-for-working-on-a-team",
    "title": "Lab 03",
    "section": "Reminder: Tips for working on a team",
    "text": "Reminder: Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other.\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#announcements",
    "href": "slides/20-logistic-prediction.html#announcements",
    "title": "Logistic Regression: Prediction",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#computational-set-up",
    "href": "slides/20-logistic-prediction.html#computational-set-up",
    "title": "Logistic Regression: Prediction",
    "section": "Computational set up",
    "text": "Computational set up"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#topics",
    "href": "slides/20-logistic-prediction.html#topics",
    "title": "Logistic Regression: Prediction",
    "section": "Topics",
    "text": "Topics\n\nCalculating predicted probabilities from the logistic regression model\nUsing predicted probabilities to classify observations\nMake decisions and assess modelperformance using\n\nConfusion matrix\nROC curve"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#data-risk-of-coronary-heart-disease",
    "href": "slides/20-logistic-prediction.html#data-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Prediction",
    "section": "Data: Risk of coronary heart disease",
    "text": "Data: Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\nhigh_risk: 1 = High risk of having heart disease in next 10 years, 0 = Not high risk of having heart disease in next 10 years\nage: Age at exam time (in years)\ntotChol: Total cholesterol (in mg/dL)\ncurrentSmoker: 0 = nonsmoker; 1 = smoker"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#modeling-risk-of-coronary-heart-disease",
    "href": "slides/20-logistic-prediction.html#modeling-risk-of-coronary-heart-disease",
    "title": "Logistic Regression: Prediction",
    "section": "Modeling risk of coronary heart disease",
    "text": "Modeling risk of coronary heart disease\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-6.638\n0.372\n-17.860\n0.000\n-7.374\n-5.917\n\n\nage\n0.082\n0.006\n14.430\n0.000\n0.071\n0.093\n\n\ntotChol\n0.002\n0.001\n2.001\n0.045\n0.000\n0.004\n\n\ncurrentSmoker1\n0.457\n0.092\n4.951\n0.000\n0.277\n0.639"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#prediction-and-classification",
    "href": "slides/20-logistic-prediction.html#prediction-and-classification",
    "title": "Logistic Regression: Prediction",
    "section": "Prediction and classification",
    "text": "Prediction and classification\n\nWe are often interested in using the model to classify observations, i.e., predict whether a given observation will have a 1 or 0 response\nFor each observation\n\nUse the logistic regression model to calculate the predicted log-odds the response for the \\(i^{th}\\) observation is 1\nUse the log-odds to calculate the predicted probability the $i^{th} observation is 1\nThen, use the predicted probabilities to classify the observation as having a 1 or 0 response using some predefined threshold"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predicted-log-odds",
    "href": "slides/20-logistic-prediction.html#predicted-log-odds",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted log-odds",
    "text": "Predicted log-odds\n\n\n# A tibble: 4,190 × 1\n   .fitted\n     &lt;dbl&gt;\n 1  -3.06 \n 2  -2.38 \n 3  -1.77 \n 4  -0.751\n 5  -1.86 \n 6  -2.67 \n 7  -1.08 \n 8  -1.88 \n 9  -1.87 \n10  -2.22 \n# ℹ 4,180 more rows\n\n\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 1\n\\[\n\\text{predicted log-odds} = \\log(\\hat{\\omega}) = \\log\\Big(\\frac{\\hat{\\pi}}{1- \\hat{\\pi}}\\Big) = -3.06\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predicted-probability",
    "href": "slides/20-logistic-prediction.html#predicted-probability",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted probability",
    "text": "Predicted probability\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 1\n\\[\n\\text{predicted odds} = \\hat{\\omega} = \\frac{\\hat{\\pi}}{1- \\hat{\\pi}} = \\exp\\{-3.06\\} = 0.0469\n\\]"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predicted-probability-1",
    "href": "slides/20-logistic-prediction.html#predicted-probability-1",
    "title": "Logistic Regression: Prediction",
    "section": "Predicted probability",
    "text": "Predicted probability\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 1\n\\[\n\\text{predicted prob.} = \\hat{\\pi} = \\frac{\\hat{\\omega}}{1+\\hat{\\omega}} = \\frac{\\exp\\{-3.06\\}}{1 + \\exp\\{-3.06\\}}= 0.045\n\\]\n\n\n\nWould you classify this individual as high risk \\((\\hat{y} = 1)\\) or not high risk \\((\\hat{y} = 0)\\)?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#another-individual",
    "href": "slides/20-logistic-prediction.html#another-individual",
    "title": "Logistic Regression: Prediction",
    "section": "Another individual",
    "text": "Another individual\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1  -3.06 \n2  -2.38 \n3  -1.77 \n4  -0.751\n5  -1.86 \n\n\n\nObservation 4\n\\[\n\\text{predicted prob.} = \\hat{\\pi} = \\frac{\\hat{\\omega}}{1+\\hat{\\omega}} = \\frac{\\exp\\{-0.751\\}}{1 + \\exp\\{-0.751\\}}= 0.321\n\\]\n\n\n\nWould you classify this individual as high risk \\((\\hat{y} = 1)\\) or not high risk \\((\\hat{y} = 0)\\)?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predictions-in-r",
    "href": "slides/20-logistic-prediction.html#predictions-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "Predictions in R",
    "text": "Predictions in R\nWe can calculate predicted probabilities using the predict.glm() function. Use type = \"response\" to get probabilities.1\n\n\n\npredict.glm(heart_disease_fit, type = \"response\")\n\n\n\nPredicted probabilities for Observations 1 -5\n\n\n         1          2          3          4          5 \n0.04459439 0.08445209 0.14523257 0.32065849 0.13515474 \n\n\n\nThe default is type = \"link\", which produces the predicted log-odds."
  },
  {
    "objectID": "slides/20-logistic-prediction.html#predictions-in-r-1",
    "href": "slides/20-logistic-prediction.html#predictions-in-r-1",
    "title": "Logistic Regression: Prediction",
    "section": "Predictions in R",
    "text": "Predictions in R\n\npred_prob &lt;- predict.glm(heart_disease_fit, type = \"response\")\n\nheart_disease_aug &lt;- heart_disease_aug |&gt; \n  bind_cols(pred_prob = pred_prob)\n\n\n\n\n# A tibble: 5 × 3\n  high_risk .fitted pred_prob\n  &lt;fct&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 0          -3.06     0.0446\n2 0          -2.38     0.0845\n3 0          -1.77     0.145 \n4 1          -0.751    0.321 \n5 0          -1.86     0.135"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#classifying-observations",
    "href": "slides/20-logistic-prediction.html#classifying-observations",
    "title": "Logistic Regression: Prediction",
    "section": "Classifying observations",
    "text": "Classifying observations\n\n\nWhat threshold would you use to classify observations as high risk or not high risk?\nWhat considerations did you make to determine the threshold?"
  },
  {
    "objectID": "slides/20-logistic-prediction.html#default-predictions-in-r",
    "href": "slides/20-logistic-prediction.html#default-predictions-in-r",
    "title": "Logistic Regression: Prediction",
    "section": "Default predictions in R",
    "text": "Default predictions in R\nWe can use the predict.glm() function in R to produce the predicted class for each observation\n\n\n         1          2          3          4          5          6          7 \n0.04459439 0.08445209 0.14523257 0.32065849 0.13515474 0.06463709 0.25260766 \n         8          9         10         11         12         13         14 \n0.13215793 0.13314260 0.09791245 0.11418102 0.06696352 0.13726415 0.06733982 \n        15         16         17         18         19         20         21 \n0.07274367 0.06680045 0.14204713 0.13655796 0.06364322 0.05209395 0.08533119 \n        22         23         24         25         26         27         28 \n0.05964728 0.12727745 0.18158977 0.11411981 0.14722411 0.22790670 0.05345782 \n        29         30         31         32         33         34         35 \n0.24701369 0.22338181 0.06581571 0.09808854 0.19727291 0.29935897 0.20680635 \n        36         37         38         39         40         41         42 \n0.04038452 0.17468400 0.11539238 0.09225879 0.03424429 0.10112559 0.08626994 \n        43         44         45         46         47         48         49 \n0.13709636 0.15575004 0.09779003 0.30410983 0.12966312 0.33647054 0.05447404 \n        50         51         52         53         54         55         56 \n0.37665793 0.11478531 0.13353126 0.25036063 0.07049215 0.12721022 0.22431496 \n        57         58         59         60         61         62         63 \n0.15830270 0.06439569 0.07547618 0.25551610 0.34062785 0.19560509 0.25779349 \n        64         65         66         67         68         69         70 \n0.17583354 0.27069010 0.24003847 0.06704925 0.14873109 0.14309900 0.26911989 \n        71         72         73         74         75         76         77 \n0.08302767 0.03849807 0.07902456 0.10461698 0.21318818 0.06646641 0.10313352 \n        78         79         80         81         82         83         84 \n0.06923699 0.09226009 0.28050191 0.05288809 0.13108514 0.16864541 0.22476454 \n        85         86         87         88         89         90         91 \n0.05478268 0.25829374 0.36596989 0.08865473 0.06043600 0.18576907 0.07687917 \n        92         93         94         95         96         97         98 \n0.12057589 0.34782612 0.31076396 0.27982361 0.36365465 0.04912819 0.18616930 \n        99        100        101        102        103        104        105 \n0.25513733 0.12966138 0.23320750 0.12221107 0.10063981 0.08272484 0.27902762 \n       106        107        108        109        110        111        112 \n0.06238698 0.08817430 0.33306659 0.14350813 0.34511622 0.11438110 0.09501507 \n       113        114        115        116        117        118        119 \n0.29949568 0.05942593 0.11478688 0.23427790 0.05785140 0.03627671 0.14822150 \n       120        121        122        123        124        125        126 \n0.04866569 0.12436256 0.33750632 0.07706261 0.14407317 0.05491814 0.07185004 \n       127        128        129        130        131        132        133 \n0.04451025 0.09530467 0.05389331 0.20323738 0.09738585 0.31893188 0.24652802 \n       134        135        136        137        138        139        140 \n0.14204336 0.13169988 0.06936747 0.23750670 0.07873508 0.15856831 0.17126655 \n       141        142        143        144        145        146        147 \n0.10058364 0.04459373 0.18950984 0.25894159 0.10580208 0.30020179 0.08600397 \n       148        149        150        151        152        153        154 \n0.27029396 0.14555532 0.31561428 0.22825471 0.26213149 0.30537278 0.07049215 \n       155        156        157        158        159        160        161 \n0.18049807 0.10827581 0.10617815 0.07224754 0.05099238 0.08737553 0.07921381 \n       162        163        164        165        166        167        168 \n0.26047061 0.12399843 0.26020655 0.04227736 0.06006161 0.13678937 0.11594176 \n       169        170        171        172        173        174        175 \n0.12749889 0.04325658 0.17231195 0.06932641 0.25438383 0.34768181 0.25148975 \n       176        177        178        179        180        181        182 \n0.32239677 0.07409887 0.08913752 0.04658913 0.09093278 0.05666937 0.19717707 \n       183        184        185        186        187        188        189 \n0.34197141 0.12334739 0.11311515 0.16294789 0.08946153 0.15998314 0.07088576 \n       190        191        192        193        194        195        196 \n0.24468251 0.23356116 0.12436424 0.09248433 0.15075621 0.16151607 0.23238504 \n       197        198        199        200        201        202        203 \n0.26587558 0.22097199 0.03939218 0.18607058 0.18910884 0.08658453 0.05796007 \n       204        205        206        207        208        209        210 \n0.05975998 0.29574780 0.23416378 0.33839429 0.09109631 0.10387147 0.23499061 \n       211        212        213        214        215        216        217 \n0.33617134 0.02828920 0.13176912 0.10668601 0.06898266 0.15358323 0.16321768 \n       218        219        220        221        222        223        224 \n0.08886356 0.05013172 0.06188555 0.22165861 0.04623442 0.06821896 0.12727573 \n       225        226        227        228        229        230        231 \n0.21644349 0.16957455 0.11806556 0.07994451 0.15366596 0.23107968 0.09484391 \n       232        233        234        235        236        237        238 \n0.08383564 0.21711996 0.04872778 0.30271878 0.17268492 0.24138703 0.08019339 \n       239        240        241        242        243        244        245 \n0.28547830 0.39268078 0.07777514 0.07437162 0.37338958 0.12787524 0.21755916 \n       246        247        248        249        250        251        252 \n0.26744287 0.28453990 0.07287920 0.20920840 0.04350394 0.22966141 0.17632373 \n       253        254        255        256        257        258        259 \n0.22511454 0.03641626 0.08333504 0.05318592 0.26174935 0.12861104 0.14474059 \n       260        261        262        263        264        265        266 \n0.07979810 0.27305314 0.16348994 0.07184901 0.12157141 0.15314451 0.05723768 \n       267        268        269        270        271        272        273 \n0.12639837 0.15653545 0.26510166 0.26289985 0.06285381 0.08507025 0.20910571 \n       274        275        276        277        278        279        280 \n0.12313214 0.36241981 0.05522834 0.06261772 0.12928403 0.25148975 0.03339858 \n       281        282        283        284        285        286        287 \n0.05044827 0.31905331 0.15574801 0.04053861 0.05025776 0.05806978 0.05060815 \n       288        289        290        291        292        293        294 \n0.07538163 0.11159079 0.21610583 0.10898579 0.13844613 0.09844432 0.12078728 \n       295        296        297        298        299        300        301 \n0.04772343 0.04997180 0.26677840 0.05219470 0.09450242 0.15340305 0.17013852 \n       302        303        304        305        306        307        308 \n0.11411668 0.06692667 0.13499273 0.14948541 0.07873732 0.16052138 0.09098411 \n       309        310        311        312        313        314        315 \n0.32501003 0.07716240 0.12306846 0.04875800 0.12051008 0.37338958 0.05998511 \n       316        317        318        319        320        321        322 \n0.12899366 0.06211816 0.10022238 0.15436174 0.20195009 0.17117626 0.06134554 \n       323        324        325        326        327        328        329 \n0.25261641 0.07220801 0.24652802 0.20920584 0.18138835 0.09126138 0.13376013 \n       330        331        332        333        334        335        336 \n0.26174637 0.19571008 0.07194155 0.08978661 0.17719336 0.14285112 0.12529922 \n       337        338        339        340        341        342        343 \n0.31218207 0.18197610 0.09292830 0.08167399 0.10148832 0.36319379 0.08584872 \n       344        345        346        347        348        349        350 \n0.14043108 0.08642711 0.21375549 0.24150356 0.07565871 0.14107692 0.08033931 \n       351        352        353        354        355        356        357 \n0.06881404 0.16124228 0.25136419 0.12928056 0.21241676 0.07617417 0.17402109 \n       358        359        360        361        362        363        364 \n0.08705957 0.06459957 0.08951086 0.12588906 0.28090726 0.03984756 0.07274263 \n       365        366        367        368        369        370        371 \n0.22131777 0.11614611 0.33794843 0.05767003 0.15838337 0.12973145 0.08689892 \n       372        373        374        375        376        377        378 \n0.13851650 0.29603672 0.12589076 0.31819169 0.46771480 0.25374348 0.16349416 \n       379        380        381        382        383        384        385 \n0.06192249 0.12313047 0.07194155 0.07409781 0.04811529 0.25943736 0.17757689 \n       386        387        388        389        390        391        392 \n0.04227736 0.06742308 0.17690311 0.14931114 0.10904909 0.19498382 0.30579879 \n       393        394        395        396        397        398        399 \n0.31175116 0.04519230 0.11573615 0.27889965 0.33218215 0.24987346 0.05409683 \n       400        401        402        403        404        405        406 \n0.06077625 0.05054231 0.11351546 0.06472098 0.06609750 0.07482597 0.05440345 \n       407        408        409        410        411        412        413 \n0.10611925 0.03385119 0.23678872 0.11903992 0.06320584 0.26009301 0.31246996 \n       414        415        416        417        418        419        420 \n0.11758690 0.08647735 0.06448023 0.18758616 0.08172056 0.06499841 0.08333150 \n       421        422        423        424        425        426        427 \n0.17844458 0.06142455 0.17516943 0.29367745 0.20583026 0.20789062 0.04820590 \n       428        429        430        431        432        433        434 \n0.16929204 0.15101341 0.07496507 0.07645502 0.09703620 0.14407507 0.11635235 \n       435        436        437        438        439        440        441 \n0.05785224 0.26483157 0.04356168 0.16051722 0.10517957 0.22790670 0.07171731 \n       442        443        444        445        446        447        448 \n0.33514447 0.21519475 0.11841461 0.06051216 0.15050331 0.15083372 0.18011874 \n       449        450        451        452        453        454        455 \n0.07565763 0.08838211 0.06297034 0.10040217 0.08182353 0.15522282 0.12220776 \n       456        457        458        459        460        461        462 \n0.13329916 0.08721804 0.04882092 0.11621302 0.06364322 0.10885269 0.06984330 \n       463        464        465        466        467        468        469 \n0.26355214 0.22397122 0.09242317 0.08647491 0.17069961 0.24627338 0.07730547 \n       470        471        472        473        474        475        476 \n0.17325265 0.12392934 0.17777048 0.09098155 0.12654817 0.06532653 0.10731637 \n       477        478        479        480        481        482        483 \n0.20131370 0.28751754 0.12436592 0.03676685 0.24998694 0.21208369 0.04417194 \n       484        485        486        487        488        489        490 \n0.12436088 0.09738449 0.11559746 0.08363753 0.25336061 0.13147224 0.08318181 \n       491        492        493        494        495        496        497 \n0.28293304 0.11553717 0.17835811 0.11492629 0.17497138 0.21251805 0.07617417 \n       498        499        500        501        502        503        504 \n0.13040768 0.28670207 0.06544733 0.11498945 0.08078198 0.20109082 0.17923560 \n       505        506        507        508        509        510        511 \n0.12292054 0.12029910 0.13686269 0.15185917 0.29907467 0.19227658 0.25855951 \n       512        513        514        515        516        517        518 \n0.13147224 0.26755241 0.10112559 0.05406586 0.11987810 0.21756442 0.11559904 \n       519        520        521        522        523        524        525 \n0.32895552 0.19248965 0.17894046 0.20045151 0.12523289 0.14797212 0.13916051 \n       526        527        528        529        530        531        532 \n0.31004401 0.05638375 0.22720366 0.07716020 0.17183718 0.03437630 0.06671501 \n       533        534        535        536        537        538        539 \n0.07062482 0.25261058 0.26366665 0.08152586 0.15152294 0.11519391 0.07892482 \n       540        541        542        543        544        545        546 \n0.18729451 0.03939218 0.07287815 0.09479063 0.05533157 0.15724181 0.09709060 \n       547        548        549        550        551        552        553 \n0.07950716 0.22709740 0.32851933 0.13804359 0.15803539 0.05268811 0.10636589 \n       554        555        556        557        558        559        560 \n0.17013634 0.11015343 0.06412066 0.05554100 0.15706222 0.04969030 0.04383737 \n       561        562        563        564        565        566        567 \n0.06273748 0.16901641 0.21824078 0.02974830 0.10860099 0.15619078 0.10943377 \n       568        569        570        571        572        573        574 \n0.08663241 0.27503779 0.07990113 0.09616695 0.23463823 0.08212335 0.22755906 \n       575        576        577        578        579        580        581 \n0.12995828 0.34272867 0.15909649 0.12501482 0.04658913 0.22720638 0.18158977 \n       582        583        584        585        586        587        588 \n0.07437162 0.18011418 0.07414041 0.33293214 0.08212335 0.07355402 0.12072137 \n       589        590        591        592        593        594        595 \n0.07547618 0.06597369 0.04227798 0.23356392 0.08946153 0.07318991 0.13561931 \n       596        597        598        599        600        601        602 \n0.18406809 0.12764980 0.32939882 0.36642867 0.38794393 0.13169988 0.16025312 \n       603        604        605        606        607        608        609 \n0.08978661 0.22327414 0.03103922 0.04838903 0.09326207 0.19033379 0.27069010 \n       610        611        612        613        614        615        616 \n0.04527834 0.22745810 0.19664275 0.18397256 0.32296446 0.14180640 0.30411310 \n       617        618        619        620        621        622        623 \n0.15461993 0.37759383 0.04950250 0.06655251 0.08486590 0.06958491 0.17430540 \n       624        625        626        627        628        629        630 \n0.32109596 0.08333268 0.07989886 0.25400324 0.06780080 0.27543518 0.09915242 \n       631        632        633        634        635        636        637 \n0.04527767 0.12184907 0.34183868 0.07744548 0.05186854 0.05150763 0.13709636 \n       638        639        640        641        642        643        644 \n0.03517871 0.07931727 0.04358755 0.03606782 0.06435830 0.22028690 0.29231407 \n       645        646        647        648        649        650        651 \n0.26394198 0.15540272 0.26355214 0.08674221 0.07382493 0.17777499 0.11035036 \n       652        653        654        655        656        657        658 \n0.03558666 0.30495693 0.16948932 0.11099511 0.11218311 0.27849919 0.27345488 \n       659        660        661        662        663        664        665 \n0.26278256 0.19601898 0.14722217 0.06411973 0.10770014 0.34918654 0.09060396 \n       666        667        668        669        670        671        672 \n0.13079308 0.06667637 0.11931096 0.09622092 0.27332849 0.30905979 0.03326970 \n       673        674        675        676        677        678        679 \n0.15470109 0.15496380 0.11371608 0.30707223 0.15645351 0.07345958 0.09197621 \n       680        681        682        683        684        685        686 \n0.10022099 0.19664763 0.37338596 0.30778506 0.19126126 0.20366081 0.08455938 \n       687        688        689        690        691        692        693 \n0.06411973 0.22640154 0.04459439 0.11717253 0.29769356 0.23213501 0.21486111 \n       694        695        696        697        698        699        700 \n0.04922133 0.22293153 0.09849806 0.28010627 0.07565871 0.10392783 0.11331205 \n       701        702        703        704        705        706        707 \n0.05551007 0.10076260 0.15856625 0.23919943 0.07088474 0.08913877 0.08774220 \n       708        709        710        711        712        713        714 \n0.07291906 0.14722023 0.06423938 0.21994758 0.06305222 0.07464742 0.31677223 \n       715        716        717        718        719        720        721 \n0.29491865 0.12905995 0.18197840 0.05359018 0.36920797 0.13923305 0.05603297 \n       722        723        724        725        726        727        728 \n0.08902499 0.04442429 0.11661967 0.15830476 0.36966484 0.12765668 0.28264552 \n       729        730        731        732        733        734        735 \n0.08004543 0.09314747 0.09902725 0.06779983 0.34949473 0.19073440 0.11910341 \n       736        737        738        739        740        741        742 \n0.14622457 0.11034733 0.31303157 0.10166871 0.22269139 0.06227056 0.05268656 \n       743        744        745        746        747        748        749 \n0.33928686 0.25336061 0.24076602 0.12292054 0.26990427 0.07441436 0.07960645 \n       750        751        752        753        754        755        756 \n0.10555368 0.21442586 0.14139570 0.06376204 0.08564267 0.12178100 0.20269328 \n       757        758        759        760        761        762        763 \n0.06658917 0.18129848 0.22258395 0.42491765 0.25932404 0.03464127 0.06188555 \n       764        765        766        767        768        769        770 \n0.25449280 0.08137681 0.08009229 0.13662570 0.32470927 0.04108387 0.05659610 \n       771        772        773        774        775        776        777 \n0.04808687 0.07758793 0.12787524 0.04863624 0.08983609 0.12029746 0.09343197 \n       778        779        780        781        782        783        784 \n0.18040855 0.07950716 0.09616829 0.16078584 0.27384777 0.13592590 0.11820681 \n       785        786        787        788        789        790        791 \n0.14973886 0.06859883 0.05987201 0.37852700 0.26315968 0.20723529 0.13245080 \n       792        793        794        795        796        797        798 \n0.27531439 0.20259297 0.05406586 0.08262201 0.06032386 0.08600397 0.14897957 \n       799        800        801        802        803        804        805 \n0.22235209 0.22052518 0.12328028 0.30905979 0.15083768 0.31346011 0.03648677 \n       806        807        808        809        810        811        812 \n0.20625517 0.03820476 0.06305313 0.15963439 0.10536575 0.05358940 0.10725987 \n       813        814        815        816        817        818        819 \n0.03886846 0.17670577 0.05285546 0.06142544 0.15593248 0.10982267 0.47317387 \n       820        821        822        823        824        825        826 \n0.10387291 0.13804359 0.05648901 0.09884828 0.05763630 0.13995083 0.24652515 \n       827        828        829        830        831        832        833 \n0.13284132 0.15436174 0.20237153 0.15971561 0.20756276 0.15006986 0.06297125 \n       834        835        836        837        838        839        840 \n0.08068021 0.06297125 0.09315008 0.15384238 0.06134643 0.24076884 0.03641626 \n       841        842        843        844        845        846        847 \n0.07023154 0.09314747 0.04676504 0.29231088 0.09467303 0.07510440 0.09616829 \n       848        849        850        851        852        853        854 \n0.06560638 0.13018194 0.27889655 0.03606889 0.07010056 0.40366342 0.20877645 \n       855        856        857        858        859        860        861 \n0.21519997 0.16762207 0.27332849 0.22884773 0.07506022 0.05298564 0.09744043 \n       862        863        864        865        866        867        868 \n0.06605919 0.30368841 0.12099736 0.07260941 0.16132626 0.28833440 0.17661323 \n       869        870        871        872        873        874        875 \n0.10808362 0.19939381 0.08806163 0.18456912 0.22650217 0.16016752 0.27650526 \n       876        877        878        879        880        881        882 \n0.26405359 0.04140017 0.24689537 0.29574780 0.33839774 0.03909350 0.06188555 \n       883        884        885        886        887        888        889 \n0.07368989 0.08674098 0.11946000 0.21019627 0.24467966 0.34723014 0.28171589 \n       890        891        892        893        894        895        896 \n0.12334906 0.26665094 0.10387291 0.23571039 0.16873897 0.07859406 0.13337090 \n       897        898        899        900        901        902        903 \n0.09376999 0.36734695 0.24222846 0.04712155 0.04673669 0.33085772 0.15366596 \n       904        905        906        907        908        909        910 \n0.07888082 0.12787524 0.13330095 0.26833391 0.08837962 0.08595518 0.35952663 \n       911        912        913        914        915        916        917 \n0.18677370 0.09348457 0.07645611 0.28063657 0.10763901 0.38182386 0.22605012 \n       918        919        920        921        922        923        924 \n0.27690396 0.20420685 0.06281816 0.06400214 0.25525826 0.13314081 0.31375197 \n       925        926        927        928        929        930        931 \n0.21052718 0.11251853 0.06859982 0.13238303 0.05248960 0.14880775 0.13585301 \n       932        933        934        935        936        937        938 \n0.19342511 0.13515113 0.12327861 0.06157536 0.12854149 0.06475763 0.26124178 \n       939        940        941        942        943        944        945 \n0.04900699 0.09501640 0.41957569 0.06556833 0.20301541 0.26626761 0.27069010 \n       946        947        948        949        950        951        952 \n0.14906025 0.04235872 0.26821811 0.10750885 0.08337894 0.05108887 0.08978661 \n       953        954        955        956        957        958        959 \n0.08093232 0.19686436 0.28183839 0.22476454 0.15470311 0.24113318 0.17690086 \n       960        961        962        963        964        965        966 \n0.03939218 0.18637716 0.06006161 0.18456912 0.17430984 0.32196511 0.04171633 \n       967        968        969        970        971        972        973 \n0.22954887 0.28183839 0.21442065 0.12009007 0.31732796 0.06332756 0.13261023 \n       974        975        976        977        978        979        980 \n0.22190062 0.14872522 0.08216900 0.06427763 0.14956632 0.04922206 0.06919799 \n       981        982        983        984        985        986        987 \n0.26833391 0.35860616 0.08758411 0.12544959 0.14399854 0.16267846 0.22408182 \n       988        989        990        991        992        993        994 \n0.03558613 0.04950104 0.07936036 0.20462676 0.29161559 0.05853968 0.11139039 \n       995        996        997        998        999       1000       1001 \n0.04325658 0.19043186 0.18516718 0.17117626 0.09209210 0.27570894 0.19812237 \n      1002       1003       1004       1005       1006       1007       1008 \n0.13176735 0.18496037 0.32109596 0.28630116 0.20592923 0.13615823 0.09377130 \n      1009       1010       1011       1012       1013       1014       1015 \n0.03565562 0.10827432 0.03339808 0.19289852 0.03201278 0.07950603 0.08689892 \n      1016       1017       1018       1019       1020       1021       1022 \n0.37853064 0.28955910 0.07663862 0.12458134 0.21960333 0.11192160 0.06463615 \n      1023       1024       1025       1026       1027       1028       1029 \n0.07220801 0.05502082 0.35631487 0.10154495 0.16651322 0.10976199 0.25702896 \n      1030       1031       1032       1033       1034       1035       1036 \n0.26124178 0.16132626 0.24875207 0.32036320 0.22165594 0.16505199 0.05308569 \n      1037       1038       1039       1040       1041       1042       1043 \n0.10750736 0.09861989 0.14999857 0.21042658 0.06250180 0.14729819 0.27970475 \n      1044       1045       1046       1047       1048       1049       1050 \n0.44498815 0.07552059 0.07716020 0.12861104 0.04747993 0.23380949 0.07220594 \n      1051       1052       1053       1054       1055       1056       1057 \n0.04730007 0.03627617 0.10467659 0.06634578 0.10209148 0.12973145 0.19844150 \n      1058       1059       1060       1061       1062       1063       1064 \n0.11994198 0.11132896 0.31432149 0.08152354 0.08647369 0.10276415 0.26278256 \n      1065       1066       1067       1068       1069       1070       1071 \n0.17902942 0.21042402 0.17932694 0.34466612 0.24764268 0.21824342 0.16097513 \n      1072       1073       1074       1075       1076       1077       1078 \n0.15812007 0.07579815 0.26900691 0.08491532 0.07701956 0.10443052 0.08034045 \n      1079       1080       1081       1082       1083       1084       1085 \n0.04325722 0.12742985 0.13726232 0.10480518 0.14407698 0.17089382 0.19094854 \n      1086       1087       1088       1089       1090       1091       1092 \n0.11994198 0.10750736 0.06894379 0.11827314 0.03961895 0.09861852 0.35906804 \n      1093       1094       1095       1096       1097       1098       1099 \n0.16873247 0.19875855 0.08833211 0.23072043 0.04502003 0.19476139 0.23216254 \n      1100       1101       1102       1103       1104       1105       1106 \n0.26638589 0.31560761 0.19560509 0.09343328 0.06618125 0.28861904 0.15600810 \n      1107       1108       1109       1110       1111       1112       1113 \n0.42443848 0.17757463 0.21576855 0.28670207 0.06746213 0.08584872 0.07506022 \n      1114       1115       1116       1117       1118       1119       1120 \n0.09565009 0.36227281 0.09587634 0.25449866 0.12313214 0.11277662 0.30411310 \n      1121       1122       1123       1124       1125       1126       1127 \n0.29120424 0.08690137 0.10918089 0.10687601 0.27214003 0.10387291 0.16781349 \n      1128       1129       1130       1131       1132       1133       1134 \n0.17439698 0.13291106 0.29616611 0.17699127 0.26482857 0.25400032 0.24029435 \n      1135       1136       1137       1138       1139       1140       1141 \n0.16541025 0.07960645 0.16206056 0.04485037 0.17583578 0.44351265 0.07441436 \n      1142       1143       1144       1145       1146       1147       1148 \n0.37431861 0.16587509 0.05854138 0.13655796 0.21722287 0.08409671 0.08231936 \n      1149       1150       1151       1152       1153       1154       1155 \n0.22615605 0.35235160 0.07834860 0.21950490 0.19414456 0.15058270 0.11438110 \n      1156       1157       1158       1159       1160       1161       1162 \n0.12523120 0.34152327 0.10009879 0.13923305 0.03457523 0.27504087 0.19601654 \n      1163       1164       1165       1166       1167       1168       1169 \n0.06028781 0.18257686 0.11251699 0.10004288 0.08967460 0.23631963 0.06073906 \n      1170       1171       1172       1173       1174       1175       1176 \n0.17961803 0.41909815 0.07777403 0.10866110 0.17117846 0.29244251 0.08460385 \n      1177       1178       1179       1180       1181       1182       1183 \n0.26860626 0.31806373 0.08705835 0.29866047 0.24701081 0.35906093 0.41086922 \n      1184       1185       1186       1187       1188       1189       1190 \n0.23463823 0.05656297 0.09044250 0.20453077 0.10467514 0.12414411 0.38936391 \n      1191       1192       1193       1194       1195       1196       1197 \n0.08538086 0.19570279 0.31431816 0.05308647 0.07464636 0.10480663 0.12120939 \n      1198       1199       1200       1201       1202       1203       1204 \n0.06180688 0.11703394 0.18728275 0.18737491 0.09331850 0.04940812 0.05196583 \n      1205       1206       1207       1208       1209       1210       1211 \n0.06487932 0.20172917 0.06238608 0.07238325 0.05905654 0.06305131 0.05832218 \n      1212       1213       1214       1215       1216       1217       1218 \n0.04317293 0.05961247 0.17296528 0.08455818 0.08642589 0.29149056 0.05627704 \n      1219       1220       1221       1222       1223       1224       1225 \n0.13215439 0.20365831 0.06962311 0.23025974 0.34827114 0.30271226 0.03613768 \n      1226       1227       1228       1229       1230       1231       1232 \n0.05160428 0.12072301 0.17865024 0.06783810 0.03391691 0.10027838 0.18189061 \n      1233       1234       1235       1236       1237       1238       1239 \n0.04940812 0.09582121 0.16124437 0.12966138 0.07748984 0.18496037 0.04597295 \n      1240       1241       1242       1243       1244       1245       1246 \n0.10374390 0.14498736 0.19948800 0.07482704 0.26509865 0.27069010 0.06180598 \n      1247       1248       1249       1250       1251       1252       1253 \n0.14705203 0.08774220 0.12676852 0.10924128 0.03879469 0.25855358 0.18798232 \n      1254       1255       1256       1257       1258       1259       1260 \n0.07565763 0.22755363 0.26977892 0.04912819 0.15627261 0.15522079 0.07386738 \n      1261       1262       1263       1264       1265       1266       1267 \n0.11847943 0.21108931 0.30482536 0.06868552 0.20615609 0.37105847 0.14059669 \n      1268       1269       1270       1271       1272       1273       1274 \n0.05131258 0.06622058 0.22814537 0.08033931 0.05180038 0.29079005 0.07386738 \n      1275       1276       1277       1278       1279       1280       1281 \n0.13452637 0.22028690 0.08107947 0.22327414 0.09093278 0.08262084 0.11139039 \n      1282       1283       1284       1285       1286       1287       1288 \n0.11271607 0.08486950 0.23309651 0.04641043 0.21208885 0.11397968 0.09126138 \n      1289       1290       1291       1292       1293       1294       1295 \n0.26058723 0.14333776 0.12921417 0.24149507 0.08995081 0.06830617 0.30906309 \n      1296       1297       1298       1299       1300       1301       1302 \n0.02867506 0.15777050 0.27849919 0.10630836 0.02587660 0.26096827 0.20204518 \n      1303       1304       1305       1306       1307       1308       1309 \n0.15108906 0.16477551 0.04966026 0.18138606 0.23392072 0.20034956 0.09479063 \n      1310       1311       1312       1313       1314       1315       1316 \n0.25024703 0.03769565 0.04155796 0.29066523 0.10943528 0.10542428 0.07960532 \n      1317       1318       1319       1320       1321       1322       1323 \n0.06154217 0.04912963 0.24924067 0.10331793 0.06572955 0.04510642 0.04333845 \n      1324       1325       1326       1327       1328       1329       1330 \n0.08414454 0.18910884 0.16043983 0.19876101 0.26355214 0.10076260 0.27214615 \n      1331       1332       1333       1334       1335       1336       1337 \n0.09831857 0.06009667 0.28780171 0.05953651 0.35767963 0.15963439 0.22476993 \n      1338       1339       1340       1341       1342       1343       1344 \n0.06484167 0.02623043 0.04147868 0.04903521 0.32209727 0.27029396 0.12898845 \n      1345       1346       1347       1348       1349       1350       1351 \n0.10668748 0.06805207 0.21745614 0.08595640 0.17525914 0.31992962 0.14580517 \n      1352       1353       1354       1355       1356       1357       1358 \n0.17786801 0.06227056 0.10725692 0.18707882 0.22675334 0.33914771 0.14432091 \n      1359       1360       1361       1362       1363       1364       1365 \n0.24442916 0.06512052 0.06536350 0.16450366 0.34511971 0.09076824 0.42006843 \n      1366       1367       1368       1369       1370       1371       1372 \n0.11035036 0.08302767 0.09164658 0.06885482 0.13662753 0.16532457 0.12743157 \n      1373       1374       1375       1376       1377       1378       1379 \n0.14680427 0.44203815 0.16150979 0.11172375 0.10443052 0.09814484 0.09142801 \n      1380       1381       1382       1383       1384       1385       1386 \n0.11452321 0.09131288 0.05060815 0.36966844 0.09634024 0.03372113 0.30074774 \n      1387       1388       1389       1390       1391       1392       1393 \n0.14548005 0.28023147 0.07888082 0.04903521 0.05368974 0.08595397 0.24774973 \n      1394       1395       1396       1397       1398       1399       1400 \n0.03798576 0.04268439 0.10879099 0.07617525 0.07673791 0.20944047 0.13726050 \n      1401       1402       1403       1404       1405       1406       1407 \n0.17296528 0.08753451 0.09192567 0.06270008 0.07916967 0.08929814 0.15944844 \n      1408       1409       1410       1411       1412       1413       1414 \n0.05961247 0.12721022 0.12114657 0.19591873 0.11432135 0.13662935 0.18277930 \n      1415       1416       1417       1418       1419       1420       1421 \n0.04614733 0.11952369 0.16186605 0.09376999 0.34376676 0.18376909 0.04757081 \n      1422       1423       1424       1425       1426       1427       1428 \n0.15160277 0.09547924 0.09796729 0.08009229 0.33425729 0.06907078 0.14083570 \n      1429       1430       1431       1432       1433       1434       1435 \n0.13238303 0.21385725 0.27703756 0.06843405 0.09467303 0.20844502 0.07127935 \n      1436       1437       1438       1439       1440       1441       1442 \n0.13376371 0.19696008 0.11614611 0.30158628 0.20920584 0.14506434 0.05044753 \n      1443       1444       1445       1446       1447       1448       1449 \n0.20713332 0.11438110 0.24887387 0.20616114 0.06696255 0.15514751 0.20625517 \n      1450       1451       1452       1453       1454       1455       1456 \n0.05189832 0.19467374 0.15263051 0.13757021 0.12399676 0.29977697 0.05318670 \n      1457       1458       1459       1460       1461       1462       1463 \n0.09570380 0.11945837 0.25487974 0.11317899 0.16734000 0.06783810 0.04450959 \n      1464       1465       1466       1467       1468       1469       1470 \n0.25563420 0.04730007 0.16267846 0.21418716 0.19466889 0.13970937 0.10655539 \n      1471       1472       1473       1474       1475       1476       1477 \n0.06581476 0.15600810 0.36596989 0.26289685 0.20205265 0.11862273 0.27650526 \n      1478       1479       1480       1481       1482       1483       1484 \n0.15917749 0.09044250 0.22052253 0.09915104 0.07224754 0.19592116 0.12727745 \n      1485       1486       1487       1488       1489       1490       1491 \n0.27305314 0.26367265 0.06009667 0.13445591 0.07049316 0.13429640 0.09011275 \n      1492       1493       1494       1495       1496       1497       1498 \n0.07154355 0.13757387 0.04623578 0.25905480 0.05617215 0.26782426 0.13702659 \n      1499       1500       1501       1502       1503       1504       1505 \n0.03690876 0.17211426 0.13726232 0.16313924 0.09773936 0.26821811 0.18547260 \n      1506       1507       1508       1509       1510       1511       1512 \n0.04775094 0.04155857 0.06250180 0.05720419 0.22476454 0.20324238 0.09275921 \n      1513       1514       1515       1516       1517       1518       1519 \n0.09032595 0.03627617 0.11291700 0.14260737 0.20582774 0.20690820 0.09808717 \n      1520       1521       1522       1523       1524       1525       1526 \n0.09938467 0.07414041 0.18426717 0.19279948 0.11945837 0.28711279 0.12816519 \n      1527       1528       1529       1530       1531       1532       1533 \n0.12633495 0.08838087 0.13726050 0.05491733 0.21926477 0.04987804 0.11093539 \n      1534       1535       1536       1537       1538       1539       1540 \n0.07369094 0.11291391 0.46474414 0.22087046 0.06532559 0.06285381 0.22546493 \n      1541       1542       1543       1544       1545       1546       1547 \n0.23895277 0.16780917 0.14236586 0.32645896 0.03776741 0.16431527 0.13336911 \n      1548       1549       1550       1551       1552       1553       1554 \n0.15314451 0.26008409 0.27822993 0.18697973 0.08409671 0.08112343 0.08600397 \n      1555       1556       1557       1558       1559       1560       1561 \n0.08690260 0.34376676 0.28183839 0.13192785 0.11682506 0.07114861 0.31161467 \n      1562       1563       1564       1565       1566       1567       1568 \n0.05723851 0.09479196 0.13592590 0.05961420 0.07519864 0.26366965 0.23167509 \n      1569       1570       1571       1572       1573       1574       1575 \n0.05810290 0.23631685 0.07396231 0.20301791 0.19790214 0.11952044 0.06754845 \n      1576       1577       1578       1579       1580       1581       1582 \n0.04545021 0.25374056 0.12263912 0.04579717 0.29562174 0.06305404 0.42006090 \n      1583       1584       1585       1586       1587       1588       1589 \n0.26328607 0.26833694 0.30990793 0.08440530 0.08817306 0.09450375 0.07763348 \n      1590       1591       1592       1593       1594       1595       1596 \n0.08247114 0.11512908 0.37994482 0.06796613 0.07565763 0.12399508 0.28792580 \n      1597       1598       1599       1600       1601       1602       1603 \n0.09131160 0.05054231 0.11198331 0.14948345 0.18767607 0.19917992 0.10374533 \n      1604       1605       1606       1607       1608       1609       1610 \n0.16892924 0.12093299 0.32996259 0.15255024 0.05745305 0.08353249 0.16232286 \n      1611       1612       1613       1614       1615       1616       1617 \n0.06585104 0.17013416 0.21756705 0.09897601 0.06609750 0.05550926 0.19094854 \n      1618       1619       1620       1621       1622       1623       1624 \n0.06758756 0.05509297 0.07247642 0.23560135 0.08721927 0.05131333 0.10172684 \n      1625       1626       1627       1628       1629       1630       1631 \n0.07314781 0.04866426 0.07409781 0.11478531 0.07287920 0.23072317 0.06499935 \n      1632       1633       1634       1635       1636       1637       1638 \n0.09192567 0.17865024 0.04459439 0.06293372 0.15697596 0.08023805 0.07127833 \n      1639       1640       1641       1642       1643       1644       1645 \n0.07772951 0.16761991 0.09065513 0.23775513 0.09599260 0.20517723 0.29824660 \n      1646       1647       1648       1649       1650       1651       1652 \n0.13947196 0.17033223 0.10821589 0.26124178 0.09393941 0.10046105 0.06805403 \n      1653       1654       1655       1656       1657       1658       1659 \n0.18307705 0.19971202 0.07946061 0.16267636 0.12285530 0.25551316 0.07301182 \n      1660       1661       1662       1663       1664       1665       1666 \n0.32953597 0.04499401 0.26097423 0.16541025 0.03326970 0.04203604 0.21543166 \n      1667       1668       1669       1670       1671       1672       1673 \n0.13452637 0.05245874 0.25186202 0.06881306 0.07617308 0.10405993 0.33840466 \n      1674       1675       1676       1677       1678       1679       1680 \n0.10081886 0.05799313 0.08517825 0.41521583 0.11682506 0.26355214 0.24627051 \n      1681       1682       1683       1684       1685       1686       1687 \n0.16587295 0.03103922 0.09445064 0.13561931 0.05502242 0.18889627 0.09410910 \n      1688       1689       1690       1691       1692       1693       1694 \n0.20517975 0.14253337 0.14572595 0.16651322 0.22201049 0.18337518 0.10523510 \n      1695       1696       1697       1698       1699       1700       1701 \n0.10574191 0.07702066 0.09553153 0.07261045 0.28304647 0.10612071 0.15101341 \n      1702       1703       1704       1705       1706       1707       1708 \n0.26950582 0.18828895 0.15963439 0.17382407 0.07561639 0.12464569 0.11238167 \n      1709       1710       1711       1712       1713       1714       1715 \n0.16985744 0.08277313 0.36781363 0.27344874 0.19445158 0.12442849 0.06817852 \n      1716       1717       1718       1719       1720       1721       1722 \n0.06805207 0.14456709 0.07437374 0.04969103 0.24727171 0.22546493 0.09914828 \n      1723       1724       1725       1726       1727       1728       1729 \n0.24838863 0.09885103 0.12529922 0.18616930 0.06328800 0.10523510 0.18138835 \n      1730       1731       1732       1733       1734       1735       1736 \n0.03827746 0.08537966 0.32896234 0.10240022 0.05147655 0.07960758 0.06771321 \n      1737       1738       1739       1740       1741       1742       1743 \n0.10744782 0.21086361 0.27293606 0.14647344 0.17211206 0.05268888 0.20356516 \n      1744       1745       1746       1747       1748       1749       1750 \n0.23143108 0.24259431 0.05649148 0.12950845 0.28224491 0.23274059 0.09098411 \n      1751       1752       1753       1754       1755       1756       1757 \n0.24211170 0.14333776 0.09535821 0.21185720 0.05229104 0.05498855 0.09849668 \n      1758       1759       1760       1761       1762       1763       1764 \n0.06020842 0.09808854 0.11764972 0.05617215 0.30116684 0.30905320 0.08753328 \n      1765       1766       1767       1768       1769       1770       1771 \n0.16186814 0.10536430 0.26587558 0.08663364 0.15909649 0.29727401 0.04950177 \n      1772       1773       1774       1775       1776       1777       1778 \n0.22604742 0.12928056 0.08865348 0.20723529 0.07314676 0.23320750 0.16024896 \n      1779       1780       1781       1782       1783       1784       1785 \n0.03690821 0.06945405 0.09773663 0.17098399 0.11021429 0.29148737 0.07989999 \n      1786       1787       1788       1789       1790       1791       1792 \n0.06569144 0.06975326 0.14704622 0.11594335 0.09027495 0.26587860 0.06729890 \n      1793       1794       1795       1796       1797       1798       1799 \n0.04685324 0.15280595 0.16051722 0.43224682 0.33173696 0.09932912 0.24394978 \n      1800       1801       1802       1803       1804       1805       1806 \n0.33174038 0.13169635 0.17806637 0.26162344 0.14829990 0.03909176 0.04467934 \n      1807       1808       1809       1810       1811       1812       1813 \n0.36688769 0.08679140 0.08197332 0.09691476 0.32501342 0.06308981 0.18496037 \n      1814       1815       1816       1817       1818       1819       1820 \n0.05596129 0.21553138 0.29121062 0.10094325 0.27306234 0.16623479 0.05843168 \n      1821       1822       1823       1824       1825       1826       1827 \n0.15750803 0.15732204 0.05060889 0.18859361 0.04775094 0.24738152 0.09761713 \n      1828       1829       1830       1831       1832       1833       1834 \n0.14697225 0.08626873 0.05799398 0.10923978 0.04623510 0.21152476 0.29202090 \n      1835       1836       1837       1838       1839       1840       1841 \n0.22268871 0.22674522 0.22131511 0.48510895 0.06729793 0.23249580 0.06634482 \n      1842       1843       1844       1845       1846       1847       1848 \n0.16395467 0.10885269 0.06721288 0.06262044 0.18020587 0.20109330 0.05338613 \n      1849       1850       1851       1852       1853       1854       1855 \n0.16588150 0.27096701 0.03648623 0.26328307 0.37199598 0.06988264 0.08063417 \n      1856       1857       1858       1859       1860       1861       1862 \n0.18768313 0.23595474 0.17865250 0.17815950 0.04588566 0.05209471 0.12988635 \n      1863       1864       1865       1866       1867       1868       1869 \n0.14973886 0.20844502 0.05767003 0.35722564 0.31949634 0.10846681 0.20713332 \n      1870       1871       1872       1873       1874       1875       1876 \n0.08034159 0.08217016 0.20162922 0.14156227 0.19498382 0.29991378 0.35951596 \n      1877       1878       1879       1880       1881       1882       1883 \n0.15811801 0.07260941 0.21419235 0.16614662 0.08726378 0.37946471 0.27782386 \n      1884       1885       1886       1887       1888       1889       1890 \n0.15998522 0.15998314 0.08460505 0.09011275 0.14211903 0.08994955 0.08742381 \n      1891       1892       1893       1894       1895       1896       1897 \n0.10504622 0.37292722 0.08690137 0.06667733 0.25399739 0.11458305 0.13169635 \n      1898       1899       1900       1901       1902       1903       1904 \n0.18159206 0.12486320 0.33929032 0.06073995 0.10918089 0.29602707 0.21219002 \n      1905       1906       1907       1908       1909       1910       1911 \n0.10148973 0.08579880 0.05073459 0.22338449 0.19413973 0.31604808 0.08425028 \n      1912       1913       1914       1915       1916       1917       1918 \n0.12099900 0.23642332 0.11662286 0.26834907 0.10879399 0.30537933 0.07649886 \n      1919       1920       1921       1922       1923       1924       1925 \n0.26483157 0.06754942 0.04676504 0.10112278 0.15653342 0.35175557 0.05777754 \n      1926       1927       1928       1929       1930       1931       1932 \n0.09164658 0.19165857 0.12551602 0.19758856 0.08023805 0.11478531 0.05575037 \n      1933       1934       1935       1936       1937       1938       1939 \n0.25867557 0.13892204 0.06043425 0.14132035 0.27890586 0.09225750 0.27782386 \n      1940       1941       1942       1943       1944       1945       1946 \n0.10276415 0.10319096 0.07748984 0.19749261 0.11841623 0.19187351 0.24479726 \n      1947       1948       1949       1950       1951       1952       1953 \n0.07878012 0.09779139 0.12898672 0.14302101 0.10040217 0.35175557 0.08425028 \n      1954       1955       1956       1957       1958       1959       1960 \n0.31993298 0.22780291 0.20130873 0.30440012 0.10764346 0.03871932 0.28305274 \n      1961       1962       1963       1964       1965       1966       1967 \n0.26599677 0.27650218 0.32458332 0.27610384 0.11132743 0.23463268 0.10319239 \n      1968       1969       1970       1971       1972       1973       1974 \n0.16957238 0.04375266 0.09518517 0.06536350 0.11158773 0.11641461 0.20044903 \n      1975       1976       1977       1978       1979       1980       1981 \n0.17690311 0.04820590 0.12242328 0.11212129 0.28616802 0.06524097 0.06643078 \n      1982       1983       1984       1985       1986       1987       1988 \n0.05939124 0.39553858 0.13916051 0.09933050 0.14481362 0.13757204 0.17430540 \n      1989       1990       1991       1992       1993       1994       1995 \n0.14506625 0.03783931 0.12479876 0.09093278 0.13892204 0.06609750 0.08918919 \n      1996       1997       1998       1999       2000       2001       2002 \n0.06043513 0.10995680 0.26289985 0.31048024 0.17211206 0.05950349 0.07274367 \n      2003       2004       2005       2006       2007       2008       2009 \n0.05995012 0.07478621 0.35554383 0.25600463 0.04132057 0.04527901 0.08785079 \n      2010       2011       2012       2013       2014       2015       2016 \n0.04333909 0.16957890 0.05179962 0.08212568 0.05063947 0.10674519 0.32777100 \n      2017       2018       2019       2020       2021       2022       2023 \n0.14432091 0.10063842 0.08004657 0.22825743 0.06780080 0.14722217 0.03791360 \n      2024       2025       2026       2027       2028       2029       2030 \n0.13662935 0.16368179 0.11973512 0.07579923 0.09427775 0.07538055 0.12206073 \n      2031       2032       2033       2034       2035       2036       2037 \n0.15566234 0.18496269 0.33781646 0.07010056 0.04333909 0.26626761 0.26755241 \n      2038       2039       2040       2041       2042       2043       2044 \n0.16431103 0.09142801 0.22052518 0.09933050 0.27730301 0.08322799 0.05613925 \n      2045       2046       2047       2048       2049       2050       2051 \n0.03074104 0.16052138 0.34768181 0.07141134 0.11472381 0.05582260 0.30158953 \n      2052       2053       2054       2055       2056       2057       2058 \n0.20076602 0.07234055 0.13452817 0.13445411 0.08004657 0.27663256 0.10154495 \n      2059       2060       2061       2062       2063       2064       2065 \n0.11351391 0.23775793 0.17382185 0.11519234 0.16422792 0.06032211 0.29907467 \n      2066       2067       2068       2069       2070       2071       2072 \n0.08455698 0.41666768 0.05035146 0.26939274 0.04325594 0.09461984 0.04579785 \n      2073       2074       2075       2076       2077       2078       2079 \n0.11198331 0.12486658 0.04364476 0.04023100 0.07132046 0.23096666 0.22501166 \n      2080       2081       2082       2083       2084       2085       2086 \n0.33884043 0.10885269 0.27017763 0.07062178 0.05756103 0.24211737 0.17554727 \n      2087       2088       2089       2090       2091       2092       2093 \n0.07154355 0.33514103 0.18707412 0.06679949 0.22189262 0.17041779 0.15263051 \n      2094       2095       2096       2097       2098       2099       2100 \n0.22755363 0.04459439 0.05519596 0.23001677 0.35175909 0.26008409 0.16422580 \n      2101       2102       2103       2104       2105       2106       2107 \n0.09518650 0.26978196 0.21042402 0.28023147 0.05720336 0.28251967 0.17468622 \n      2108       2109       2110       2111       2112       2113       2114 \n0.15680070 0.06729696 0.18436515 0.07989886 0.11132896 0.05561298 0.11519234 \n      2115       2116       2117       2118       2119       2120       2121 \n0.05318670 0.06320858 0.16587723 0.17516943 0.23642332 0.06332573 0.22511724 \n      2122       2123       2124       2125       2126       2127       2128 \n0.12973145 0.05457594 0.06767695 0.03464179 0.06556833 0.16706691 0.07478408 \n      2129       2130       2131       2132       2133       2134       2135 \n0.05083210 0.11311670 0.15314652 0.06971199 0.08881456 0.25110912 0.14872913 \n      2136       2137       2138       2139       2140       2141       2142 \n0.30452831 0.22710011 0.19196978 0.05308880 0.05318592 0.09343328 0.11946000 \n      2143       2144       2145       2146       2147       2148       2149 \n0.09114772 0.07251712 0.23750391 0.05288655 0.27108661 0.24357401 0.15619078 \n      2150       2151       2152       2153       2154       2155       2156 \n0.13947011 0.13804359 0.06475763 0.24738440 0.26174040 0.27492019 0.07730547 \n      2157       2158       2159       2160       2161       2162       2163 \n0.29272634 0.14755052 0.11841623 0.19280429 0.18849863 0.08930191 0.09209210 \n      2164       2165       2166       2167       2168       2169       2170 \n0.05571770 0.18667708 0.10239880 0.12877000 0.09897463 0.12654987 0.04417194 \n      2171       2172       2173       2174       2175       2176       2177 \n0.28711279 0.08533119 0.16403979 0.08142208 0.07950716 0.03916724 0.10982267 \n      2178       2179       2180       2181       2182       2183       2184 \n0.19529427 0.20844757 0.16560818 0.03269834 0.11554032 0.12727745 0.05564640 \n      2185       2186       2187       2188       2189       2190       2191 \n0.12853976 0.37060089 0.13875624 0.31806373 0.10879249 0.06868650 0.09808854 \n      2192       2193       2194       2195       2196       2197       2198 \n0.04577073 0.08409552 0.33028293 0.44253716 0.11431979 0.07859406 0.04493579 \n      2199       2200       2201       2202       2203       2204       2205 \n0.19601411 0.15653342 0.23320198 0.05592769 0.06894280 0.13899632 0.11614769 \n      2206       2207       2208       2209       2210       2211       2212 \n0.08595640 0.12399508 0.27889965 0.14285301 0.09726538 0.23203263 0.07673791 \n      2213       2214       2215       2216       2217       2218       2219 \n0.08758411 0.11614769 0.15514143 0.12349742 0.03558666 0.13875624 0.16809187 \n      2220       2221       2222       2223       2224       2225       2226 \n0.26405659 0.06165465 0.16078584 0.05887163 0.06667637 0.09032595 0.22884773 \n      2227       2228       2229       2230       2231       2232       2233 \n0.17013852 0.08257497 0.09484391 0.18109045 0.11172528 0.07589427 0.12221107 \n      2234       2235       2236       2237       2238       2239       2240 \n0.20463430 0.38888670 0.09686314 0.03769453 0.08048662 0.24627338 0.27982984 \n      2241       2242       2243       2244       2245       2246       2247 \n0.05898038 0.10058364 0.22362785 0.09570246 0.08353368 0.09950610 0.18517650 \n      2248       2249       2250       2251       2252       2253       2254 \n0.08167283 0.08994955 0.27571202 0.19135252 0.14880579 0.04571087 0.16532457 \n      2255       2256       2257       2258       2259       2260       2261 \n0.15436174 0.14572595 0.09814347 0.07888194 0.16159806 0.11868765 0.20615356 \n      2262       2263       2264       2265       2266       2267       2268 \n0.18197610 0.07663971 0.21654617 0.12156811 0.05389410 0.27147432 0.08157004 \n      2269       2270       2271       2272       2273       2274       2275 \n0.20066643 0.30524439 0.11418414 0.05298642 0.03424429 0.04077230 0.04292736 \n      2276       2277       2278       2279       2280       2281       2282 \n0.26405659 0.40269728 0.08983609 0.06830716 0.28466944 0.08838336 0.04187651 \n      2283       2284       2285       2286       2287       2288       2289 \n0.10148832 0.10166871 0.10313352 0.38322816 0.25790933 0.08187018 0.07706261 \n      2290       2291       2292       2293       2294       2295       2296 \n0.29066204 0.35952307 0.16340717 0.33513759 0.29189257 0.03444249 0.10221726 \n      2297       2298       2299       2300       2301       2302       2303 \n0.30651326 0.12921417 0.14697225 0.43860546 0.07382493 0.05670174 0.10611925 \n      2304       2305       2306       2307       2308       2309       2310 \n0.11271452 0.14646958 0.05522995 0.17117846 0.15306602 0.10058504 0.04510642 \n      2311       2312       2313       2314       2315       2316       2317 \n0.09902725 0.08333268 0.04367132 0.06332481 0.38369548 0.10467514 0.05111972 \n      2318       2319       2320       2321       2322       2323       2324 \n0.13820684 0.32384978 0.11827153 0.29450458 0.20723783 0.15910269 0.06448023 \n      2325       2326       2327       2328       2329       2330       2331 \n0.28373579 0.17325486 0.06475857 0.10461843 0.10294941 0.06317092 0.11418102 \n      2332       2333       2334       2335       2336       2337       2338 \n0.18197610 0.11472852 0.13678937 0.04372863 0.04857354 0.20921095 0.27018677 \n      2339       2340       2341       2342       2343       2344       2345 \n0.10190619 0.21151961 0.16790235 0.08142208 0.10172401 0.07386738 0.25449280 \n      2346       2347       2348       2349       2350       2351       2352 \n0.22931190 0.13757204 0.20920840 0.06258311 0.29025467 0.04838832 0.13284310 \n      2353       2354       2355       2356       2357       2358       2359 \n0.15548828 0.11519234 0.25970388 0.09513704 0.05543740 0.09326598 0.17382407 \n      2360       2361       2362       2363       2364       2365       2366 \n0.09726402 0.09348588 0.27702518 0.33603972 0.09011528 0.09950471 0.07607664 \n      2367       2368       2369       2370       2371       2372       2373 \n0.05638293 0.35951951 0.10130962 0.02900942 0.05478188 0.22605012 0.26822114 \n      2374       2375       2376       2377       2378       2379       2380 \n0.17117626 0.15750803 0.24775261 0.17719787 0.11779536 0.13078957 0.06805207 \n      2381       2382       2383       2384       2385       2386       2387 \n0.18129619 0.13868207 0.09011149 0.28751438 0.28914946 0.23167234 0.10611778 \n      2388       2389       2390       2391       2392       2393       2394 \n0.24259431 0.12442681 0.29120105 0.04364411 0.11987810 0.14253149 0.26174040 \n      2395       2396       2397       2398       2399       2400       2401 \n0.23956778 0.08769252 0.10331793 0.14253149 0.29769356 0.13916051 0.14156039 \n      2402       2403       2404       2405       2406       2407       2408 \n0.19156481 0.05111898 0.05060815 0.14473485 0.30313944 0.11513065 0.10063842 \n      2409       2410       2411       2412       2413       2414       2415 \n0.11620985 0.27691015 0.04829881 0.26871913 0.15134673 0.14647344 0.35175557 \n      2416       2417       2418       2419       2420       2421       2422 \n0.37525581 0.15830064 0.11257745 0.09674189 0.24040769 0.13146871 0.17873681 \n      2423       2424       2425       2426       2427       2428       2429 \n0.07158480 0.07409887 0.05785140 0.25551610 0.22234942 0.12551602 0.22720909 \n      2430       2431       2432       2433       2434       2435       2436 \n0.31004401 0.07659689 0.21019883 0.08363872 0.06376296 0.26212253 0.23858789 \n      2437       2438       2439       2440       2441       2442       2443 \n0.03798633 0.14872913 0.06085370 0.12036317 0.17316375 0.43272818 0.14779931 \n      2444       2445       2446       2447       2448       2449       2450 \n0.13970751 0.24394408 0.07355402 0.21119014 0.16403979 0.09175951 0.07979924 \n      2451       2452       2453       2454       2455       2456       2457 \n0.15178122 0.15989973 0.05950176 0.19166096 0.25779349 0.08705712 0.50751508 \n      2458       2459       2460       2461       2462       2463       2464 \n0.06634291 0.32153375 0.08157004 0.32283886 0.09247914 0.04739062 0.07345958 \n      2465       2466       2467       2468       2469       2470       2471 \n0.13686269 0.45731928 0.20013242 0.12328195 0.12414747 0.23143108 0.13314081 \n      2472       2473       2474       2475       2476       2477       2478 \n0.11371919 0.10821440 0.47168434 0.16985308 0.20789062 0.13804175 0.10499078 \n      2479       2480       2481       2482       2483       2484       2485 \n0.10598777 0.07010157 0.08897466 0.09109759 0.03634642 0.17325707 0.05229104 \n      2486       2487       2488       2489       2490       2491       2492 \n0.23499339 0.26833694 0.05073384 0.12508105 0.19435436 0.06200220 0.11391701 \n      2493       2494       2495       2496       2497       2498       2499 \n0.13284132 0.05457514 0.04978372 0.07288024 0.29824013 0.04757081 0.15203588 \n      2500       2501       2502       2503       2504       2505       2506 \n0.06679949 0.06548720 0.08967334 0.09778866 0.36241981 0.08486710 0.08082809 \n      2507       2508       2509       2510       2511       2512       2513 \n0.06512052 0.15211394 0.22052253 0.15050331 0.25324611 0.09518650 0.03820362 \n      2514       2515       2516       2517       2518       2519       2520 \n0.09622092 0.04667563 0.18586533 0.05596211 0.29285169 0.13733402 0.12943848 \n      2521       2522       2523       2524       2525       2526       2527 \n0.16286324 0.04757011 0.27782695 0.17719111 0.07589318 0.16753547 0.03398174 \n      2528       2529       2530       2531       2532       2533       2534 \n0.11682506 0.07946174 0.07878124 0.04597160 0.07027310 0.13994897 0.11703075 \n      2535       2536       2537       2538       2539       2540       2541 \n0.03783931 0.32764444 0.05550926 0.12313214 0.08292332 0.07274367 0.22477262 \n      2542       2543       2544       2545       2546       2547       2548 \n0.07975366 0.11600858 0.15522889 0.08580122 0.25703780 0.29603672 0.09814347 \n      2549       2550       2551       2552       2553       2554       2555 \n0.15007183 0.30566702 0.05063799 0.10350407 0.21241676 0.09098155 0.13040593 \n      2556       2557       2558       2559       2560       2561       2562 \n0.10937479 0.11925223 0.08946153 0.04227861 0.22327949 0.07427727 0.29450458 \n      2563       2564       2565       2566       2567       2568       2569 \n0.05656297 0.37105847 0.20647977 0.22955434 0.28820703 0.23380949 0.26251997 \n      2570       2571       2572       2573       2574       2575       2576 \n0.20658656 0.05606581 0.29354870 0.20301541 0.22756449 0.13131397 0.19445158 \n      2577       2578       2579       2580       2581       2582       2583 \n0.17430762 0.16725997 0.12227437 0.08674221 0.12831850 0.10258204 0.08769499 \n      2584       2585       2586       2587       2588       2589       2590 \n0.04545088 0.06364322 0.26173741 0.10821589 0.13828080 0.07496721 0.13176735 \n      2591       2592       2593       2594       2595       2596       2597 \n0.21824078 0.13702476 0.09365352 0.12639837 0.12479876 0.26239682 0.31935803 \n      2598       2599       2600       2601       2602       2603       2604 \n0.07496614 0.06157536 0.33737443 0.06285563 0.08272484 0.31633456 0.21891865 \n      2605       2606       2607       2608       2609       2610       2611 \n0.06859982 0.16404402 0.13492026 0.16025104 0.04203666 0.12051008 0.30074450 \n      2612       2613       2614       2615       2616       2617       2618 \n0.29120424 0.06881306 0.22581030 0.23248753 0.28833440 0.08262318 0.12742985 \n      2619       2620       2621       2622       2623       2624       2625 \n0.14456709 0.08242301 0.12861104 0.07994451 0.15032413 0.08197448 0.10276558 \n      2626       2627       2628       2629       2630       2631       2632 \n0.19156481 0.34422328 0.12950845 0.05248806 0.09897463 0.25061518 0.07603410 \n      2633       2634       2635       2636       2637       2638       2639 \n0.09530734 0.20593428 0.15392119 0.29491544 0.25074339 0.20746829 0.05961420 \n      2640       2641       2642       2643       2644       2645       2646 \n0.35951596 0.05720336 0.16976775 0.12206073 0.13655614 0.18951221 0.04978445 \n      2647       2648       2649       2650       2651       2652       2653 \n0.35371659 0.14043294 0.32253577 0.11945675 0.15007183 0.42005714 0.25223174 \n      2654       2655       2656       2657       2658       2659       2660 \n0.18798232 0.04502003 0.26833694 0.26277658 0.05275582 0.07820376 0.39220948 \n      2661       2662       2663       2664       2665       2666       2667 \n0.05063799 0.11492943 0.17612465 0.50352753 0.12809412 0.25790933 0.16725997 \n      2668       2669       2670       2671       2672       2673       2674 \n0.09565276 0.07593673 0.11119183 0.11492786 0.32909257 0.04284623 0.10480518 \n      2675       2676       2677       2678       2679       2680       2681 \n0.13515474 0.14747051 0.05044679 0.09826765 0.17526361 0.09076951 0.13329916 \n      2682       2683       2684       2685       2686       2687       2688 \n0.25036063 0.20756530 0.43076941 0.06605919 0.08995081 0.06006161 0.36642867 \n      2689       2690       2691       2692       2693       2694       2695 \n0.10536575 0.10245729 0.10649777 0.05810290 0.13033555 0.07758793 0.12457965 \n      2696       2697       2698       2699       2700       2701       2702 \n0.11883117 0.26704975 0.07931615 0.18637247 0.24332144 0.08611304 0.21949696 \n      2703       2704       2705       2706       2707       2708       2709 \n0.11073907 0.36103643 0.10221726 0.10840680 0.03849750 0.07873620 0.07301182 \n      2710       2711       2712       2713       2714       2715       2716 \n0.10706927 0.28535799 0.11034733 0.28902506 0.04375330 0.30919567 0.06988264 \n      2717       2718       2719       2720       2721       2722       2723 \n0.08108062 0.14880970 0.12632643 0.06821699 0.11594335 0.07772951 0.18041312 \n      2724       2725       2726       2727       2728       2729       2730 \n0.14018892 0.04968884 0.07185004 0.06683819 0.11512908 0.12832023 0.05229104 \n      2731       2732       2733       2734       2735       2736       2737 \n0.08197332 0.27214309 0.30453158 0.06949518 0.05543740 0.22825743 0.21621101 \n      2738       2739       2740       2741       2742       2743       2744 \n0.08048776 0.06043513 0.18138835 0.13314260 0.14679847 0.06573050 0.09309635 \n      2745       2746       2747       2748       2749       2750       2751 \n0.06250271 0.10337546 0.16017375 0.18728040 0.26599978 0.16929638 0.07902456 \n      2752       2753       2754       2755       2756       2757       2758 \n0.06177000 0.16615090 0.10630836 0.24175201 0.14481554 0.14309522 0.05305527 \n      2759       2760       2761       2762       2763       2764       2765 \n0.14523449 0.14796823 0.24040769 0.11119489 0.08353604 0.17211206 0.22966141 \n      2766       2767       2768       2769       2770       2771       2772 \n0.08983862 0.11675943 0.27863015 0.23249029 0.03411328 0.16892707 0.09360215 \n      2773       2774       2775       2776       2777       2778       2779 \n0.05006719 0.09861714 0.07906975 0.07382493 0.07492203 0.13773299 0.09496170 \n      2780       2781       2782       2783       2784       2785       2786 \n0.13306918 0.06487839 0.07247642 0.10027977 0.20658403 0.13383566 0.08978661 \n      2787       2788       2789       2790       2791       2792       2793 \n0.13215616 0.15540678 0.22955434 0.22131777 0.05585614 0.26432617 0.11910503 \n      2794       2795       2796       2797       2798       2799       2800 \n0.09011275 0.05035146 0.11431979 0.22790398 0.09109631 0.14555532 0.07758793 \n      2801       2802       2803       2804       2805       2806       2807 \n0.22651028 0.07519864 0.19885251 0.16560178 0.12421162 0.18397256 0.10674666 \n      2808       2809       2810       2811       2812       2813       2814 \n0.12163442 0.08440291 0.10764050 0.15618874 0.18487378 0.15366395 0.12809412 \n      2815       2816       2817       2818       2819       2820       2821 \n0.18910884 0.06391912 0.11952531 0.10956598 0.27135156 0.23249855 0.18850336 \n      2822       2823       2824       2825       2826       2827       2828 \n0.04116242 0.08726378 0.28171589 0.08383682 0.15997899 0.28224491 0.06066088 \n      2829       2830       2831       2832       2833       2834       2835 \n0.16595886 0.14522874 0.12831850 0.13796974 0.16213439 0.06843109 0.37013275 \n      2836       2837       2838       2839       2840       2841       2842 \n0.13780856 0.20723529 0.09142801 0.09060524 0.14572787 0.16809403 0.08946028 \n      2843       2844       2845       2846       2847       2848       2849 \n0.14780126 0.14697031 0.34331750 0.09043996 0.20527849 0.12457965 0.07305490 \n      2850       2851       2852       2853       2854       2855       2856 \n0.08383682 0.05519676 0.13108866 0.09450110 0.14830185 0.10504912 0.39600388 \n      2857       2858       2859       2860       2861       2862       2863 \n0.29203367 0.06717397 0.10480228 0.11337754 0.08429938 0.12943500 0.27214309 \n      2864       2865       2866       2867       2868       2869       2870 \n0.03579234 0.16678988 0.23523444 0.08197448 0.07916967 0.09461984 0.24295485 \n      2871       2872       2873       2874       2875       2876       2877 \n0.28779854 0.36288025 0.09060396 0.15263450 0.04969030 0.05502082 0.09879574 \n      2878       2879       2880       2881       2882       2883       2884 \n0.13383387 0.07278451 0.23642611 0.15679457 0.11113507 0.23992806 0.26861536 \n      2885       2886       2887       2888       2889       2890       2891 \n0.13238480 0.10276700 0.06203741 0.37618670 0.11498945 0.14156227 0.10617815 \n      2892       2893       2894       2895       2896       2897       2898 \n0.11903992 0.27650835 0.11519076 0.08658575 0.17690311 0.07533622 0.21185462 \n      2899       2900       2901       2902       2903       2904       2905 \n0.25563420 0.10725987 0.29284849 0.05430027 0.08318064 0.18347047 0.16431103 \n      2906       2907       2908       2909       2910       2911       2912 \n0.16431103 0.13678937 0.18346816 0.12184907 0.22028955 0.14236397 0.12921243 \n      2913       2914       2915       2916       2917       2918       2919 \n0.07892594 0.16025520 0.16541238 0.22097465 0.08995081 0.13353126 0.28466630 \n      2920       2921       2922       2923       2924       2925       2926 \n0.09376868 0.13359953 0.14333776 0.20844757 0.13268343 0.18698208 0.10136194 \n      2927       2928       2929       2930       2931       2932       2933 \n0.43957912 0.06958391 0.15007183 0.10898729 0.12436256 0.16016960 0.08127321 \n      2934       2935       2936       2937       2938       2939       2940 \n0.35448584 0.21175872 0.24394978 0.24627338 0.06667637 0.06074083 0.16124228 \n      2941       2942       2943       2944       2945       2946       2947 \n0.09242576 0.07950716 0.15410389 0.16340928 0.13429640 0.17033223 0.27610692 \n      2948       2949       2950       2951       2952       2953       2954 \n0.24554601 0.05140964 0.18287436 0.09879437 0.07902569 0.27570894 0.07863679 \n      2955       2956       2957       2958       2959       2960       2961 \n0.06096676 0.23499061 0.18316760 0.28023458 0.10923978 0.05509297 0.07053284 \n      2962       2963       2964       2965       2966       2967       2968 \n0.07400484 0.10668748 0.11158619 0.22120814 0.14847709 0.26058425 0.18366905 \n      2969       2970       2971       2972       2973       2974       2975 \n0.03977142 0.15410188 0.07617417 0.12135883 0.04400403 0.14930918 0.26200845 \n      2976       2977       2978       2979       2980       2981       2982 \n0.05585533 0.17719111 0.04772273 0.04641111 0.13709636 0.24431453 0.16313924 \n      2983       2984       2985       2986       2987       2988       2989 \n0.07931727 0.21375549 0.21052718 0.14261115 0.12178431 0.20162922 0.33085772 \n      2990       2991       2992       2993       2994       2995       2996 \n0.09011402 0.08307729 0.13632324 0.08548801 0.23214327 0.12242660 0.26124178 \n      2997       2998       2999       3000       3001       3002       3003 \n0.25551316 0.13452637 0.03195111 0.06742405 0.06560638 0.08142323 0.19601898 \n      3004       3005       3006       3007       3008       3009       3010 \n0.24149790 0.06153950 0.18020587 0.09365484 0.07036174 0.13639089 0.19382825 \n      3011       3012       3013       3014       3015       3016       3017 \n0.36011427 0.32240014 0.26638589 0.15724181 0.17069961 0.15785506 0.28944094 \n      3018       3019       3020       3021       3022       3023       3024 \n0.12327861 0.13147577 0.28211291 0.08004543 0.17517166 0.10617815 0.11119336 \n      3025       3026       3027       3028       3029       3030       3031 \n0.31849261 0.13780856 0.02623043 0.09726809 0.19002698 0.11172375 0.11573773 \n      3032       3033       3034       3035       3036       3037       3038 \n0.37152710 0.07946061 0.05189756 0.12291721 0.09197879 0.24479155 0.04292863 \n      3039       3040       3041       3042       3043       3044       3045 \n0.10593189 0.32689714 0.06180688 0.10712420 0.28548460 0.03314179 0.12399676 \n      3046       3047       3048       3049       3050       3051       3052 \n0.05875964 0.07758793 0.16450366 0.23273507 0.04641111 0.20495620 0.13017844 \n      3053       3054       3055       3056       3057       3058       3059 \n0.25753415 0.19063859 0.24150073 0.04793244 0.14772114 0.19342270 0.26316567 \n      3060       3061       3062       3063       3064       3065       3066 \n0.13940118 0.10221868 0.05150763 0.15109104 0.12443017 0.19497654 0.11889618 \n      3067       3068       3069       3070       3071       3072       3073 \n0.05832387 0.14880579 0.15410590 0.26911989 0.08108062 0.08287847 0.12742985 \n      3074       3075       3076       3077       3078       3079       3080 \n0.08440291 0.07382704 0.07105702 0.07079347 0.21108931 0.09444932 0.22224210 \n      3081       3082       3083       3084       3085       3086       3087 \n0.14597605 0.07274471 0.14805040 0.24442631 0.11119183 0.04685393 0.11291391 \n      3088       3089       3090       3091       3092       3093       3094 \n0.06783907 0.10227424 0.06356247 0.12464569 0.28386510 0.22885318 0.29866047 \n      3095       3096       3097       3098       3099       3100       3101 \n0.31260666 0.11238167 0.31547687 0.38666940 0.11472538 0.07844768 0.08631767 \n      3102       3103       3104       3105       3106       3107       3108 \n0.04885048 0.18677135 0.28984763 0.35920381 0.10593336 0.32676735 0.12995653 \n      3109       3110       3111       3112       3113       3114       3115 \n0.12727916 0.12486658 0.09547924 0.06340620 0.17554504 0.05099313 0.09861989 \n      3116       3117       3118       3119       3120       3121       3122 \n0.05817800 0.07158377 0.18197610 0.05437232 0.34772034 0.25036063 0.09242576 \n      3123       3124       3125       3126       3127       3128       3129 \n0.09703484 0.08212568 0.13422963 0.20269078 0.29978021 0.14407698 0.07328194 \n      3130       3131       3132       3133       3134       3135       3136 \n0.14115403 0.08078198 0.23463545 0.03620713 0.13170165 0.16976992 0.09275921 \n      3137       3138       3139       3140       3141       3142       3143 \n0.11800093 0.11080174 0.09060396 0.18436747 0.12285363 0.14456900 0.06779983 \n      3144       3145       3146       3147       3148       3149       3150 \n0.06742405 0.06262044 0.14277702 0.22303106 0.24700794 0.09048850 0.12263746 \n      3151       3152       3153       3154       3155       3156       3157 \n0.20745814 0.09479063 0.06572765 0.06667637 0.11391545 0.08870240 0.11192160 \n      3158       3159       3160       3161       3162       3163       3164 \n0.20236903 0.06572955 0.12854495 0.16423004 0.06017330 0.12831850 0.08202121 \n      3165       3166       3167       3168       3169       3170       3171 \n0.10063842 0.04260243 0.17864797 0.03733544 0.11152620 0.17182839 0.09467568 \n      3172       3173       3174       3175       3176       3177       3178 \n0.13631960 0.11862273 0.16845324 0.15496178 0.04667632 0.04829739 0.09093278 \n      3179       3180       3181       3182       3183       3184       3185 \n0.24259431 0.31561095 0.05457674 0.06621962 0.17033223 0.06157536 0.11060410 \n      3186       3187       3188       3189       3190       3191       3192 \n0.08107832 0.11192467 0.07659470 0.17240050 0.25513146 0.14229385 0.07158377 \n      3193       3194       3195       3196       3197       3198       3199 \n0.32646235 0.14974279 0.11237859 0.08522543 0.09360084 0.07198507 0.39839984 \n      3200       3201       3202       3203       3204       3205       3206 \n0.07328299 0.12589076 0.20195258 0.11498945 0.21926212 0.25982325 0.11764972 \n      3207       3208       3209       3210       3211       3212       3213 \n0.16892707 0.08533361 0.05189908 0.14400234 0.14872913 0.07547618 0.09393941 \n      3214       3215       3216       3217       3218       3219       3220 \n0.20845266 0.29189895 0.07318991 0.38275376 0.11703235 0.03599862 0.15444279 \n      3221       3222       3223       3224       3225       3226       3227 \n0.30397847 0.39330776 0.05785224 0.18307705 0.07816014 0.18950747 0.12371657 \n      3228       3229       3230       3231       3232       3233       3234 \n0.06821797 0.08642589 0.16070834 0.07496400 0.06548436 0.11820520 0.13169988 \n      3235       3236       3237       3238       3239       3240       3241 \n0.07478301 0.33603282 0.05876050 0.47913265 0.15470513 0.42297542 0.11411824 \n      3242       3243       3244       3245       3246       3247       3248 \n0.06423938 0.26008409 0.06855918 0.18436515 0.09633890 0.20690820 0.26677538 \n      3249       3250       3251       3252       3253       3254       3255 \n0.29120105 0.06123093 0.08137566 0.24505372 0.07607664 0.12721022 0.07603518 \n      3256       3257       3258       3259       3260       3261       3262 \n0.09197621 0.13101796 0.14722217 0.17382185 0.07010056 0.33692234 0.09247785 \n      3263       3264       3265       3266       3267       3268       3269 \n0.13169811 0.08689892 0.15705813 0.05512529 0.07701956 0.27372434 0.14572787 \n      3270       3271       3272       3273       3274       3275       3276 \n0.37291638 0.33558850 0.20003307 0.08616069 0.08721681 0.10808660 0.30736080 \n      3277       3278       3279       3280       3281       3282       3283 \n0.06581476 0.05666937 0.13406496 0.20205016 0.25400032 0.10802230 0.27017459 \n      3284       3285       3286       3287       3288       3289       3290 \n0.34677874 0.23356116 0.10840829 0.08553414 0.38086933 0.18070329 0.04383673 \n      3291       3292       3293       3294       3295       3296       3297 \n0.07607664 0.07114657 0.35859905 0.04502070 0.11139039 0.12787524 0.12479539 \n      3298       3299       3300       3301       3302       3303       3304 \n0.22441762 0.30075099 0.29811346 0.28874652 0.20324238 0.12306513 0.05850547 \n      3305       3306       3307       3308       3309       3310       3311 \n0.08399234 0.21960069 0.19187590 0.11987973 0.13756837 0.39220948 0.10209007 \n      3312       3313       3314       3315       3316       3317       3318 \n0.20172668 0.14400044 0.10827731 0.38794760 0.16817870 0.09192567 0.21858349 \n      3319       3320       3321       3322       3323       3324       3325 \n0.29533306 0.12421330 0.21881780 0.34827815 0.19311211 0.03791303 0.16929855 \n      3326       3327       3328       3329       3330       3331       3332 \n0.08790178 0.05073384 0.35448938 0.31346344 0.11021278 0.22086515 0.10281998 \n      3333       3334       3335       3336       3337       3338       3339 \n0.06062639 0.36057700 0.31504684 0.08383682 0.04038392 0.12988635 0.14948737 \n      3340       3341       3342       3343       3344       3345       3346 \n0.11703075 0.24040487 0.24431453 0.05723768 0.12654646 0.19156959 0.06520500 \n      3347       3348       3349       3350       3351       3352       3353 \n0.26161748 0.17231195 0.06356063 0.22720366 0.09599394 0.22062394 0.31764184 \n      3354       3355       3356       3357       3358       3359       3360 \n0.07301287 0.11231668 0.16232496 0.10802379 0.26873127 0.24431738 0.27135461 \n      3361       3362       3363       3364       3365       3366       3367 \n0.19812482 0.12721022 0.25715047 0.12529922 0.08242418 0.09343066 0.22063191 \n      3368       3369       3370       3371       3372       3373       3374 \n0.19445158 0.17690311 0.34048497 0.05723685 0.06988264 0.19570522 0.18397720 \n      3375       3376       3377       3378       3379       3380       3381 \n0.13314081 0.15058072 0.31561762 0.34452243 0.06100319 0.08548801 0.32514962 \n      3382       3383       3384       3385       3386       3387       3388 \n0.12421162 0.10356168 0.20713586 0.09115156 0.07589427 0.07127935 0.11764972 \n      3389       3390       3391       3392       3393       3394       3395 \n0.11472381 0.06746213 0.22018029 0.25400324 0.18129619 0.06123182 0.13899632 \n      3396       3397       3398       3399       3400       3401       3402 \n0.05540491 0.06077537 0.12764980 0.17402331 0.05305527 0.35585810 0.21925948 \n      3403       3404       3405       3406       3407       3408       3409 \n0.05741945 0.28821020 0.20334042 0.10009879 0.09639430 0.24468251 0.32326776 \n      3410       3411       3412       3413       3414       3415       3416 \n0.12015405 0.08611183 0.26239084 0.09164529 0.16286534 0.20388582 0.12334739 \n      3417       3418       3419       3420       3421       3422       3423 \n0.26162344 0.22790398 0.27822993 0.23487903 0.16403555 0.31290141 0.17061393 \n      3424       3425       3426       3427       3428       3429       3430 \n0.22466177 0.13040768 0.14555532 0.11074059 0.21019627 0.26638891 0.07551951 \n      3431       3432       3433       3434       3435       3436       3437 \n0.08318181 0.06671501 0.13609612 0.04476379 0.08398877 0.06512052 0.28902506 \n      3438       3439       3440       3441       3442       3443       3444 \n0.22442031 0.25905480 0.16477551 0.04632371 0.05041781 0.17382407 0.10840680 \n      3445       3446       3447       3448       3449       3450       3451 \n0.04730007 0.04799506 0.35782937 0.27266402 0.23284870 0.19372886 0.07464849 \n      3452       3453       3454       3455       3456       3457       3458 \n0.27902762 0.22755635 0.14059483 0.15945258 0.10448715 0.34407619 0.15732409 \n      3459       3460       3461       3462       3463       3464       3465 \n0.08009115 0.08078312 0.06223342 0.16295000 0.07917079 0.16733785 0.09814210 \n      3466       3467       3468       3469       3470       3471       3472 \n0.15830064 0.07863679 0.10518102 0.18011646 0.17757463 0.15134871 0.04493579 \n      3473       3474       3475       3476       3477       3478       3479 \n0.22097465 0.13561750 0.07631447 0.23071769 0.03538212 0.09668766 0.17154729 \n      3480       3481       3482       3483       3484       3485       3486 \n0.19134774 0.10387435 0.10898879 0.15332244 0.07950603 0.21790110 0.08946028 \n      3487       3488       3489       3490       3491       3492       3493 \n0.31719684 0.21553399 0.10885569 0.06435923 0.13170341 0.10227282 0.18397024 \n      3494       3495       3496       3497       3498       3499       3500 \n0.31806373 0.32108923 0.22029221 0.14548005 0.12072465 0.13353126 0.06821797 \n      3501       3502       3503       3504       3505       3506       3507 \n0.13284310 0.03791247 0.18227514 0.14880383 0.14830185 0.17786801 0.12988810 \n      3508       3509       3510       3511       3512       3513       3514 \n0.04476445 0.03916724 0.09968613 0.12008844 0.35326132 0.13399470 0.08995081 \n      3515       3516       3517       3518       3519       3520       3521 \n0.23848074 0.06754845 0.08152470 0.11862273 0.12327861 0.19623274 0.21086104 \n      3522       3523       3524       3525       3526       3527       3528 \n0.25249339 0.04519164 0.10982418 0.11015494 0.03939277 0.10725987 0.10956598 \n      3529       3530       3531       3532       3533       3534       3535 \n0.26405959 0.17070617 0.26136161 0.03586169 0.09365221 0.22500358 0.13994897 \n      3536       3537       3538       3539       3540       3541       3542 \n0.06805207 0.08626873 0.39173102 0.07603410 0.05248883 0.05530074 0.09535821 \n      3543       3544       3545       3546       3547       3548       3549 \n0.11847782 0.34903495 0.22337913 0.11862596 0.20388331 0.09043742 0.04545088 \n      3550       3551       3552       3553       3554       3555       3556 \n0.10937479 0.09691611 0.12221107 0.28050815 0.07478408 0.07328299 0.11987647 \n      3557       3558       3559       3560       3561       3562       3563 \n0.11411981 0.13101620 0.25893862 0.23320750 0.06111829 0.05745222 0.19727536 \n      3564       3565       3566       3567       3568       3569       3570 \n0.07001123 0.26521961 0.13631778 0.17117626 0.04802343 0.11682824 0.04931392 \n      3571       3572       3573       3574       3575       3576       3577 \n0.15134474 0.07314886 0.22293153 0.07207363 0.16477551 0.21375290 0.29491222 \n      3578       3579       3580       3581       3582       3583       3584 \n0.24258863 0.11377554 0.08983609 0.06484073 0.20485255 0.04022981 0.39078209 \n      3585       3586       3587       3588       3589       3590       3591 \n0.12794104 0.10898729 0.08157004 0.19539185 0.10649777 0.10918239 0.15514143 \n      3592       3593       3594       3595       3596       3597       3598 \n0.08455818 0.08538207 0.11512751 0.11744469 0.05854053 0.19413973 0.09622092 \n      3599       3600       3601       3602       3603       3604       3605 \n0.03477527 0.23167509 0.42199577 0.06843405 0.23883990 0.15566437 0.13337090 \n      3606       3607       3608       3609       3610       3611       3612 \n0.23967526 0.07180763 0.09126395 0.06006074 0.21175357 0.22744453 0.11799932 \n      3613       3614       3615       3616       3617       3618       3619 \n0.10962656 0.04730076 0.06618316 0.06250271 0.11655574 0.09399226 0.10209148 \n      3620       3621       3622       3623       3624       3625       3626 \n0.09991949 0.21620840 0.13352769 0.08721681 0.06130980 0.22131777 0.16105482 \n      3627       3628       3629       3630       3631       3632       3633 \n0.21543166 0.14204713 0.35462437 0.32689714 0.09225750 0.13306918 0.14974083 \n      3634       3635       3636       3637       3638       3639       3640 \n0.09175951 0.12765152 0.31590723 0.26638891 0.26743682 0.05994838 0.16431103 \n      3641       3642       3643       3644       3645       3646       3647 \n0.19971695 0.07287711 0.10240022 0.04331272 0.14456518 0.06683819 0.11377866 \n      3648       3649       3650       3651       3652       3653       3654 \n0.12529922 0.26405659 0.10058364 0.08705835 0.04542396 0.03813106 0.10561085 \n      3655       3656       3657       3658       3659       3660       3661 \n0.05635073 0.29811346 0.08167515 0.10094605 0.05533237 0.09564875 0.17316817 \n      3662       3663       3664       3665       3666       3667       3668 \n0.15076016 0.21587100 0.13284310 0.10744633 0.15592841 0.06054834 0.06146124 \n      3669       3670       3671       3672       3673       3674       3675 \n0.12838622 0.27135766 0.06721191 0.23714892 0.13330095 0.07673681 0.06320584 \n      3676       3677       3678       3679       3680       3681       3682 \n0.41764014 0.14622264 0.25362595 0.05670256 0.07878012 0.25174506 0.23823459 \n      3683       3684       3685       3686       3687       3688       3689 \n0.06949418 0.23642053 0.30020179 0.21418975 0.17033659 0.14572403 0.11231822 \n      3690       3691       3692       3693       3694       3695       3696 \n0.16322190 0.15785301 0.08363753 0.26510166 0.27982361 0.03769565 0.20854492 \n      3697       3698       3699       3700       3701       3702       3703 \n0.11696981 0.07167599 0.23096666 0.23534892 0.06188555 0.20495369 0.23320750 \n      3704       3705       3706       3707       3708       3709       3710 \n0.14382959 0.11472381 0.06328800 0.16568331 0.03226015 0.04585781 0.09879437 \n      3711       3712       3713       3714       3715       3716       3717 \n0.13261378 0.11073907 0.17117846 0.16458687 0.19907599 0.31204547 0.08611547 \n      3718       3719       3720       3721       3722       3723       3724 \n0.23213776 0.04585781 0.07154253 0.18880354 0.05365978 0.16016960 0.09376999 \n      3725       3726       3727       3728       3729       3730       3731 \n0.08817430 0.07464636 0.07127935 0.15358123 0.13177089 0.21185462 0.04061676 \n      3732       3733       3734       3735       3736       3737       3738 \n0.34768531 0.12220776 0.35280985 0.40318397 0.14930918 0.05799482 0.22338181 \n      3739       3740       3741       3742       3743       3744       3745 \n0.09011275 0.04276460 0.14302290 0.09691476 0.23463268 0.12683555 0.17154729 \n      3746       3747       3748       3749       3750       3751       3752 \n0.21341829 0.03201278 0.19445158 0.24542531 0.09348457 0.21185462 0.13662753 \n      3753       3754       3755       3756       3757       3758       3759 \n0.06250271 0.22466177 0.10227424 0.10010018 0.11758530 0.09159234 0.14358635 \n      3760       3761       3762       3763       3764       3765       3766 \n0.17316375 0.24653949 0.06403749 0.40174304 0.10982267 0.18517650 0.05325658 \n      3767       3768       3769       3770       3771       3772       3773 \n0.33248643 0.07359634 0.09479328 0.23001677 0.21655666 0.14772503 0.08595640 \n      3774       3775       3776       3777       3778       3779       3780 \n0.13569029 0.09467303 0.07010157 0.04046119 0.29202409 0.06830519 0.03740710 \n      3781       3782       3783       3784       3785       3786       3787 \n0.03712123 0.04417194 0.17373272 0.15653342 0.25487387 0.13585482 0.18367137 \n      3788       3789       3790       3791       3792       3793       3794 \n0.36934896 0.10976199 0.26020655 0.14755052 0.05843083 0.34332447 0.27384777 \n      3795       3796       3797       3798       3799       3800       3801 \n0.16151397 0.12184741 0.07400378 0.19497897 0.40031864 0.07341734 0.20691327 \n      3802       3803       3804       3805       3806       3807       3808 \n0.07645393 0.05624408 0.12349742 0.07261045 0.14107879 0.25110912 0.16403979 \n      3809       3810       3811       3812       3813       3814       3815 \n0.35144294 0.07318886 0.29603672 0.07692104 0.08753204 0.09427907 0.04614801 \n      3816       3817       3818       3819       3820       3821       3822 \n0.26638287 0.44498815 0.11946000 0.06177089 0.09348849 0.09956312 0.32196174 \n      3823       3824       3825       3826       3827       3828       3829 \n0.12683555 0.29824337 0.19289852 0.11966970 0.13655796 0.07537947 0.07023255 \n      3830       3831       3832       3833       3834       3835       3836 \n0.23487903 0.20854746 0.09032595 0.25753415 0.09548057 0.05734527 0.08353368 \n      3837       3838       3839       3840       3841       3842       3843 \n0.26123284 0.22896548 0.09433341 0.04342112 0.28466630 0.05828725 0.04793244 \n      3844       3845       3846       3847       3848       3849       3850 \n0.14580517 0.06039901 0.18050036 0.07830156 0.04519230 0.06932641 0.32646575 \n      3851       3852       3853       3854       3855       3856       3857 \n0.13011341 0.19104208 0.36103643 0.05248960 0.04243960 0.14804846 0.18667708 \n      3858       3859       3860       3861       3862       3863       3864 \n0.27305621 0.15314652 0.06771321 0.08774220 0.05734444 0.27849919 0.23061301 \n      3865       3866       3867       3868       3869       3870       3871 \n0.04884976 0.06134554 0.09093150 0.05406507 0.16789804 0.12057425 0.40751299 \n      3872       3873       3874       3875       3876       3877       3878 \n0.10480373 0.29658153 0.15784890 0.07801894 0.06006074 0.03820362 0.20986575 \n      3879       3880       3881       3882       3883       3884       3885 \n0.20550734 0.04276397 0.04956633 0.23001404 0.45287324 0.25665461 0.15785301 \n      3886       3887       3888       3889       3890       3891       3892 \n0.14622457 0.18728510 0.09599394 0.07355297 0.07878012 0.23858789 0.03134019 \n      3893       3894       3895       3896       3897       3898       3899 \n0.15101143 0.10337546 0.13892204 0.10879249 0.06894181 0.11539396 0.14383529 \n      3900       3901       3902       3903       3904       3905       3906 \n0.16132626 0.18466257 0.20259547 0.05054231 0.14898153 0.08983609 0.08307494 \n      3907       3908       3909       3910       3911       3912       3913 \n0.15058270 0.09616561 0.35357469 0.23214327 0.05670256 0.08897716 0.08197564 \n      3914       3915       3916       3917       3918       3919       3920 \n0.07631447 0.34466961 0.14067358 0.04614733 0.16513330 0.29161559 0.09861989 \n      3921       3922       3923       3924       3925       3926       3927 \n0.05389253 0.20388080 0.10240022 0.26444090 0.18920642 0.27703137 0.29120424 \n      3928       3929       3930       3931       3932       3933       3934 \n0.10058364 0.18346816 0.11696662 0.30145229 0.06379818 0.16762207 0.23356116 \n      3935       3936       3937       3938       3939       3940       3941 \n0.14754858 0.07887970 0.11138886 0.04956633 0.07748874 0.11952369 0.03511169 \n      3942       3943       3944       3945       3946       3947       3948 \n0.16568544 0.06471911 0.09011149 0.04775094 0.21745877 0.08063417 0.09674459 \n      3949       3950       3951       3952       3953       3954       3955 \n0.10166871 0.06006161 0.23560135 0.11655574 0.24333566 0.08870490 0.24542817 \n      3956       3957       3958       3959       3960       3961       3962 \n0.06754845 0.14481745 0.08078312 0.08507025 0.04484905 0.38322451 0.14523257 \n      3963       3964       3965       3966       3967       3968       3969 \n0.11093692 0.08379153 0.07902681 0.16623693 0.03849750 0.35631487 0.06692378 \n      3970       3971       3972       3973       3974       3975       3976 \n0.35357469 0.11392012 0.16568544 0.19939381 0.31375863 0.11492629 0.13796974 \n      3977       3978       3979       3980       3981       3982       3983 \n0.14647731 0.23025974 0.03250936 0.09547524 0.30608997 0.03015344 0.07382493 \n      3984       3985       3986       3987       3988       3989       3990 \n0.09394335 0.15255024 0.07659580 0.17864797 0.17210985 0.12921417 0.04342112 \n      3991       3992       3993       3994       3995       3996       3997 \n0.18456912 0.31046701 0.15864703 0.06721191 0.26549296 0.04459439 0.15288433 \n      3998       3999       4000       4001       4002       4003       4004 \n0.11945837 0.07369200 0.24369979 0.14156414 0.17146127 0.08152470 0.07645611 \n      4005       4006       4007       4008       4009       4010       4011 \n0.06145946 0.08838087 0.12264078 0.07318991 0.27214615 0.09348457 0.14779737 \n      4012       4013       4014       4015       4016       4017       4018 \n0.04139955 0.06145946 0.22476454 0.08383801 0.07423354 0.13615823 0.10859650 \n      4019       4020       4021       4022       4023       4024       4025 \n0.08833211 0.09343328 0.12486489 0.04884976 0.14163960 0.14655107 0.17719336 \n      4026       4027       4028       4029       4030       4031       4032 \n0.05054305 0.34722664 0.24442916 0.06391819 0.05832133 0.35448938 0.03524639 \n      4033       4034       4035       4036       4037       4038       4039 \n0.27108356 0.09164529 0.08399115 0.17098618 0.19382825 0.14704622 0.25249631 \n      4040       4041       4042       4043       4044       4045       4046 \n0.14622650 0.27902452 0.11559746 0.09326337 0.07773062 0.08127321 0.35539452 \n      4047       4048       4049       4050       4051       4052       4053 \n0.21185204 0.17932694 0.21711996 0.05774292 0.24664335 0.48559883 0.23595474 \n      4054       4055       4056       4057       4058       4059       4060 \n0.16976992 0.11931420 0.03969482 0.08881331 0.13445771 0.09343197 0.17554727 \n      4061       4062       4063       4064       4065       4066       4067 \n0.23596030 0.07414041 0.24149790 0.10172542 0.39744530 0.31604140 0.26990427 \n      4068       4069       4070       4071       4072       4073       4074 \n0.04987804 0.09656930 0.03565456 0.16422580 0.07062178 0.15864910 0.45632300 \n      4075       4076       4077       4078       4079       4080       4081 \n0.12573823 0.17041561 0.27902452 0.04292800 0.10467659 0.13522371 0.16348994 \n      4082       4083       4084       4085       4086       4087       4088 \n0.12721194 0.24837998 0.18737726 0.04459439 0.12654817 0.05460798 0.09259300 \n      4089       4090       4091       4092       4093       4094       4095 \n0.06100319 0.43321346 0.14091270 0.17203022 0.09048977 0.13284132 0.15627058 \n      4096       4097       4098       4099       4100       4101       4102 \n0.20625517 0.22920221 0.06066176 0.13491845 0.09109759 0.14779737 0.23822618 \n      4103       4104       4105       4106       4107       4108       4109 \n0.06131158 0.17353596 0.08658453 0.13522551 0.13124317 0.04383737 0.26717127 \n      4110       4111       4112       4113       4114       4115       4116 \n0.36241267 0.25073469 0.24431453 0.06223432 0.12988635 0.40078583 0.08137797 \n      4117       4118       4119       4120       4121       4122       4123 \n0.07001223 0.16845324 0.07621786 0.28346031 0.06593640 0.08137566 0.08817306 \n      4124       4125       4126       4127       4128       4129       4130 \n0.18889627 0.16431527 0.18487146 0.13452817 0.05248883 0.18247962 0.08212335 \n      4131       4132       4133       4134       4135       4136       4137 \n0.13994897 0.07185107 0.04451025 0.28102955 0.03909234 0.10668748 0.14797212 \n      4138       4139       4140       4141       4142       4143       4144 \n0.08674098 0.06379818 0.22258662 0.05554181 0.05656214 0.11655733 0.29244251 \n      4145       4146       4147       4148       4149       4150       4151 \n0.40557930 0.07575467 0.08023805 0.27266096 0.18910884 0.24664335 0.03924170 \n      4152       4153       4154       4155       4156       4157       4158 \n0.24076602 0.06077537 0.36411577 0.04292800 0.07892482 0.09192438 0.24296053 \n      4159       4160       4161       4162       4163       4164       4165 \n0.20779604 0.31863073 0.11994524 0.09428039 0.13655431 0.08838087 0.24065538 \n      4166       4167       4168       4169       4170       4171       4172 \n0.26444390 0.29686448 0.27623102 0.13429640 0.09016240 0.22511454 0.11539553 \n      4173       4174       4175       4176       4177       4178       4179 \n0.15007380 0.18346816 0.12479539 0.11152620 0.19196739 0.09142673 0.11539553 \n      4180       4181       4182       4183       4184       4185       4186 \n0.18011646 0.25475893 0.17815272 0.32426922 0.18637950 0.16753331 0.14597605 \n      4187       4188       4189       4190 \n0.10258204 0.13522551 0.04730007 0.06881404 \n\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-00.html#meet-your-tas",
    "href": "slides/lab-00.html#meet-your-tas",
    "title": "Welcome to STA 221 labs!",
    "section": "Meet your TAs!",
    "text": "Meet your TAs!"
  },
  {
    "objectID": "slides/lab-00.html#meet-each-other",
    "href": "slides/lab-00.html#meet-each-other",
    "title": "Welcome to STA 221 labs!",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\nGet into groups of 2 or 3\nIntroduce yourself: Name, year, major (or academic interest), a highlight from the summer\nIntroduce your partner to the class\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab-00.html#what-to-expect-in-lab",
    "href": "slides/lab-00.html#what-to-expect-in-lab",
    "title": "Welcome to STA 221 labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the lab assignment (~ 5 - 10 minutes)\nReview lecture content, as needed (~ 10 minutes)\nWork on the lab assignment (individual for Lab 01 and in teams for the remainder of the semester)\nStarting with Lab 01, you will find the starter materials for lab in your repo in the course GitHub organization."
  },
  {
    "objectID": "slides/lab-00.html#todays-lab",
    "href": "slides/lab-00.html#todays-lab",
    "title": "Welcome to STA 221 labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on setting up the computing for the course and completing the class survey. Click the link below for the Lab 00 instructions. The instructions are available on the course website.\n\n🔗 sta221-fa24.netlify.app/labs/lab-00.html\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/lab-04.html#goals",
    "href": "slides/lab-04.html#goals",
    "title": "Lab 04",
    "section": "Goals",
    "text": "Goals\n\nTeam feedback\nMid-semester survey\nLab 04: Maximum likelihood estimation (with Palmer penguins)"
  },
  {
    "objectID": "slides/lab-04.html#team-feedback",
    "href": "slides/lab-04.html#team-feedback",
    "title": "Lab 04",
    "section": "Team feedback",
    "text": "Team feedback\n\nPurpose: To reflect on the team’s collaboration and your contribution thus far\nYou should have received an email from Teammates with a link to the feedback from on October 21 around 11am\n\nPlease let your TA know if you do not see the email (check your spam folder first!)\n\nTeam feedback is due Thursday, October 24 at 11:59pm\nThis feedback will be graded for completion only (go towards the Participation grade)"
  },
  {
    "objectID": "slides/lab-04.html#mid-semester-feedback",
    "href": "slides/lab-04.html#mid-semester-feedback",
    "title": "Lab 04",
    "section": "Mid-semester feedback",
    "text": "Mid-semester feedback\n\nPurpose: To give the teaching team feedback on what is working well (or not as well) in helping you learn the course content\nThe feedback is anonymous and will not be graded\nIt will be available until Thursday, October 24 at 11:59pm.\n\nWe (the teaching team) appreciate you taking a few minutes to fill it out!\n🔗 duke.qualtrics.com/jfe/form/SV_244HYi8U8X85pgW"
  },
  {
    "objectID": "slides/lab-04.html#lab-04-maximum-likelihood-estimation",
    "href": "slides/lab-04.html#lab-04-maximum-likelihood-estimation",
    "title": "Lab 04",
    "section": "Lab 04: Maximum likelihood estimation",
    "text": "Lab 04: Maximum likelihood estimation\nThis lab focuses on\n\nusing linear regression and statistical inference to draw conclusions about penguins living in Palmer Archipelago in Antarctica.\nexploring maximum likelihood estimators and their connection to least-squares estimators\n\n🔗 https://sta221-fa24.netlify.app/labs/lab-04"
  },
  {
    "objectID": "slides/lab-04.html#reminder-tips-for-working-on-a-team",
    "href": "slides/lab-04.html#reminder-tips-for-working-on-a-team",
    "title": "Lab 04",
    "section": "Reminder: Tips for working on a team",
    "text": "Reminder: Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other.\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/01-welcome.html#meet-prof.-tackett",
    "href": "slides/01-welcome.html#meet-prof.-tackett",
    "title": "Welcome to STA 221!",
    "section": "Meet Prof. Tackett!",
    "text": "Meet Prof. Tackett!\n\n\nEducation and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 19-month-old twins 🙂"
  },
  {
    "objectID": "slides/01-welcome.html#teaching-assistants-tas",
    "href": "slides/01-welcome.html#teaching-assistants-tas",
    "title": "Welcome to STA 221!",
    "section": "Teaching Assistants (TAs)",
    "text": "Teaching Assistants (TAs)\n\nKat Husar (PhD): Head TA + Lab 02 leader\nJon Campbell (MS): Lab 01 leader\nIshrit Gupta (UG): Lab 01 helper\nAlan Wang (UG): Lab 02 helper"
  },
  {
    "objectID": "slides/01-welcome.html#check-in-on-ed-discussion",
    "href": "slides/01-welcome.html#check-in-on-ed-discussion",
    "title": "Welcome to STA 221!",
    "section": "Check-in on Ed Discussion!",
    "text": "Check-in on Ed Discussion!\n\nClick on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/62513/discussion/625046"
  },
  {
    "objectID": "slides/01-welcome.html#topics",
    "href": "slides/01-welcome.html#topics",
    "title": "Welcome to STA 221!",
    "section": "Topics",
    "text": "Topics\n\nIntroduction to the course\nSyllabus activity\nReproducibility"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-regression-analysis",
    "href": "slides/01-welcome.html#what-is-regression-analysis",
    "title": "Welcome to STA 221!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nRegression analysis is a statistical method used to examine the relationship between a response variable and one or more predictor variables. It is used for predicting future values, understanding relationships between variables, and identifying key predictors. It also helps in modeling trends, assessing the impact of changes, and detecting outliers in data.\n\nSource: ChatGPT (with modification)"
  },
  {
    "objectID": "slides/01-welcome.html#example-rent-vs.-commute-time",
    "href": "slides/01-welcome.html#example-rent-vs.-commute-time",
    "title": "Welcome to STA 221!",
    "section": "Example: Rent vs. commute time",
    "text": "Example: Rent vs. commute time\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\n\n\\[\n\\text{rent} = \\beta_0 + \\beta_1 ~ \\text{commute_time} + \\epsilon\n\\]\n\n\n\n\\[\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & x_1 \\\\\n1 & x_2 \\\\\n\\vdots & \\vdots \\\\\n1 & x_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\end{bmatrix} +  \\begin{bmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-sta-221",
    "href": "slides/01-welcome.html#what-is-sta-221",
    "title": "Welcome to STA 221!",
    "section": "What is STA 221?",
    "text": "What is STA 221?\n\n\n\n\n\n STA 210 \n\nApplication\n\n\n\n\n+\n\n\n\n\n\nSTA 211\n\nTheory\n\n\n\nPrerequisites: Introductory statistics or probability course and linear algebra\nRecommended corequisite: Probability course at Duke"
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 221!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze data to explore real-world multivariable relationships.\nfit, interpret, and draw conclusions from linear and logistic regression models.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\nexplain the mathematical foundations of linear and logistic regression.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 221!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nMatrix representation of regression\nEstimators\nModel conditions and diagnostics\nDifferent types of predictor variables\n\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nInference\n\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta221-fa24.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/38867\n\nGradebook\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta221-fa24\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit",
    "href": "slides/01-welcome.html#computing-toolkit",
    "title": "Welcome to STA 221!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 210 Docker Containers\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 221 course organization"
  },
  {
    "objectID": "slides/01-welcome.html#classroom-community",
    "href": "slides/01-welcome.html#classroom-community",
    "title": "Welcome to STA 221!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 221!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity",
    "href": "slides/01-welcome.html#syllabus-activity",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nIntroduce yourself to your group members.\nChoose a reporter. This person will share the group’s summary with the class.\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have.\nThe reporter will share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-assignments",
    "href": "slides/01-welcome.html#syllabus-activity-assignments",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation (Application exercises + teamwork)\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-report-out",
    "href": "slides/01-welcome.html#syllabus-activity-report-out",
    "title": "Welcome to STA 221!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\n\nGroup 1: What to expect in lectures and labs\nGroup 2: Homework and lab assignments\nGroup 3: Exams and project\nGroup 4: Participation (Application exercises + teamwork)\nGroup 5: Academic honesty (except AI policy)\nGroup 6: Artificial intelligence policy\nGroup 7: Late work policy and waiver for extenuating circumstances\nGroup 8: Attendance and lecture recording request\nGroup 9: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 221!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n25%\n\n\nFinal project\n15%\n\n\nLab\n15%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs and teamwork)\n5%\n\n\nTotal\n100%"
  },
  {
    "objectID": "slides/01-welcome.html#five-tips-for-success-in-sta-221",
    "href": "slides/01-welcome.html#five-tips-for-success-in-sta-221",
    "title": "Welcome to STA 221!",
    "section": "Five tips for success in STA 221",
    "text": "Five tips for success in STA 221\n\nComplete all the preparation work before class.\nAsk questions in class, office hours, and on Ed Discussion.\nDo the homework and labs; get started on homework early when possible.\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStay up-to-date on announcements on Ed Discussion and sent via email."
  },
  {
    "objectID": "slides/01-welcome.html#reproducibility-checklist",
    "href": "slides/01-welcome.html#reproducibility-checklist",
    "title": "Welcome to STA 221!",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/01-welcome.html#why-is-reproducibility-important",
    "href": "slides/01-welcome.html#why-is-reproducibility-important",
    "title": "Welcome to STA 221!",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/01-welcome.html#toolkit",
    "href": "slides/01-welcome.html#toolkit",
    "title": "Welcome to STA 221!",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/01-welcome.html#r-and-rstudio",
    "href": "slides/01-welcome.html#r-and-rstudio",
    "title": "Welcome to STA 221!",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/01-welcome.html#rstudio-ide",
    "href": "slides/01-welcome.html#rstudio-ide",
    "title": "Welcome to STA 221!",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/01-welcome.html#quarto",
    "href": "slides/01-welcome.html#quarto",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/01-welcome.html#quarto-1",
    "href": "slides/01-welcome.html#quarto-1",
    "title": "Welcome to STA 221!",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/01-welcome.html#how-will-we-use-quarto",
    "href": "slides/01-welcome.html#how-will-we-use-quarto",
    "title": "Welcome to STA 221!",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-versioning",
    "href": "slides/01-welcome.html#what-is-versioning",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-versioning-1",
    "href": "slides/01-welcome.html#what-is-versioning-1",
    "title": "Welcome to STA 221!",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/01-welcome.html#why-do-we-need-version-control",
    "href": "slides/01-welcome.html#why-do-we-need-version-control",
    "title": "Welcome to STA 221!",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/01-welcome.html#git-and-github",
    "href": "slides/01-welcome.html#git-and-github",
    "title": "Welcome to STA 221!",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/01-welcome.html#this-week",
    "href": "slides/01-welcome.html#this-week",
    "title": "Welcome to STA 221!",
    "section": "This week",
    "text": "This week\n\nComplete Lab 00 tasks\nReview syllabus\nComplete reading to prepare for Thursday’s lecture\nThursday’s lecture: Simple linear regression"
  },
  {
    "objectID": "slides/01-welcome.html#references",
    "href": "slides/01-welcome.html#references",
    "title": "Welcome to STA 221!",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 221 - Fall 2024\n\n\n\n\nAlexander, Rohan. 2023. “Telling Stories with Data,” June. https://doi.org/10.1201/9781003229407.\n\n\nOstblom, Joel, and Tiffany Timbers. 2022. “Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice.” Journal of Statistics and Data Science Education 30 (3): 241–50. https://doi.org/10.1080/26939169.2022.2074922."
  },
  {
    "objectID": "slides/09-inference-pt2.html#announcements",
    "href": "slides/09-inference-pt2.html#announcements",
    "title": "Inference for regression",
    "section": "Announcements",
    "text": "Announcements\n\nProject\n\nResearch questions due Thursday at 11:59pm\nProposal due Thursday, October 3 at 11:59pm\n\nLab 03 due Thursday, October 3 at 11:59pm\nStatistics experience due Tue, Nov 26 at 11:59pm"
  },
  {
    "objectID": "slides/09-inference-pt2.html#topics",
    "href": "slides/09-inference-pt2.html#topics",
    "title": "Inference for regression",
    "section": "Topics",
    "text": "Topics\n\nUnderstand statistical inference in the context of regression\nDescribe the assumptions for regression\nUnderstand connection between distribution of residuals and inferential procedures\nConduct inference on a single coefficient\nConduct inference on the overall regression model"
  },
  {
    "objectID": "slides/09-inference-pt2.html#computing-setup",
    "href": "slides/09-inference-pt2.html#computing-setup",
    "title": "Inference for regression",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/09-inference-pt2.html#data-ncaa-football-expenditures",
    "href": "slides/09-inference-pt2.html#data-ncaa-football-expenditures",
    "title": "Inference for regression",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)\n\n\nfootball &lt;- read_csv(\"data/ncaa-football-exp.csv\")"
  },
  {
    "objectID": "slides/09-inference-pt2.html#univariate-eda",
    "href": "slides/09-inference-pt2.html#univariate-eda",
    "title": "Inference for regression",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2.html#bivariate-eda",
    "href": "slides/09-inference-pt2.html#bivariate-eda",
    "title": "Inference for regression",
    "section": "Bivariate EDA",
    "text": "Bivariate EDA"
  },
  {
    "objectID": "slides/09-inference-pt2.html#regression-model",
    "href": "slides/09-inference-pt2.html#regression-model",
    "title": "Inference for regression",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\nFor every additional 1,000 students, we expect the institution’s total expenditures on football to increase by $780,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2.html#statistical-inference",
    "href": "slides/09-inference-pt2.html#statistical-inference",
    "title": "Inference for regression",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/09-inference-pt2.html#inference-for-linear-regression",
    "href": "slides/09-inference-pt2.html#inference-for-linear-regression",
    "title": "Inference for regression",
    "section": "Inference for linear regression",
    "text": "Inference for linear regression\n\nInference based on ANOVA\n\nHypothesis test for the statistical significance of the overall regression model\nHypothesis test for a subset of coefficients\n\nInference for a single coefficient \\(\\beta_j\\)\n\nHypothesis test for a coefficient \\(\\beta_j\\)\nConfidence interval for a coefficient \\(\\beta_j\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#linear-regression-model",
    "href": "slides/09-inference-pt2.html#linear-regression-model",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\begin{aligned}\n\\mathbf{y} &= Model + Error \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n\\]\n\n\n\nWe have discussed multiple ways to find the least squares estimates of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}\\)\n\nNone of these approaches depend on the distribution of \\(\\boldsymbol{\\epsilon}\\)\n\nNow we will use statistical inference to draw conclusions about \\(\\boldsymbol{\\beta}\\) that depend on particular assumptions about the distribution of \\(\\boldsymbol{\\epsilon}\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#linear-regression-model-1",
    "href": "slides/09-inference-pt2.html#linear-regression-model-1",
    "title": "Inference for regression",
    "section": "Linear regression model",
    "text": "Linear regression model\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#expected-value-of-mathbfy",
    "href": "slides/09-inference-pt2.html#expected-value-of-mathbfy",
    "title": "Inference for regression",
    "section": "Expected value of \\(\\mathbf{y}\\)",
    "text": "Expected value of \\(\\mathbf{y}\\)\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of random variables.\n\n\nThen \\(E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(E(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/09-inference-pt2.html#variance",
    "href": "slides/09-inference-pt2.html#variance",
    "title": "Inference for regression",
    "section": "Variance",
    "text": "Variance\nLet \\(\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}\\) be a \\(p \\times 1\\) vector of independent random variables.\n\n\nThen \\(Var(\\mathbf{b}) = \\begin{bmatrix}Var(b_1) & 0 & \\dots & 0 \\\\ 0 & Var(b_2) & \\dots & 0 \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ 0 & 0 & \\dots & Var(b_p)\\end{bmatrix}\\)\n\n\n\n\nUse this to find \\(Var(\\mathbf{y}|\\mathbf{X})\\)."
  },
  {
    "objectID": "slides/09-inference-pt2.html#assumptions-of-regression",
    "href": "slides/09-inference-pt2.html#assumptions-of-regression",
    "title": "Inference for regression",
    "section": "Assumptions of regression",
    "text": "Assumptions of regression\n\n\n\\[\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n\\]\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the residuals is approximately normal.\nIndependence: The residuals are independent from one another."
  },
  {
    "objectID": "slides/09-inference-pt2.html#estimating-sigma2_epsilon",
    "href": "slides/09-inference-pt2.html#estimating-sigma2_epsilon",
    "title": "Inference for regression",
    "section": "Estimating \\(\\sigma^2_{\\epsilon}\\)",
    "text": "Estimating \\(\\sigma^2_{\\epsilon}\\)\n\nOnce we fit the model, we can use the residuals to estimate \\(\\sigma_{\\epsilon}^2\\)\n\\(\\hat{\\sigma}^2_{\\epsilon}\\) is needed for hypothesis testing and constructing confidence intervals for regression\n\n\\[\n\\hat{\\sigma}^2_\\epsilon = \\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-p-1} = \\frac{\\sum_\\limits{i=1}^ne_i^2}{n - p - 1} = \\frac{SSR}{n - p - 1}\n\\]\n\nThe regression standard error \\(\\hat{\\sigma}_{\\epsilon}\\) is a measure of the average distance between the observations and regression line\n\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#inference-for-beta_j",
    "href": "slides/09-inference-pt2.html#inference-for-beta_j",
    "title": "Inference for regression",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?\n\nBut first we need to understand the distribution of \\(\\hat{\\beta}_j\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta_j",
    "href": "slides/09-inference-pt2.html#sampling-distribution-of-hatbeta_j",
    "title": "Inference for regression",
    "section": "Sampling distribution of \\(\\hat{\\beta}_j\\)",
    "text": "Sampling distribution of \\(\\hat{\\beta}_j\\)\n\\[\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1})\n\\]\nLet \\(\\mathbf{C} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\). Then, for each coefficient \\(\\hat{\\beta}_j\\),\n\n\n\\(E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j\\), the \\(j^{th}\\) element of \\(\\boldsymbol{\\beta}\\)\n\\(Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}\\)\n\\(Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}\\)"
  },
  {
    "objectID": "slides/09-inference-pt2.html#steps-for-a-hypothesis-test",
    "href": "slides/09-inference-pt2.html#steps-for-a-hypothesis-test",
    "title": "Inference for regression",
    "section": "Steps for a hypothesis test",
    "text": "Steps for a hypothesis test\n\nState the null and alternative hypotheses.\nCalculate a test statistic.\nCalculate the p-value.\nState the conclusion."
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-hypotheses",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-hypotheses",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Hypotheses",
    "text": "Hypothesis test for \\(\\beta_j\\): Hypotheses\nWe will generally test the hypotheses:\n\nNull Hypothesis: \\(H_0: \\beta_j = 0\\)\n\nThere is no linear relationship between \\(\\beta_j\\) and \\(y\\) after accounting for the other variables in the model\n\nAlternative hypothesis: \\(H_a: \\beta_j \\neq 0\\)\n\nThere is a linear relationship between \\(\\beta_j\\) and \\(y\\) after accounting for the other variables in the model"
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-test-statistic",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Test statistic",
    "text": "Hypothesis test for \\(\\beta_j\\): Test statistic\nTest statistic: Number of standard errors the estimate is away from the null hypothesized value\n\\[\n\\text{Test Statstic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\n\n\\[T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-p-value",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-p-value",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): P-value",
    "text": "Hypothesis test for \\(\\beta_j\\): P-value\nThe p-value is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n- p - 1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2.html#understanding-the-p-value",
    "href": "slides/09-inference-pt2.html#understanding-the-p-value",
    "title": "Inference for regression",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-conclusion",
    "href": "slides/09-inference-pt2.html#hypothesis-test-for-beta_j-conclusion",
    "title": "Inference for regression",
    "section": "Hypothesis test for \\(\\beta_j\\): Conclusion",
    "text": "Hypothesis test for \\(\\beta_j\\): Conclusion\nThere are two parts to the conclusion\n\nMake a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( \\(\\alpha\\) level)\n\nIf \\(\\text{p-value} &lt; \\alpha\\): Reject \\(H_0\\)\nIf \\(\\text{p-value} \\geq \\alpha\\): Fail to reject \\(H_0\\)\n\nState the conclusion in the context of the data"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-1",
    "href": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-1",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/09-inference-pt2.html#what-confidence-means",
    "href": "slides/09-inference-pt2.html#what-confidence-means",
    "title": "Inference for regression",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals.\n\nThe confidence level impacts the width of the interval\n\n\n\n\n“Confident” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) CIs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\n\n\n\nBalance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-2",
    "href": "slides/09-inference-pt2.html#confidence-interval-for-beta_j-2",
    "title": "Inference for regression",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2.html#confidence-interval-critical-value",
    "href": "slides/09-inference-pt2.html#confidence-interval-critical-value",
    "title": "Inference for regression",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/09-inference-pt2.html#ci-for-beta_j-calculation",
    "href": "slides/09-inference-pt2.html#ci-for-beta_j-calculation",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\): Calculation",
    "text": "95% CI for \\(\\beta_j\\): Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/09-inference-pt2.html#ci-for-beta_j-in-r",
    "href": "slides/09-inference-pt2.html#ci-for-beta_j-in-r",
    "title": "Inference for regression",
    "section": "95% CI for \\(\\beta_j\\) in R",
    "text": "95% CI for \\(\\beta_j\\) in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986\n\n\n\n\n\n\nInterpretation: We are 95% confident that for each additional 1,000 students enrolled, the institution’s expenditures on football will be greater by $562,000 to $999,000, on average, holding institution type constant."
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-hypotheses",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-hypotheses",
    "title": "Inference for regression",
    "section": "Test for overall significance: Hypotheses",
    "text": "Test for overall significance: Hypotheses\nWe can conduct a hypothesis test using the ANOVA table to determine if there is at least one non-zero coefficient in the model\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n\nFor the football data\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-test-statistic",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-test-statistic",
    "title": "Inference for regression",
    "section": "Test for overall significance: Test statistic",
    "text": "Test for overall significance: Test statistic\n\n\n\n\n\nSource\nDf\nSum Sq\nMean Sq\nF Stat\nPr(&gt; F)\n\n\n\n\nModel\n2\n7138.591\n3569.296\n26.628\n0\n\n\nResiduals\n124\n16621.344\n134.043\n\n\n\n\nTotal\n126\n23759.935\n\n\n\n\n\n\n\n\n\nTest statistic: Ratio of explained to unexplained variability\n\\[\nF = \\frac{\\text{Mean Square Model}}{\\text{Mean Square Residuals}}\n\\]\nThe test statistic follows an \\(F\\) distribution with \\(p\\) and \\(n -  p - 1\\) degrees of freedom"
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-p-value",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-p-value",
    "title": "Inference for regression",
    "section": "Test for overall significance: P-value",
    "text": "Test for overall significance: P-value\n\n\\[\n\\text{P-value} = \\text{Pr}(F &gt; \\text{F Stat})\n\\]"
  },
  {
    "objectID": "slides/09-inference-pt2.html#test-for-overall-significance-conclusion",
    "href": "slides/09-inference-pt2.html#test-for-overall-significance-conclusion",
    "title": "Inference for regression",
    "section": "Test for overall significance: Conclusion",
    "text": "Test for overall significance: Conclusion\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n\nfootball_anova |&gt;\n  kable(digits = 3)\n\n\n\n\nSource\nDf\nSum Sq\nMean Sq\nF Stat\nPr(&gt; F)\n\n\n\n\nModel\n2\n7138.591\n3569.296\n26.628\n0\n\n\nResiduals\n124\n16621.344\n134.043\n\n\n\n\nTotal\n126\n23759.935\n\n\n\n\n\n\n\n\n\nWhat is the conclusion from this hypothesis test?"
  },
  {
    "objectID": "slides/09-inference-pt2.html#recap",
    "href": "slides/09-inference-pt2.html#recap",
    "title": "Inference for regression",
    "section": "Recap",
    "text": "Recap\n\nIntroduced statistical inference in the context of regression\nDescribed the assumptions for regression\nConnected the distribution of residuals and inferential procedures\nConducted inference on a single coefficient\nConducted inference on the overall regression model\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#announcements",
    "href": "slides/07-mlr-pt3.html#announcements",
    "title": "ANOVA + Geometric interpretation",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due on Thursday at 11:59pm\n\nPush work to GitHub repo\nSubmit final PDF on Gradescope + select all team members + mark pages for each question\n\nHW 01 due Thursday at 11:59pm\n\nNote submission instructions"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#homework-submission",
    "href": "slides/07-mlr-pt3.html#homework-submission",
    "title": "ANOVA + Geometric interpretation",
    "section": "Homework submission",
    "text": "Homework submission\nIf you write your responses to Exercises 1 - 4 by hand, you will need to combine your written work to the completed PDF for Exercises 5 - 10 before submitting on Gradescope.\nInstructions to combine PDFs:\n\nPreview (Mac): support.apple.com/guide/preview/combine-pdfs-prvw43696/mac\nAdobe (Mac or PC): helpx.adobe.com/acrobat/using/merging-files-single-pdf.html\n\nGet free access to Adobe Acrobat as a Duke student: oit.duke.edu/help/articles/kb0030141/"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#latex-in-this-class",
    "href": "slides/07-mlr-pt3.html#latex-in-this-class",
    "title": "ANOVA + Geometric interpretation",
    "section": "Latex in this class",
    "text": "Latex in this class\nFor this class you will need to be able to…\n\nProperly write mathematical symbols, e.g., \\(\\beta_1\\) not B1, \\(R^2\\) not R2\nWrite basic regression equations, e.g., \\(\\hat{y} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\\)\nWrite matrix equations: \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\)\nWrite hypotheses (we’ll start this next week), e.g., \\(H_0: \\beta = 0\\)\n\nYou are welcome to but not required to write math proofs using LaTex."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#topics",
    "href": "slides/07-mlr-pt3.html#topics",
    "title": "ANOVA + Geometric interpretation",
    "section": "Topics",
    "text": "Topics\n\nCompare models using Adjusted \\(R^2\\)\nIntroduce the ANOVA table\nUse a geometric interpretation to find the least squares estimates"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#computing-setup",
    "href": "slides/07-mlr-pt3.html#computing-setup",
    "title": "ANOVA + Geometric interpretation",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(viridis) #adjust color palette\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#data-peer-to-peer-lender",
    "href": "slides/07-mlr-pt3.html#data-peer-to-peer-lender",
    "title": "ANOVA + Geometric interpretation",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income_th debt_to_income verified_income interest_rate\n              &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1             59           0.558  Not Verified            10.9 \n 2             60           1.31   Not Verified             9.92\n 3             75           1.06   Verified                26.3 \n 4             75           0.574  Not Verified             9.92\n 5            254           0.238  Not Verified             9.43\n 6             67           1.08   Source Verified          9.92\n 7             28.8         0.0997 Source Verified         17.1 \n 8             80           0.351  Not Verified             6.08\n 9             34           0.698  Not Verified             7.97\n10             80           0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#variables",
    "href": "slides/07-mlr-pt3.html#variables",
    "title": "ANOVA + Geometric interpretation",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income_th: Annual income (in $1000s)\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nResponse: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#model-fit-in-r",
    "href": "slides/07-mlr-pt3.html#model-fit-in-r",
    "title": "ANOVA + Geometric interpretation",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th, data = loan50)\n\nint_fit2 &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th + verified_income * annual_income_th, data = loan50)"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#rmse-r2",
    "href": "slides/07-mlr-pt3.html#rmse-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "RMSE & \\(R^2\\)",
    "text": "RMSE & \\(R^2\\)\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#comparing-models",
    "href": "slides/07-mlr-pt3.html#comparing-models",
    "title": "ANOVA + Geometric interpretation",
    "section": "Comparing models",
    "text": "Comparing models\n\n\nThough we use \\(R^2\\) to assess the model fit, it is generally unreliable for comparing models with different number of predictors. Why?\n\n\\(R^2\\) will stay the same or increase as we add more variables to the model . Let’s show why this is true.\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#adjusted-r2",
    "href": "slides/07-mlr-pt3.html#adjusted-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3.html#r2-and-adjusted-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n\n\\[R^2_{adj} = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#compare-models",
    "href": "slides/07-mlr-pt3.html#compare-models",
    "title": "ANOVA + Geometric interpretation",
    "section": "Compare models",
    "text": "Compare models\nWhich model would you select int_fit (main effects only) or int_fit2 (main effects + interaction) based on…\n\\(R^2\\)\n\nglance(int_fit)$r.squared\n\n[1] 0.279854\n\nglance(int_fit2)$r.squared\n\n[1] 0.2963437\n\n\n\n\\(Adj. R^2\\)\n\nglance(int_fit)$adj.r.squared\n\n[1] 0.215841\n\nglance(int_fit2)$adj.r.squared\n\n[1] 0.1981591"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#anova-table",
    "href": "slides/07-mlr-pt3.html#anova-table",
    "title": "ANOVA + Geometric interpretation",
    "section": "ANOVA table",
    "text": "ANOVA table\n\n\n\nSource\nSum of squares\nDF\nMean square\nF\n\n\n\n\nModel\n\\(\\sum_{i=1}^n(\\hat{y}_i - \\bar{y})^2\\)\n\\(p\\)\n\\(SSM / p\\)\n\\(MSM / MSR\\)\n\n\nResidual\n\\(\\sum_{i=1}^n(y_i- \\hat{y}_i)^2\\)\n\\(n - p - 1\\)\n\\(SSR / (n - p - 1)\\)\n\n\n\nTotal\n\\(\\sum_{i = 1}^n(y_i - \\bar{y})^2\\)\n\\(n - 1\\)\n\n\n\n\n\n\n\n\nThe degrees of freedom (df) are the number of independent pieces of information used to calculate a statistic.\nMean square (MS) is the sum of squares divided by the associated degrees of freedom."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#using-r2-and-adjusted-r2",
    "href": "slides/07-mlr-pt3.html#using-r2-and-adjusted-r2",
    "title": "ANOVA + Geometric interpretation",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression",
    "href": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression",
    "title": "ANOVA + Geometric interpretation",
    "section": "Geometry of least squares regression",
    "text": "Geometry of least squares regression\n\n\nLet \\(\\text{Col}(\\mathbf{X})\\) be the column space of \\(\\mathbf{X}\\): the set all possible linear combinations (span) of the columns of \\(\\mathbf{X}\\)\nThe vector of responses \\(\\mathbf{y}\\) is not in \\(\\text{Col}(\\mathbf{X})\\).\nGoal: Find another vector \\(\\mathbf{z} = \\mathbf{Xb}\\) that is in \\(\\text{Col}(\\mathbf{X})\\) and is as close as possible to \\(\\mathbf{y}\\).\n\n\\(\\mathbf{z}\\) is called a projection of \\(\\mathbf{y}\\) onto \\(\\text{Col}(\\mathbf{X})\\) ."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-1",
    "href": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-1",
    "title": "ANOVA + Geometric interpretation",
    "section": "Geometry of least squares regression",
    "text": "Geometry of least squares regression\n\n\nFor any \\(\\mathbf{z} = \\mathbf{Xb}\\) in \\(\\text{Col}(\\mathbf{X})\\), the vector \\(\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}\\) is the difference between \\(\\mathbf{y}\\) and \\(\\mathbf{Xb}\\).\n\nIn other words, we want to minimize \\(||\\mathbf{e}||^2 = ||\\mathbf{y} - \\mathbf{Xb}||^2\\)\n\nThis is minimized for the \\(\\mathbf{b}\\) ( we’ll call it \\(\\hat{\\boldsymbol{\\beta}}\\) ) that makes \\(\\mathbf{e}\\) orthogonal to \\(\\text{Col}(\\mathbf{X})\\)\nRecall: If \\(\\mathbf{e}\\) is orthogonal to \\(\\text{Col}(\\mathbf{X})\\), then the inner product of any vector in \\(\\text{Col}(\\mathbf{X})\\) and \\(\\mathbf{e}\\) is 0 \\(\\Rightarrow \\mathbf{X}^T\\mathbf{e} = \\mathbf{0}\\)"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-2",
    "href": "slides/07-mlr-pt3.html#geometry-of-least-squares-regression-2",
    "title": "ANOVA + Geometric interpretation",
    "section": "Geometry of least squares regression",
    "text": "Geometry of least squares regression\n\nTherefore, we have\n\n\\[\n\\mathbf{X}^T(\\mathbf{y} - \\mathbf{Xb}) = \\mathbf{0}\n\\]\nLet’s solve for \\(\\mathbf{b}\\) to get the least squares estimate."
  },
  {
    "objectID": "slides/07-mlr-pt3.html#recap",
    "href": "slides/07-mlr-pt3.html#recap",
    "title": "ANOVA + Geometric interpretation",
    "section": "Recap",
    "text": "Recap\n\nCompared models using Adjusted \\(R^2\\)\nIntroduced the ANOVA table\nUsed a geometric interpretation to find the least squares estimates"
  },
  {
    "objectID": "slides/07-mlr-pt3.html#next-class",
    "href": "slides/07-mlr-pt3.html#next-class",
    "title": "ANOVA + Geometric interpretation",
    "section": "Next class",
    "text": "Next class\n\nInference for regression\nSee Sep 19 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/13-mle.html#announcements",
    "href": "slides/13-mle.html#announcements",
    "title": "Maximum likelihood estimation",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours:\n\nThis week: Thursday - Friday\nNext week: Wednesday - Friday\n\nNo class next Monday or Tuesday\n\n\n\n🍁 Have a good Fall Break! 🍁"
  },
  {
    "objectID": "slides/13-mle.html#topics",
    "href": "slides/13-mle.html#topics",
    "title": "Maximum likelihood estimation",
    "section": "Topics",
    "text": "Topics\n\nLikelihood\nMaximum likelihood estimation\nMLE for linear regression\nProperties of maximum likelihood estimator"
  },
  {
    "objectID": "slides/13-mle.html#motivation",
    "href": "slides/13-mle.html#motivation",
    "title": "Maximum likelihood estimation",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe can find the estimators of \\(\\boldsymbol{\\beta}\\) and \\(\\sigma^2_{\\epsilon}\\) for the model\n\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(0, \\sigma^2_\\epsilon\\mathbf{I})\n\\]using least-squares estimation\n\nWe have also shown some nice properties of the least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\), given \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\) and \\(Var(\\boldsymbol{\\epsilon}) = \\sigma^2_{\\epsilon}\\mathbf{I}\\)\nToday we will introduce another way to find these estimators - maximum likelihood estimation. We will see…\n\nthe maximum likelihood estimators have nice properties\nthe least-squares estimator is equal to the maximum likelihood estimator when certain assumptions hold"
  },
  {
    "objectID": "slides/13-mle.html#example-shooting-free-throws",
    "href": "slides/13-mle.html#example-shooting-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Example: Shooting free throws",
    "text": "Example: Shooting free throws\nSuppose a basketball player shoots a single free throw, such that the probability of making a basket is \\(p\\)\n\n\n\nWhat is the probability distribution for this random phenomenon?\nSuppose the probability is \\(p = 0.5\\)? What is the probability the player makes a single shot, given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.8\\)? What is the probability the player makes a single shot, given this value of \\(p\\)?"
  },
  {
    "objectID": "slides/13-mle.html#shooting-three-free-throws",
    "href": "slides/13-mle.html#shooting-three-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Shooting three free throws",
    "text": "Shooting three free throws\nSuppose the player shoots three free throws. They are all independent and the player has the same probability \\(p\\) of making each shot.\nLet \\(B\\) represent a made basket, and \\(M\\) represent a missed basket. The player shoots three free throws with the outcome \\(BBM\\).\n\n\n\nSuppose the probability is \\(p = 0.5\\)? What is the probability of observing the data \\(BBM\\), given this value of \\(p\\)?\nSuppose the probability is \\(p = 0.3\\)? What is the probability of observing the data \\(BBM\\), given this value of \\(p\\) ?"
  },
  {
    "objectID": "slides/13-mle.html#shooting-three-free-throws-1",
    "href": "slides/13-mle.html#shooting-three-free-throws-1",
    "title": "Maximum likelihood estimation",
    "section": "Shooting three free throws",
    "text": "Shooting three free throws\nSuppose the player shoots three free throws. They are all independent and the player has the same probability \\(p\\) of making each shot.\nThe player shoots three free throws with the outcome \\(BBM\\).\n\n\n\nHow would you describe in words the probabilities we previously calculated?\nNew question: What parameter value of \\(p\\) do you think maximizes the probability of observing this data?\nWe will use a likelihood function to answer this question."
  },
  {
    "objectID": "slides/13-mle.html#likelihood",
    "href": "slides/13-mle.html#likelihood",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood",
    "text": "Likelihood\n\n\nA likelihood is a function that tells us how likely we are to observe our data for a given parameter value (or values). \nNote that this is not the same as the probability function.\nProbability function: Fixed parameter value(s) + input possible outcomes \\(\\Rightarrow\\) probability of seeing the different outcomes given the parameter value(s)\nLikelihood function: Fixed data + input possible parameter values \\(\\Rightarrow\\) probability of seeing the fixed data for each parameter value"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-shooting-three-free-throws",
    "href": "slides/13-mle.html#likelihood-shooting-three-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: shooting three free throws",
    "text": "Likelihood: shooting three free throws\nThe likelihood function for the probability of a basket \\(p\\) given we observed \\(BBM\\) when shooting three independent free throws is \\[\nL(p|BBM) = p \\times p \\times (1 - p)\n\\]\n\n\nThus, if the likelihood for \\(p = 0.8\\) is\n\\[\nL(p = 0.8|BBM) = 0.8 \\times 0.8 \\times (1 - 0.8) = 0.128\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-shooting-three-free-throws-1",
    "href": "slides/13-mle.html#likelihood-shooting-three-free-throws-1",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: shooting three free throws",
    "text": "Likelihood: shooting three free throws\n\nWhat is the general formula for the likelihood function for \\(p\\) given the observed data \\(BBM\\)?\nWhy do we need to assume independence?\nWhy does having identically distributed data simplify things?"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-shooting-three-free-throws-2",
    "href": "slides/13-mle.html#likelihood-shooting-three-free-throws-2",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood: shooting three free throws",
    "text": "Likelihood: shooting three free throws\nThe likelihood function for \\(p\\) given the data \\(BBM\\) is\n\\[\nL(p|BBM) = p \\times p \\times (1 - p) = p^2 \\times (1 - p)\n\\]\n\n\n\nWe want of the value of \\(p\\) that maximizes this likelihood function, i.e., the value of \\(p\\) that is most likely given the observed data.\nThe process of finding this value is maximum likelihood estimation.\nThere are three primary ways to find the maximum likelihood estimator\n\nApproximate using a graph\nUsing calculus\nNumerical approximation"
  },
  {
    "objectID": "slides/13-mle.html#finding-the-mle-using-graphs",
    "href": "slides/13-mle.html#finding-the-mle-using-graphs",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using graphs",
    "text": "Finding the MLE using graphs\n\n\nWhat do you think is the approximate value of the MLE of \\(p\\) given the data?"
  },
  {
    "objectID": "slides/13-mle.html#finding-the-mle-using-calculus",
    "href": "slides/13-mle.html#finding-the-mle-using-calculus",
    "title": "Maximum likelihood estimation",
    "section": "Finding the MLE using calculus",
    "text": "Finding the MLE using calculus\n\nFind the MLE using the first derivative of the likelihood function.\n\n\n\nThis can be tricky because of the Product Rule, so we can maximize the log(Likelihood) instead. The same value maximizes the likelihood and log(Likelihood).\n\n\nUse calculus to find the MLE of \\(p\\) given the data \\(BBM\\)."
  },
  {
    "objectID": "slides/13-mle.html#shooting-n-free-throws",
    "href": "slides/13-mle.html#shooting-n-free-throws",
    "title": "Maximum likelihood estimation",
    "section": "Shooting \\(n\\) free throws",
    "text": "Shooting \\(n\\) free throws\nSuppose the player shoots \\(n\\) free throws. They are all independent and the player has the same probability \\(p\\) of making each shot.\nSuppose the player makes \\(k\\) baskets out of the \\(n\\) free throws. This is the observed data.\n\n\n\nWhat is the formula for the probability distribution to describe this random phenomenon?\n\n\n\nWhat is the formula for the likelihood function for \\(p\\) given the observed data?\nFor what value of \\(p\\) do we maximize the likelihood given the observed data? Use calculus to find the response."
  },
  {
    "objectID": "slides/13-mle.html#why-maximum-likelihood-estimation",
    "href": "slides/13-mle.html#why-maximum-likelihood-estimation",
    "title": "Maximum likelihood estimation",
    "section": "Why maximum likelihood estimation?",
    "text": "Why maximum likelihood estimation?\n\n“Maximum likelihood estimation is, by far, the most popular technique for deriving estimators.” (Casella and Berger 2024, 315)\nMLEs have nice statistical properties. They are\n\nConsistent\nEfficient - Have the smallest MSE among all consistent estimators\nAsymptotically normal\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf the normality assumption holds, the least squares estimator is the maximum likelihood estimator for \\(\\beta\\). Therefore, it has all these properties of the MLE."
  },
  {
    "objectID": "slides/13-mle.html#linear-regression",
    "href": "slides/13-mle.html#linear-regression",
    "title": "Maximum likelihood estimation",
    "section": "Linear regression",
    "text": "Linear regression\nRecall the linear model\n\\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}, \\hspace{10mm} \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2_{\\epsilon}\\mathbf{I})\n\\]\n\n\n\nWe have discussed least-squares estimation to find \\(\\hat{\\boldsymbol{\\beta}}\\) and \\(\\hat{\\sigma}_\\epsilon^2\\)\nWe have discussed properties of \\(\\hat{\\boldsymbol{\\beta}}\\) that depend on \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\) and \\(Var(\\boldsymbol{\\epsilon}) = \\sigma^2_{\\epsilon}\\mathbf{I}\\)\nWe have used the fact that \\(\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1})\\) when doing hypothesis testing and confidence intervals.\nNow we will discuss how we know \\(\\hat{\\boldsymbol{\\beta}}\\) is normally distributed, as we introduce MLE for linear regression"
  },
  {
    "objectID": "slides/13-mle.html#simple-linear-regression-model",
    "href": "slides/13-mle.html#simple-linear-regression-model",
    "title": "Maximum likelihood estimation",
    "section": "Simple linear regression model",
    "text": "Simple linear regression model\nSuppose we have the simple linear regression (SLR) model\n\\[\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i, \\hspace{10mm} \\epsilon_i \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nsuch that \\(\\epsilon_i\\) are independently and identically distributed.\n\n\nWe can write this model in the form below and use this to find the MLE\n\\[\ny_i | x_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma^2_{\\epsilon})\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#side-note-normal-distribution",
    "href": "slides/13-mle.html#side-note-normal-distribution",
    "title": "Maximum likelihood estimation",
    "section": "Side note: Normal distribution",
    "text": "Side note: Normal distribution\nLet \\(X\\) be a random variable, such that \\(X \\sim N(\\mu, \\sigma^2)\\). Then the probability function is\n\\[\nP(X = x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\Big\\{-{\\frac{1}{2\\sigma^2}(x - \\mu)^2}\\Big\\}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#likelihood-for-slr",
    "href": "slides/13-mle.html#likelihood-for-slr",
    "title": "Maximum likelihood estimation",
    "section": "Likelihood for SLR",
    "text": "Likelihood for SLR\nThe likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\nL&(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n) \\\\[5pt]\n&= \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma_\n\\epsilon^2}}\\exp\\Big\\{{-\\frac{1}{2\\sigma_\\epsilon^2}(y_i - [\\beta_0 + \\beta_1x_i])^2}\\Big\\} \\\\[10pt]\n& = (2\\pi\\sigma^2_{\\epsilon})^{-\\frac{n}{2}}\\exp\\Big\\{-\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\\Big\\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#log-likelihood-for-slr",
    "href": "slides/13-mle.html#log-likelihood-for-slr",
    "title": "Maximum likelihood estimation",
    "section": "Log-likelihood for SLR",
    "text": "Log-likelihood for SLR\nThe log-likelihood function for \\(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon}\\) is\n\\[\n\\begin{aligned}\n\\log &L(\\beta_0, \\beta_1, \\sigma^2_{\\epsilon} | x_i, \\dots, x_n, y_i, \\dots, y_n)\n  \\\\[8pt]\n& = -\\frac{n}{2}\\log(2\\pi\\sigma^2_{\\epsilon}) -\\frac{1}{2\\sigma^2_{\\epsilon}}\\sum_{i=1}^n(y_i - \\beta_0 - \\beta_1x_i)^2\n\\end{aligned}\n\\]\n\n\nWe will use the log-likelihood function to find the MLEs"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_0",
    "href": "slides/13-mle.html#mle-for-beta_0",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n1️⃣ Take derivative of \\(\\log L\\) with respect to \\(\\beta_0\\) and set it equal to 0\n\\[\n\\frac{\\partial \\log L}{\\partial \\beta_0} = -\\frac{2}{2\\sigma^2_\\epsilon}\\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1x_i)(-1) = 0\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_0-1",
    "href": "slides/13-mle.html#mle-for-beta_0-1",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n2️⃣ Find the \\(\\tilde{\\beta}_0\\) that satisfies the equality on the previous slide\n\nAfter a few steps…\n\\[\n\\begin{aligned}\n&\\Rightarrow \\sum_{i=1}^ny_i - n\\tilde{\\beta}_0 - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = 0 \\\\\n&\\Rightarrow \\sum_{i=1}^ny_i  - \\tilde{\\beta}_1\\sum_{i=1}^n x_i = n\\tilde{\\beta}_0 \\\\\n&\\Rightarrow \\frac{1}{n}\\sum_{i=1}^ny_i  - \\frac{1}{n}\\tilde{\\beta}_1\\sum_{i=1}^n x_i = \\tilde{\\beta}_0\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_0-2",
    "href": "slides/13-mle.html#mle-for-beta_0-2",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_0\\)",
    "text": "MLE for \\(\\beta_0\\)\n3️⃣ We can use the second derivative to show we’ve found the maximum\n\\[\n\\frac{\\partial^2 \\log L}{\\partial \\beta_0^2} = -\\frac{n}{2\\tilde{\\sigma}^2_\\epsilon}  &lt; 0\n\\]\n\n\nTherefore, we have found the maximum. Thus, MLE for \\(\\beta_0\\) is\n\\[\n\\tilde{\\beta}_0 = \\bar{y} - \\tilde{\\beta}_1\\bar{x}\n\\]\n$$$$"
  },
  {
    "objectID": "slides/13-mle.html#mle-for-beta_1-and-sigma2_epsilon",
    "href": "slides/13-mle.html#mle-for-beta_1-and-sigma2_epsilon",
    "title": "Maximum likelihood estimation",
    "section": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)",
    "text": "MLE for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\nWe can use a similar process to find the MLEs for \\(\\beta_1\\) and \\(\\sigma^2_{\\epsilon}\\)\n\\[\n\\tilde{\\beta}_1 = \\frac{\\sum_{i=1}^n y_i(x_i - \\bar{x})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\n\\]\n\n\\[\n\\tilde{\\sigma}^2_{\\epsilon} = \\frac{\\sum_{i=1}^n(y_i - \\tilde{\\beta}_0 - \\tilde{\\beta}_1x_i)^2}{n} = \\frac{\\sum_{i=1}^ne_i^2}{n}\n\\]"
  },
  {
    "objectID": "slides/13-mle.html#putting-it-all-together",
    "href": "slides/13-mle.html#putting-it-all-together",
    "title": "Maximum likelihood estimation",
    "section": "Putting it all together",
    "text": "Putting it all together\n\n\nThe MLEs \\(\\tilde{\\beta}_0\\) and \\(\\tilde{\\beta}_1\\) are equivalent to the least-squares estimators, when the errors follow independent and identical normal distributions\nThis means the least-squares estimators \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) and inherit all the nice properties of MLEs\n\nConsistency\nEfficiency - minimum variance among all consistent estimators\nAsymptotically normal"
  },
  {
    "objectID": "slides/13-mle.html#putting-it-all-together-1",
    "href": "slides/13-mle.html#putting-it-all-together-1",
    "title": "Maximum likelihood estimation",
    "section": "Putting it all together",
    "text": "Putting it all together\n\nFrom previous work, we also know estimators \\(\\tilde{\\beta}_0\\) and \\(\\tilde{\\beta}_1\\) are unbiased\nNote that the MLE \\(\\tilde{\\sigma}^2_{\\epsilon}\\) is asymptotically unbiased\n\nThe estimate from least-squares \\(\\hat{\\sigma}_{\\epsilon}^2\\) is unbiased"
  },
  {
    "objectID": "slides/13-mle.html#references",
    "href": "slides/13-mle.html#references",
    "title": "Maximum likelihood estimation",
    "section": "References",
    "text": "References\n\n\n\n\n🔗 STA 221 - Fall 2024\n\n\n\n\nCasella, George, and Roger Berger. 2024. Statistical Inference. CRC Press."
  },
  {
    "objectID": "slides/04-slr-matrix.html#topics",
    "href": "slides/04-slr-matrix.html#topics",
    "title": "SLR: Matrix representation",
    "section": "Topics",
    "text": "Topics\n\nMatrix representation for simple linear regression\n\nModel form\nLeast square estimate\nPredicted (fitted) values\nResiduals\n\nMatrix representation in R"
  },
  {
    "objectID": "slides/04-slr-matrix.html#slr-statistical-model-population",
    "href": "slides/04-slr-matrix.html#slr-statistical-model-population",
    "title": "SLR: Matrix representation",
    "section": "SLR: Statistical model (population)",
    "text": "SLR: Statistical model (population)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[\\large{Y = \\mathbf{\\beta_0 + \\beta_1 X} + \\epsilon}, \\hspace{8mm} \\epsilon \\sim N(0, \\sigma_{\\epsilon}^2)\\]\n\n\n\\(\\beta_1\\): Population (true) slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): Population (true) intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error"
  },
  {
    "objectID": "slides/04-slr-matrix.html#slr-in-matrix-form",
    "href": "slides/04-slr-matrix.html#slr-in-matrix-form",
    "title": "SLR: Matrix representation",
    "section": "SLR in matrix form",
    "text": "SLR in matrix form\nSuppose we have \\(n\\) observations.\n\\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_1 \\\\\n\\vdots &  \\vdots \\\\\n1 &  x_n\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), and \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/04-slr-matrix.html#sum-of-squared-residuals",
    "href": "slides/04-slr-matrix.html#sum-of-squared-residuals",
    "title": "SLR: Matrix representation",
    "section": "Sum of squared residuals",
    "text": "Sum of squared residuals\nWe use the sum of squared residuals (also called “sum of squared error”) to find the least squares line:\n\\[\nSSR = \\sum_{i=1}^ne_i^2 = \\mathbf{e}^T\\mathbf{e} = (\\mathbf{y} - \\hat{\\mathbf{y}})^T(\\mathbf{y} - \\hat{\\mathbf{y}})\n\\]\n\n\n\nWhat is the dimension of SSR?\nWhat is \\(\\hat{\\mathbf{y}}\\) in terms of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), and/or \\(\\boldsymbol{\\beta}\\) ?"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-1",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-1",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-2",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-2",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-3",
    "href": "slides/04-slr-matrix.html#minimize-sum-of-squared-residuals-3",
    "title": "SLR: Matrix representation",
    "section": "Minimize sum of squared residuals",
    "text": "Minimize sum of squared residuals\nWe want to find values of \\(\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) that minimize the sum of squared residuals \\[\n\\begin{aligned}\n\\mathbf{e}^T\\mathbf{e} &= (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\\\[10pt]\n&= (\\mathbf{y}^T - \\boldsymbol{\\beta}^T\\mathbf{X}^T)(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - \\mathbf{y}^T\\mathbf{X}\\boldsymbol{\\beta} - \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\\\\[10pt]\n&=\\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#least-squares-estimators",
    "href": "slides/04-slr-matrix.html#least-squares-estimators",
    "title": "SLR: Matrix representation",
    "section": "Least squares estimators",
    "text": "Least squares estimators\n\\[\nSSR = \\mathbf{e}^T\\mathbf{e} =\\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{y} + \\boldsymbol{\\beta}^T\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}\n\\]\n\n\nThe least squares estimators must satisfy\n\\[\n\\nabla_{\\boldsymbol{\\beta}} SSR = -2\\mathbf{X}^T\\mathbf{y} + 2\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = 0\n\\]\n\n\n\n\\[\n\\color{#993399}{\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#did-we-find-a-minimum",
    "href": "slides/04-slr-matrix.html#did-we-find-a-minimum",
    "title": "SLR: Matrix representation",
    "section": "Did we find a minimum?",
    "text": "Did we find a minimum?\n\\[\n\\nabla^2_{\\beta} SSR \\propto  2\\mathbf{X}^T\\mathbf{X} = 0\n\\]\n\n\n\\(\\mathbf{X}\\) is full rank \\(\\Rightarrow\\) \\(\\mathbf{X}^T\\mathbf{X}\\) is positive definite\nTherefore we have found the minimizing point"
  },
  {
    "objectID": "slides/04-slr-matrix.html#obtain-mathbfy-vector",
    "href": "slides/04-slr-matrix.html#obtain-mathbfy-vector",
    "title": "SLR: Matrix representation",
    "section": "Obtain \\(\\mathbf{y}\\) vector",
    "text": "Obtain \\(\\mathbf{y}\\) vector\nLet’s go back to the Duke Forest data. We want to use the matrix representation to fit a model of the form:\n\\[\nprice = \\beta_0 + \\beta_1 ~ area + \\epsilon, \\hspace{5mm} \\epsilon \\sim N(0, \\sigma^2_\\epsilon)\n\\]\n\nGet \\(\\mathbf{y}\\), the vector of responses\n\ny &lt;- duke_forest$price\n\n\n\n\nLet’s look at the first 10 observations of \\(y\\)\n\ny[1:10]\n\n [1] 1520000 1030000  420000  680000  428500  456000 1270000  557450  697500\n[10]  650000"
  },
  {
    "objectID": "slides/04-slr-matrix.html#obtain-mathbfx-matrix",
    "href": "slides/04-slr-matrix.html#obtain-mathbfx-matrix",
    "title": "SLR: Matrix representation",
    "section": "Obtain \\(\\mathbf{X}\\) matrix",
    "text": "Obtain \\(\\mathbf{X}\\) matrix\nUse the model.matrix() function to get \\(\\mathbf{X}\\)\n\nX &lt;- model.matrix(price ~ area, data = duke_forest)\n\n\n\nLet’s look at the first 10 rows of \\(\\mathbf{X}\\)\n\nX[1:10,]\n\n   (Intercept) area\n1            1 6040\n2            1 4475\n3            1 1745\n4            1 2091\n5            1 1772\n6            1 1950\n7            1 3909\n8            1 2841\n9            1 3924\n10           1 2173"
  },
  {
    "objectID": "slides/04-slr-matrix.html#calculate-hatboldsymbolbeta",
    "href": "slides/04-slr-matrix.html#calculate-hatboldsymbolbeta",
    "title": "SLR: Matrix representation",
    "section": "Calculate \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Calculate \\(\\hat{\\boldsymbol{\\beta}}\\)\nMatrix functions in R. Let \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) be matrices\n\nt(A): transpose \\(\\mathbf{A}\\)\nsolve(A): inverse of \\(\\mathbf{A}\\)\nA %*% B: multiply \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\)\n\n\nNow let’s calculate \\(\\hat{\\boldsymbol{\\beta}}\\)\n\nbeta_hat &lt;- solve(t(X)%*%X)%*%t(X)%*%y\nbeta_hat\n\n                   [,1]\n(Intercept) 116652.3251\narea           159.4833"
  },
  {
    "objectID": "slides/04-slr-matrix.html#compare-to-result-from-lm",
    "href": "slides/04-slr-matrix.html#compare-to-result-from-lm",
    "title": "SLR: Matrix representation",
    "section": "Compare to result from lm",
    "text": "Compare to result from lm\n\nduke_forest_model &lt;- lm(price ~ area, data = duke_forest)\ntidy(duke_forest_model) |&gt; kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000\n\n\n\n\n\n\n\n\nbeta_hat \n\n                   [,1]\n(Intercept) 116652.3251\narea           159.4833"
  },
  {
    "objectID": "slides/04-slr-matrix.html#predicted-fitted-values",
    "href": "slides/04-slr-matrix.html#predicted-fitted-values",
    "title": "SLR: Matrix representation",
    "section": "Predicted (fitted) values",
    "text": "Predicted (fitted) values\nNow that we have \\(\\hat{\\boldsymbol{\\beta}}\\), let’s predict values of \\(\\mathbf{y}\\) using the model\n\\[\n\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\underbrace{\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T}_{\\mathbf{H}}\\mathbf{y} = \\mathbf{H}\\mathbf{y}\n\\]\n\nHat matrix: \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\)\n\n\\(\\mathbf{H}\\) is an \\(n\\times n\\) matrix\nMaps vector of observed values \\(\\mathbf{y}\\) to a vector of fitted values \\(\\hat{\\mathbf{y}}\\)"
  },
  {
    "objectID": "slides/04-slr-matrix.html#residuals",
    "href": "slides/04-slr-matrix.html#residuals",
    "title": "SLR: Matrix representation",
    "section": "Residuals",
    "text": "Residuals\nRecall that the residuals are the difference between the observed and predicted values\n\\[\n\\begin{aligned}\n\\mathbf{e} &= \\mathbf{y} - \\hat{\\mathbf{y}}\\\\[10pt]\n& = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}} \\\\[10pt]\n& = \\mathbf{y} - \\mathbf{H}\\mathbf{y} \\\\[10pt]\n& = (\\mathbf{I} - \\mathbf{H})\\mathbf{y}\n\\end{aligned}\n\\]\n\n\\[\n\\color{#993399}{\\mathbf{e} = (\\mathbf{I} - \\mathbf{H})\\mathbf{y}}\n\\]"
  },
  {
    "objectID": "slides/04-slr-matrix.html#recap",
    "href": "slides/04-slr-matrix.html#recap",
    "title": "SLR: Matrix representation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced matrix representation for simple linear regression\n\nModel from\nLeast square estimate\nPredicted (fitted) values\nResiduals\n\nUsed R for matrix calculations"
  },
  {
    "objectID": "slides/04-slr-matrix.html#next-class",
    "href": "slides/04-slr-matrix.html#next-class",
    "title": "SLR: Matrix representation",
    "section": "Next class",
    "text": "Next class\n\nMultiple linear regression\nSee Sep 10 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#announcements",
    "href": "slides/03-slr-model-assessment.html#announcements",
    "title": "SLR: Model Assessment",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours start this week. See schedule on Overview page of the course website or on Canvas."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#topics",
    "href": "slides/03-slr-model-assessment.html#topics",
    "title": "SLR: Model Assessment",
    "section": "Topics",
    "text": "Topics\n\nUse R to conduct exploratory data analysis and fit a model\nEvaluate models using RMSE and \\(R^2\\)\nUse analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#computing-set-up",
    "href": "slides/03-slr-model-assessment.html#computing-set-up",
    "title": "SLR: Model Assessment",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling (includes broom, yardstick, and other packages)\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#data-houses-in-duke-forest",
    "href": "slides/03-slr-model-assessment.html#data-houses-in-duke-forest",
    "title": "SLR: Model Assessment",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#clone-repo-start-new-rstudio-project",
    "href": "slides/03-slr-model-assessment.html#clone-repo-start-new-rstudio-project",
    "title": "SLR: Model Assessment",
    "section": "Clone repo + Start new RStudio project",
    "text": "Clone repo + Start new RStudio project\n\nGo to the course organization. Click on the repo with the prefix ae-01. It contains the starter documents you need to complete the AE.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File → New Project → Version Control → Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick ae-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the AE."
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#two-statistics",
    "href": "slides/03-slr-model-assessment.html#two-statistics",
    "title": "SLR: Model Assessment",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n\n\nWhat indicates a good model fit? Higher or lower RMSE? Higher or lower \\(R^2\\)?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#rmse",
    "href": "slides/03-slr-model-assessment.html#rmse",
    "title": "SLR: Model Assessment",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#analysis-of-variance-anova",
    "href": "slides/03-slr-model-assessment.html#analysis-of-variance-anova",
    "title": "SLR: Model Assessment",
    "section": "ANOVA",
    "text": "ANOVA\nAnalysis of Variance (ANOVA): Technique to partition variability in \\(Y\\) by the sources of variability"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#total-variability-response",
    "href": "slides/03-slr-model-assessment.html#total-variability-response",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\n\n\n\n\nMin\nMedian\nMax\nMean\nStd.Dev\n\n\n\n\n95000\n540000\n1520000\n559898.7\n225448.1"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#partition-sources-of-variability-in-price",
    "href": "slides/03-slr-model-assessment.html#partition-sources-of-variability-in-price",
    "title": "SLR: Model Assessment",
    "section": "Partition sources of variability in price",
    "text": "Partition sources of variability in price"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#total-variability-response-1",
    "href": "slides/03-slr-model-assessment.html#total-variability-response-1",
    "title": "SLR: Model Assessment",
    "section": "Total variability (Response)",
    "text": "Total variability (Response)\n\n\\[\\text{Sum of Squares Total (SST)} = \\sum_{i=1}^n(y_i - \\bar{y})^2 = (n-1)s_y^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#explained-variability-model",
    "href": "slides/03-slr-model-assessment.html#explained-variability-model",
    "title": "SLR: Model Assessment",
    "section": "Explained variability (Model)",
    "text": "Explained variability (Model)\n\n\\[\\text{Sum of Squares Model (SSM)} = \\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#unexplained-variability-residuals",
    "href": "slides/03-slr-model-assessment.html#unexplained-variability-residuals",
    "title": "SLR: Model Assessment",
    "section": "Unexplained variability (Residuals)",
    "text": "Unexplained variability (Residuals)\n\n\\[\\text{Sum of Squares Residuals (SSR)} = \\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#sum-of-squares",
    "href": "slides/03-slr-model-assessment.html#sum-of-squares",
    "title": "SLR: Model Assessment",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#r2",
    "href": "slides/03-slr-model-assessment.html#r2",
    "title": "SLR: Model Assessment",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\\large{R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}}\\]\n\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#interpreting-r2",
    "href": "slides/03-slr-model-assessment.html#interpreting-r2",
    "title": "SLR: Model Assessment",
    "section": "Interpreting $R^2$",
    "text": "Interpreting $R^2$\n\nQuestionSubmit\n\n\n\nSubmit your response to the following question on Ed Discussion.\n\nThe \\(R^2\\) of the model for price from area of houses in Duke Forest is 44.5%. Which of the following is the correct interpretation of this value?\n\nArea correctly predicts 44.5% of price for houses in Duke Forest.\n44.5% of the variability in price for houses in Duke Forest can be explained by area.\n44.5% of the variability in area for houses in Duke Forest can be explained by price.\n44.5% of the time price for houses in Duke Forest can be predicted by area.\n\nDo you think this model is useful for explaining variability in the price of Duke Forest houses?\n\n\n\n\n\n\n\n\n🔗 https://edstem.org/us/courses/62513/discussion/629888"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#augmented-data-frame",
    "href": "slides/03-slr-model-assessment.html#augmented-data-frame",
    "title": "SLR: Model Assessment",
    "section": "Augmented data frame",
    "text": "Augmented data frame\nUse the augment() function from the broom package to add columns for predicted values, residuals, and other observation-level model statistics\n\n\nduke_forest_aug &lt;- augment(duke_forest_fit)\nduke_forest_aug\n\n# A tibble: 98 × 8\n     price  area  .fitted  .resid   .hat  .sigma   .cooksd .std.resid\n     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 1520000  6040 1079931. 440069. 0.133  162605. 0.604         2.80  \n 2 1030000  4475  830340. 199660. 0.0435 168386. 0.0333        1.21  \n 3  420000  1745  394951.  25049. 0.0226 169664. 0.000260      0.150 \n 4  680000  2091  450132. 229868. 0.0157 168011. 0.0150        1.37  \n 5  428500  1772  399257.  29243. 0.0220 169657. 0.000345      0.175 \n 6  456000  1950  427645.  28355. 0.0182 169659. 0.000266      0.170 \n 7 1270000  3909  740072. 529928. 0.0250 160502. 0.130         3.18  \n 8  557450  2841  569744. -12294. 0.0102 169679. 0.0000277    -0.0732\n 9  697500  3924  742465. -44965. 0.0254 169620. 0.000948     -0.270 \n10  650000  2173  463209. 186791. 0.0145 168582. 0.00912       1.11  \n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#finding-rmse-in-r",
    "href": "slides/03-slr-model-assessment.html#finding-rmse-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     167067.\n\n\n\n\nDo you think this model is useful for predicting the price of Duke Forest houses?"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#finding-r2-in-r",
    "href": "slides/03-slr-model-assessment.html#finding-r2-in-r",
    "title": "SLR: Model Assessment",
    "section": "Finding \\(R^2\\) in R",
    "text": "Finding \\(R^2\\) in R\nUse the rsq() function from the yardstick package (part of tidymodels)\n\nrsq(duke_forest_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.445\n\n\n\n\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(duke_forest_fit)$r.squared\n\n[1] 0.4451945"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#recap",
    "href": "slides/03-slr-model-assessment.html#recap",
    "title": "SLR: Model Assessment",
    "section": "Recap",
    "text": "Recap\n\nUsed R to conduct exploratory data analysis and fit a model\nEvaluated models using RMSE and \\(R^2\\)\nUsed analysis of variance to partition variability in the response variable"
  },
  {
    "objectID": "slides/03-slr-model-assessment.html#next-class",
    "href": "slides/03-slr-model-assessment.html#next-class",
    "title": "SLR: Model Assessment",
    "section": "Next class",
    "text": "Next class\n\nMatrix representation of simple linear regression\n\nSee Sep 5 prepare\n\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/05-mlr.html#topics",
    "href": "slides/05-mlr.html#topics",
    "title": "Multiple linear regression (MLR)",
    "section": "Topics",
    "text": "Topics\n\nExploratory data analysis for multiple linear regression\nFitting the least squares line\nInterpreting coefficients for quantitative predictors\nPrediction"
  },
  {
    "objectID": "slides/05-mlr.html#computing-setup",
    "href": "slides/05-mlr.html#computing-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/05-mlr.html#data-peer-to-peer-lender",
    "href": "slides/05-mlr.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income debt_to_income verified_income interest_rate\n           &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1         59000         0.558  Not Verified            10.9 \n 2         60000         1.31   Not Verified             9.92\n 3         75000         1.06   Verified                26.3 \n 4         75000         0.574  Not Verified             9.92\n 5        254000         0.238  Not Verified             9.43\n 6         67000         1.08   Source Verified          9.92\n 7         28800         0.0997 Source Verified         17.1 \n 8         80000         0.351  Not Verified             6.08\n 9         34000         0.698  Not Verified             7.97\n10         80000         0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/05-mlr.html#variables",
    "href": "slides/05-mlr.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income: Annual income\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nOutcome: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/05-mlr.html#outcome-interest_rate",
    "href": "slides/05-mlr.html#outcome-interest_rate",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome: interest_rate",
    "text": "Outcome: interest_rate\n\n\n\n\n\n\nMin\nMedian\nMax\nIQR\n\n\n\n\n5.31\n9.93\n26.3\n5.755"
  },
  {
    "objectID": "slides/05-mlr.html#predictors",
    "href": "slides/05-mlr.html#predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/05-mlr.html#data-manipulation-1-rescale-income",
    "href": "slides/05-mlr.html#data-manipulation-1-rescale-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 1: Rescale income",
    "text": "Data manipulation 1: Rescale income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(annual_income_th = annual_income / 1000)\n\n\n\n\nWhy did we rescale income?"
  },
  {
    "objectID": "slides/05-mlr.html#outcome-vs.-predictors",
    "href": "slides/05-mlr.html#outcome-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome vs. predictors",
    "text": "Outcome vs. predictors\n\n\nGoal: Use these predictors in a single model to understand variability in interest rate.\n\n\n\nWhy do we want to use a single model versus 3 separate simple linear regression models?"
  },
  {
    "objectID": "slides/05-mlr.html#multiple-linear-regression-mlr",
    "href": "slides/05-mlr.html#multiple-linear-regression-mlr",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\text{interest_rate} ~ =\n\\beta_0 & + \\beta_1 ~ \\text{debt_to_income} \\\\ & + \\beta_2 ~ \\text{verified_income} \\\\ &+ \\beta_3~ \\text{annual_income_th} \\\\\n& +\\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/05-mlr.html#multiple-linear-regression-1",
    "href": "slides/05-mlr.html#multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nRecall: The simple linear regression model\n\\[\nY = \\beta_0 + \\beta_1~ X + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\nThe form of the multiple linear regression model is\n\\[\nY = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\n\n\nTherefore,\n\\[\nE(Y|X_1, \\ldots, X_p) = \\beta_0 + \\beta_1X_1 +  \\dots + \\beta_pX_p\n\\]"
  },
  {
    "objectID": "slides/05-mlr.html#fitting-the-least-squares-line",
    "href": "slides/05-mlr.html#fitting-the-least-squares-line",
    "title": "Multiple linear regression (MLR)",
    "section": "Fitting the least squares line",
    "text": "Fitting the least squares line\nSimilar to simple linear regression, we want to find estimates for \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) that minimize\n\\[\n\\sum_{i=1}^{n}e_i^2 = \\sum_{i=1}^n[y_i - \\hat{y}_i]^2 = \\sum_{i=1}^n[y_i - (\\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_px_{ip})]^2\n\\]\n\n\nThe calculations can be very tedious, especially if \\(p\\) is large"
  },
  {
    "objectID": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression",
    "href": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nSuppose we have \\(n\\) observations, a quantitative response variable, and \\(p\\) &gt; 1 predictors \\[\n\\underbrace{\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} }_\n{\\mathbf{y}} \\hspace{3mm}\n=\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n1 &x_{11} & \\dots & x_{1p}\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n1 &  x_{n1} & \\dots &x_{np}\n\\end{bmatrix}\n}_{\\mathbf{X}}\n\\hspace{2mm}\n\\underbrace{\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix}\n}_{\\boldsymbol{\\beta}}\n\\hspace{3mm}\n+\n\\hspace{3mm}\n\\underbrace{\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots\\\\\n\\epsilon_n\n\\end{bmatrix}\n}_\\boldsymbol{\\epsilon}\n\\]\n\nWhat are the dimensions of \\(\\mathbf{y}\\), \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\epsilon}\\)?"
  },
  {
    "objectID": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression-1",
    "href": "slides/05-mlr.html#matrix-form-of-multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Matrix form of multiple linear regression",
    "text": "Matrix form of multiple linear regression\nAs with simple linear regression, we have\n\\[\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nGeneralizing the derivations from SLR to \\(p &gt; 2\\), we have\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n\\]\nas before."
  },
  {
    "objectID": "slides/05-mlr.html#model-fit-in-r",
    "href": "slides/05-mlr.html#model-fit-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit in R",
    "text": "Model fit in R\n\nint_fit &lt;- lm(interest_rate ~ debt_to_income + verified_income  + annual_income_th,\n              data = loan50)\n\ntidy(int_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/05-mlr.html#model-equation",
    "href": "slides/05-mlr.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\hat{\\text{interest_rate}} =  10.726 &+0.671 \\times \\text{debt_to_income}\\\\\n&+ 2.211 \\times \\text{source_verified}\\\\  \n&+ 6.880 \\times \\text{verified}\\\\\n& -0.021 \\times \\text{annual_income_th}\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\nWe will talk about why there are two terms in the model for verified_income soon!"
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_j",
    "href": "slides/05-mlr.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n\n\nExample: The estimated coefficient for debt_to_income is 0.671. This means for each point in an borrower’s debt to income ratio, the interest rate on the loan is expected to be greater by 0.671%, holding annual income and income verification constant."
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_j-1",
    "href": "slides/05-mlr.html#interpreting-hatbeta_j-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient for annual_income_th is -0.021. Interpret this coefficient in the context of the data.\n\n\n\n\nWhy do we need to include a statement about holding all other predictors constant?"
  },
  {
    "objectID": "slides/05-mlr.html#interpreting-hatbeta_0",
    "href": "slides/05-mlr.html#interpreting-hatbeta_0",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_0\\)",
    "text": "Interpreting \\(\\hat{\\beta}_0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\nDescribe the subset of borrowers who are expected to get an interest rate of 10.726% based on our model. Is this interpretation meaningful? Why or why not?"
  },
  {
    "objectID": "slides/05-mlr.html#prediction",
    "href": "slides/05-mlr.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted interest rate for an borrower with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000?\n\n\n\n10.726 + 0.671 * 0.558 + 2.211 * 0 + 6.880 * 0 - 0.021 * 59\n\n[1] 9.861418\n\n\n\nThe predicted interest rate for an borrower with with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000 is 9.86%."
  },
  {
    "objectID": "slides/05-mlr.html#prediction-in-r",
    "href": "slides/05-mlr.html#prediction-in-r",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction in R",
    "text": "Prediction in R\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_borrower &lt;- tibble(\n  debt_to_income  = 0.558, \n  verified_income = \"Not Verified\", \n  annual_income_th = 59\n)\n\npredict(int_fit, new_borrower)\n\n       1 \n9.890888 \n\n\n\n\n\n\n\n\nNote\n\n\nDifference in predicted value due to rounding the coefficients on the previous slide."
  },
  {
    "objectID": "slides/05-mlr.html#cautions",
    "href": "slides/05-mlr.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/05-mlr.html#recap",
    "href": "slides/05-mlr.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nShowed exploratory data analysis for multiple linear regression\nUsed least squares to fit the regression line\nInterpreted the coefficients for quantitative predictors\nPredicted the response for new observations"
  },
  {
    "objectID": "slides/05-mlr.html#next-class",
    "href": "slides/05-mlr.html#next-class",
    "title": "Multiple linear regression (MLR)",
    "section": "Next class",
    "text": "Next class\n\nMore on multiple linear regression\n\nCategorical predictors\nModel assessment\nGeometric interpretation (as time permits)\n\nSee Sep 12 prepare\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#announcements",
    "href": "slides/11-prop-of-estimators-pt2.html#announcements",
    "title": "Properties of estimators",
    "section": "Announcements",
    "text": "Announcements\n\nProject Proposal due Thursday, October 3 at 11:59pm\nLab 03 due Thursday, October 3 at 11:59pm\nHW 02 due Thursday, October 3 at 11:59pm (released after class)\nExam 01: Tuesday, October 8 (in class + take-home)\n\nLecture recordings available until the start of the in-class exam (Link on side bar of webpage)\nExam review on Thursday\nMonday’s lab: Exam office hours\nNo office hours while take-home exam is out"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#topics",
    "href": "slides/11-prop-of-estimators-pt2.html#topics",
    "title": "Properties of estimators",
    "section": "Topics",
    "text": "Topics\n\nProperties of the least squares estimator\n\n\n\n\n\n\n\nNote\n\n\nThis is not a mathematical statistics class. There are semester-long courses that will go into these topics in much more detail; we will barely scratch the surface in this course.\nOur goals are to understand\n\nEstimators have properties\nA few properties of the least squares estimator and why they are useful"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#motivation",
    "href": "slides/11-prop-of-estimators-pt2.html#motivation",
    "title": "Properties of estimators",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe have discussed how to use least squares to find an estimator of \\(\\hat{\\boldsymbol{\\beta}}\\)\nHow do we know whether our least-squares estimator is a “good” estimator?\nWhen we consider what makes an estimator “good”, we’ll look at three criteria:\n\nBias\nVariance\nMean squared error\n\nWe’ll take a look at these and motivate why we might prefer using least squares to compute \\(\\hat{\\boldsymbol{\\beta}}\\) versus other methods"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#bias-and-variance",
    "href": "slides/11-prop-of-estimators-pt2.html#bias-and-variance",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\nSuppose you are throwing darts at a target\n\n\n\n\n\n\nImage source: Analytics Vidhya\n\n\n\n\nIdeal scenario: Darts are clustered around the target (unbiased and low variance)\nWorst case scenario: Darts are widely spread out and systematically far from the target (high bias and high variance)\nAcceptable scenario: There’s some trade-off between the bias and variance."
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-1",
    "href": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator\nBest Linear Unbiased Estimator (BLUE)\n\n\nInfinite sample ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator",
    "href": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator",
    "title": "Properties of estimators",
    "section": "Unbiased estimator",
    "text": "Unbiased estimator\nThe bias of an estimator is the difference between the estimator’s expected value and the true value of the parameter\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\nBias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\]\nAn estimator is unbiased if the bias is 0 and thus \\(E(\\hat{\\theta}) = \\theta\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator-1",
    "href": "slides/11-prop-of-estimators-pt2.html#unbiased-estimator-1",
    "title": "Properties of estimators",
    "section": "Unbiased estimator",
    "text": "Unbiased estimator\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}) &= E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}] \\\\[8pt]\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon})] \\\\[8pt]\n& = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}] + E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon}]\\\\[8pt]\n& = \\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^TE(\\boldsymbol{\\epsilon}) \\\\[8pt]\n& = \\boldsymbol{\\beta}\n\\end{aligned}\n\\]\nThe least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is an unbiased estimator of \\(\\boldsymbol{\\beta}\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#variance-of-hatboldsymbolbeta",
    "href": "slides/11-prop-of-estimators-pt2.html#variance-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) &= Var((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}) \\\\[8pt]\n& = [(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]Var(\\mathbf{y})[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]^T \\\\[8pt]\n& = [(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]\\sigma^2_{\\epsilon}\\mathbf{I}[\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\[8pt]\n& = \\sigma^2_{\\epsilon}[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}] \\\\[8pt]\n& = \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#linear-regression-model",
    "href": "slides/11-prop-of-estimators-pt2.html#linear-regression-model",
    "title": "Properties of estimators",
    "section": "“Linear” regression model",
    "text": "“Linear” regression model\nWhat does it mean for a model to be a “linear” regression model?\n\nLinear regression models are linear in the parameters, i.e. given an observation \\(y_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1f_1(x_{i1}) +  \\dots + \\beta_pf_p(x_{ip}) + \\epsilon_i\n\\]\nThe functions \\(f_1, \\ldots, f_p\\) can be non-linear as long as \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) are linear in \\(Y\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nSuppose \\(\\tilde{\\boldsymbol{\\beta}}\\) is another linear unbiased estimator of \\(\\boldsymbol{\\beta}\\) that can be expressed as \\(\\tilde{\\boldsymbol{\\beta}} = \\mathbf{Cy}\\) , such that \\(\\hat{\\mathbf{y}} = \\mathbf{X}\\tilde{\\boldsymbol{\\beta}} = \\mathbf{XCy}\\)\n\nLet \\(\\mathbf{C} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B}\\) for a non-zero matrix \\(\\mathbf{B}\\).\n\n\nWhat is the dimension of \\(\\mathbf{B}\\)?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-1",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-1",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\tilde{\\boldsymbol{\\beta}} = \\mathbf{Cy} = ((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})\\mathbf{y}\n\\]\nWe need to show\n\n\\(\\tilde{\\boldsymbol{\\beta}}\\) is unbiased\n\\(Var(\\tilde{\\boldsymbol{\\beta}}) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-2",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-2",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nE(\\tilde{\\boldsymbol{\\beta}}) & = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})\\mathbf{y}] \\\\\n& = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon})] \\\\\n& = E[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta})] \\\\\n& = ((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})(\\mathbf{X}\\boldsymbol{\\beta}) \\\\\n& = (\\mathbf{I} + \\mathbf{BX})\\boldsymbol{\\beta}\n\\end{aligned}\n\\]\n\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?\nWhat must be true for \\(\\tilde{\\boldsymbol{\\beta}}\\) to be unbiased?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-3",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-3",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\n\\(\\mathbf{BX}\\) must be the \\(\\mathbf{0}\\) matrix (dimension = \\((p+1) \\times (p+1)\\)) in order for \\(\\tilde{\\boldsymbol{\\beta}}\\) to be unbiased\nNow we need to find \\(Var(\\tilde{\\boldsymbol{\\beta}})\\) and see how it compares to \\(Var(\\hat{\\boldsymbol{\\beta}})\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-4",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-4",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\n\\[\n\\begin{aligned}\nVar(\\tilde{\\boldsymbol{\\beta}}) &= Var[((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})\\mathbf{y}] \\\\[8pt]\n& = ((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})Var(\\mathbf{y})((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T + \\mathbf{B})^T \\\\[8pt]\n& = \\small{\\sigma^2_{\\epsilon}[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{B}^T + \\mathbf{BX}(\\mathbf{X}^T\\mathbf{X})^{-1} + \\mathbf{BB}^T]}\\\\[8pt]\n& = \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1} + \\sigma^2_{\\epsilon}\\mathbf{BB}^T\\end{aligned}\n\\]\n\nWhat assumption(s) of the Gauss-Markov Theorem did we use?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-5",
    "href": "slides/11-prop-of-estimators-pt2.html#gauss-markov-theorem-proof-5",
    "title": "Properties of estimators",
    "section": "Gauss-Markov Theorem Proof",
    "text": "Gauss-Markov Theorem Proof\nWe have\n\\[\nVar(\\tilde{\\boldsymbol{\\beta}}) = \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1} + \\sigma^2_\\epsilon \\mathbf{BB}^T\n\\]\n\nWe know that \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^T \\geq \\mathbf{0}\\).\n\n\n\n\nWhen is \\(\\sigma^2_{\\epsilon}\\mathbf{BB}^T = \\mathbf{0}\\)?\n\n\n\nTherefore, we have shown that \\(Var(\\tilde{\\boldsymbol{\\beta}}) &gt; Var(\\hat{\\boldsymbol{\\beta}})\\) and have completed the proof."
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-2",
    "href": "slides/11-prop-of-estimators-pt2.html#properties-of-hatboldsymbolbeta-2",
    "title": "Properties of estimators",
    "section": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nInfinite sample ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator\nEfficient estimator"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#mean-squared-error",
    "href": "slides/11-prop-of-estimators-pt2.html#mean-squared-error",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\nThe mean squared error (MSE) is the squared difference between the estimator and parameter.\n\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\n\\begin{aligned}\nMSE(\\hat{\\theta}) &= E[(\\hat{\\theta} - \\theta)^2] \\\\\n& = E(\\hat{\\theta}^2 - 2\\hat{\\theta}\\theta + \\theta^2) \\\\\n& = E(\\hat{\\theta}^2) - 2\\theta E(\\hat{\\theta}) + \\theta^2 \\\\\n& = \\underbrace{E(\\hat{\\theta}^2) -  E(\\hat{\\theta})^2}_{Var(\\hat{\\theta})} + \\underbrace{E(\\hat{\\theta})^2 - 2\\theta E(\\hat{\\theta}) + \\theta^2}_{Bias(\\theta)^2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#mean-squared-error-1",
    "href": "slides/11-prop-of-estimators-pt2.html#mean-squared-error-1",
    "title": "Properties of estimators",
    "section": "Mean squared error",
    "text": "Mean squared error\n\\[\nMSE(\\hat{\\theta}) = Var(\\hat{\\theta}) + Bias(\\hat{\\theta})^2\n\\]\n\n\nThe least-squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is unbiased, so \\[MSE(\\hat{\\boldsymbol{\\beta}}) = Var(\\hat{\\boldsymbol{\\beta}})\\]"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#consistency",
    "href": "slides/11-prop-of-estimators-pt2.html#consistency",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of a parameter \\(\\theta\\) if it converges in probability to \\(\\theta\\). Given a sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, . . .\\), then for every \\(\\epsilon &gt; 0\\),\n\\[\n\\displaystyle \\lim_{n\\to\\infty} P(|\\hat{\\theta}_n - \\theta| \\geq \\epsilon) = 0\n\\]\n\nThis means that as the sample size goes to \\(\\infty\\) (and thus the sample information gets better and better), the estimator will be arbitrarily close to the parameter with high probability.\n\n\n\nWhy is this a useful property of an estimator?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#consistency-1",
    "href": "slides/11-prop-of-estimators-pt2.html#consistency-1",
    "title": "Properties of estimators",
    "section": "Consistency",
    "text": "Consistency\n\n\n\n\n\nImportant\n\n\nTheorem\nAn estimator \\(\\hat{\\theta}\\) is a consistent estimator of the parameter \\(\\theta\\) if the sequence of estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2, \\ldots\\) satisfies\n\n\\(\\lim_{n \\to \\infty} Var(\\hat{\\theta}) = 0\\)\n\\(\\lim_{n \\to \\infty} Bias(\\hat{\\theta}) = 0\\)"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#consistency-of-hatboldsymbolbeta",
    "href": "slides/11-prop-of-estimators-pt2.html#consistency-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Consistency of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\(Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\), so \\(\\lim_{n \\to \\infty} Bias(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nNow we need to show that \\(\\lim_{n \\to \\infty} Var(\\hat{\\boldsymbol{\\beta}}) = \\mathbf{0}\\)\n\n\nWhat is \\(Var(\\hat{\\boldsymbol{\\beta}})\\)?\nDoes \\(Var(\\hat{\\boldsymbol{\\beta}}) \\to \\mathbf{0}\\) as \\(n \\to \\infty\\)?"
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#efficiency",
    "href": "slides/11-prop-of-estimators-pt2.html#efficiency",
    "title": "Properties of estimators",
    "section": "Efficiency",
    "text": "Efficiency\n\nThe efficiency of an estimator is concerned with the asymptotic variance of an estimator.\nThe estimator with the smallest variance is considered the most efficient.\nBy the Gauss-Markov Theorem, we have shown that the least-squares estimator is the most efficient among linear unbiased estimators."
  },
  {
    "objectID": "slides/11-prop-of-estimators-pt2.html#recap",
    "href": "slides/11-prop-of-estimators-pt2.html#recap",
    "title": "Properties of estimators",
    "section": "Recap",
    "text": "Recap\nFinite sample ( \\(n\\) ) properties\n\nUnbiased estimator ✅\nBest Linear Unbiased Estimator (BLUE) ✅\n\n\nInfinite sample ( \\(n \\rightarrow \\infty\\) ) properties\n\nConsistent estimator ✅\nEfficient estimator ✅\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/17-compare-models.html#announcements",
    "href": "slides/17-compare-models.html#announcements",
    "title": "Model comparison",
    "section": "Announcements",
    "text": "Announcements\n\nHW 03 due Thursday at 11:59pm\nProject: Exploratory data analysis due Thursday at 11:59pm\nLooking ahead\n\nProject presentations November 11\nStatistics experience due Tuesday, November 26"
  },
  {
    "objectID": "slides/17-compare-models.html#computing-set-up",
    "href": "slides/17-compare-models.html#computing-set-up",
    "title": "Model comparison",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(kableExtra) # for formatting tables\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/17-compare-models.html#topics",
    "href": "slides/17-compare-models.html#topics",
    "title": "Model comparison",
    "section": "Topics",
    "text": "Topics\n\nANOVA for Multiple Linear Regression\nNested (Partial) F Test\nAIC & BIC"
  },
  {
    "objectID": "slides/17-compare-models.html#restaurant-tips",
    "href": "slides/17-compare-models.html#restaurant-tips",
    "title": "Model comparison",
    "section": "Restaurant tips",
    "text": "Restaurant tips\nWhat affects the amount customers tip at a restaurant?\n\nResponse:\n\nTip: amount of the tip\n\nPredictors:\n\nParty: number of people in the party\nMeal: time of day (Lunch, Dinner, Late Night)\nAge: age category of person paying the bill (Yadult, Middle, SenCit)\n\n\n\n\nRows: 422 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Day, Meal, Payment, Age, GiftCard, Comps, Alcohol, Bday\ndbl (5): Party, Bill, W/Tip, Tip, Tip Percentage\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "slides/17-compare-models.html#response-variable",
    "href": "slides/17-compare-models.html#response-variable",
    "title": "Model comparison",
    "section": "Response Variable",
    "text": "Response Variable\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/17-compare-models.html#predictor-variables",
    "href": "slides/17-compare-models.html#predictor-variables",
    "title": "Model comparison",
    "section": "Predictor Variables",
    "text": "Predictor Variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/17-compare-models.html#response-vs.-predictors",
    "href": "slides/17-compare-models.html#response-vs.-predictors",
    "title": "Model comparison",
    "section": "Response vs. Predictors",
    "text": "Response vs. Predictors"
  },
  {
    "objectID": "slides/17-compare-models.html#restaurant-tips-model",
    "href": "slides/17-compare-models.html#restaurant-tips-model",
    "title": "Model comparison",
    "section": "Restaurant tips: model",
    "text": "Restaurant tips: model\n\nmodel1 &lt;- lm(Tip ~ Party +  Age , data = tips)\ntidy(model1, conf.int = TRUE) |&gt;\n  kable(format = \"markdown\", digits=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.838\n0.397\n2.112\n0.036\n0.055\n1.622\n\n\nParty\n1.837\n0.124\n14.758\n0.000\n1.591\n2.083\n\n\nAgeSenCit\n0.379\n0.410\n0.925\n0.356\n-0.430\n1.189\n\n\nAgeYadult\n-1.009\n0.408\n-2.475\n0.014\n-1.813\n-0.204\n\n\n\n\n\n\nIs this the best model to explain variation in Tips?"
  },
  {
    "objectID": "slides/17-compare-models.html#test-for-overall-significance-hypotheses",
    "href": "slides/17-compare-models.html#test-for-overall-significance-hypotheses",
    "title": "Model comparison",
    "section": "Test for overall significance: Hypotheses",
    "text": "Test for overall significance: Hypotheses\nWe can conduct a hypothesis test using the ANOVA table to determine if there is at least one non-zero coefficient in the model\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n\nFor the tips data:\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/17-compare-models.html#test-for-overall-significance-test-statistic",
    "href": "slides/17-compare-models.html#test-for-overall-significance-test-statistic",
    "title": "Model comparison",
    "section": "Test for overall significance: Test statistic",
    "text": "Test for overall significance: Test statistic\n\n\n\n\n\nSource\nDf\nSum Sq\nMean Sq\nF Stat\nPr(&gt; F)\n\n\n\n\nModel\n3\n1226.664\n408.888\n98.284\n0\n\n\nResiduals\n165\n686.444\n4.16\n\n\n\n\nTotal\n168\n1913.108\n\n\n\n\n\n\n\n\n\nTest statistic: Ratio of explained to unexplained variability\n\\[\nF = \\frac{\\text{Mean Square Model}}{\\text{Mean Square Residuals}}\n\\]\nThe test statistic follows an \\(F\\) distribution with \\(p\\) and \\(n -  p - 1\\) degrees of freedom"
  },
  {
    "objectID": "slides/17-compare-models.html#test-for-overall-significance-p-value",
    "href": "slides/17-compare-models.html#test-for-overall-significance-p-value",
    "title": "Model comparison",
    "section": "Test for overall significance: P-value",
    "text": "Test for overall significance: P-value\n\n\\[\n\\text{P-value} = \\text{Pr}(F &gt; \\text{F Stat})\n\\]"
  },
  {
    "objectID": "slides/17-compare-models.html#test-for-overall-significance-conclusion",
    "href": "slides/17-compare-models.html#test-for-overall-significance-conclusion",
    "title": "Model comparison",
    "section": "Test for overall significance: Conclusion",
    "text": "Test for overall significance: Conclusion\n\\[\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j\n\\end{aligned}\n\\]\n\n\n\n\n\nSource\nDf\nSum Sq\nMean Sq\nF Stat\nPr(&gt; F)\n\n\n\n\nModel\n3\n1226.664\n408.888\n98.284\n0\n\n\nResiduals\n165\n686.444\n4.16\n\n\n\n\nTotal\n168\n1913.108\n\n\n\n\n\n\n\n\n\n\nWhat is the conclusion from this hypothesis test?"
  },
  {
    "objectID": "slides/17-compare-models.html#why-use-overall-f-test",
    "href": "slides/17-compare-models.html#why-use-overall-f-test",
    "title": "Model comparison",
    "section": "Why use overall F test?",
    "text": "Why use overall F test?\nWhy do we use overall F test instead of just looking at the test for individual coefficients?1\nSuppose we have a model such that \\(p = 100\\) and \\(H_0: \\beta_1 = \\dots = \\beta_{100} = 0\\) is true\n\n\n\nAbout 5% of the p-values for individual coefficients will be below 0.05 by chance.\nSo we expect to see 5 small p-values if even no linear association actually exists.\nTherefore, it is very likely we will see at least one small p-value by chance.\nThe F-test does not have this problem, because it accounts for the number of predictors. There is only a 5% chance we will get a p-value below 0.05, if a linear relationship truly does not exist.\n\n\n\nExample from Introduction to Statistical Learning"
  },
  {
    "objectID": "slides/17-compare-models.html#testing-subset-of-coefficients",
    "href": "slides/17-compare-models.html#testing-subset-of-coefficients",
    "title": "Model comparison",
    "section": "Testing subset of coefficients",
    "text": "Testing subset of coefficients\n\nSometimes we want to test whether a subset of coefficients are all equal to 0\nThis is often the case when we want test\n\nwhether a categorical variable with \\(k\\) levels is a significant predictor of the response\nwhether the interaction between a categorical and quantitative variable is significant\n\nTo do so, we will use the Nested (Partial) F-test"
  },
  {
    "objectID": "slides/17-compare-models.html#nested-partial-f-test",
    "href": "slides/17-compare-models.html#nested-partial-f-test",
    "title": "Model comparison",
    "section": "Nested (Partial) F Test",
    "text": "Nested (Partial) F Test\n\nSuppose we have a full and reduced model:\n\n\\[\\begin{aligned}&\\text{Full}: y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_q x_q + \\beta_{q+1} x_{q+1} + \\dots \\beta_p x_p \\\\\n&\\text{Reduced}: y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_q x_q\\end{aligned}\\]\n\n\nWe want to test whether any of the variables \\(x_{q+1}, x_{q+2}, \\ldots, x_p\\) are significant predictors. To do so, we will test the hypothesis:\n\\[\\begin{aligned}&H_0: \\beta_{q+1} =  \\beta_{q+2} = \\dots = \\beta_p = 0 \\\\\n&H_a: \\text{at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}\\]"
  },
  {
    "objectID": "slides/17-compare-models.html#nested-f-test",
    "href": "slides/17-compare-models.html#nested-f-test",
    "title": "Model comparison",
    "section": "Nested F Test",
    "text": "Nested F Test\n\nThe test statistic for this test is\n\n\\[F = \\frac{(SSR_{reduced} - SSR_{full})\\big/\\text{# predictors tested}}{SSR_{full}\\big/(n-p_{full}-1)}\\] \n\nCalculate the p-value using the F distribution with df1 = # predictors tested and df2 = \\((n-p_{full}-1)\\)"
  },
  {
    "objectID": "slides/17-compare-models.html#is-meal-a-significant-predictor-of-tips",
    "href": "slides/17-compare-models.html#is-meal-a-significant-predictor-of-tips",
    "title": "Model comparison",
    "section": "Is Meal a significant predictor of tips?",
    "text": "Is Meal a significant predictor of tips?\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n1.254\n\n\nParty\n1.808\n\n\nAgeSenCit\n0.390\n\n\nAgeYadult\n-0.505\n\n\nMealLate Night\n-1.632\n\n\nMealLunch\n-0.612"
  },
  {
    "objectID": "slides/17-compare-models.html#tips-nested-f-test",
    "href": "slides/17-compare-models.html#tips-nested-f-test",
    "title": "Model comparison",
    "section": "Tips: Nested F test",
    "text": "Tips: Nested F test\n\\[\\begin{aligned}&H_0: \\beta_{late night} = \\beta_{lunch} = 0\\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to 0}\\end{aligned}\\]\n\n\nreduced &lt;- lm(Tip ~ Party + Age, data = tips)\n\n\n\n\nfull &lt;- lm(Tip ~ Party + Age + Meal, data = tips)\n\n\n\n\n\n#Nested F test in R\nanova(reduced, full)"
  },
  {
    "objectID": "slides/17-compare-models.html#tips-nested-f-test-1",
    "href": "slides/17-compare-models.html#tips-nested-f-test-1",
    "title": "Model comparison",
    "section": "Tips: Nested F test",
    "text": "Tips: Nested F test\n\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n\n165\n686.444\nNA\nNA\nNA\nNA\n\n\n163\n622.979\n2\n63.465\n8.303\n0\n\n\n\n\n\n\n\n\nF Stat: \\(\\frac{(686.444 - 622.979)/2}{622.979/(169 - 5 - 1)} = 8.303\\)\n\n\nP-value: P(F &gt; 8.303) = 0.0003 - calculated using an F distribution with 2 and 163 degrees of freedom\n\n\nThe data provide sufficient evidence to conclude that at least one coefficient associated with Meal is not zero. Therefore, Meal is a significant predictor of Tips."
  },
  {
    "objectID": "slides/17-compare-models.html#model-with-meal",
    "href": "slides/17-compare-models.html#model-with-meal",
    "title": "Model comparison",
    "section": "Model with Meal",
    "text": "Model with Meal\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n1.254\n0.394\n3.182\n0.002\n0.476\n2.032\n\n\nParty\n1.808\n0.121\n14.909\n0.000\n1.568\n2.047\n\n\nAgeSenCit\n0.390\n0.394\n0.990\n0.324\n-0.388\n1.168\n\n\nAgeYadult\n-0.505\n0.412\n-1.227\n0.222\n-1.319\n0.308\n\n\nMealLate Night\n-1.632\n0.407\n-4.013\n0.000\n-2.435\n-0.829\n\n\nMealLunch\n-0.612\n0.402\n-1.523\n0.130\n-1.405\n0.181"
  },
  {
    "objectID": "slides/17-compare-models.html#including-interactions",
    "href": "slides/17-compare-models.html#including-interactions",
    "title": "Model comparison",
    "section": "Including interactions",
    "text": "Including interactions\nDoes the effect of Party differ based on the Meal time?\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n1.276\n\n\nParty\n1.795\n\n\nAgeSenCit\n0.401\n\n\nAgeYadult\n-0.470\n\n\nMealLate Night\n-1.845\n\n\nMealLunch\n-0.461\n\n\nParty:MealLate Night\n0.111\n\n\nParty:MealLunch\n-0.050"
  },
  {
    "objectID": "slides/17-compare-models.html#nested-f-test-for-interactions",
    "href": "slides/17-compare-models.html#nested-f-test-for-interactions",
    "title": "Model comparison",
    "section": "Nested F test for interactions",
    "text": "Nested F test for interactions\nLet’s use a Nested F test to determine if Party*Meal is statistically significant.\n\nreduced &lt;- lm(Tip ~ Party + Age + Meal, data = tips)\n\n\n\nfull &lt;- lm(Tip ~ Party + Age + Meal + Meal * Party, \n           data = tips)\n\n\n\n\nkable(anova(reduced, full), format = \"markdown\", digits = 3) |&gt;\n  row_spec(2, background = \"#dce5b2\")\n\n\n\n\nRes.Df\nRSS\nDf\nSum of Sq\nF\nPr(&gt;F)\n\n\n\n\n163\n622.979\nNA\nNA\nNA\nNA\n\n\n161\n621.965\n2\n1.014\n0.131\n0.877"
  },
  {
    "objectID": "slides/17-compare-models.html#final-model-for-now",
    "href": "slides/17-compare-models.html#final-model-for-now",
    "title": "Model comparison",
    "section": "Final model for now",
    "text": "Final model for now\nWe conclude that the effect of Party does not differ based Meal. Therefore, we will use the original model that only included main effects.\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.254\n0.394\n3.182\n0.002\n\n\nParty\n1.808\n0.121\n14.909\n0.000\n\n\nAgeSenCit\n0.390\n0.394\n0.990\n0.324\n\n\nAgeYadult\n-0.505\n0.412\n-1.227\n0.222\n\n\nMealLate Night\n-1.632\n0.407\n-4.013\n0.000\n\n\nMealLunch\n-0.612\n0.402\n-1.523\n0.130"
  },
  {
    "objectID": "slides/17-compare-models.html#tips-comparing-models",
    "href": "slides/17-compare-models.html#tips-comparing-models",
    "title": "Model comparison",
    "section": "Tips: Comparing models",
    "text": "Tips: Comparing models\nLet’s compare two models:\n\nmodel1 &lt;- lm(Tip ~ Party + Age + Meal, data = tips)\nglance(model1) |&gt; select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.674         0.664\n\n\n\n\nmodel2 &lt;- lm(Tip ~ Party + Age + Meal + Day, data = tips)\nglance(model2) |&gt; select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.683         0.662"
  },
  {
    "objectID": "slides/17-compare-models.html#aic-bic",
    "href": "slides/17-compare-models.html#aic-bic",
    "title": "Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\nAkaike’s Information Criterion (AIC): \\[AIC = n\\log(SSR)  + 2(p+1)\\] \nSchwarz’s Bayesian Information Criterion (BIC) \\[BIC = n\\log(SSR) + log(n)\\times(p+1)\\]"
  },
  {
    "objectID": "slides/17-compare-models.html#aic-bic-1",
    "href": "slides/17-compare-models.html#aic-bic-1",
    "title": "Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\n\\[\\begin{aligned} & AIC = \\color{blue}{n\\log(SSR)} \\color{black}{ + 2(p+1)} \\\\\n& BIC = \\color{blue}{n\\log(SSR)}  \\color{black}{+ \\log(n)\\times(p+1) }\\end{aligned}\\]\n\n\nFirst Term: Generally decreases as p increases"
  },
  {
    "objectID": "slides/17-compare-models.html#aic-bic-2",
    "href": "slides/17-compare-models.html#aic-bic-2",
    "title": "Model comparison",
    "section": "AIC & BIC",
    "text": "AIC & BIC\n\\[\\begin{aligned} & AIC = n\\log(SSR)  + \\color{blue}{2(p+1)} \\\\\n& BIC = n\\log(SSR) + \\color{blue}{\\log(n)\\times(p+1)} \\end{aligned}\\]\n\nSecond Term: Increases as p increases"
  },
  {
    "objectID": "slides/17-compare-models.html#using-aic-bic",
    "href": "slides/17-compare-models.html#using-aic-bic",
    "title": "Model comparison",
    "section": "Using AIC & BIC",
    "text": "Using AIC & BIC\n\\[\\begin{aligned} & AIC = n\\log(SSR)  + \\color{red}{2(p+1)} \\\\\n& BIC = n\\log(SSR) + \\color{red}{\\log(n)\\times(p+1)} \\end{aligned}\\]  \n\nChoose model with the smaller value of AIC or BIC\nIf \\(n \\geq 8\\), the penalty for BIC is larger than that of AIC, so BIC tends to favor more parsimonious models (i.e. models with fewer terms)"
  },
  {
    "objectID": "slides/17-compare-models.html#tips-aic-bic",
    "href": "slides/17-compare-models.html#tips-aic-bic",
    "title": "Model comparison",
    "section": "Tips: AIC & BIC",
    "text": "Tips: AIC & BIC\n\nmodel1 &lt;- lm(Tip ~ Party + Age + Meal, data = tips)\nglance(model1) |&gt; select(AIC, BIC)\n\n# A tibble: 1 × 2\n    AIC   BIC\n  &lt;dbl&gt; &lt;dbl&gt;\n1  714.  736.\n\n\n\n\n\nmodel2 &lt;- lm(Tip ~ Party + Age + Meal + Day, data = tips)\nglance(model2) |&gt; select(AIC, BIC)\n\n# A tibble: 1 × 2\n    AIC   BIC\n  &lt;dbl&gt; &lt;dbl&gt;\n1  720.  757.\n\n\n\n\n\nWhich model do you choose?"
  },
  {
    "objectID": "slides/17-compare-models.html#parsimony-and-occams-razor",
    "href": "slides/17-compare-models.html#parsimony-and-occams-razor",
    "title": "Model comparison",
    "section": "Parsimony and Occam’s razor",
    "text": "Parsimony and Occam’s razor\n\nThe principle of parsimony is attributed to William of Occam (early 14th-century English nominalist philosopher), who insisted that, given a set of equally good explanations for a given phenomenon, the correct explanation is the simplest explanation1\nCalled Occam’s razor because he “shaved” his explanations down to the bare minimum\nParsimony in modeling:\n\nmodels should have as few parameters as possible\nlinear models should be preferred to non-linear models\nexperiments relying on few assumptions should be preferred to those relying on many\nmodels should be pared down until they are minimal adequate\nsimple explanations should be preferred to complex explanations\n\n\nSource: The R Book by Michael J. Crawley"
  },
  {
    "objectID": "slides/17-compare-models.html#in-pursuit-of-occams-razor",
    "href": "slides/17-compare-models.html#in-pursuit-of-occams-razor",
    "title": "Model comparison",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\nOccam’s razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\nModel selection follows this principle\nWe only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\nIn other words, we prefer the simplest best model, i.e. parsimonious model"
  },
  {
    "objectID": "slides/17-compare-models.html#in-pursuit-of-occams-razor-1",
    "href": "slides/17-compare-models.html#in-pursuit-of-occams-razor-1",
    "title": "Model comparison",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\nOccam’s razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\nModel selection follows this principle\nWe only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\nIn other words, we prefer the simplest best model, i.e. parsimonious model"
  },
  {
    "objectID": "slides/17-compare-models.html#alternate-views",
    "href": "slides/17-compare-models.html#alternate-views",
    "title": "Model comparison",
    "section": "Alternate views",
    "text": "Alternate views\n\nSometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.\n\nRadford Neal - Bayesian Learning for Neural Networks1\n\nSuggested blog post: Occam by Andrew Gelman"
  },
  {
    "objectID": "slides/17-compare-models.html#recap",
    "href": "slides/17-compare-models.html#recap",
    "title": "Model comparison",
    "section": "Recap",
    "text": "Recap\n\nANOVA for Multiple Linear Regression\nNested F Test\nAIC & BIC\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#announcements",
    "href": "slides/10-prop-of-estimators.html#announcements",
    "title": "Properties of estimators",
    "section": "Announcements",
    "text": "Announcements\n\nProject\n\nResearch questions due TODAY\nProposal due Thursday, October 3 at 11:59pm\n\nLab 03 due Thursday, October 3 at 11:59pm\nHW 02 due Thursday, October 3 at 11:59pm (released after class)\nStatistics experience due Tue, Nov 26 at 11:59pm"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#topics",
    "href": "slides/10-prop-of-estimators.html#topics",
    "title": "Properties of estimators",
    "section": "Topics",
    "text": "Topics\n\nCompute and interpret confidence interval for a single coefficient\nProperties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nDefine “linear” model"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#computing-setup",
    "href": "slides/10-prop-of-estimators.html#computing-setup",
    "title": "Properties of estimators",
    "section": "Computing setup",
    "text": "Computing setup\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#data-ncaa-football-expenditures",
    "href": "slides/10-prop-of-estimators.html#data-ncaa-football-expenditures",
    "title": "Properties of estimators",
    "section": "Data: NCAA Football expenditures",
    "text": "Data: NCAA Football expenditures\nToday’s data come from Equity in Athletics Data Analysis and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a March 2022 Tidy Tuesday.\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\ntotal_exp_m: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\nenrollment_th: Total student enrollment in the 2019 - 2020 academic year (in thousands)\ntype: institution type (Public or Private)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#regression-model",
    "href": "slides/10-prop-of-estimators.html#regression-model",
    "title": "Properties of estimators",
    "section": "Regression model",
    "text": "Regression model\n\nexp_fit &lt;- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#inference-for-beta_j",
    "href": "slides/10-prop-of-estimators.html#inference-for-beta_j",
    "title": "Properties of estimators",
    "section": "Inference for \\(\\beta_j\\)",
    "text": "Inference for \\(\\beta_j\\)\nWe often want to conduct inference on individual model coefficients\n\nHypothesis test: Is there a linear relationship between the response and \\(x_j\\)?\nConfidence interval: What is a plausible range of values \\(\\beta_j\\) can take?"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-1",
    "href": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-1",
    "title": "Properties of estimators",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#what-confidence-means",
    "href": "slides/10-prop-of-estimators.html#what-confidence-means",
    "title": "Properties of estimators",
    "section": "What “confidence” means",
    "text": "What “confidence” means\n\n\nWe will construct \\(C\\%\\) confidence intervals\n\nThe confidence level impacts the width of the interval\n\n“Confidence” means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate \\(C\\%\\) CIs for the coefficient of \\(x_j\\), then \\(C\\%\\) of those intervals will contain the true value of the coefficient \\(\\beta_j\\)\nNeed to balance precision and accuracy when selecting a confidence level"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-2",
    "href": "slides/10-prop-of-estimators.html#confidence-interval-for-beta_j-2",
    "title": "Properties of estimators",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-p-1\\) degrees of freedom"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#computing-t-in-r",
    "href": "slides/10-prop-of-estimators.html#computing-t-in-r",
    "title": "Properties of estimators",
    "section": "Computing \\(t^*\\) in R",
    "text": "Computing \\(t^*\\) in R\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n\n[1] 1.97928\n\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n\n[1] 1.657235\n\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n\n[1] 2.61606"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#ci-for-coefficient-of-enrollment",
    "href": "slides/10-prop-of-estimators.html#ci-for-coefficient-of-enrollment",
    "title": "Properties of estimators",
    "section": "95% CI for coefficient of enrollment",
    "text": "95% CI for coefficient of enrollment\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n\n\n\n\n\n\n\n\\[\n\\hat{\\beta}_j \\pm t^* \\times SE(\\hat{\\beta}_j)\n\\]\n\n\n\\[\n0.7804 \\pm 1.9793 \\times 0.1103\n\\]\n\n\n\\[\n[0.562, 0.999]\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#interpreting-the-ci",
    "href": "slides/10-prop-of-estimators.html#interpreting-the-ci",
    "title": "Properties of estimators",
    "section": "Interpreting the CI",
    "text": "Interpreting the CI\n🔗 edstem.org/us/courses/62513/discussion/648045"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#computing-ci-in-r",
    "href": "slides/10-prop-of-estimators.html#computing-ci-in-r",
    "title": "Properties of estimators",
    "section": "Computing CI in R",
    "text": "Computing CI in R\n\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n19.332\n2.984\n6.478\n0\n13.426\n25.239\n\n\nenrollment_th\n0.780\n0.110\n7.074\n0\n0.562\n0.999\n\n\ntypePublic\n-13.226\n3.153\n-4.195\n0\n-19.466\n-6.986"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#motivation",
    "href": "slides/10-prop-of-estimators.html#motivation",
    "title": "Properties of estimators",
    "section": "Motivation",
    "text": "Motivation\n\n\nWe have discussed how to use least squares to find an estimator of \\(\\hat{\\boldsymbol{\\beta}}\\)\nHow do we know whether our least squares estimator is a “good” estimator?\nWhen we consider what makes an estimator “good”, we’ll look at three criteria:\n\nBias\nVariance\nMean squared error\n\nWe’ll take a look at these over the course of a few lectures and motivate why we might prefer using least squares to compute \\(\\hat{\\boldsymbol{\\beta}}\\) versus other methods"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#bias-and-variance",
    "href": "slides/10-prop-of-estimators.html#bias-and-variance",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\nSuppose you are throwing darts at a target\n\n\n\n\n\n\nImage source: Analytics Vidhya\n\n\n\n\nUnbiased: Darts distributed around the target\nBiased: Darts systematically away from the target\nVariance: Darts could be widely spread (high variance) or generally clustered together (low variance)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#bias-and-variance-1",
    "href": "slides/10-prop-of-estimators.html#bias-and-variance-1",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\nIdeal scenario: Darts are clustered around the target (unbiased and low variance)\nWorst case scenario: Darts are widely spread out and systematically far from the target (high bias and high variance)\nAcceptable scenario: There’s some trade-off between the bias and variance. For example, it may be acceptable for the darts to be clustered around a point that is close to the target (low bias and low variance)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#bias-and-variance-2",
    "href": "slides/10-prop-of-estimators.html#bias-and-variance-2",
    "title": "Properties of estimators",
    "section": "Bias and variance",
    "text": "Bias and variance\n\n\nEach time we take a sample of size \\(n\\), we can find the least squares estimator (throw dart at target)\nSuppose we take many independent samples of size \\(n\\) and find the least squares estimator for each sample (throw many darts at the target). Ideally,\n\nThe estimators are centered at the true parameter (unbiased)\nThe estimators are clustered around the true parameter (unbiased with low variance)\n\n\n\n\nLet’s take a look at the mean and variance of the least squares estimator"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta",
    "href": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nThe bias of an estimator is the difference between the estimator’s expected value and the true value of the parameter\n\nLet \\(\\hat{\\theta}\\) be an estimator of the parameter \\(\\theta\\). Then\n\\[\nBias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta\n\\]\n\n\nAn estimator is unbiased if the bias is 0 and thus \\(E(\\hat{\\theta}) = \\theta\\)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#finding-expected-value-and-variance",
    "href": "slides/10-prop-of-estimators.html#finding-expected-value-and-variance",
    "title": "Properties of estimators",
    "section": "Finding expected value and variance",
    "text": "Finding expected value and variance\nLet \\(\\mathbf{A}\\) be a \\(n \\times p\\) matrix of constants and \\(\\mathbf{b}\\) a \\(p \\times 1\\) vector of random variables. Then\n\\[\nE(\\mathbf{Ab}) = \\mathbf{A}E(\\mathbf{b})\n\\]\n\\[\nVar(\\mathbf{Ab}) = \\mathbf{A}Var(\\mathbf{b})\\mathbf{A}^T\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-1",
    "href": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nLet’s take a look at the expected value of the least squares estimator. Given \\(E(\\boldsymbol{\\epsilon}) = \\mathbf{0}\\),\n\\[\n\\begin{aligned}\nE(\\hat{\\boldsymbol{\\beta}}) &= E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}] \\\\[8pt]\n& = \\class{fragment}{E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon})]} \\\\[8pt]\n& = \\class{fragment}{E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}] + E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\epsilon}]}\\\\[8pt]\n& = \\class{fragment}{\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^TE(\\boldsymbol{\\epsilon})} \\\\[8pt]\n& = \\class{fragment}{\\boldsymbol{\\beta}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-2",
    "href": "slides/10-prop-of-estimators.html#expected-value-of-hatboldsymbolbeta-2",
    "title": "Properties of estimators",
    "section": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Expected value of \\(\\hat{\\boldsymbol{\\beta}}\\)\nThe least squares estimator \\(\\hat{\\boldsymbol{\\beta}}\\) is an unbiased estimator of \\(\\boldsymbol{\\beta}\\)\n\\[\nE(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}\n\\]\n\n\nNow let’s take a look at the variance"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta",
    "href": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\n\\begin{aligned}\nVar(\\hat{\\boldsymbol{\\beta}}) &= Var((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}) \\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]Var(\\mathbf{y})[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]^T }\\\\[8pt]\n& = \\class{fragment}{[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T]\\sigma^2_{\\epsilon}\\mathbf{I}[\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}]} \\\\[8pt]\n& = \\class{fragment}{\\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta-1",
    "href": "slides/10-prop-of-estimators.html#variance-of-hatboldsymbolbeta-1",
    "title": "Properties of estimators",
    "section": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)",
    "text": "Variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\n\\[\nVar(\\hat{\\boldsymbol{\\beta}}) =  \\sigma^2_{\\epsilon}(\\mathbf{X}^T\\mathbf{X})^{-1}\n\\]\nWe will show that \\(\\hat{\\boldsymbol{\\beta}}\\) is the “best” estimator (has the lowest variance) among the class of linear unbiased estimators"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#linear-regression-model",
    "href": "slides/10-prop-of-estimators.html#linear-regression-model",
    "title": "Properties of estimators",
    "section": "“Linear” regression model",
    "text": "“Linear” regression model\nWhat does it mean for a model to be a “linear” regression model?\n\n\nLinear regression models are linear in the parameters, i.e. given an observation \\(y_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1f_1(x_{i1}) +  \\dots + \\beta_pf_p(x_{ip}) + \\epsilon_i\n\\]\nThe functions \\(f_1, \\ldots, f_p\\) can be non-linear as long as \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) are linear in \\(Y\\)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model",
    "href": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model",
    "title": "Properties of estimators",
    "section": "Identify the linear regression model",
    "text": "Identify the linear regression model\n🔗 edstem.org/us/courses/62513/discussion/648051"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model-1",
    "href": "slides/10-prop-of-estimators.html#identify-the-linear-regression-model-1",
    "title": "Properties of estimators",
    "section": "Identify the linear regression model",
    "text": "Identify the linear regression model\n\n\n\\(y_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i1}^2 + \\beta_3x_{i2}  + \\epsilon_i\\)\n\\(y_i = \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i1}x_{i2} + \\epsilon_i\\)\n\\(y_i = \\beta_0  + \\beta_1\\sin(x_{i1} + \\beta_2x_{i2}) + \\beta_3x_{i3} + \\epsilon_i\\)\n\\(y_i = \\beta_0 + \\beta_1e^{x_{i1}} + \\beta_2e^{x_{i2}} + \\epsilon_i\\)\n\\(y_i = \\exp(\\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\beta_3x_{i3}) + \\epsilon_i\\)"
  },
  {
    "objectID": "slides/10-prop-of-estimators.html#recap",
    "href": "slides/10-prop-of-estimators.html#recap",
    "title": "Properties of estimators",
    "section": "Recap",
    "text": "Recap\n\nComputed and interpreted confidence interval for a single coefficient\nShowed some properties of \\(\\hat{\\boldsymbol{\\beta}}\\)\nDefined “linear” model\n\n\n\n\n\n🔗 STA 221 - Fall 2024"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 for Duke Container Manager\n\n\nCourse GitHub organization\n🔗 for GitHub\n\n\nCourse Canvas site\n🔗 for Canvas\n\n\nDiscussion forum\n🔗 to Ed Discussion\n\n\nAssignment submission\n🔗 to Gradescope\n\n\nZoom links\n🔗 on Canvas",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 221 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 11:45am - 1pm\nOld Chemistry 116\n\n\nLab 01\nMon 11:45am - 1pm\nLSRC A247\n\n\nLab 02\nMon 4:40 - 5:55pm\nOld Chemistry 101\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\nOffice Hours\n\n\n\n\nProf. Maria Tackett\nInstructor\nMon 1:30 - 2:30pm, Old Chem 118B\nThu 3 - 4pm, Old Chem 118B\nor by appointment\n\n\nKat Husar\nHead TA\nLab 02L leader\nTue 1:30 - 3:30pm, Old Chem 220\n\n\nJon Campbell\nLab 01L leader\nTue & Thu 9 - 10am, Old Chem 025\n\n\nIshrit Gupta\nLab 01L helper\nFri 1- 3pm, Old Chem 203B\n\n\nAlan Wang\nLab 02L helper\nMon & Wed 10 - 11am, Old Chem 203B",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "STA 221 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 11:45am - 1pm\nOld Chemistry 116\n\n\nLab 01\nMon 11:45am - 1pm\nLSRC A247\n\n\nLab 02\nMon 4:40 - 5:55pm\nOld Chemistry 101\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\nOffice Hours\n\n\n\n\nProf. Maria Tackett\nInstructor\nMon 1:30 - 2:30pm, Old Chem 118B\nThu 3 - 4pm, Old Chem 118B\nor by appointment\n\n\nKat Husar\nHead TA\nLab 02L leader\nTue 1:30 - 3:30pm, Old Chem 220\n\n\nJon Campbell\nLab 01L leader\nTue & Thu 9 - 10am, Old Chem 025\n\n\nIshrit Gupta\nLab 01L helper\nFri 1- 3pm, Old Chem 203B\n\n\nAlan Wang\nLab 02L helper\nMon & Wed 10 - 11am, Old Chem 203B",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "STA 221 Syllabus",
    "section": "Course description",
    "text": "Course description\nIn STA 221, students will learn how linear and logistic regression models are used to explore multivariable relationships, apply these methods to answer relevant and engaging questions using a data-driven approach, and learn the mathematical underpinnings of the models. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, analysis of variance, model diagnostics, and model selection. Regression parameter estimation via maximum likelihood least squares will also be discussed. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields.\n\nPrerequisites\nEither any STA 100-level course or STA 230, 231, or 240L and MATH 216, 218, or 221. The recommended co-requisite is STA 230, 231, or 240L. Interested students with different backgrounds should seek instructor consent.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "STA 221 Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze data to explore real-world multivariable relationships.\nfit, interpret, and draw conclusions from linear and logistic regression models.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\nexplain the mathematical foundations of linear and logistic regression.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "STA 221 Syllabus",
    "section": "Course materials",
    "text": "Course materials\nWhile there is no official textbook for the course; readings will primarily be made available as they are assigned. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "STA 221 Syllabus",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can find instructions to do so here. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, sta221-fa24.netlify.app.\nLinks to Zoom meetings may be found in Canvas. Periodic announcements will be sent via email and will also be available through Ed Discussion and Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at maria.tackett@duke.edu. If you email me, please include “STA 221” in the subject line. Barring extenuating circumstances, I will respond to STA 221 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "STA 221 Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings and other preparation work.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#getting-help-in-the-course",
    "href": "syllabus.html#getting-help-in-the-course",
    "title": "STA 221 Syllabus",
    "section": "Getting help in the course",
    "text": "Getting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-expect-in-the-course",
    "href": "syllabus.html#what-to-expect-in-the-course",
    "title": "STA 221 Syllabus",
    "section": "What to expect in the course",
    "text": "What to expect in the course\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities during the lectures and labs. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or any device with internet and a keyboard to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\n\n\nTeams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the group activities, labs and the final project. You will be asked to complete teamwork evaluations and self-reflections throughout the semester. Failure to adequately contribute to an assignment can result in a penalty to your score relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as one of several metrics of each team member’s relative contribution for each project.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "STA 221 Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on six components: application exercises, homework, labs, exams, project, and teamwork.\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository in the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks and explain the underlying mathematics. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-notes in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding of the applied and mathematical content and application through analysis and computational tasks. The exams will be based on content in reading assignments, lectures, application exercises, homework, and lab assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work through a written report and presentation. More information about the project will be provided during the semester. You can learn more on the final project page.\n\n\nParticipation (Application exercises + teamwork)\n\nApplication exercises\nYou will get the most out of the course if you actively participate in class and when working with your team. Parts of some lectures will be dedicated to working on Application Exercises (AEs). AEs are submitted by pushing your work to the relevant GitHub repo. AEs from Tuesday lectures should be submitted by Friday by 11:59p ET, and AEs from Thursday lectures are should be submitted by Sunday at 11:59p ET. Because AEs are intended for in-class activities, there are no extensions given on AEs.\nAEs will be graded based on making a good-faith effort to attempt all questions covered in class. You are welcome to, but not required, to work on AEs beyond lecture.\nSuccessful on-time effort on at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nTeamwork\nGiven the collaborative nature of statistics and data science work, teamwork will be a key part of this course. You will work in teams for in-class activities, lab assignments, and the final course project. There will be periodic peer and self-evaluations to reflect on the team’s collaboration. These evaluations will be counted as part of the participation grade.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 221 Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n25%\n\n\nFinal project\n15%\n\n\nLabs\n15%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "STA 221 Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email me at maria.tackett@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\n\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/Y46k4dqRLY\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "STA 221 Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-and-wellness-support",
    "href": "syllabus.html#academic-and-wellness-support",
    "title": "STA 221 Syllabus",
    "section": "Academic and wellness support",
    "text": "Academic and wellness support\n\nAcademic Resource Center\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.\n\n\nCAPS\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "STA 221 Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAugust 26: Classes begin\nSeptember 2: Labor Day. No classes\nSeptember 6: Drop/Add ends\nOctober 14 - 15: Fall Break. No classes\nNovember 8: Last day to withdraw with “W”\nNovember 27 - 29: Thanksgiving recess\nDecember 6: Classes end\nDecember 7 - 10: Reading period\nDecember 11 - 16: Final exam period\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 221 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  }
]