[
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "project-draft.html",
    "href": "project-draft.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#project-milestones",
    "href": "project-draft.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#introduction",
    "href": "project-draft.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the final deliverables."
  },
  {
    "objectID": "project-draft.html#research-topics",
    "href": "project-draft.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified at this point.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic.\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic.\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. [Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.]\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, February 13 at 11:59pm."
  },
  {
    "objectID": "project-draft.html#project-proposal",
    "href": "project-draft.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research questions. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Questions milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\n\nDescription of data cleaning you need to do to prepare for analysis (can focus on the response variable for now), such as joining data sets, imputing missing values, variable transformation, creating a new variable, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#eda",
    "href": "project-draft.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about about 4 - 6 pages.\n\n\n\n\n\n\nTip\n\n\n\nYou can suppress code, warnings, and messages by including the following in the YAML:\nexecute: \n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (14 - 15 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (11 - 13 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (8 - 10 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (7 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#presentation",
    "href": "project-draft.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores."
  },
  {
    "objectID": "project-draft.html#presentation-comments",
    "href": "project-draft.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day, November 11."
  },
  {
    "objectID": "project-draft.html#draft-report-peer-review",
    "href": "project-draft.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 221 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team."
  },
  {
    "objectID": "project-draft.html#written-report",
    "href": "project-draft.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\n\n\nResults\n\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report."
  },
  {
    "objectID": "project-draft.html#project-highlights",
    "href": "project-draft.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights"
  },
  {
    "objectID": "project-draft.html#reproducibility-organization",
    "href": "project-draft.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-questions.qmd & research-questions.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and a few sentences (~ 2 -5) describing your final project.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-draft.html#final-project-survey",
    "href": "project-draft.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey"
  },
  {
    "objectID": "project-draft.html#peer-teamwork-evaluation",
    "href": "project-draft.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly."
  },
  {
    "objectID": "project-draft.html#overall-grading",
    "href": "project-draft.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-draft.html#late-work-policy",
    "href": "project-draft.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nFiveThirtyEight data\nTidyTuesday\nData Is Plural\nR Data Sources for Regression Analysis\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "slides/05-sim-testing.html#announcements",
    "href": "slides/05-sim-testing.html#announcements",
    "title": "SLR: Permutation test for the slope",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Tuesday, January 28 at 11:59pm\nLabs resume on Monday"
  },
  {
    "objectID": "slides/05-sim-testing.html#topics",
    "href": "slides/05-sim-testing.html#topics",
    "title": "SLR: Permutation test for the slope",
    "section": "Topics",
    "text": "Topics\n\nEvaluate a claim about the slope using hypothesis testing\nConstruct a null distribution using simulation\nDefine mathematical models to conduct inference for slope"
  },
  {
    "objectID": "slides/05-sim-testing.html#computational-setup",
    "href": "slides/05-sim-testing.html#computational-setup",
    "title": "SLR: Permutation test for the slope",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/05-sim-testing.html#data-duke-forest-houses",
    "href": "slides/05-sim-testing.html#data-duke-forest-houses",
    "title": "SLR: Permutation test for the slope",
    "section": "Data: Duke Forest houses",
    "text": "Data: Duke Forest houses"
  },
  {
    "objectID": "slides/05-sim-testing.html#the-regression-model",
    "href": "slides/05-sim-testing.html#the-regression-model",
    "title": "SLR: Permutation test for the slope",
    "section": "The regression model",
    "text": "The regression model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/05-sim-testing.html#inference-for-simple-linear-regression",
    "href": "slides/05-sim-testing.html#inference-for-simple-linear-regression",
    "title": "SLR: Permutation test for the slope",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/05-sim-testing.html#statistical-inference",
    "href": "slides/05-sim-testing.html#statistical-inference",
    "title": "SLR: Permutation test for the slope",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/05-sim-testing.html#sampling-is-natural",
    "href": "slides/05-sim-testing.html#sampling-is-natural",
    "title": "SLR: Permutation test for the slope",
    "section": "Sampling is natural",
    "text": "Sampling is natural\n\n\nWhen you taste a spoonful of soup and decide the spoonful you tasted isn’t salty enough, that’s exploratory analysis\nIf you generalize and conclude that your entire soup needs salt, that’s an inference\nFor your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)"
  },
  {
    "objectID": "slides/05-sim-testing.html#confidence-interval-via-bootstrapping",
    "href": "slides/05-sim-testing.html#confidence-interval-via-bootstrapping",
    "title": "SLR: Permutation test for the slope",
    "section": "Confidence interval via bootstrapping",
    "text": "Confidence interval via bootstrapping\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-i",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline I",
    "text": "Bootstrapping pipeline I\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-ii",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline II",
    "text": "Bootstrapping pipeline II\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1         1  290000  2414\n 2         1  285000  2108\n 3         1  265000  1300\n 4         1  416000  2949\n 5         1  541000  2740\n 6         1  525000  2256\n 7         1 1270000  3909\n 8         1  265000  1300\n 9         1  815000  3904\n10         1  535000  2937\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-iii",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline III",
    "text": "Bootstrapping pipeline III\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   80699.\n 2         1 area          168.\n 3         2 intercept  -18821.\n 4         2 area          205.\n 5         3 intercept  234297.\n 6         3 area          117.\n 7         4 intercept  134481.\n 8         4 area          150.\n 9         5 intercept   23861.\n10         5 area          190.\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-iv",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline IV",
    "text": "Bootstrapping pipeline IV\n\nset.seed(210)\n\nboot_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing.html#visualize-the-bootstrap-distribution",
    "href": "slides/05-sim-testing.html#visualize-the-bootstrap-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\nboot_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)"
  },
  {
    "objectID": "slides/05-sim-testing.html#compute-the-ci",
    "href": "slides/05-sim-testing.html#compute-the-ci",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the CI",
    "text": "Compute the CI"
  },
  {
    "objectID": "slides/05-sim-testing.html#but-first",
    "href": "slides/05-sim-testing.html#but-first",
    "title": "SLR: Permutation test for the slope",
    "section": "But first…",
    "text": "But first…\n\nobs_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobs_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/05-sim-testing.html#compute-95-confidence-interval",
    "href": "slides/05-sim-testing.html#compute-95-confidence-interval",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute 95% confidence interval",
    "text": "Compute 95% confidence interval\n\nboot_dist |&gt;\n  get_confidence_interval(\n    point_estimate = obs_fit,\n    level = 0.95,\n    type = \"percentile\"\n  )\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          91.7     211.\n2 intercept -18290.   287711."
  },
  {
    "objectID": "slides/05-sim-testing.html#research-question-and-hypotheses",
    "href": "slides/05-sim-testing.html#research-question-and-hypotheses",
    "title": "SLR: Permutation test for the slope",
    "section": "Research question and hypotheses",
    "text": "Research question and hypotheses\n“Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”\n\nNull hypothesis: there is no linear relationship between area and price\n\\[\nH_0: \\beta_1 = 0\n\\]\n\n\nAlternative hypothesis: there is a linear relationship between area and price\n\\[\nH_a: \\beta_1 \\ne 0\n\\]"
  },
  {
    "objectID": "slides/05-sim-testing.html#hypothesis-testing-as-a-us-court-trial",
    "href": "slides/05-sim-testing.html#hypothesis-testing-as-a-us-court-trial",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing as a US court trial",
    "text": "Hypothesis testing as a US court trial\n\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_a\\): Defendant is guilty\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/05-sim-testing.html#hypothesis-testing-framework",
    "href": "slides/05-sim-testing.html#hypothesis-testing-framework",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_a\\) that represents the research question, i.e. claim we’re testing\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of getting the observed or a more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/05-sim-testing.html#quantify-the-variability-of-the-slope",
    "href": "slides/05-sim-testing.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Permutation test for the slope",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor testing\n\n\nTwo approaches:\n\nVia simulation\nVia mathematical models\n\nUse Permutation to quantify the variability of the slope for the purpose of testing, under the assumption that the null hypothesis is true:\n\nSimulate new samples from the original sample via permutation\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to conduct a hypothesis test"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-described",
    "href": "slides/05-sim-testing.html#permutation-described",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, described",
    "text": "Permutation, described\n\n\n\nUse permuting to simulate data under the assumption the null hypothesis is true and measure the natural variability in the data due to sampling, not due to variables being correlated\n\nPermute one variable to eliminate any existing relationship between the variables\n\nEach price value is randomly assigned to the area of a given house, i.e. area and price are no longer matched for a given house\n\n\n\n\n# A tibble: 98 × 3\n   price_Observed price_Permuted  area\n            &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-visualized",
    "href": "slides/05-sim-testing.html#permutation-visualized",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, visualized",
    "text": "Permutation, visualized\n\n\n\nEach of the observed values for area (and for price) exist in both the observed data plot as well as the permuted price plot\nThe permutation removes the relationship between area and price"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-repeated",
    "href": "slides/05-sim-testing.html#permutation-repeated",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, repeated",
    "text": "Permutation, repeated\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)"
  },
  {
    "objectID": "slides/05-sim-testing.html#concluding-the-hypothesis-test",
    "href": "slides/05-sim-testing.html#concluding-the-hypothesis-test",
    "title": "SLR: Permutation test for the slope",
    "section": "Concluding the hypothesis test",
    "text": "Concluding the hypothesis test\n\nIs the observed slope of \\(\\hat{\\beta_1} = 159\\) (or an even more extreme slope) a likely outcome under the null hypothesis that \\(\\beta = 0\\)? What does this mean for our original question: “Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-i",
    "href": "slides/05-sim-testing.html#permutation-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline I",
    "text": "Permutation pipeline I\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-ii",
    "href": "slides/05-sim-testing.html#permutation-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline II",
    "text": "Permutation pipeline II\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-iii",
    "href": "slides/05-sim-testing.html#permutation-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline III",
    "text": "Permutation pipeline III\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n 1  465000  6040         1\n 2  481000  4475         1\n 3 1020000  1745         1\n 4  520000  2091         1\n 5  592000  1772         1\n 6  650000  1950         1\n 7  473000  3909         1\n 8  705000  2841         1\n 9  785000  3924         1\n10  671500  2173         1\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-iv",
    "href": "slides/05-sim-testing.html#permutation-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline IV",
    "text": "Permutation pipeline IV\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term       estimate\n       &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1         1 intercept 553355.  \n 2         1 area           2.35\n 3         2 intercept 635824.  \n 4         2 area         -27.3 \n 5         3 intercept 536072.  \n 6         3 area           8.57\n 7         4 intercept 598649.  \n 8         4 area         -13.9 \n 9         5 intercept 556202.  \n10         5 area           1.33\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-v",
    "href": "slides/05-sim-testing.html#permutation-pipeline-v",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline V",
    "text": "Permutation pipeline V\n\nset.seed(1125)\n\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing.html#visualize-the-null-distribution",
    "href": "slides/05-sim-testing.html#visualize-the-null-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the null distribution",
    "text": "Visualize the null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")"
  },
  {
    "objectID": "slides/05-sim-testing.html#reason-around-the-p-value",
    "href": "slides/05-sim-testing.html#reason-around-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Reason around the p-value",
    "text": "Reason around the p-value\n\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price (\\(\\beta_1 = 0\\)), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?"
  },
  {
    "objectID": "slides/05-sim-testing.html#compute-the-p-value",
    "href": "slides/05-sim-testing.html#compute-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the p-value",
    "text": "Compute the p-value\n\nWhat does this warning mean?\n\n\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/05-sim-testing.html#the-regression-model-revisited",
    "href": "slides/05-sim-testing.html#the-regression-model-revisited",
    "title": "SLR: Permutation test for the slope",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/05-sim-testing.html#inference-revisited",
    "href": "slides/05-sim-testing.html#inference-revisited",
    "title": "SLR: Permutation test for the slope",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we’ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/05-sim-testing.html#mathematical-representation-of-the-model",
    "href": "slides/05-sim-testing.html#mathematical-representation-of-the-model",
    "title": "SLR: Permutation test for the slope",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= \\text{Model} + \\text{Error} \\\\\n&= f(X) + \\epsilon \\\\\n&= \\mu_{Y|X} + \\epsilon \\\\\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed (now we are making an assumption about the distribution of the error terms)\n\n\nindependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/05-sim-testing.html#simple-linear-regression-model-fully-specified",
    "href": "slides/05-sim-testing.html#simple-linear-regression-model-fully-specified",
    "title": "SLR: Permutation test for the slope",
    "section": "Simple linear regression model fully specified",
    "text": "Simple linear regression model fully specified\n\\[\n\\mathbf{Y} = \\beta_0 + \\beta_1X + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\n\n\n\\(\\beta_0\\): the population intercept\n\\(\\beta_1\\): the population slope\n\\(\\epsilon\\) : independent and identically distributed (i.i.d.) error terms"
  },
  {
    "objectID": "slides/05-sim-testing.html#mathematical-representation-visualized",
    "href": "slides/05-sim-testing.html#mathematical-representation-visualized",
    "title": "SLR: Permutation test for the slope",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the expected value of \\(Y\\) based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/05-sim-testing.html#regression-standard-error",
    "href": "slides/05-sim-testing.html#regression-standard-error",
    "title": "SLR: Permutation test for the slope",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error (the spread of the distribution of the response, for a given value of the predictor variable):\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/05-sim-testing.html#standard-error-of-hatbeta_1",
    "href": "slides/05-sim-testing.html#standard-error-of-hatbeta_1",
    "title": "SLR: Permutation test for the slope",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n\nor…\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html",
    "href": "slides/05-sim-testing-notes.html",
    "title": "SLR: Permutation test for the slope",
    "section": "",
    "text": "HW 01 due Tuesday, January 28 at 11:59pm\nLabs resume on Monday"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#announcements",
    "href": "slides/05-sim-testing-notes.html#announcements",
    "title": "SLR: Permutation test for the slope",
    "section": "",
    "text": "HW 01 due Tuesday, January 28 at 11:59pm\nLabs resume on Monday"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#topics",
    "href": "slides/05-sim-testing-notes.html#topics",
    "title": "SLR: Permutation test for the slope",
    "section": "Topics",
    "text": "Topics\n\nEvaluate a claim about the slope using hypothesis testing\nConstruct a null distribution using simulation\nDefine mathematical models to conduct inference for slope"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#computational-setup",
    "href": "slides/05-sim-testing-notes.html#computational-setup",
    "title": "SLR: Permutation test for the slope",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#data-duke-forest-houses",
    "href": "slides/05-sim-testing-notes.html#data-duke-forest-houses",
    "title": "SLR: Permutation test for the slope",
    "section": "Data: Duke Forest houses",
    "text": "Data: Duke Forest houses"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#the-regression-model",
    "href": "slides/05-sim-testing-notes.html#the-regression-model",
    "title": "SLR: Permutation test for the slope",
    "section": "The regression model",
    "text": "The regression model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n. . .\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#inference-for-simple-linear-regression",
    "href": "slides/05-sim-testing-notes.html#inference-for-simple-linear-regression",
    "title": "SLR: Permutation test for the slope",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#statistical-inference",
    "href": "slides/05-sim-testing-notes.html#statistical-inference",
    "title": "SLR: Permutation test for the slope",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#sampling-is-natural",
    "href": "slides/05-sim-testing-notes.html#sampling-is-natural",
    "title": "SLR: Permutation test for the slope",
    "section": "Sampling is natural",
    "text": "Sampling is natural\n\n\n\n\n\n\nWhen you taste a spoonful of soup and decide the spoonful you tasted isn’t salty enough, that’s exploratory analysis\nIf you generalize and conclude that your entire soup needs salt, that’s an inference\nFor your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#confidence-interval-via-bootstrapping",
    "href": "slides/05-sim-testing-notes.html#confidence-interval-via-bootstrapping",
    "title": "SLR: Permutation test for the slope",
    "section": "Confidence interval via bootstrapping",
    "text": "Confidence interval via bootstrapping\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-i",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline I",
    "text": "Bootstrapping pipeline I\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-ii",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline II",
    "text": "Bootstrapping pipeline II\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1         1  290000  2414\n 2         1  285000  2108\n 3         1  265000  1300\n 4         1  416000  2949\n 5         1  541000  2740\n 6         1  525000  2256\n 7         1 1270000  3909\n 8         1  265000  1300\n 9         1  815000  3904\n10         1  535000  2937\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iii",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline III",
    "text": "Bootstrapping pipeline III\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   80699.\n 2         1 area          168.\n 3         2 intercept  -18821.\n 4         2 area          205.\n 5         3 intercept  234297.\n 6         3 area          117.\n 7         4 intercept  134481.\n 8         4 area          150.\n 9         5 intercept   23861.\n10         5 area          190.\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iv",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline IV",
    "text": "Bootstrapping pipeline IV\n\nset.seed(210)\n\nboot_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#visualize-the-bootstrap-distribution",
    "href": "slides/05-sim-testing-notes.html#visualize-the-bootstrap-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\nboot_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#compute-the-ci",
    "href": "slides/05-sim-testing-notes.html#compute-the-ci",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the CI",
    "text": "Compute the CI"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#but-first",
    "href": "slides/05-sim-testing-notes.html#but-first",
    "title": "SLR: Permutation test for the slope",
    "section": "But first…",
    "text": "But first…\n\nobs_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobs_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#compute-95-confidence-interval",
    "href": "slides/05-sim-testing-notes.html#compute-95-confidence-interval",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute 95% confidence interval",
    "text": "Compute 95% confidence interval\n\nboot_dist |&gt;\n  get_confidence_interval(\n    point_estimate = obs_fit,\n    level = 0.95,\n    type = \"percentile\"\n  )\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          91.7     211.\n2 intercept -18290.   287711."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#research-question-and-hypotheses",
    "href": "slides/05-sim-testing-notes.html#research-question-and-hypotheses",
    "title": "SLR: Permutation test for the slope",
    "section": "Research question and hypotheses",
    "text": "Research question and hypotheses\n“Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”\n. . .\nNull hypothesis: there is no linear relationship between area and price\n\\[\nH_0: \\beta_1 = 0\n\\]\n. . .\nAlternative hypothesis: there is a linear relationship between area and price\n\\[\nH_a: \\beta_1 \\ne 0\n\\]"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#hypothesis-testing-as-a-us-court-trial",
    "href": "slides/05-sim-testing-notes.html#hypothesis-testing-as-a-us-court-trial",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing as a US court trial",
    "text": "Hypothesis testing as a US court trial\n\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_a\\): Defendant is guilty\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#hypothesis-testing-framework",
    "href": "slides/05-sim-testing-notes.html#hypothesis-testing-framework",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_a\\) that represents the research question, i.e. claim we’re testing\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of getting the observed or a more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#quantify-the-variability-of-the-slope",
    "href": "slides/05-sim-testing-notes.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Permutation test for the slope",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor testing\n\n\nTwo approaches:\n\nVia simulation\nVia mathematical models\n\nUse Permutation to quantify the variability of the slope for the purpose of testing, under the assumption that the null hypothesis is true:\n\nSimulate new samples from the original sample via permutation\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to conduct a hypothesis test"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-described",
    "href": "slides/05-sim-testing-notes.html#permutation-described",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, described",
    "text": "Permutation, described\n\n\n\nUse permuting to simulate data under the assumption the null hypothesis is true and measure the natural variability in the data due to sampling, not due to variables being correlated\n\nPermute one variable to eliminate any existing relationship between the variables\n\nEach price value is randomly assigned to the area of a given house, i.e. area and price are no longer matched for a given house\n\n\n\n\n# A tibble: 98 × 3\n   price_Observed price_Permuted  area\n            &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-visualized",
    "href": "slides/05-sim-testing-notes.html#permutation-visualized",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, visualized",
    "text": "Permutation, visualized\n\n\n\nEach of the observed values for area (and for price) exist in both the observed data plot as well as the permuted price plot\nThe permutation removes the relationship between area and price"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-repeated",
    "href": "slides/05-sim-testing-notes.html#permutation-repeated",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, repeated",
    "text": "Permutation, repeated\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#concluding-the-hypothesis-test",
    "href": "slides/05-sim-testing-notes.html#concluding-the-hypothesis-test",
    "title": "SLR: Permutation test for the slope",
    "section": "Concluding the hypothesis test",
    "text": "Concluding the hypothesis test\n\nIs the observed slope of \\(\\hat{\\beta_1} = 159\\) (or an even more extreme slope) a likely outcome under the null hypothesis that \\(\\beta = 0\\)? What does this mean for our original question: “Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-i",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline I",
    "text": "Permutation pipeline I\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-ii",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline II",
    "text": "Permutation pipeline II\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-iii",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline III",
    "text": "Permutation pipeline III\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n 1  465000  6040         1\n 2  481000  4475         1\n 3 1020000  1745         1\n 4  520000  2091         1\n 5  592000  1772         1\n 6  650000  1950         1\n 7  473000  3909         1\n 8  705000  2841         1\n 9  785000  3924         1\n10  671500  2173         1\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-iv",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline IV",
    "text": "Permutation pipeline IV\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term       estimate\n       &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1         1 intercept 553355.  \n 2         1 area           2.35\n 3         2 intercept 635824.  \n 4         2 area         -27.3 \n 5         3 intercept 536072.  \n 6         3 area           8.57\n 7         4 intercept 598649.  \n 8         4 area         -13.9 \n 9         5 intercept 556202.  \n10         5 area           1.33\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-v",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-v",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline V",
    "text": "Permutation pipeline V\n\nset.seed(1125)\n\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#visualize-the-null-distribution",
    "href": "slides/05-sim-testing-notes.html#visualize-the-null-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the null distribution",
    "text": "Visualize the null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#reason-around-the-p-value",
    "href": "slides/05-sim-testing-notes.html#reason-around-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Reason around the p-value",
    "text": "Reason around the p-value\n\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price (\\(\\beta_1 = 0\\)), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#compute-the-p-value",
    "href": "slides/05-sim-testing-notes.html#compute-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the p-value",
    "text": "Compute the p-value\n\nWhat does this warning mean?\n\n\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#the-regression-model-revisited",
    "href": "slides/05-sim-testing-notes.html#the-regression-model-revisited",
    "title": "SLR: Permutation test for the slope",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#inference-revisited",
    "href": "slides/05-sim-testing-notes.html#inference-revisited",
    "title": "SLR: Permutation test for the slope",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we’ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#mathematical-representation-of-the-model",
    "href": "slides/05-sim-testing-notes.html#mathematical-representation-of-the-model",
    "title": "SLR: Permutation test for the slope",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= \\text{Model} + \\text{Error} \\\\\n&= f(X) + \\epsilon \\\\\n&= \\mu_{Y|X} + \\epsilon \\\\\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed (now we are making an assumption about the distribution of the error terms)\n. . .\n\nindependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#simple-linear-regression-model-fully-specified",
    "href": "slides/05-sim-testing-notes.html#simple-linear-regression-model-fully-specified",
    "title": "SLR: Permutation test for the slope",
    "section": "Simple linear regression model fully specified",
    "text": "Simple linear regression model fully specified\n\\[\n\\mathbf{Y} = \\beta_0 + \\beta_1X + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\n\n\n\\(\\beta_0\\): the population intercept\n\\(\\beta_1\\): the population slope\n\\(\\epsilon\\) : independent and identically distributed (i.i.d.) error terms"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#mathematical-representation-visualized",
    "href": "slides/05-sim-testing-notes.html#mathematical-representation-visualized",
    "title": "SLR: Permutation test for the slope",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the expected value of \\(Y\\) based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#regression-standard-error",
    "href": "slides/05-sim-testing-notes.html#regression-standard-error",
    "title": "SLR: Permutation test for the slope",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error (the spread of the distribution of the response, for a given value of the predictor variable):\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n. . .\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#standard-error-of-hatbeta_1",
    "href": "slides/05-sim-testing-notes.html#standard-error-of-hatbeta_1",
    "title": "SLR: Permutation test for the slope",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n. . .\nor…\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/anova-table.html",
    "href": "slides/anova-table.html",
    "title": "ANOVA Output in R",
    "section": "",
    "text": "We will use the Tips data set for this example.\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nThe variables of interest in this analysis are"
  },
  {
    "objectID": "slides/anova-table.html#model-fit",
    "href": "slides/anova-table.html#model-fit",
    "title": "ANOVA Output in R",
    "section": "Model fit",
    "text": "Model fit\n\ntip_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(Tip ~ Party + Age, data = tips)\n\ntidy(tip_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.17\n0.37\n-0.46\n0.64\n\n\nParty\n1.84\n0.12\n14.76\n0.00\n\n\nAgeMiddle\n1.01\n0.41\n2.47\n0.01\n\n\nAgeSenCit\n1.39\n0.48\n2.86\n0.00"
  },
  {
    "objectID": "slides/anova-table.html#anova",
    "href": "slides/anova-table.html#anova",
    "title": "ANOVA Output in R",
    "section": "ANOVA",
    "text": "ANOVA\nBelow is the ANOVA output for the model fit above.\n\nanova(tip_fit$fit) |&gt;\n  tidy() |&gt;\n  kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\nParty\n1\n1188.64\n1188.64\n285.71\n0.00\n\n\nAge\n2\n38.03\n19.01\n4.57\n0.01\n\n\nResiduals\n165\n686.44\n4.16\nNA\nNA\n\n\n\n\n\nWe will focus on the sum of squares in this document. The sum of squares are as follows:\n$$\n\\[\\begin{aligned}\n&SS_{Party} = 1188.64 \\\\\n&SS_{Age|Party} = 38.03 \\\\\n&SS_{Error} = SS_{Residuals} = 686.44 \\\\\n&SS_{Total} = 1913.11\n\\end{aligned}\\]\n$$"
  },
  {
    "objectID": "slides/anova-table.html#sum-of-squares-in-anova-table",
    "href": "slides/anova-table.html#sum-of-squares-in-anova-table",
    "title": "ANOVA Output in R",
    "section": "Sum of squares in ANOVA table",
    "text": "Sum of squares in ANOVA table\nR uses a sequential method to calculate sum of squares for the variables in the model. This means that the sum of squares attributed to each variable is the variation in the response explained by that variable after accounting for the total variation explained by the other variables already in the model.\nThe order of the sequence is determined by the order of the variables in the model fit code. This order is reflected in the order the variables appear in the ANOVA output. The sequential sum of squares attributed to each variable will change if the order of the variables in the model changes; however, the sum of squares attributed to the model overall will not change, regardless of the order of the variables.\nLet’s take a look at the sum of squares for Party, the first variable in the model. This value is calculated as the total variation in Tips explained by Party only. We can calculate this value by looking at the ANOVA table for simple linear regression model where Party is the only predictor.\n\nparty_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(Tip ~ Party, data = tips)\n\nanova(party_fit$fit) |&gt;\n  tidy() |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\nParty\n1\n1188.64\n1188.64\n274\n0\n\n\nResiduals\n167\n724.47\n4.34\nNA\nNA\n\n\n\n\n\nNotice that the sum of squares in this table is the value of \\(SS_{Party}\\) above.\nNext, let’s add Age to the model. The sum of squares associated with Age is the additional variation in Tips explained by Age after accounting for variation explained by Party. This can be understood as the additional model variation in the model with Party and Age compared to a model that only includes Party. We can calculate this additional variation as follows:\n\nanova(party_fit$fit, tip_fit$fit) |&gt;\n  tidy() |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\ndf.residual\nrss\ndf\nsumsq\nstatistic\np.value\n\n\n\n\nTip ~ Party\n167\n724.47\nNA\nNA\nNA\nNA\n\n\nTip ~ Party + Age\n165\n686.44\n2\n38.03\n4.57\n0.01\n\n\n\n\n\nNotice that the sum of squares in this table is the value of \\(SS_{Age|Party}\\) above.\n\n\n\n\n\n\nNote\n\n\n\nWhen we input two model is the anova() function, e.g., anova(Model 1, Model 2), the output produced is the additional sum of squares accounted for by the new variable(s) in Model 2 after accounting for the variables in Model 1. In this case, it is the additional sum of squares accounted for by Age after accounting for Party.\n\n\nWhen we use the ANOVA table, we are most interested in the variation in the response explained by the entire model, not the contribution from each variable. Therefore, we will primarily consider the \\(SS_{Model}\\), Sum of Squares Model. Because sum of squares are additive, it can be calculated as\n\\[\n\\begin{aligned}\nSS_{Model} &= SS_{Total} - SS_{Error} \\\\\n&= 1913.11 - 686.44 \\\\\n& = 1226.67\n\\end{aligned}\n\\]It can also be calculated as\n\\[\n\\begin{aligned}\nSS_{Model} &= SS_{Party} + SS_{Age | Party} \\\\\n& = 1188.64 + 38.03 \\\\\n& = 1226.67\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/08-model-eval.html#announcements",
    "href": "slides/08-model-eval.html#announcements",
    "title": "Model evaluation",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due Thursday at 11:59pm\nHW 02 released later today\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/08-model-eval.html#office-hours-poll",
    "href": "slides/08-model-eval.html#office-hours-poll",
    "title": "Model evaluation",
    "section": "Office hours poll",
    "text": "Office hours poll\n\n \n🔗 https://forms.office.com/r/QTxJvhGSFF"
  },
  {
    "objectID": "slides/08-model-eval.html#topics",
    "href": "slides/08-model-eval.html#topics",
    "title": "Model evaluation",
    "section": "Topics",
    "text": "Topics\n\n\nRecap of MLR and predictor types\nInteraction terms\nANOVA and sum of squares\n\\(R^2\\) and RMSE"
  },
  {
    "objectID": "slides/08-model-eval.html#computational-setup",
    "href": "slides/08-model-eval.html#computational-setup",
    "title": "Model evaluation",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(colorblindr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/08-model-eval.html#data-palmer-penguins",
    "href": "slides/08-model-eval.html#data-palmer-penguins",
    "title": "Model evaluation",
    "section": "Data: Palmer penguins",
    "text": "Data: Palmer penguins\nThe penguins data set contains data for penguins found on three islands in the Palmer Archipelago, Antarctica. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. These data can be found in the palmerpenguins R package.\n\n\n\n# A tibble: 342 × 4\n   body_mass_g flipper_length_mm bill_length_mm species\n         &lt;int&gt;             &lt;int&gt;          &lt;dbl&gt; &lt;fct&gt;  \n 1        3750               181           39.1 Adelie \n 2        3800               186           39.5 Adelie \n 3        3250               195           40.3 Adelie \n 4        3450               193           36.7 Adelie \n 5        3650               190           39.3 Adelie \n 6        3625               181           38.9 Adelie \n 7        4675               195           39.2 Adelie \n 8        3475               193           34.1 Adelie \n 9        4250               190           42   Adelie \n10        3300               186           37.8 Adelie \n# ℹ 332 more rows"
  },
  {
    "objectID": "slides/08-model-eval.html#variables",
    "href": "slides/08-model-eval.html#variables",
    "title": "Model evaluation",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\nbill_length_mm: Bill length in millimeters\nflipper_length_mm: Flipper length in millimeters\nspecies: Adelie, Gentoo, or Chinstrap species\n\nResponse: body_mass_g: Body mass in grams\n\nThe goal of this analysis is to use the bill length, flipper length, and species to predict body mass."
  },
  {
    "objectID": "slides/08-model-eval.html#response-vs.-predictors",
    "href": "slides/08-model-eval.html#response-vs.-predictors",
    "title": "Model evaluation",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors"
  },
  {
    "objectID": "slides/08-model-eval.html#model-fit",
    "href": "slides/08-model-eval.html#model-fit",
    "title": "Model evaluation",
    "section": "Model fit",
    "text": "Model fit\n\npenguin_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + \n                bill_length_mm, data = penguins)\n\ntidy(penguin_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000"
  },
  {
    "objectID": "slides/08-model-eval.html#interpreting-hatbeta_j",
    "href": "slides/08-model-eval.html#interpreting-hatbeta_j",
    "title": "Model evaluation",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n\n\nExample: The estimated coefficient for flipper_length_mm is 27.429. This means for each additional millimeter in a penguin’s flipper length, its body mass is expected to be greater by 27.429 grams, on average, holding species and bill length constant."
  },
  {
    "objectID": "slides/08-model-eval.html#indicator-variables",
    "href": "slides/08-model-eval.html#indicator-variables",
    "title": "Model evaluation",
    "section": "Indicator variables",
    "text": "Indicator variables\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n-4945.450\n-2863.324\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753\n\n\n\n\n\n\n\n\n\nInterpret the coefficient of Gentoo in the context of the data."
  },
  {
    "objectID": "slides/08-model-eval.html#centering",
    "href": "slides/08-model-eval.html#centering",
    "title": "Model evaluation",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\n\n\\[\nX_{cent} = X  - C\n\\]\n\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nHow does centering change the model and/or interpretations?"
  },
  {
    "objectID": "slides/08-model-eval.html#standardizing",
    "href": "slides/08-model-eval.html#standardizing",
    "title": "Model evaluation",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\n\n\\[\nX_{std} = \\frac{X - \\bar{X}}{S_X}\n\\]\n\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nHow does standardizing change the model and/or interpretations?"
  },
  {
    "objectID": "slides/08-model-eval.html#interaction-terms-1",
    "href": "slides/08-model-eval.html#interaction-terms-1",
    "title": "Model evaluation",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/08-model-eval.html#bill-length-versus-species",
    "href": "slides/08-model-eval.html#bill-length-versus-species",
    "title": "Model evaluation",
    "section": "Bill length versus species",
    "text": "Bill length versus species\nIf the lines are not parallel, there is indication of a potential interaction effect, i.e., the slope of bill length may differ based on the species."
  },
  {
    "objectID": "slides/08-model-eval.html#interaction-term-in-model",
    "href": "slides/08-model-eval.html#interaction-term-in-model",
    "title": "Model evaluation",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\npenguin_int_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + bill_length_mm + species * bill_length_mm,\n      data = penguins)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4297.905\n645.054\n-6.663\n0.000\n\n\nflipper_length_mm\n27.263\n3.175\n8.586\n0.000\n\n\nspeciesChinstrap\n1146.287\n726.217\n1.578\n0.115\n\n\nspeciesGentoo\n54.716\n619.934\n0.088\n0.930\n\n\nbill_length_mm\n72.692\n10.642\n6.831\n0.000\n\n\nspeciesChinstrap:bill_length_mm\n-41.035\n16.104\n-2.548\n0.011\n\n\nspeciesGentoo:bill_length_mm\n-1.163\n14.436\n-0.081\n0.936"
  },
  {
    "objectID": "slides/08-model-eval.html#interaction-terms-in-the-model",
    "href": "slides/08-model-eval.html#interaction-terms-in-the-model",
    "title": "Model evaluation",
    "section": "Interaction terms in the model",
    "text": "Interaction terms in the model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4297.905\n645.054\n-6.663\n0.000\n\n\nflipper_length_mm\n27.263\n3.175\n8.586\n0.000\n\n\nspeciesChinstrap\n1146.287\n726.217\n1.578\n0.115\n\n\nspeciesGentoo\n54.716\n619.934\n0.088\n0.930\n\n\nbill_length_mm\n72.692\n10.642\n6.831\n0.000\n\n\nspeciesChinstrap:bill_length_mm\n-41.035\n16.104\n-2.548\n0.011\n\n\nspeciesGentoo:bill_length_mm\n-1.163\n14.436\n-0.081\n0.936\n\n\n\n\n\n\n\n\n\n\nWrite the model equation for penguins in the Adelie species.\nWrite the model equation for penguins in the Chinstrap species."
  },
  {
    "objectID": "slides/08-model-eval.html#interpreting-interaction-terms",
    "href": "slides/08-model-eval.html#interpreting-interaction-terms",
    "title": "Model evaluation",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of bill length on the body mass is 41.035 less when the penguin is from the Chinstrap species compared to the effect for the Adelie species, holding all else constant.\nInterpreting bill_length_mm for Chinstrap: For each additional millimeter in bill length, we expect the body mass of Chinstrap penguins to increase by 31.657 grams (72.692 - 41.035), holding all else constant."
  },
  {
    "objectID": "slides/08-model-eval.html#summary",
    "href": "slides/08-model-eval.html#summary",
    "title": "Model evaluation",
    "section": "Summary",
    "text": "Summary\n\n\nIn general, how do\n\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?"
  },
  {
    "objectID": "slides/08-model-eval.html#data-restaurant-tips",
    "href": "slides/08-model-eval.html#data-restaurant-tips",
    "title": "Model evaluation",
    "section": "Data: Restaurant tips",
    "text": "Data: Restaurant tips\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\n\n\n# A tibble: 8 × 4\n    Tip Party Meal   Age   \n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n1  2.99     1 Dinner Yadult\n2  2        1 Dinner Yadult\n3  5        1 Dinner SenCit\n4  4        3 Dinner Middle\n5 10.3      2 Dinner SenCit\n6  4.85     2 Dinner Middle\n7  5        4 Dinner Yadult\n8  4        3 Dinner Middle\n\n\n\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College"
  },
  {
    "objectID": "slides/08-model-eval.html#variables-1",
    "href": "slides/08-model-eval.html#variables-1",
    "title": "Model evaluation",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nParty: Number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\n\n\nResponse: Tip: Amount of tip in US dollars"
  },
  {
    "objectID": "slides/08-model-eval.html#response-tip",
    "href": "slides/08-model-eval.html#response-tip",
    "title": "Model evaluation",
    "section": "Response: Tip",
    "text": "Response: Tip\n\n\n\n\n\n\nMin\nQ1\nMedian\nQ3\nMax\nMean\nSD\n\n\n\n\n0\n3\n4.5\n6\n19.46\n4.98\n3.37"
  },
  {
    "objectID": "slides/08-model-eval.html#predictors",
    "href": "slides/08-model-eval.html#predictors",
    "title": "Model evaluation",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/08-model-eval.html#relevel-categorical-predictors",
    "href": "slides/08-model-eval.html#relevel-categorical-predictors",
    "title": "Model evaluation",
    "section": "Relevel categorical predictors",
    "text": "Relevel categorical predictors\n\ntips &lt;- tips |&gt;\n  mutate(\n    Meal = fct_relevel(Meal, \"Lunch\", \"Dinner\", \"Late Night\"),\n    Age  = fct_relevel(Age, \"Yadult\", \"Middle\", \"SenCit\")\n  )"
  },
  {
    "objectID": "slides/08-model-eval.html#predictors-again",
    "href": "slides/08-model-eval.html#predictors-again",
    "title": "Model evaluation",
    "section": "Predictors, again",
    "text": "Predictors, again"
  },
  {
    "objectID": "slides/08-model-eval.html#response-vs.-predictors-1",
    "href": "slides/08-model-eval.html#response-vs.-predictors-1",
    "title": "Model evaluation",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors"
  },
  {
    "objectID": "slides/08-model-eval.html#fit-and-summarize-model",
    "href": "slides/08-model-eval.html#fit-and-summarize-model",
    "title": "Model evaluation",
    "section": "Fit and summarize model",
    "text": "Fit and summarize model\n\ntip_fit &lt;- lm(Tip ~ Party + Age, data = tips)\n\ntidy(tip_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.170\n0.366\n-0.465\n0.643\n\n\nParty\n1.837\n0.124\n14.758\n0.000\n\n\nAgeMiddle\n1.009\n0.408\n2.475\n0.014\n\n\nAgeSenCit\n1.388\n0.485\n2.862\n0.005\n\n\n\n\n\n\n\n\nOverall, how well does this model help us understand variability n tips?"
  },
  {
    "objectID": "slides/08-model-eval.html#two-statistics",
    "href": "slides/08-model-eval.html#two-statistics",
    "title": "Model evaluation",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model\n\n\nWhat indicates a good model fit? Higher or lower RMSE? Higher or lower \\(R^2\\)?"
  },
  {
    "objectID": "slides/08-model-eval.html#rmse",
    "href": "slides/08-model-eval.html#rmse",
    "title": "Model evaluation",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/08-model-eval.html#compute-rmse-augmented-data-frame",
    "href": "slides/08-model-eval.html#compute-rmse-augmented-data-frame",
    "title": "Model evaluation",
    "section": "Compute RMSE: Augmented data frame",
    "text": "Compute RMSE: Augmented data frame\nUse the augment() function from the broom package to add columns for predicted values, residuals, and other observation-level model statistics\n\ntip_aug &lt;- augment(tip_fit)\n\n\n\n\n# A tibble: 169 × 9\n     Tip Party Age    .fitted .resid   .hat .sigma   .cooksd .std.resid\n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1  2.99     1 Yadult    1.67  1.32  0.0247   2.04 0.00274        0.657\n 2  2        1 Yadult    1.67  0.333 0.0247   2.05 0.000173       0.165\n 3  5        1 SenCit    3.05  1.95  0.0371   2.04 0.00911        0.972\n 4  4        3 Middle    6.35 -2.35  0.0111   2.04 0.00376       -1.16 \n 5 10.3      2 SenCit    4.89  5.45  0.0301   2.00 0.0571         2.71 \n 6  4.85     2 Middle    4.51  0.337 0.0126   2.05 0.0000881      0.166\n 7  5        4 Yadult    7.18 -2.18  0.0471   2.04 0.0148        -1.09 \n 8  4        3 Middle    6.35 -2.35  0.0111   2.04 0.00376       -1.16 \n 9  5        2 Middle    4.51  0.487 0.0126   2.05 0.000184       0.240\n10  1.58     1 SenCit    3.05 -1.47  0.0371   2.04 0.00524       -0.737\n# ℹ 159 more rows"
  },
  {
    "objectID": "slides/08-model-eval.html#finding-rmse-in-r",
    "href": "slides/08-model-eval.html#finding-rmse-in-r",
    "title": "Model evaluation",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(tip_aug, truth = Tip, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        2.02\n\n\n\n\n\nIs the model a good fit for the data? What information do you need to make this determination?"
  },
  {
    "objectID": "slides/08-model-eval.html#analysis-of-variance-anova-1",
    "href": "slides/08-model-eval.html#analysis-of-variance-anova-1",
    "title": "Model evaluation",
    "section": "Analysis of variance (ANOVA)",
    "text": "Analysis of variance (ANOVA)\nAnalysis of Variance (ANOVA): Technique to partition variability in Y by the sources of variability"
  },
  {
    "objectID": "slides/08-model-eval.html#anova",
    "href": "slides/08-model-eval.html#anova",
    "title": "Model evaluation",
    "section": "ANOVA",
    "text": "ANOVA\n\nMain Idea: Decompose the total variation in the response into\n\nthe variation that can be explained by the each of the variables in the model\nthe variation that can’t be explained by the model (left in the residuals)\n\nIf the variation that can be explained by the variables in the model is greater than the variation in the residuals, this signals that the model might be “valuable” (at least one of the \\(\\beta\\)’s not equal to 0)"
  },
  {
    "objectID": "slides/08-model-eval.html#sum-of-squares",
    "href": "slides/08-model-eval.html#sum-of-squares",
    "title": "Model evaluation",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\nClick here to see why this equality holds."
  },
  {
    "objectID": "slides/08-model-eval.html#anova-output-in-r1",
    "href": "slides/08-model-eval.html#anova-output-in-r1",
    "title": "Model evaluation",
    "section": "ANOVA output in R1",
    "text": "ANOVA output in R1\n\nanova(tip_fit) |&gt;\n  tidy() |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\nParty\n1\n1188.64\n1188.64\n285.71\n0.00\n\n\nAge\n2\n38.03\n19.01\n4.57\n0.01\n\n\nResiduals\n165\n686.44\n4.16\nNA\nNA\n\n\n\n\n\nClick here for explanation about the way R calculates sum of squares for each variable."
  },
  {
    "objectID": "slides/08-model-eval.html#anova-output-with-totals",
    "href": "slides/08-model-eval.html#anova-output-with-totals",
    "title": "Model evaluation",
    "section": "ANOVA output, with totals",
    "text": "ANOVA output, with totals\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\nParty\n1\n1188.64\n1188.64\n285.71\n0\n\n\nAge\n2\n38.03\n19.01\n4.57\n0.01\n\n\nResiduals\n165\n686.44\n4.16\n\n\n\n\nTotal\n168\n1913.11"
  },
  {
    "objectID": "slides/08-model-eval.html#sum-of-squares-1",
    "href": "slides/08-model-eval.html#sum-of-squares-1",
    "title": "Model evaluation",
    "section": "Sum of squares",
    "text": "Sum of squares\n\n\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SST\\): Sum of squares total, variability of the response, \\(\\sum_{i = 1}^n (y_i - \\bar{y})^2\\)\n\\(SSR\\): Sum of squares residuals, variability of residuals, \\(\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2\\)\n\\(SSM = SST - SSR\\): Sum of squares model, variability explained by the model"
  },
  {
    "objectID": "slides/08-model-eval.html#sum-of-squares-sst",
    "href": "slides/08-model-eval.html#sum-of-squares-sst",
    "title": "Model evaluation",
    "section": "Sum of squares: \\(SST\\)",
    "text": "Sum of squares: \\(SST\\)\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SST\\): Sum of squares total, variability of the response\n\n\\(\\sum_{i = 1}^n (y_i - \\bar{y})^2\\) = 1913.11"
  },
  {
    "objectID": "slides/08-model-eval.html#sum-of-squares-ssr",
    "href": "slides/08-model-eval.html#sum-of-squares-ssr",
    "title": "Model evaluation",
    "section": "Sum of squares: \\(SSR\\)",
    "text": "Sum of squares: \\(SSR\\)\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SSR\\): Sum of squares residuals, variability of residuals\n\n\\(\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2\\) = 686.44"
  },
  {
    "objectID": "slides/08-model-eval.html#sum-of-squares-ssm",
    "href": "slides/08-model-eval.html#sum-of-squares-ssm",
    "title": "Model evaluation",
    "section": "Sum of squares: \\(SSM\\)",
    "text": "Sum of squares: \\(SSM\\)\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SSM\\): Sum of squares model, Variability explained by the model\n\n\\(SST - SSR\\) = 1226.67"
  },
  {
    "objectID": "slides/08-model-eval.html#r2",
    "href": "slides/08-model-eval.html#r2",
    "title": "Model evaluation",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\nR^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST} = 1 - \\frac{686.44}{1913.11} = 0.641\n\\]\n\n\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/08-model-eval.html#interpreting-r2",
    "href": "slides/08-model-eval.html#interpreting-r2",
    "title": "Model evaluation",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\nglance(tip_fit)$r.squared\n\n[1] 0.6411891\n\n\n\n\nSelect the best interpretation for \\(R^2\\) .\n\nParty and age correctly predicts 64.12% of tips.\n64.12% of the variability in tips can be explained by party and age.\n64.12% of the variability in party and age can be explained by tips.\n64.12% of the time tips can be predicted by party and age."
  },
  {
    "objectID": "slides/08-model-eval.html#recap",
    "href": "slides/08-model-eval.html#recap",
    "title": "Model evaluation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced interaction terms\nIntroduced ANOVA and sum of squares\nIntroduced \\(R^2\\) and RMSE"
  },
  {
    "objectID": "slides/08-model-eval.html#next-class",
    "href": "slides/08-model-eval.html#next-class",
    "title": "Model evaluation",
    "section": "Next class",
    "text": "Next class\n\nModel comparison"
  },
  {
    "objectID": "slides/08-model-eval-notes.html",
    "href": "slides/08-model-eval-notes.html",
    "title": "Model evaluation",
    "section": "",
    "text": "Lab 02 due Thursday at 11:59pm\nHW 02 released later today\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#announcements",
    "href": "slides/08-model-eval-notes.html#announcements",
    "title": "Model evaluation",
    "section": "",
    "text": "Lab 02 due Thursday at 11:59pm\nHW 02 released later today\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#office-hours-poll",
    "href": "slides/08-model-eval-notes.html#office-hours-poll",
    "title": "Model evaluation",
    "section": "Office hours poll",
    "text": "Office hours poll\n\n \n🔗 https://forms.office.com/r/QTxJvhGSFF"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#topics",
    "href": "slides/08-model-eval-notes.html#topics",
    "title": "Model evaluation",
    "section": "Topics",
    "text": "Topics\n\n\nRecap of MLR and predictor types\nInteraction terms\nANOVA and sum of squares\n\\(R^2\\) and RMSE"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#computational-setup",
    "href": "slides/08-model-eval-notes.html#computational-setup",
    "title": "Model evaluation",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(colorblindr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#data-palmer-penguins",
    "href": "slides/08-model-eval-notes.html#data-palmer-penguins",
    "title": "Model evaluation",
    "section": "Data: Palmer penguins",
    "text": "Data: Palmer penguins\nThe penguins data set contains data for penguins found on three islands in the Palmer Archipelago, Antarctica. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. These data can be found in the palmerpenguins R package.\n. . .\n\n\n# A tibble: 342 × 4\n   body_mass_g flipper_length_mm bill_length_mm species\n         &lt;int&gt;             &lt;int&gt;          &lt;dbl&gt; &lt;fct&gt;  \n 1        3750               181           39.1 Adelie \n 2        3800               186           39.5 Adelie \n 3        3250               195           40.3 Adelie \n 4        3450               193           36.7 Adelie \n 5        3650               190           39.3 Adelie \n 6        3625               181           38.9 Adelie \n 7        4675               195           39.2 Adelie \n 8        3475               193           34.1 Adelie \n 9        4250               190           42   Adelie \n10        3300               186           37.8 Adelie \n# ℹ 332 more rows"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#variables",
    "href": "slides/08-model-eval-notes.html#variables",
    "title": "Model evaluation",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\nbill_length_mm: Bill length in millimeters\nflipper_length_mm: Flipper length in millimeters\nspecies: Adelie, Gentoo, or Chinstrap species\n\nResponse: body_mass_g: Body mass in grams\n\nThe goal of this analysis is to use the bill length, flipper length, and species to predict body mass."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#response-vs.-predictors",
    "href": "slides/08-model-eval-notes.html#response-vs.-predictors",
    "title": "Model evaluation",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#model-fit",
    "href": "slides/08-model-eval-notes.html#model-fit",
    "title": "Model evaluation",
    "section": "Model fit",
    "text": "Model fit\n\npenguin_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + \n                bill_length_mm, data = penguins)\n\ntidy(penguin_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#interpreting-hatbeta_j",
    "href": "slides/08-model-eval-notes.html#interpreting-hatbeta_j",
    "title": "Model evaluation",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n. . .\n\nExample: The estimated coefficient for flipper_length_mm is 27.429. This means for each additional millimeter in a penguin’s flipper length, its body mass is expected to be greater by 27.429 grams, on average, holding species and bill length constant."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#indicator-variables",
    "href": "slides/08-model-eval-notes.html#indicator-variables",
    "title": "Model evaluation",
    "section": "Indicator variables",
    "text": "Indicator variables\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n-4945.450\n-2863.324\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753\n\n\n\n\n\n\n\n\n\nInterpret the coefficient of Gentoo in the context of the data."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#centering",
    "href": "slides/08-model-eval-notes.html#centering",
    "title": "Model evaluation",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\n\n\\[\nX_{cent} = X  - C\n\\]\n\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nHow does centering change the model and/or interpretations?"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#standardizing",
    "href": "slides/08-model-eval-notes.html#standardizing",
    "title": "Model evaluation",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\n\n\\[\nX_{std} = \\frac{X - \\bar{X}}{S_X}\n\\]\n\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nHow does standardizing change the model and/or interpretations?"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#interaction-terms-1",
    "href": "slides/08-model-eval-notes.html#interaction-terms-1",
    "title": "Model evaluation",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#bill-length-versus-species",
    "href": "slides/08-model-eval-notes.html#bill-length-versus-species",
    "title": "Model evaluation",
    "section": "Bill length versus species",
    "text": "Bill length versus species\nIf the lines are not parallel, there is indication of a potential interaction effect, i.e., the slope of bill length may differ based on the species."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#interaction-term-in-model",
    "href": "slides/08-model-eval-notes.html#interaction-term-in-model",
    "title": "Model evaluation",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\npenguin_int_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + bill_length_mm + species * bill_length_mm,\n      data = penguins)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4297.905\n645.054\n-6.663\n0.000\n\n\nflipper_length_mm\n27.263\n3.175\n8.586\n0.000\n\n\nspeciesChinstrap\n1146.287\n726.217\n1.578\n0.115\n\n\nspeciesGentoo\n54.716\n619.934\n0.088\n0.930\n\n\nbill_length_mm\n72.692\n10.642\n6.831\n0.000\n\n\nspeciesChinstrap:bill_length_mm\n-41.035\n16.104\n-2.548\n0.011\n\n\nspeciesGentoo:bill_length_mm\n-1.163\n14.436\n-0.081\n0.936"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#interaction-terms-in-the-model",
    "href": "slides/08-model-eval-notes.html#interaction-terms-in-the-model",
    "title": "Model evaluation",
    "section": "Interaction terms in the model",
    "text": "Interaction terms in the model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4297.905\n645.054\n-6.663\n0.000\n\n\nflipper_length_mm\n27.263\n3.175\n8.586\n0.000\n\n\nspeciesChinstrap\n1146.287\n726.217\n1.578\n0.115\n\n\nspeciesGentoo\n54.716\n619.934\n0.088\n0.930\n\n\nbill_length_mm\n72.692\n10.642\n6.831\n0.000\n\n\nspeciesChinstrap:bill_length_mm\n-41.035\n16.104\n-2.548\n0.011\n\n\nspeciesGentoo:bill_length_mm\n-1.163\n14.436\n-0.081\n0.936\n\n\n\n\n\n\n\n\n\n\nWrite the model equation for penguins in the Adelie species.\nWrite the model equation for penguins in the Chinstrap species."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#interpreting-interaction-terms",
    "href": "slides/08-model-eval-notes.html#interpreting-interaction-terms",
    "title": "Model evaluation",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of bill length on the body mass is 41.035 less when the penguin is from the Chinstrap species compared to the effect for the Adelie species, holding all else constant.\nInterpreting bill_length_mm for Chinstrap: For each additional millimeter in bill length, we expect the body mass of Chinstrap penguins to increase by 31.657 grams (72.692 - 41.035), holding all else constant."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#summary",
    "href": "slides/08-model-eval-notes.html#summary",
    "title": "Model evaluation",
    "section": "Summary",
    "text": "Summary\n\n\nIn general, how do\n\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#data-restaurant-tips",
    "href": "slides/08-model-eval-notes.html#data-restaurant-tips",
    "title": "Model evaluation",
    "section": "Data: Restaurant tips",
    "text": "Data: Restaurant tips\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\n\n\n# A tibble: 8 × 4\n    Tip Party Meal   Age   \n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n1  2.99     1 Dinner Yadult\n2  2        1 Dinner Yadult\n3  5        1 Dinner SenCit\n4  4        3 Dinner Middle\n5 10.3      2 Dinner SenCit\n6  4.85     2 Dinner Middle\n7  5        4 Dinner Yadult\n8  4        3 Dinner Middle\n\n\n\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#variables-1",
    "href": "slides/08-model-eval-notes.html#variables-1",
    "title": "Model evaluation",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nParty: Number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\n\n\nResponse: Tip: Amount of tip in US dollars"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#response-tip",
    "href": "slides/08-model-eval-notes.html#response-tip",
    "title": "Model evaluation",
    "section": "Response: Tip",
    "text": "Response: Tip\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMin\nQ1\nMedian\nQ3\nMax\nMean\nSD\n\n\n\n\n0\n3\n4.5\n6\n19.46\n4.98\n3.37"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#predictors",
    "href": "slides/08-model-eval-notes.html#predictors",
    "title": "Model evaluation",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#relevel-categorical-predictors",
    "href": "slides/08-model-eval-notes.html#relevel-categorical-predictors",
    "title": "Model evaluation",
    "section": "Relevel categorical predictors",
    "text": "Relevel categorical predictors\n\ntips &lt;- tips |&gt;\n  mutate(\n    Meal = fct_relevel(Meal, \"Lunch\", \"Dinner\", \"Late Night\"),\n    Age  = fct_relevel(Age, \"Yadult\", \"Middle\", \"SenCit\")\n  )"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#predictors-again",
    "href": "slides/08-model-eval-notes.html#predictors-again",
    "title": "Model evaluation",
    "section": "Predictors, again",
    "text": "Predictors, again"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#response-vs.-predictors-1",
    "href": "slides/08-model-eval-notes.html#response-vs.-predictors-1",
    "title": "Model evaluation",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#fit-and-summarize-model",
    "href": "slides/08-model-eval-notes.html#fit-and-summarize-model",
    "title": "Model evaluation",
    "section": "Fit and summarize model",
    "text": "Fit and summarize model\n\ntip_fit &lt;- lm(Tip ~ Party + Age, data = tips)\n\ntidy(tip_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.170\n0.366\n-0.465\n0.643\n\n\nParty\n1.837\n0.124\n14.758\n0.000\n\n\nAgeMiddle\n1.009\n0.408\n2.475\n0.014\n\n\nAgeSenCit\n1.388\n0.485\n2.862\n0.005\n\n\n\n\n\n. . .\n\n\nOverall, how well does this model help us understand variability n tips?"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#two-statistics",
    "href": "slides/08-model-eval-notes.html#two-statistics",
    "title": "Model evaluation",
    "section": "Two statistics",
    "text": "Two statistics\n\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model\n\n\nWhat indicates a good model fit? Higher or lower RMSE? Higher or lower \\(R^2\\)?"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#rmse",
    "href": "slides/08-model-eval-notes.html#rmse",
    "title": "Model evaluation",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n. . .\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#compute-rmse-augmented-data-frame",
    "href": "slides/08-model-eval-notes.html#compute-rmse-augmented-data-frame",
    "title": "Model evaluation",
    "section": "Compute RMSE: Augmented data frame",
    "text": "Compute RMSE: Augmented data frame\nUse the augment() function from the broom package to add columns for predicted values, residuals, and other observation-level model statistics\n\ntip_aug &lt;- augment(tip_fit)\n\n. . .\n\n\n# A tibble: 169 × 9\n     Tip Party Age    .fitted .resid   .hat .sigma   .cooksd .std.resid\n   &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1  2.99     1 Yadult    1.67  1.32  0.0247   2.04 0.00274        0.657\n 2  2        1 Yadult    1.67  0.333 0.0247   2.05 0.000173       0.165\n 3  5        1 SenCit    3.05  1.95  0.0371   2.04 0.00911        0.972\n 4  4        3 Middle    6.35 -2.35  0.0111   2.04 0.00376       -1.16 \n 5 10.3      2 SenCit    4.89  5.45  0.0301   2.00 0.0571         2.71 \n 6  4.85     2 Middle    4.51  0.337 0.0126   2.05 0.0000881      0.166\n 7  5        4 Yadult    7.18 -2.18  0.0471   2.04 0.0148        -1.09 \n 8  4        3 Middle    6.35 -2.35  0.0111   2.04 0.00376       -1.16 \n 9  5        2 Middle    4.51  0.487 0.0126   2.05 0.000184       0.240\n10  1.58     1 SenCit    3.05 -1.47  0.0371   2.04 0.00524       -0.737\n# ℹ 159 more rows"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#finding-rmse-in-r",
    "href": "slides/08-model-eval-notes.html#finding-rmse-in-r",
    "title": "Model evaluation",
    "section": "Finding RMSE in R",
    "text": "Finding RMSE in R\nUse the rmse() function from the yardstick package (part of tidymodels)\n\nrmse(tip_aug, truth = Tip, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        2.02\n\n\n\n. . .\n\nIs the model a good fit for the data? What information do you need to make this determination?"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#analysis-of-variance-anova-1",
    "href": "slides/08-model-eval-notes.html#analysis-of-variance-anova-1",
    "title": "Model evaluation",
    "section": "Analysis of variance (ANOVA)",
    "text": "Analysis of variance (ANOVA)\nAnalysis of Variance (ANOVA): Technique to partition variability in Y by the sources of variability"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#anova",
    "href": "slides/08-model-eval-notes.html#anova",
    "title": "Model evaluation",
    "section": "ANOVA",
    "text": "ANOVA\n\nMain Idea: Decompose the total variation in the response into\n\nthe variation that can be explained by the each of the variables in the model\nthe variation that can’t be explained by the model (left in the residuals)\n\nIf the variation that can be explained by the variables in the model is greater than the variation in the residuals, this signals that the model might be “valuable” (at least one of the \\(\\beta\\)’s not equal to 0)"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#sum-of-squares",
    "href": "slides/08-model-eval-notes.html#sum-of-squares",
    "title": "Model evaluation",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\nClick here to see why this equality holds."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#anova-output-in-r1",
    "href": "slides/08-model-eval-notes.html#anova-output-in-r1",
    "title": "Model evaluation",
    "section": "ANOVA output in R1",
    "text": "ANOVA output in R1\n\nanova(tip_fit) |&gt;\n  tidy() |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\nParty\n1\n1188.64\n1188.64\n285.71\n0.00\n\n\nAge\n2\n38.03\n19.01\n4.57\n0.01\n\n\nResiduals\n165\n686.44\n4.16\nNA\nNA"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#anova-output-with-totals",
    "href": "slides/08-model-eval-notes.html#anova-output-with-totals",
    "title": "Model evaluation",
    "section": "ANOVA output, with totals",
    "text": "ANOVA output, with totals\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\nParty\n1\n1188.64\n1188.64\n285.71\n0\n\n\nAge\n2\n38.03\n19.01\n4.57\n0.01\n\n\nResiduals\n165\n686.44\n4.16\n\n\n\n\nTotal\n168\n1913.11"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#sum-of-squares-1",
    "href": "slides/08-model-eval-notes.html#sum-of-squares-1",
    "title": "Model evaluation",
    "section": "Sum of squares",
    "text": "Sum of squares\n\n\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SST\\): Sum of squares total, variability of the response, \\(\\sum_{i = 1}^n (y_i - \\bar{y})^2\\)\n\\(SSR\\): Sum of squares residuals, variability of residuals, \\(\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2\\)\n\\(SSM = SST - SSR\\): Sum of squares model, variability explained by the model"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#sum-of-squares-sst",
    "href": "slides/08-model-eval-notes.html#sum-of-squares-sst",
    "title": "Model evaluation",
    "section": "Sum of squares: \\(SST\\)",
    "text": "Sum of squares: \\(SST\\)\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SST\\): Sum of squares total, variability of the response\n\n\\(\\sum_{i = 1}^n (y_i - \\bar{y})^2\\) = 1913.11"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#sum-of-squares-ssr",
    "href": "slides/08-model-eval-notes.html#sum-of-squares-ssr",
    "title": "Model evaluation",
    "section": "Sum of squares: \\(SSR\\)",
    "text": "Sum of squares: \\(SSR\\)\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SSR\\): Sum of squares residuals, variability of residuals\n\n\\(\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2\\) = 686.44"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#sum-of-squares-ssm",
    "href": "slides/08-model-eval-notes.html#sum-of-squares-ssm",
    "title": "Model evaluation",
    "section": "Sum of squares: \\(SSM\\)",
    "text": "Sum of squares: \\(SSM\\)\n\n\n\n\n\nterm\ndf\nsumsq\n\n\n\n\nParty\n1\n1188.64\n\n\nAge\n2\n38.03\n\n\nResiduals\n165\n686.44\n\n\nTotal\n168\n1913.11\n\n\n\n\n\n\n\n\n\n\\(SSM\\): Sum of squares model, Variability explained by the model\n\n\\(SST - SSR\\) = 1226.67"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#r2",
    "href": "slides/08-model-eval-notes.html#r2",
    "title": "Model evaluation",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n. . .\n\\[\nR^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST} = 1 - \\frac{686.44}{1913.11} = 0.641\n\\]\n. . .\n\nWhat is the range of \\(R^2\\)? Does \\(R^2\\) have units?"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#interpreting-r2",
    "href": "slides/08-model-eval-notes.html#interpreting-r2",
    "title": "Model evaluation",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\nglance(tip_fit)$r.squared\n\n[1] 0.6411891\n\n\n. . .\n\nSelect the best interpretation for \\(R^2\\) .\n\nParty and age correctly predicts 64.12% of tips.\n64.12% of the variability in tips can be explained by party and age.\n64.12% of the variability in party and age can be explained by tips.\n64.12% of the time tips can be predicted by party and age."
  },
  {
    "objectID": "slides/08-model-eval-notes.html#recap",
    "href": "slides/08-model-eval-notes.html#recap",
    "title": "Model evaluation",
    "section": "Recap",
    "text": "Recap\n\nIntroduced interaction terms\nIntroduced ANOVA and sum of squares\nIntroduced \\(R^2\\) and RMSE"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#next-class",
    "href": "slides/08-model-eval-notes.html#next-class",
    "title": "Model evaluation",
    "section": "Next class",
    "text": "Next class\n\nModel comparison"
  },
  {
    "objectID": "slides/08-model-eval-notes.html#footnotes",
    "href": "slides/08-model-eval-notes.html#footnotes",
    "title": "Model evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nClick here for explanation about the way R calculates sum of squares for each variable.↩︎"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#announcements",
    "href": "slides/14-multicollinearity-contd.html#announcements",
    "title": "Multicollinearity",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due TODAY at 11:59pm on Canvas\nTeam Feedback (email from Teammates) due TODAY at 11:59pm\nHW 03 due Tuesday March 18 at 11:59pm\n\nassigned later today\n\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 17\n\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#computing-set-up",
    "href": "slides/14-multicollinearity-contd.html#computing-set-up",
    "title": "Multicollinearity",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#topics",
    "href": "slides/14-multicollinearity-contd.html#topics",
    "title": "Multicollinearity",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nRecap\nWhat to do about it"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#data-trail-users",
    "href": "slides/14-multicollinearity-contd.html#data-trail-users",
    "title": "Multicollinearity",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#variables",
    "href": "slides/14-multicollinearity-contd.html#variables",
    "title": "Multicollinearity",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#eda-relationship-between-predictors",
    "href": "slides/14-multicollinearity-contd.html#eda-relationship-between-predictors",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#multicollinearity",
    "href": "slides/14-multicollinearity-contd.html#multicollinearity",
    "title": "Multicollinearity",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nMulticollinearity: near-linear dependence among predictors\nThe variance inflation factor (VIF) measures how much the linear dependencies impact the variance of the predictors\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by all the other predictors\n\nThresholds:\n\nVIF &gt; 10: concerning multicollinearity\nVIF &gt; 5: potentially worth further investigationApplication exercise"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#how-multicollinearity-impacts-model",
    "href": "slides/14-multicollinearity-contd.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\n\nWhen we have perfect collinearities, we are unable to get estimates for the coefficients\nWhen we have almost perfect collinearities (i.e. highly correlated predictor variables), the standard errors for our regression coefficients inflate\n\nIn other words, we lose precision in our estimates of the regression coefficients\nThis impedes our ability to use the model for inference\n\nIt is also difficult to interpret the model coefficients"
  },
  {
    "objectID": "slides/14-multicollinearity-contd.html#dealing-with-multicollinearity",
    "href": "slides/14-multicollinearity-contd.html#dealing-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html",
    "href": "slides/14-multicollinearity-contd-notes.html",
    "title": "Multicollinearity",
    "section": "",
    "text": "Exam corrections (optional) due TODAY at 11:59pm on Canvas\nTeam Feedback (email from Teammates) due TODAY at 11:59pm\nHW 03 due Tuesday March 18 at 11:59pm\n\nassigned later today\n\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 17\n\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#announcements",
    "href": "slides/14-multicollinearity-contd-notes.html#announcements",
    "title": "Multicollinearity",
    "section": "",
    "text": "Exam corrections (optional) due TODAY at 11:59pm on Canvas\nTeam Feedback (email from Teammates) due TODAY at 11:59pm\nHW 03 due Tuesday March 18 at 11:59pm\n\nassigned later today\n\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 17\n\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#computing-set-up",
    "href": "slides/14-multicollinearity-contd-notes.html#computing-set-up",
    "title": "Multicollinearity",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#topics",
    "href": "slides/14-multicollinearity-contd-notes.html#topics",
    "title": "Multicollinearity",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nRecap\nWhat to do about it"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#data-trail-users",
    "href": "slides/14-multicollinearity-contd-notes.html#data-trail-users",
    "title": "Multicollinearity",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#variables",
    "href": "slides/14-multicollinearity-contd-notes.html#variables",
    "title": "Multicollinearity",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#eda-relationship-between-predictors",
    "href": "slides/14-multicollinearity-contd-notes.html#eda-relationship-between-predictors",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#multicollinearity",
    "href": "slides/14-multicollinearity-contd-notes.html#multicollinearity",
    "title": "Multicollinearity",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nMulticollinearity: near-linear dependence among predictors\nThe variance inflation factor (VIF) measures how much the linear dependencies impact the variance of the predictors\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by all the other predictors\n\nThresholds:\n\nVIF &gt; 10: concerning multicollinearity\nVIF &gt; 5: potentially worth further investigationApplication exercise"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#how-multicollinearity-impacts-model",
    "href": "slides/14-multicollinearity-contd-notes.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\n\nWhen we have perfect collinearities, we are unable to get estimates for the coefficients\nWhen we have almost perfect collinearities (i.e. highly correlated predictor variables), the standard errors for our regression coefficients inflate\n\nIn other words, we lose precision in our estimates of the regression coefficients\nThis impedes our ability to use the model for inference\n\nIt is also difficult to interpret the model coefficients"
  },
  {
    "objectID": "slides/14-multicollinearity-contd-notes.html#dealing-with-multicollinearity",
    "href": "slides/14-multicollinearity-contd-notes.html#dealing-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#goals",
    "href": "slides/project-peer-review-lab.html#goals",
    "title": "Project peer review",
    "section": "Goals",
    "text": "Goals\n\nProject milestones\nProject peer review"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#upcoming-project-milestones",
    "href": "slides/project-peer-review-lab.html#upcoming-project-milestones",
    "title": "Project peer review",
    "section": "Upcoming project milestones",
    "text": "Upcoming project milestones\n\nDecember 3: Peer review due\nDecember 8: Deadline for Round 1 submission (optional)\nDecember 12: Final report + organized GitHub repo due\n\nSee project instructions for more detail."
  },
  {
    "objectID": "slides/project-peer-review-lab.html#peer-review-assignments---section-01l",
    "href": "slides/project-peer-review-lab.html#peer-review-assignments---section-01l",
    "title": "Project peer review",
    "section": "Peer review assignments - Section 01L",
    "text": "Peer review assignments - Section 01L"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#peer-review-assignments---section-02l",
    "href": "slides/project-peer-review-lab.html#peer-review-assignments---section-02l",
    "title": "Project peer review",
    "section": "Peer review assignments - Section 02L",
    "text": "Peer review assignments - Section 02L"
  },
  {
    "objectID": "slides/project-peer-review-lab.html#getting-started",
    "href": "slides/project-peer-review-lab.html#getting-started",
    "title": "Project peer review",
    "section": "Getting started",
    "text": "Getting started\nFor each team you’re reviewing…\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue.\nWrite your responses to the prompts in the issue.\n\n\n\n\n\n\n\nNote\n\n\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team."
  },
  {
    "objectID": "slides/17-logistic-regression.html#announcements",
    "href": "slides/17-logistic-regression.html#announcements",
    "title": "Logistic regression",
    "section": "Announcements",
    "text": "Announcements\n\nExploratory data analysis due TODAY at 11:59pm\n\nNext milestone: Project presentations March 31 in lab\n\nStatistics experience due April 15"
  },
  {
    "objectID": "slides/17-logistic-regression.html#topics",
    "href": "slides/17-logistic-regression.html#topics",
    "title": "Logistic regression",
    "section": "Topics",
    "text": "Topics\n\n\nOdds and probabilities\nInterpret the coefficients of a logistic regression model with\n\na single categorical predictor\na single quantitative predictor\nmultiple predictors"
  },
  {
    "objectID": "slides/17-logistic-regression.html#computational-setup",
    "href": "slides/17-logistic-regression.html#computational-setup",
    "title": "Logistic regression",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/17-logistic-regression.html#probabilities-vs.-odds1",
    "href": "slides/17-logistic-regression.html#probabilities-vs.-odds1",
    "title": "Logistic regression",
    "section": "Probabilities vs. odds1",
    "text": "Probabilities vs. odds1\nScenario 1: Suppose the probability of a disease among a population of unvaccinated individuals is 0.00369, and the probability of the disease is 0.001 among a population of vaccinated individuals.\nScenario 2: Suppose the probability of a disease among a population of unvaccinated individuals is 0.48052 and the probability of the disease is 0.2 among a population of vaccinated individuals.\n\n\nWhat is the difference in the probability of disease for these two populations?\nWhat are the odds of disease in the population without a vaccine relative to the odds of disease in the with vaccine?\n\n\n\nThis example is from Ledolter (2003) ."
  },
  {
    "objectID": "slides/17-logistic-regression.html#from-odds-to-probabilities",
    "href": "slides/17-logistic-regression.html#from-odds-to-probabilities",
    "title": "Logistic regression",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nodds\n\\[\\text{odds} = \\frac{p}{1-p}\\]\n\nprobability\n\\[p = \\frac{\\text{odds}}{1 + \\text{odds}}\\]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#from-odds-to-probabilities-1",
    "href": "slides/17-logistic-regression.html#from-odds-to-probabilities-1",
    "title": "Logistic regression",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nLogistic model: \\(\\log\\big(\\frac{p}{1-p}\\big) = \\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\)\nOdds = \\(\\exp\\big\\{\\log\\big(\\frac{p}{1-p}\\big)\\big\\} = \\frac{p}{1-p}\\)\nCombining (1) and (2) with what we saw earlier\n\n\n\n\\[p = \\frac{\\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}\\]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#logistic-regression-model",
    "href": "slides/17-logistic-regression.html#logistic-regression-model",
    "title": "Logistic regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\nLogit form: \\[\\log\\Big(\\frac{p}{1-p}\\Big) = \\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\]\n\nProbability form:\n\\[\n\\text{probability} = p = \\frac{\\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}\n\\]\n\nWhy is there no error term \\(\\epsilon\\) when writing the statistical model for logistic regression?"
  },
  {
    "objectID": "slides/17-logistic-regression.html#data-concern-about-rising-ai",
    "href": "slides/17-logistic-regression.html#data-concern-about-rising-ai",
    "title": "Logistic regression",
    "section": "Data: Concern about rising AI",
    "text": "Data: Concern about rising AI\nThis data comes from the 2023 Pew Research Center’s American Trends Panel. The survey aims to capture public opinion about a variety of topics including politics, religion, and technology, among others. We will use data from respondents in Wave 132 of the survey conducted July 31 - August 6, 2023 who completed the survey in 70 minutes or less.\n\nThe goal of this analysis is to understand the relationship between age, how much someone has heard about artificial intelligence (AI), and concern about the increased use of AI in daily life.\n\nA more complete analysis on this topic can be found in the Pew Research Center article Growing public concern about the role of artificial intelligence in daily life by Alec Tyson and Emma Kikuchi."
  },
  {
    "objectID": "slides/17-logistic-regression.html#variables",
    "href": "slides/17-logistic-regression.html#variables",
    "title": "Logistic regression",
    "section": "Variables",
    "text": "Variables\n\nai_concern: Whether a respondent said they are “more concerned than excited” about in the increased use of AI in daily life (1: yes, 0: no)"
  },
  {
    "objectID": "slides/17-logistic-regression.html#variables-1",
    "href": "slides/17-logistic-regression.html#variables-1",
    "title": "Logistic regression",
    "section": "Variables",
    "text": "Variables\n\nsurvey_time: Time to complete the survey (in minutes)\nage_cat: Age category\n\n18-29\n30-49\n50-64\n65+\nRefused"
  },
  {
    "objectID": "slides/17-logistic-regression.html#odds-ratios-concern-about-ai-vs.-age",
    "href": "slides/17-logistic-regression.html#odds-ratios-concern-about-ai-vs.-age",
    "title": "Logistic regression",
    "section": "Odds ratios: Concern about AI vs. age",
    "text": "Odds ratios: Concern about AI vs. age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n487\n380\n\n\n30-49\n1661\n1470\n\n\n50-64\n1257\n1680\n\n\n65+\n1252\n1858\n\n\nRefused\n18\n23"
  },
  {
    "objectID": "slides/17-logistic-regression.html#lets-fit-the-model",
    "href": "slides/17-logistic-regression.html#lets-fit-the-model",
    "title": "Logistic regression",
    "section": "Let’s fit the model",
    "text": "Let’s fit the model\n\nai_concern_fit &lt;- glm(ai_concern ~ age_cat, data = pew_data, \n                      family = \"binomial\")\n\ntidy(ai_concern_fit) |&gt; kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.248\n0.068\n-3.625\n0.000\n\n\nage_cat30-49\n0.126\n0.077\n1.630\n0.103\n\n\nage_cat50-64\n0.538\n0.078\n6.904\n0.000\n\n\nage_cat65+\n0.643\n0.078\n8.284\n0.000\n\n\nage_catRefused\n0.493\n0.322\n1.531\n0.126"
  },
  {
    "objectID": "slides/17-logistic-regression.html#the-model",
    "href": "slides/17-logistic-regression.html#the-model",
    "title": "Logistic regression",
    "section": "The model",
    "text": "The model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.248\n0.068\n-3.625\n0.000\n\n\nage_cat30-49\n0.126\n0.077\n1.630\n0.103\n\n\nage_cat50-64\n0.538\n0.078\n6.904\n0.000\n\n\nage_cat65+\n0.643\n0.078\n8.284\n0.000\n\n\nage_catRefused\n0.493\n0.322\n1.531\n0.126\n\n\n\n\n\n\n\\[\\begin{aligned}\\log\\Big(\\frac{\\hat{p}}{1-\\hat{p}}\\Big) =& -0.248 + 0.126\\times\\text{age_cat30-49} + 0.538 \\times \\text{age_cat50-64}\\\\\n&+ 0.643 \\times \\text{age_cat65+} + 0.493\\times \\text{age_catRefused} \\end{aligned}\\]\nwhere \\(\\hat{p}\\) is the predicted probability of being concerned about increased use of AI in daily life"
  },
  {
    "objectID": "slides/17-logistic-regression.html#interpreting-age_cat30-49-log-odds",
    "href": "slides/17-logistic-regression.html#interpreting-age_cat30-49-log-odds",
    "title": "Logistic regression",
    "section": "Interpreting age_cat30-49: log-odds",
    "text": "Interpreting age_cat30-49: log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.248\n0.068\n-3.625\n0.000\n\n\nage_cat30-49\n0.126\n0.077\n1.630\n0.103\n\n\nage_cat50-64\n0.538\n0.078\n6.904\n0.000\n\n\nage_cat65+\n0.643\n0.078\n8.284\n0.000\n\n\nage_catRefused\n0.493\n0.322\n1.531\n0.126\n\n\n\n\n\n\nThe log-odds of being concerned about increased use of AI in daily life are expected to be 0.126 higher for individuals 30 - 49 years old compared to 18-29 year-olds (the baseline group).\n\n\n\n\n\n\n\nWarning\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/17-logistic-regression.html#interpreting-age_cat30-49-odds",
    "href": "slides/17-logistic-regression.html#interpreting-age_cat30-49-odds",
    "title": "Logistic regression",
    "section": "Interpreting age_cat30-49: odds",
    "text": "Interpreting age_cat30-49: odds\n\n\n\nThe odds of being concerned about increased use of AI in daily life for 30 - 49 year olds are expected to be 1.134 ( \\(e^{0.126}\\) ) times the odds for 18-29 year olds."
  },
  {
    "objectID": "slides/17-logistic-regression.html#coefficients-odds-ratios",
    "href": "slides/17-logistic-regression.html#coefficients-odds-ratios",
    "title": "Logistic regression",
    "section": "Coefficients & odds ratios",
    "text": "Coefficients & odds ratios\nThe model coefficient, 0.126, is the expected difference in the log-odds when comparing 30 - 49 year olds to 18 - 29 year olds.\n\nTherefore, \\(e^{0.126}\\) = 1.134 is the expected change in the odds when comparing 30 - 49 year olds to 18-29 year olds.\n\n\n\\[\nOR  = e^{\\hat{\\beta}_j} = \\exp\\{\\hat{\\beta}_j\\}\n\\]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#interpret-in-terms-of-percent-change",
    "href": "slides/17-logistic-regression.html#interpret-in-terms-of-percent-change",
    "title": "Logistic regression",
    "section": "Interpret in terms of percent change",
    "text": "Interpret in terms of percent change\nYou can also interpret the change in the odds in terms of a percent change. The percent change in the odds can be computed as the following\n\\[\\% \\text{ change } = (e^{\\hat{\\beta}_j} - 1) \\times 100\\]\n\n\nInterpret the coefficient of age_cat30-49 (0.126) in terms of the percent change in the odds."
  },
  {
    "objectID": "slides/17-logistic-regression.html#quantitative-predictor",
    "href": "slides/17-logistic-regression.html#quantitative-predictor",
    "title": "Logistic regression",
    "section": "Quantitative predictor",
    "text": "Quantitative predictor\nNow let’s look at the relationship between survey_time and ai_concern\n\nai_time_fit &lt;- glm(ai_concern ~ survey_time, data = pew_data,\nfamily = \"binomial\")\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.069\n0.037\n1.853\n0.064\n\n\nsurvey_time\n0.005\n0.002\n2.434\n0.015\n\n\n\n\n\n\nFor each additional minute of taking the survey, the odds of being concerned about increased AI in daily life are expected to multiply by a factor of 1.005 ( \\(e^{0.005}\\))."
  },
  {
    "objectID": "slides/17-logistic-regression.html#multiple-predictors",
    "href": "slides/17-logistic-regression.html#multiple-predictors",
    "title": "Logistic regression",
    "section": "Multiple predictors",
    "text": "Multiple predictors\nNow let’s consider a model that takes into account age , ai_heard and survey_time\n\nai_concern_full_fit &lt;- glm(ai_concern ~ age_cat + ai_heard + \n                             survey_time, data = pew_data, family = \"binomial\")"
  },
  {
    "objectID": "slides/17-logistic-regression.html#multiple-predictors-1",
    "href": "slides/17-logistic-regression.html#multiple-predictors-1",
    "title": "Logistic regression",
    "section": "Multiple predictors",
    "text": "Multiple predictors\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.405\n0.077\n-5.230\n0.000\n\n\nage_cat30-49\n0.117\n0.078\n1.504\n0.132\n\n\nage_cat50-64\n0.519\n0.079\n6.587\n0.000\n\n\nage_cat65+\n0.604\n0.079\n7.611\n0.000\n\n\nage_catRefused\n0.557\n0.325\n1.716\n0.086\n\n\nai_heardA little\n0.371\n0.043\n8.654\n0.000\n\n\nai_heardNothing at all\n-0.243\n0.085\n-2.876\n0.004\n\n\nai_heardRefused\n-0.571\n0.505\n-1.131\n0.258\n\n\nsurvey_time\n-0.001\n0.002\n-0.369\n0.712"
  },
  {
    "objectID": "slides/17-logistic-regression.html#interpretation",
    "href": "slides/17-logistic-regression.html#interpretation",
    "title": "Logistic regression",
    "section": "Interpretation",
    "text": "Interpretation\n\n\nUse the model on the previous slide.\n\nDescribe the type of respondent represented by the intercept.\nInterpret the effect of ai_heardNothing at all in terms of the odds of being concerned by increased use of AI in daily life."
  },
  {
    "objectID": "slides/17-logistic-regression.html#predicted-log-odds",
    "href": "slides/17-logistic-regression.html#predicted-log-odds",
    "title": "Logistic regression",
    "section": "Predicted log odds",
    "text": "Predicted log odds\n\naugment(ai_concern_full_fit) |&gt; select(.fitted)\n\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1 -0.0608\n2  0.0756\n3  0.473 \n4  0.560 \n5  0.563 \n\n\n\nFor observation 1\n\\[\\text{predicted odds} = \\hat{\\text{odds}} = \\frac{\\hat{p}}{1-\\hat{p}} = e^{-0.0608} = 0.941\\]"
  },
  {
    "objectID": "slides/17-logistic-regression.html#predicted-probabilities",
    "href": "slides/17-logistic-regression.html#predicted-probabilities",
    "title": "Logistic regression",
    "section": "Predicted probabilities",
    "text": "Predicted probabilities\n\n\nThe predicted log-odds for observation 1 is -0.0608. What is the predicted probability this respondent is concerned about increased use of AI in daily life?"
  },
  {
    "objectID": "slides/17-logistic-regression.html#predicted-probabilities-1",
    "href": "slides/17-logistic-regression.html#predicted-probabilities-1",
    "title": "Logistic regression",
    "section": "Predicted probabilities",
    "text": "Predicted probabilities\nWe can calculate predicted probabilities using the argument type = \"response\" in predict.glm()1\n\npredict.glm(ai_concern_full_fit, type = \"response\")\n\nShowing the predictions for the first 10 observations\n\n\n        1         2         3         4         5         6         7         8 \n0.4848067 0.5188941 0.6161912 0.6364755 0.6371220 0.6366698 0.6159500 0.5257991 \n        9        10 \n0.4898898 0.6329262 \n\n\nThe default is type = \"link\", which produces the predicted log-odds."
  },
  {
    "objectID": "slides/17-logistic-regression.html#predicted-probability-for-new-observation",
    "href": "slides/17-logistic-regression.html#predicted-probability-for-new-observation",
    "title": "Logistic regression",
    "section": "Predicted probability for new observation",
    "text": "Predicted probability for new observation\n\n\nRecall the model that includes predictors age_cat, ai_heard, and survey_time.\n\nWhat are the predicted odds for a 70-year-old respondent who has heard nothing about AI and took 60 minutes to complete the survey?\nWhat is the predicted probability this respondent is not concerned about increased use of AI in daily life?\nWould you classify this person as someone who is concerned or someone who is not? Why?"
  },
  {
    "objectID": "slides/17-logistic-regression.html#predicted-probability-for-new-observation-1",
    "href": "slides/17-logistic-regression.html#predicted-probability-for-new-observation-1",
    "title": "Logistic regression",
    "section": "Predicted probability for new observation",
    "text": "Predicted probability for new observation\n\nnew_obs &lt;- tibble(age_cat = \"65+\", ai_heard = \"Nothing at all\",  \n                  survey_time = 60)\n\npredict.glm(ai_concern_full_fit, newdata = new_obs, \n            type = \"response\")\n\n        1 \n0.4780527"
  },
  {
    "objectID": "slides/17-logistic-regression.html#recap",
    "href": "slides/17-logistic-regression.html#recap",
    "title": "Logistic regression",
    "section": "Recap",
    "text": "Recap\n\nUse the odds ratio to compare the odds of two groups\nInterpret the coefficients of a logistic regression model with\n\na single categorical predictor\na single quantitative predictor\nmultiple predictors"
  },
  {
    "objectID": "slides/17-logistic-regression.html#references",
    "href": "slides/17-logistic-regression.html#references",
    "title": "Logistic regression",
    "section": "References",
    "text": "References\n\n\n\n\nLedolter, Johannes. 2003. “The Statistical Sleuth.” Taylor & Francis."
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html",
    "href": "slides/17-logistic-regression-notes.html",
    "title": "Logistic regression",
    "section": "",
    "text": "Exploratory data analysis due TODAY at 11:59pm\n\nNext milestone: Project presentations March 31 in lab\n\nStatistics experience due April 15"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#announcements",
    "href": "slides/17-logistic-regression-notes.html#announcements",
    "title": "Logistic regression",
    "section": "",
    "text": "Exploratory data analysis due TODAY at 11:59pm\n\nNext milestone: Project presentations March 31 in lab\n\nStatistics experience due April 15"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#topics",
    "href": "slides/17-logistic-regression-notes.html#topics",
    "title": "Logistic regression",
    "section": "Topics",
    "text": "Topics\n\n\nOdds and probabilities\nInterpret the coefficients of a logistic regression model with\n\na single categorical predictor\na single quantitative predictor\nmultiple predictors"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#computational-setup",
    "href": "slides/17-logistic-regression-notes.html#computational-setup",
    "title": "Logistic regression",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#probabilities-vs.-odds1",
    "href": "slides/17-logistic-regression-notes.html#probabilities-vs.-odds1",
    "title": "Logistic regression",
    "section": "Probabilities vs. odds1",
    "text": "Probabilities vs. odds1\nScenario 1: Suppose the probability of a disease among a population of unvaccinated individuals is 0.00369, and the probability of the disease is 0.001 among a population of vaccinated individuals.\nScenario 2: Suppose the probability of a disease among a population of unvaccinated individuals is 0.48052 and the probability of the disease is 0.2 among a population of vaccinated individuals.\n\n\nWhat is the difference in the probability of disease for these two populations?\nWhat are the odds of disease in the population without a vaccine relative to the odds of disease in the with vaccine?"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#from-odds-to-probabilities",
    "href": "slides/17-logistic-regression-notes.html#from-odds-to-probabilities",
    "title": "Logistic regression",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nodds\n\\[\\text{odds} = \\frac{p}{1-p}\\]\n\nprobability\n\\[p = \\frac{\\text{odds}}{1 + \\text{odds}}\\]"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#from-odds-to-probabilities-1",
    "href": "slides/17-logistic-regression-notes.html#from-odds-to-probabilities-1",
    "title": "Logistic regression",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nLogistic model: \\(\\log\\big(\\frac{p}{1-p}\\big) = \\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\)\nOdds = \\(\\exp\\big\\{\\log\\big(\\frac{p}{1-p}\\big)\\big\\} = \\frac{p}{1-p}\\)\nCombining (1) and (2) with what we saw earlier\n\n\n. . .\n\\[p = \\frac{\\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}\\]"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#logistic-regression-model",
    "href": "slides/17-logistic-regression-notes.html#logistic-regression-model",
    "title": "Logistic regression",
    "section": "Logistic regression model",
    "text": "Logistic regression model\nLogit form: \\[\\log\\Big(\\frac{p}{1-p}\\Big) = \\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\]\n. . .\nProbability form:\n\\[\n\\text{probability} = p = \\frac{\\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X_1 + \\dots + \\beta_pX_p\\}}\n\\]\n\nWhy is there no error term \\(\\epsilon\\) when writing the statistical model for logistic regression?"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#data-concern-about-rising-ai",
    "href": "slides/17-logistic-regression-notes.html#data-concern-about-rising-ai",
    "title": "Logistic regression",
    "section": "Data: Concern about rising AI",
    "text": "Data: Concern about rising AI\nThis data comes from the 2023 Pew Research Center’s American Trends Panel. The survey aims to capture public opinion about a variety of topics including politics, religion, and technology, among others. We will use data from respondents in Wave 132 of the survey conducted July 31 - August 6, 2023 who completed the survey in 70 minutes or less.\n\nThe goal of this analysis is to understand the relationship between age, how much someone has heard about artificial intelligence (AI), and concern about the increased use of AI in daily life.\n\nA more complete analysis on this topic can be found in the Pew Research Center article Growing public concern about the role of artificial intelligence in daily life by Alec Tyson and Emma Kikuchi."
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#variables",
    "href": "slides/17-logistic-regression-notes.html#variables",
    "title": "Logistic regression",
    "section": "Variables",
    "text": "Variables\n\nai_concern: Whether a respondent said they are “more concerned than excited” about in the increased use of AI in daily life (1: yes, 0: no)"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#variables-1",
    "href": "slides/17-logistic-regression-notes.html#variables-1",
    "title": "Logistic regression",
    "section": "Variables",
    "text": "Variables\n\nsurvey_time: Time to complete the survey (in minutes)\nage_cat: Age category\n\n18-29\n30-49\n50-64\n65+\nRefused"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#odds-ratios-concern-about-ai-vs.-age",
    "href": "slides/17-logistic-regression-notes.html#odds-ratios-concern-about-ai-vs.-age",
    "title": "Logistic regression",
    "section": "Odds ratios: Concern about AI vs. age",
    "text": "Odds ratios: Concern about AI vs. age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n487\n380\n\n\n30-49\n1661\n1470\n\n\n50-64\n1257\n1680\n\n\n65+\n1252\n1858\n\n\nRefused\n18\n23"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#lets-fit-the-model",
    "href": "slides/17-logistic-regression-notes.html#lets-fit-the-model",
    "title": "Logistic regression",
    "section": "Let’s fit the model",
    "text": "Let’s fit the model\n\nai_concern_fit &lt;- glm(ai_concern ~ age_cat, data = pew_data, \n                      family = \"binomial\")\n\ntidy(ai_concern_fit) |&gt; kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.248\n0.068\n-3.625\n0.000\n\n\nage_cat30-49\n0.126\n0.077\n1.630\n0.103\n\n\nage_cat50-64\n0.538\n0.078\n6.904\n0.000\n\n\nage_cat65+\n0.643\n0.078\n8.284\n0.000\n\n\nage_catRefused\n0.493\n0.322\n1.531\n0.126"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#the-model",
    "href": "slides/17-logistic-regression-notes.html#the-model",
    "title": "Logistic regression",
    "section": "The model",
    "text": "The model\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.248\n0.068\n-3.625\n0.000\n\n\nage_cat30-49\n0.126\n0.077\n1.630\n0.103\n\n\nage_cat50-64\n0.538\n0.078\n6.904\n0.000\n\n\nage_cat65+\n0.643\n0.078\n8.284\n0.000\n\n\nage_catRefused\n0.493\n0.322\n1.531\n0.126\n\n\n\n\n\n\n\\[\\begin{aligned}\\log\\Big(\\frac{\\hat{p}}{1-\\hat{p}}\\Big) =& -0.248 + 0.126\\times\\text{age_cat30-49} + 0.538 \\times \\text{age_cat50-64}\\\\\n&+ 0.643 \\times \\text{age_cat65+} + 0.493\\times \\text{age_catRefused} \\end{aligned}\\]\nwhere \\(\\hat{p}\\) is the predicted probability of being concerned about increased use of AI in daily life"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#interpreting-age_cat30-49-log-odds",
    "href": "slides/17-logistic-regression-notes.html#interpreting-age_cat30-49-log-odds",
    "title": "Logistic regression",
    "section": "Interpreting age_cat30-49: log-odds",
    "text": "Interpreting age_cat30-49: log-odds\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.248\n0.068\n-3.625\n0.000\n\n\nage_cat30-49\n0.126\n0.077\n1.630\n0.103\n\n\nage_cat50-64\n0.538\n0.078\n6.904\n0.000\n\n\nage_cat65+\n0.643\n0.078\n8.284\n0.000\n\n\nage_catRefused\n0.493\n0.322\n1.531\n0.126\n\n\n\n\n\n\nThe log-odds of being concerned about increased use of AI in daily life are expected to be 0.126 higher for individuals 30 - 49 years old compared to 18-29 year-olds (the baseline group).\n. . .\n\n\n\n\n\n\nWarning\n\n\n\nWe would not use the interpretation in terms of log-odds in practice."
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#interpreting-age_cat30-49-odds",
    "href": "slides/17-logistic-regression-notes.html#interpreting-age_cat30-49-odds",
    "title": "Logistic regression",
    "section": "Interpreting age_cat30-49: odds",
    "text": "Interpreting age_cat30-49: odds\n\n\n\nThe odds of being concerned about increased use of AI in daily life for 30 - 49 year olds are expected to be 1.134 ( \\(e^{0.126}\\) ) times the odds for 18-29 year olds."
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#coefficients-odds-ratios",
    "href": "slides/17-logistic-regression-notes.html#coefficients-odds-ratios",
    "title": "Logistic regression",
    "section": "Coefficients & odds ratios",
    "text": "Coefficients & odds ratios\nThe model coefficient, 0.126, is the expected difference in the log-odds when comparing 30 - 49 year olds to 18 - 29 year olds.\n. . .\nTherefore, \\(e^{0.126}\\) = 1.134 is the expected change in the odds when comparing 30 - 49 year olds to 18-29 year olds.\n. . .\n\\[\nOR  = e^{\\hat{\\beta}_j} = \\exp\\{\\hat{\\beta}_j\\}\n\\]"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#interpret-in-terms-of-percent-change",
    "href": "slides/17-logistic-regression-notes.html#interpret-in-terms-of-percent-change",
    "title": "Logistic regression",
    "section": "Interpret in terms of percent change",
    "text": "Interpret in terms of percent change\nYou can also interpret the change in the odds in terms of a percent change. The percent change in the odds can be computed as the following\n\\[\\% \\text{ change } = (e^{\\hat{\\beta}_j} - 1) \\times 100\\]\n\n\nInterpret the coefficient of age_cat30-49 (0.126) in terms of the percent change in the odds."
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#quantitative-predictor",
    "href": "slides/17-logistic-regression-notes.html#quantitative-predictor",
    "title": "Logistic regression",
    "section": "Quantitative predictor",
    "text": "Quantitative predictor\nNow let’s look at the relationship between survey_time and ai_concern\n\nai_time_fit &lt;- glm(ai_concern ~ survey_time, data = pew_data,\nfamily = \"binomial\")\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.069\n0.037\n1.853\n0.064\n\n\nsurvey_time\n0.005\n0.002\n2.434\n0.015\n\n\n\n\n\n. . .\nFor each additional minute of taking the survey, the odds of being concerned about increased AI in daily life are expected to multiply by a factor of 1.005 ( \\(e^{0.005}\\))."
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#multiple-predictors",
    "href": "slides/17-logistic-regression-notes.html#multiple-predictors",
    "title": "Logistic regression",
    "section": "Multiple predictors",
    "text": "Multiple predictors\nNow let’s consider a model that takes into account age , ai_heard and survey_time\n\nai_concern_full_fit &lt;- glm(ai_concern ~ age_cat + ai_heard + \n                             survey_time, data = pew_data, family = \"binomial\")"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#multiple-predictors-1",
    "href": "slides/17-logistic-regression-notes.html#multiple-predictors-1",
    "title": "Logistic regression",
    "section": "Multiple predictors",
    "text": "Multiple predictors\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.405\n0.077\n-5.230\n0.000\n\n\nage_cat30-49\n0.117\n0.078\n1.504\n0.132\n\n\nage_cat50-64\n0.519\n0.079\n6.587\n0.000\n\n\nage_cat65+\n0.604\n0.079\n7.611\n0.000\n\n\nage_catRefused\n0.557\n0.325\n1.716\n0.086\n\n\nai_heardA little\n0.371\n0.043\n8.654\n0.000\n\n\nai_heardNothing at all\n-0.243\n0.085\n-2.876\n0.004\n\n\nai_heardRefused\n-0.571\n0.505\n-1.131\n0.258\n\n\nsurvey_time\n-0.001\n0.002\n-0.369\n0.712"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#interpretation",
    "href": "slides/17-logistic-regression-notes.html#interpretation",
    "title": "Logistic regression",
    "section": "Interpretation",
    "text": "Interpretation\n\n\nUse the model on the previous slide.\n\nDescribe the type of respondent represented by the intercept.\nInterpret the effect of ai_heardNothing at all in terms of the odds of being concerned by increased use of AI in daily life."
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#predicted-log-odds",
    "href": "slides/17-logistic-regression-notes.html#predicted-log-odds",
    "title": "Logistic regression",
    "section": "Predicted log odds",
    "text": "Predicted log odds\n\naugment(ai_concern_full_fit) |&gt; select(.fitted)\n\n\n\n# A tibble: 5 × 1\n  .fitted\n    &lt;dbl&gt;\n1 -0.0608\n2  0.0756\n3  0.473 \n4  0.560 \n5  0.563 \n\n\n. . .\nFor observation 1\n\\[\\text{predicted odds} = \\hat{\\text{odds}} = \\frac{\\hat{p}}{1-\\hat{p}} = e^{-0.0608} = 0.941\\]"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#predicted-probabilities",
    "href": "slides/17-logistic-regression-notes.html#predicted-probabilities",
    "title": "Logistic regression",
    "section": "Predicted probabilities",
    "text": "Predicted probabilities\n\n\nThe predicted log-odds for observation 1 is -0.0608. What is the predicted probability this respondent is concerned about increased use of AI in daily life?"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#predicted-probabilities-1",
    "href": "slides/17-logistic-regression-notes.html#predicted-probabilities-1",
    "title": "Logistic regression",
    "section": "Predicted probabilities",
    "text": "Predicted probabilities\nWe can calculate predicted probabilities using the argument type = \"response\" in predict.glm()2\n\npredict.glm(ai_concern_full_fit, type = \"response\")\n\nShowing the predictions for the first 10 observations\n\n\n        1         2         3         4         5         6         7         8 \n0.4848067 0.5188941 0.6161912 0.6364755 0.6371220 0.6366698 0.6159500 0.5257991 \n        9        10 \n0.4898898 0.6329262"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#predicted-probability-for-new-observation",
    "href": "slides/17-logistic-regression-notes.html#predicted-probability-for-new-observation",
    "title": "Logistic regression",
    "section": "Predicted probability for new observation",
    "text": "Predicted probability for new observation\n\n\nRecall the model that includes predictors age_cat, ai_heard, and survey_time.\n\nWhat are the predicted odds for a 70-year-old respondent who has heard nothing about AI and took 60 minutes to complete the survey?\nWhat is the predicted probability this respondent is not concerned about increased use of AI in daily life?\nWould you classify this person as someone who is concerned or someone who is not? Why?"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#predicted-probability-for-new-observation-1",
    "href": "slides/17-logistic-regression-notes.html#predicted-probability-for-new-observation-1",
    "title": "Logistic regression",
    "section": "Predicted probability for new observation",
    "text": "Predicted probability for new observation\n\nnew_obs &lt;- tibble(age_cat = \"65+\", ai_heard = \"Nothing at all\",  \n                  survey_time = 60)\n\npredict.glm(ai_concern_full_fit, newdata = new_obs, \n            type = \"response\")\n\n        1 \n0.4780527"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#recap",
    "href": "slides/17-logistic-regression-notes.html#recap",
    "title": "Logistic regression",
    "section": "Recap",
    "text": "Recap\n\nUse the odds ratio to compare the odds of two groups\nInterpret the coefficients of a logistic regression model with\n\na single categorical predictor\na single quantitative predictor\nmultiple predictors"
  },
  {
    "objectID": "slides/17-logistic-regression-notes.html#footnotes",
    "href": "slides/17-logistic-regression-notes.html#footnotes",
    "title": "Logistic regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\nThis example is from Ledolter (2003) .\n\n↩︎\nThe default is type = \"link\", which produces the predicted log-odds.↩︎"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#announcements",
    "href": "slides/12-conditions-diagnostics.html#announcements",
    "title": "Model conditions + diagnostics",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Tuesday, March 4 at 11:59pm on Canvas\nProject proposal due Thursday, February 26 at 11:59pm"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#computing-set-up",
    "href": "slides/12-conditions-diagnostics.html#computing-set-up",
    "title": "Model conditions + diagnostics",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)   \nlibrary(viridis)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#topics",
    "href": "slides/12-conditions-diagnostics.html#topics",
    "title": "Model conditions + diagnostics",
    "section": "Topics",
    "text": "Topics\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#data-duke-lemurs",
    "href": "slides/12-conditions-diagnostics.html#data-duke-lemurs",
    "title": "Model conditions + diagnostics",
    "section": "Data: Duke lemurs",
    "text": "Data: Duke lemurs\nToday’s data contains a subset of the original Duke Lemur data set available in the TidyTuesday GitHub repo. This data includes information on “young adult” lemurs from the Coquerel’s sifaka species (PCOQ), the largest species at the Duke Lemur Center. The analysis will focus on the following variables:\n\nage_at_wt_mo: Age in months: Age of the animal when the weight was taken, in months (((Weight_Date-DOB)/365)*12)\nweight_g: Weight: Animal weight, in grams. Weights under 500g generally to nearest 0.1-1g; Weights &gt;500g generally to the nearest 1-20g.\n\nThe goal of the analysis is to use the age of the lemurs to understand variability in the weight."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#eda",
    "href": "slides/12-conditions-diagnostics.html#eda",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#eda-1",
    "href": "slides/12-conditions-diagnostics.html#eda-1",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#fit-model",
    "href": "slides/12-conditions-diagnostics.html#fit-model",
    "title": "Model conditions + diagnostics",
    "section": "Fit model",
    "text": "Fit model\n\nlemurs_fit &lt;- lm(weight_g ~ age_at_wt_mo, data = lemurs)\n\ntidy(lemurs_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#assumptions-for-regression",
    "href": "slides/12-conditions-diagnostics.html#assumptions-for-regression",
    "title": "Model conditions + diagnostics",
    "section": "Assumptions for regression",
    "text": "Assumptions for regression\n\\[\nY|X_1, \\ldots, X_p \\sim N(\\beta_0 + \\beta_1X_1 + \\dots + \\beta_pX_p, \\sigma_\\epsilon^2)\n\\]\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the errors (residuals) is approximately normal.\nIndependence: The errors (residuals) are independent from one another.\n\n\n\nHow do we know if these assumptions hold in our data?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#linearity",
    "href": "slides/12-conditions-diagnostics.html#linearity",
    "title": "Model conditions + diagnostics",
    "section": "Linearity",
    "text": "Linearity\n\nLook at plot of residuals versus fitted (predicted) values.\nLinearity is satisfied if there is no discernible pattern in the plot (i.e., points randomly scattered around \\(residuals = 0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinearity is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#example-linearity-not-satisfied",
    "href": "slides/12-conditions-diagnostics.html#example-linearity-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Linearity not satisfied",
    "text": "Example: Linearity not satisfied\n\n\n\nIf linearity is not satisfied, examine the plots of residuals versus each predictor.\nAdd higher order term(s), as needed."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#constant-variance",
    "href": "slides/12-conditions-diagnostics.html#constant-variance",
    "title": "Model conditions + diagnostics",
    "section": "Constant variance",
    "text": "Constant variance\n\nLook at plot of residuals versus fitted (predicted) values.\nConstant variance is satisfied if the vertical spread of the points is approximately equal for all fitted values\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant variance is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#example-constant-variance-not-satisfied",
    "href": "slides/12-conditions-diagnostics.html#example-constant-variance-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Constant variance not satisfied",
    "text": "Example: Constant variance not satisfied\n\n\n\nCondition is critical for inference\nAddress violations by applying transformation on the response"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#normality",
    "href": "slides/12-conditions-diagnostics.html#normality",
    "title": "Model conditions + diagnostics",
    "section": "Normality",
    "text": "Normality\n\nLook at the distribution of the residuals\nNormality is satisfied if the distribution is approximately unimodal and symmetric. Inference robust to violations if \\(n &gt; 30\\)\n\n\n\n\nDistribution approximately unimodal and symmetric, aside from the outlier. There are 62 observations, so inference robust to departures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#independence",
    "href": "slides/12-conditions-diagnostics.html#independence",
    "title": "Model conditions + diagnostics",
    "section": "Independence",
    "text": "Independence\n\nWe can often check the independence condition based on the context of the data and how the observations were collected.\nIf the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected.\nIf data has spatial element, plot residuals on a map to examine potential spatial correlation.\n\n\n\nThe independence condition is satisfied. The lemurs could reasonably be treated as independent."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#model-diagnostics-1",
    "href": "slides/12-conditions-diagnostics.html#model-diagnostics-1",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nlemurs_aug &lt;- augment(lemurs_fit)\n\nlemurs_aug |&gt; slice(1:10)\n\n# A tibble: 10 × 8\n   weight_g age_at_wt_mo .fitted .resid   .hat .sigma  .cooksd .std.resid\n      &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1     3400         32.0   3557. -157.  0.0302   494. 0.00164      -0.324\n 2     3620         33.0   4063. -443.  0.0399   491. 0.0176       -0.922\n 3     3720         32.4   3800.  -80.0 0.0163   495. 0.000224     -0.164\n 4     4440         32.6   3850.  590.  0.0177   489. 0.0132        1.21 \n 5     3770         31.8   3457.  313.  0.0458   493. 0.0102        0.652\n 6     3920         31.9   3522.  398.  0.0350   492. 0.0124        0.826\n 7     4520         32.8   3979.  541.  0.0279   490. 0.0180        1.12 \n 8     3700         33.2   4177. -477.  0.0626   491. 0.0337       -1.01 \n 9     3690         31.9   3537.  153.  0.0329   494. 0.00172       0.318\n10     3790         32.8   3949. -159.  0.0247   494. 0.00136      -0.328"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#model-diagnostics-in-r",
    "href": "slides/12-conditions-diagnostics.html#model-diagnostics-in-r",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics in R",
    "text": "Model diagnostics in R\nUse the augment() function in the broom package to output the model diagnostics (along with the predicted values and residuals)\n\nresponse and predictor variables in the model\n.fitted: predicted values\n.se.fit: standard errors of predicted values\n.resid: residuals\n.hat: leverage\n.sigma: estimate of residual standard deviation when the corresponding observation is dropped from model\n.cooksd: Cook’s distance\n.std.resid: standardized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#influential-point",
    "href": "slides/12-conditions-diagnostics.html#influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Influential Point",
    "text": "Influential Point\nAn observation is influential if removing has a noticeable impact on the regression coefficients"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#influential-points",
    "href": "slides/12-conditions-diagnostics.html#influential-points",
    "title": "Model conditions + diagnostics",
    "section": "Influential points",
    "text": "Influential points\n\n\nInfluential points have a noticeable impact on the coefficients and standard errors used for inference\nThese points can sometimes be identified in a scatterplot if there is only one predictor variable\n\nThis is often not the case when there are multiple predictors\n\nWe will use measures to quantify an individual observation’s influence on the regression model\n\nleverage, standardized & studentized residuals, and Cook’s distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#motivating-cooks-distance",
    "href": "slides/12-conditions-diagnostics.html#motivating-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Motivating Cook’s Distance",
    "text": "Motivating Cook’s Distance\n\nAn observation’s influence on the regression line depends on\n\nHow close it lies to the general trend of the data\nIts leverage\n\nCook’s Distance is a statistic that includes both of these components to measure an observation’s overall impact on the model"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#cooks-distance-1",
    "href": "slides/12-conditions-diagnostics.html#cooks-distance-1",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance for the \\(i^{th}\\) observation is\n\\[\nD_i = \\frac{r^2_i}{p + 1}\\Big(\\frac{h_{i}}{1 - h_{i}}\\Big)\n\\]\nwhere \\(r_i\\) is the studentized residual and \\(h_{i}\\) is the leverage for the \\(i^{th}\\) observation\n\nThis measure is a combination of\n\nHow well the model fits the \\(i^{th}\\) observation (magnitude of residuals)\nHow far the combination of predictors for the \\(i^{th}\\) observation is from the rest of the observations"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#using-cooks-distance",
    "href": "slides/12-conditions-diagnostics.html#using-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Using Cook’s Distance",
    "text": "Using Cook’s Distance\n\nAn observation with large value of \\(D_i\\) is said to have a strong influence on the predicted values\nGeneral thresholds .An observation with\n\n\\(D_i &gt; 0.5\\) is moderately influential\n\\(D_i &gt; 1\\) is very influential"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#cooks-distance-2",
    "href": "slides/12-conditions-diagnostics.html#cooks-distance-2",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s Distance is in the column .cooksd in the output from the augment() function"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#comparing-models",
    "href": "slides/12-conditions-diagnostics.html#comparing-models",
    "title": "Model conditions + diagnostics",
    "section": "Comparing models",
    "text": "Comparing models\nWith influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000\n\n\n\n\n\n\nWithout influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-6670.958\n3495.136\n-1.909\n0.061\n\n\nage_at_wt_mo\n321.209\n107.904\n2.977\n0.004\n\n\n\n\n\n\n\nLet’s better understand the influential point."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#leverage-1",
    "href": "slides/12-conditions-diagnostics.html#leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Leverage",
    "text": "Leverage\n\n\nLeverage \\((h_i)\\) : a measure of the distance of the predictor (or combination of predictors) for the \\(i^{th}\\) observation is from the mean value of the predictor (or combination of predictors)\nFor simple linear regression:\n\n\\[\nh_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j = 1}^n(x_j - \\bar{x})^2}\n\\]\n\nObservations with large values of \\(h_{i}\\) are far away from the typical value (or combination of values) of the predictors in the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#large-leverage",
    "href": "slides/12-conditions-diagnostics.html#large-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\n\n\nThe sum of the leverages for all points is \\(p + 1\\), where \\(p\\) is the number of predictors in the model\nThe average value of leverage is \\(\\bar{h} =  \\frac{(p+1)}{n}\\)\nAn observation has large leverage if \\[h_{i} &gt; \\frac{2(p+1)}{n}\\]"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#lemurs-leverage",
    "href": "slides/12-conditions-diagnostics.html#lemurs-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Lemurs: Leverage",
    "text": "Lemurs: Leverage\n\nh_threshold &lt;- 2 * 2 / nrow(lemurs)\nh_threshold\n\n[1] 0.06451613\n\n\n\n\nlemurs_aug |&gt;\n  filter(.hat &gt; h_threshold)\n\n# A tibble: 2 × 8\n  weight_g age_at_wt_mo .fitted .resid   .hat .sigma .cooksd .std.resid\n     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     4040         33.5   4336.  -296. 0.107    493.  0.0244     -0.639\n2     6519         33.4   4272.  2247. 0.0871   389.  1.10        4.79 \n\n\n\n\n\n\nWhy do you think these points have large leverage?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#lets-look-at-the-data",
    "href": "slides/12-conditions-diagnostics.html#lets-look-at-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Let’s look at the data",
    "text": "Let’s look at the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#large-leverage-1",
    "href": "slides/12-conditions-diagnostics.html#large-leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\nIf there is point with high leverage, ask\n\n❓ Is there a data entry error?\n❓ Is this observation within the scope of individuals for which you want to make predictions and draw conclusions?\n❓ Is this observation impacting the estimates of the model coefficients? (Need more information!)\n\n\nJust because a point has high leverage does not necessarily mean it will have a substantial impact on the regression. Therefore we need to check other measures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#scaled-residuals-1",
    "href": "slides/12-conditions-diagnostics.html#scaled-residuals-1",
    "title": "Model conditions + diagnostics",
    "section": "Scaled residuals",
    "text": "Scaled residuals\n\n\nWhat is the best way to identify outlier points that don’t fit the pattern from the regression line?\n\nLook for points that have large residuals\n\nWe can rescale residuals and put them on a common scale to more easily identify “large” residuals\nWe will consider two types of scaled residuals: standardized residuals and studentized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#standardized-residuals",
    "href": "slides/12-conditions-diagnostics.html#standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Standardized residuals",
    "text": "Standardized residuals\n\n\nThe variance of the residuals can be estimated by the mean squared residuals (MSR) \\(= \\frac{SSR}{n - p - 1} = \\hat{\\sigma}^2_{\\epsilon}\\)\nWe can use MSR to compute standardized residuals\n\\[\nstd.res_i = \\frac{e_i}{\\sqrt{MSR}}\n\\]\nStandardized residuals are produced by augment() in the column .std.resid"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#using-standardized-residuals",
    "href": "slides/12-conditions-diagnostics.html#using-standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Using standardized residuals",
    "text": "Using standardized residuals\nWe can examine the standardized residuals directly from the output from the augment() function\n\n\nAn observation is a potential outlier if its standardized residual is beyond \\(\\pm 3\\)"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#digging-in-to-the-data",
    "href": "slides/12-conditions-diagnostics.html#digging-in-to-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Digging in to the data",
    "text": "Digging in to the data\nLet’s look at the value of the response variable to better understand potential outliers"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#studentized-residuals",
    "href": "slides/12-conditions-diagnostics.html#studentized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Studentized residuals",
    "text": "Studentized residuals\n\n\nMSR is an approximation of the variance of the residuals.\nA more precise calculation of the variance for the \\(i^{th}\\) residual is is \\(Var(e_i) = \\hat{\\sigma}^2_{\\epsilon}(1 - h_{i})\\)\n\nThis is called the studentized residual\n\n\n\n\\[\nr_i = \\frac{e_{i}}{\\sqrt{\\hat{\\sigma}^2_{\\epsilon}(1 - h_{i})}}\n\\]\n\nStandardized and studentized residuals provide similar information about which points are outliers in the response.\n\nStudentized residuals are used to compute Cook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#using-these-measures",
    "href": "slides/12-conditions-diagnostics.html#using-these-measures",
    "title": "Model conditions + diagnostics",
    "section": "Using these measures",
    "text": "Using these measures\n\nStandardized residuals, leverage, and Cook’s Distance should all be examined together\nExamine plots of the measures to identify observations that are outliers, high leverage, and may potentially impact the model."
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#back-to-the-influential-point",
    "href": "slides/12-conditions-diagnostics.html#back-to-the-influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Back to the influential point",
    "text": "Back to the influential point"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "href": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nFirst consider if the outlier is a result of a data entry error.\nIf not, you may consider dropping an observation if it’s an outlier in the predictor variables if…\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. Mention this in the write up of the results and be careful to avoid extrapolation when making predictions"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "href": "slides/12-conditions-diagnostics.html#what-to-do-with-outliersinfluential-points-1",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nIt is generally not good practice to drop observations that ar outliers in the value of the response variable\n\nThese are legitimate observations and should be in the model\nYou can try transformations or increasing the sample size by collecting more data\n\nA general strategy when there are influential points is to fit the model with and without the influential points and compare the outcomes"
  },
  {
    "objectID": "slides/12-conditions-diagnostics.html#recap",
    "href": "slides/12-conditions-diagnostics.html#recap",
    "title": "Model conditions + diagnostics",
    "section": "Recap",
    "text": "Recap\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html",
    "href": "slides/12-conditions-diagnostics-notes.html",
    "title": "Model conditions + diagnostics",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm on Canvas\nProject proposal due Thursday, February 26 at 11:59pm"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#announcements",
    "href": "slides/12-conditions-diagnostics-notes.html#announcements",
    "title": "Model conditions + diagnostics",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm on Canvas\nProject proposal due Thursday, February 26 at 11:59pm"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#computing-set-up",
    "href": "slides/12-conditions-diagnostics-notes.html#computing-set-up",
    "title": "Model conditions + diagnostics",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)   \nlibrary(viridis)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#topics",
    "href": "slides/12-conditions-diagnostics-notes.html#topics",
    "title": "Model conditions + diagnostics",
    "section": "Topics",
    "text": "Topics\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#data-duke-lemurs",
    "href": "slides/12-conditions-diagnostics-notes.html#data-duke-lemurs",
    "title": "Model conditions + diagnostics",
    "section": "Data: Duke lemurs",
    "text": "Data: Duke lemurs\nToday’s data contains a subset of the original Duke Lemur data set available in the TidyTuesday GitHub repo. This data includes information on “young adult” lemurs from the Coquerel’s sifaka species (PCOQ), the largest species at the Duke Lemur Center. The analysis will focus on the following variables:\n\nage_at_wt_mo: Age in months: Age of the animal when the weight was taken, in months (((Weight_Date-DOB)/365)*12)\nweight_g: Weight: Animal weight, in grams. Weights under 500g generally to nearest 0.1-1g; Weights &gt;500g generally to the nearest 1-20g.\n\nThe goal of the analysis is to use the age of the lemurs to understand variability in the weight."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#eda",
    "href": "slides/12-conditions-diagnostics-notes.html#eda",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#eda-1",
    "href": "slides/12-conditions-diagnostics-notes.html#eda-1",
    "title": "Model conditions + diagnostics",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#fit-model",
    "href": "slides/12-conditions-diagnostics-notes.html#fit-model",
    "title": "Model conditions + diagnostics",
    "section": "Fit model",
    "text": "Fit model\n\nlemurs_fit &lt;- lm(weight_g ~ age_at_wt_mo, data = lemurs)\n\ntidy(lemurs_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#assumptions-for-regression",
    "href": "slides/12-conditions-diagnostics-notes.html#assumptions-for-regression",
    "title": "Model conditions + diagnostics",
    "section": "Assumptions for regression",
    "text": "Assumptions for regression\n\\[\nY|X_1, \\ldots, X_p \\sim N(\\beta_0 + \\beta_1X_1 + \\dots + \\beta_pX_p, \\sigma_\\epsilon^2)\n\\]\n\nLinearity: There is a linear relationship between the response and predictor variables.\nConstant Variance: The variability about the least squares line is generally constant.\nNormality: The distribution of the errors (residuals) is approximately normal.\nIndependence: The errors (residuals) are independent from one another.\n\n. . .\n\nHow do we know if these assumptions hold in our data?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#linearity",
    "href": "slides/12-conditions-diagnostics-notes.html#linearity",
    "title": "Model conditions + diagnostics",
    "section": "Linearity",
    "text": "Linearity\n\nLook at plot of residuals versus fitted (predicted) values.\nLinearity is satisfied if there is no discernible pattern in the plot (i.e., points randomly scattered around \\(residuals = 0\\)\n\n. . .\n\n\n\n\n\n\n\n\n\n. . .\n\nLinearity is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#example-linearity-not-satisfied",
    "href": "slides/12-conditions-diagnostics-notes.html#example-linearity-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Linearity not satisfied",
    "text": "Example: Linearity not satisfied\n\n\n\n\n\n\n\n\n\n. . .\n\nIf linearity is not satisfied, examine the plots of residuals versus each predictor.\nAdd higher order term(s), as needed."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#constant-variance",
    "href": "slides/12-conditions-diagnostics-notes.html#constant-variance",
    "title": "Model conditions + diagnostics",
    "section": "Constant variance",
    "text": "Constant variance\n\nLook at plot of residuals versus fitted (predicted) values.\nConstant variance is satisfied if the vertical spread of the points is approximately equal for all fitted values\n\n. . .\n\n\n\n\n\n\n\n\n\n. . .\n\nConstant variance is satisfied"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#example-constant-variance-not-satisfied",
    "href": "slides/12-conditions-diagnostics-notes.html#example-constant-variance-not-satisfied",
    "title": "Model conditions + diagnostics",
    "section": "Example: Constant variance not satisfied",
    "text": "Example: Constant variance not satisfied\n\n\n\n\n\n\n\n\n\n. . .\n\nCondition is critical for inference\nAddress violations by applying transformation on the response"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#normality",
    "href": "slides/12-conditions-diagnostics-notes.html#normality",
    "title": "Model conditions + diagnostics",
    "section": "Normality",
    "text": "Normality\n\nLook at the distribution of the residuals\nNormality is satisfied if the distribution is approximately unimodal and symmetric. Inference robust to violations if \\(n &gt; 30\\)\n\n\n\n\n\n\n\n\n\n\n. . .\n\nDistribution approximately unimodal and symmetric, aside from the outlier. There are 62 observations, so inference robust to departures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#independence",
    "href": "slides/12-conditions-diagnostics-notes.html#independence",
    "title": "Model conditions + diagnostics",
    "section": "Independence",
    "text": "Independence\n\nWe can often check the independence condition based on the context of the data and how the observations were collected.\nIf the data were collected in a particular order, examine a scatterplot of the residuals versus order in which the data were collected.\nIf data has spatial element, plot residuals on a map to examine potential spatial correlation.\n\n. . .\n\nThe independence condition is satisfied. The lemurs could reasonably be treated as independent."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-1",
    "href": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-1",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics",
    "text": "Model diagnostics\n\nlemurs_aug &lt;- augment(lemurs_fit)\n\nlemurs_aug |&gt; slice(1:10)\n\n# A tibble: 10 × 8\n   weight_g age_at_wt_mo .fitted .resid   .hat .sigma  .cooksd .std.resid\n      &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n 1     3400         32.0   3557. -157.  0.0302   494. 0.00164      -0.324\n 2     3620         33.0   4063. -443.  0.0399   491. 0.0176       -0.922\n 3     3720         32.4   3800.  -80.0 0.0163   495. 0.000224     -0.164\n 4     4440         32.6   3850.  590.  0.0177   489. 0.0132        1.21 \n 5     3770         31.8   3457.  313.  0.0458   493. 0.0102        0.652\n 6     3920         31.9   3522.  398.  0.0350   492. 0.0124        0.826\n 7     4520         32.8   3979.  541.  0.0279   490. 0.0180        1.12 \n 8     3700         33.2   4177. -477.  0.0626   491. 0.0337       -1.01 \n 9     3690         31.9   3537.  153.  0.0329   494. 0.00172       0.318\n10     3790         32.8   3949. -159.  0.0247   494. 0.00136      -0.328"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-in-r",
    "href": "slides/12-conditions-diagnostics-notes.html#model-diagnostics-in-r",
    "title": "Model conditions + diagnostics",
    "section": "Model diagnostics in R",
    "text": "Model diagnostics in R\nUse the augment() function in the broom package to output the model diagnostics (along with the predicted values and residuals)\n\nresponse and predictor variables in the model\n.fitted: predicted values\n.se.fit: standard errors of predicted values\n.resid: residuals\n.hat: leverage\n.sigma: estimate of residual standard deviation when the corresponding observation is dropped from model\n.cooksd: Cook’s distance\n.std.resid: standardized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#influential-point",
    "href": "slides/12-conditions-diagnostics-notes.html#influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Influential Point",
    "text": "Influential Point\nAn observation is influential if removing has a noticeable impact on the regression coefficients"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#influential-points",
    "href": "slides/12-conditions-diagnostics-notes.html#influential-points",
    "title": "Model conditions + diagnostics",
    "section": "Influential points",
    "text": "Influential points\n\n\nInfluential points have a noticeable impact on the coefficients and standard errors used for inference\nThese points can sometimes be identified in a scatterplot if there is only one predictor variable\n\nThis is often not the case when there are multiple predictors\n\nWe will use measures to quantify an individual observation’s influence on the regression model\n\nleverage, standardized & studentized residuals, and Cook’s distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#motivating-cooks-distance",
    "href": "slides/12-conditions-diagnostics-notes.html#motivating-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Motivating Cook’s Distance",
    "text": "Motivating Cook’s Distance\n\nAn observation’s influence on the regression line depends on\n\nHow close it lies to the general trend of the data\nIts leverage\n\nCook’s Distance is a statistic that includes both of these components to measure an observation’s overall impact on the model"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#cooks-distance-1",
    "href": "slides/12-conditions-diagnostics-notes.html#cooks-distance-1",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s distance for the \\(i^{th}\\) observation is\n\\[\nD_i = \\frac{r^2_i}{p + 1}\\Big(\\frac{h_{i}}{1 - h_{i}}\\Big)\n\\]\nwhere \\(r_i\\) is the studentized residual and \\(h_{i}\\) is the leverage for the \\(i^{th}\\) observation\n. . .\nThis measure is a combination of\n\nHow well the model fits the \\(i^{th}\\) observation (magnitude of residuals)\nHow far the combination of predictors for the \\(i^{th}\\) observation is from the rest of the observations"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#using-cooks-distance",
    "href": "slides/12-conditions-diagnostics-notes.html#using-cooks-distance",
    "title": "Model conditions + diagnostics",
    "section": "Using Cook’s Distance",
    "text": "Using Cook’s Distance\n\nAn observation with large value of \\(D_i\\) is said to have a strong influence on the predicted values\nGeneral thresholds .An observation with\n\n\\(D_i &gt; 0.5\\) is moderately influential\n\\(D_i &gt; 1\\) is very influential"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#cooks-distance-2",
    "href": "slides/12-conditions-diagnostics-notes.html#cooks-distance-2",
    "title": "Model conditions + diagnostics",
    "section": "Cook’s Distance",
    "text": "Cook’s Distance\nCook’s Distance is in the column .cooksd in the output from the augment() function"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#comparing-models",
    "href": "slides/12-conditions-diagnostics-notes.html#comparing-models",
    "title": "Model conditions + diagnostics",
    "section": "Comparing models",
    "text": "Comparing models\nWith influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-12314.360\n4252.696\n-2.896\n0.005\n\n\nage_at_wt_mo\n496.591\n131.225\n3.784\n0.000\n\n\n\n\n\n\nWithout influential point\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-6670.958\n3495.136\n-1.909\n0.061\n\n\nage_at_wt_mo\n321.209\n107.904\n2.977\n0.004\n\n\n\n\n\n. . .\n\nLet’s better understand the influential point."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#leverage-1",
    "href": "slides/12-conditions-diagnostics-notes.html#leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Leverage",
    "text": "Leverage\n\n\nLeverage \\((h_i)\\) : a measure of the distance of the predictor (or combination of predictors) for the \\(i^{th}\\) observation is from the mean value of the predictor (or combination of predictors)\nFor simple linear regression:\n\n\\[\nh_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum_{j = 1}^n(x_j - \\bar{x})^2}\n\\]\n\nObservations with large values of \\(h_{i}\\) are far away from the typical value (or combination of values) of the predictors in the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#large-leverage",
    "href": "slides/12-conditions-diagnostics-notes.html#large-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\n\n\nThe sum of the leverages for all points is \\(p + 1\\), where \\(p\\) is the number of predictors in the model\nThe average value of leverage is \\(\\bar{h} =  \\frac{(p+1)}{n}\\)\nAn observation has large leverage if \\[h_{i} &gt; \\frac{2(p+1)}{n}\\]"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#lemurs-leverage",
    "href": "slides/12-conditions-diagnostics-notes.html#lemurs-leverage",
    "title": "Model conditions + diagnostics",
    "section": "Lemurs: Leverage",
    "text": "Lemurs: Leverage\n\nh_threshold &lt;- 2 * 2 / nrow(lemurs)\nh_threshold\n\n[1] 0.06451613\n\n\n. . .\n\nlemurs_aug |&gt;\n  filter(.hat &gt; h_threshold)\n\n# A tibble: 2 × 8\n  weight_g age_at_wt_mo .fitted .resid   .hat .sigma .cooksd .std.resid\n     &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     4040         33.5   4336.  -296. 0.107    493.  0.0244     -0.639\n2     6519         33.4   4272.  2247. 0.0871   389.  1.10        4.79 \n\n\n\n. . .\n\nWhy do you think these points have large leverage?"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#lets-look-at-the-data",
    "href": "slides/12-conditions-diagnostics-notes.html#lets-look-at-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Let’s look at the data",
    "text": "Let’s look at the data"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#large-leverage-1",
    "href": "slides/12-conditions-diagnostics-notes.html#large-leverage-1",
    "title": "Model conditions + diagnostics",
    "section": "Large leverage",
    "text": "Large leverage\nIf there is point with high leverage, ask\n\n❓ Is there a data entry error?\n❓ Is this observation within the scope of individuals for which you want to make predictions and draw conclusions?\n❓ Is this observation impacting the estimates of the model coefficients? (Need more information!)\n\n. . .\nJust because a point has high leverage does not necessarily mean it will have a substantial impact on the regression. Therefore we need to check other measures."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#scaled-residuals-1",
    "href": "slides/12-conditions-diagnostics-notes.html#scaled-residuals-1",
    "title": "Model conditions + diagnostics",
    "section": "Scaled residuals",
    "text": "Scaled residuals\n\n\nWhat is the best way to identify outlier points that don’t fit the pattern from the regression line?\n\nLook for points that have large residuals\n\nWe can rescale residuals and put them on a common scale to more easily identify “large” residuals\nWe will consider two types of scaled residuals: standardized residuals and studentized residuals"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#standardized-residuals",
    "href": "slides/12-conditions-diagnostics-notes.html#standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Standardized residuals",
    "text": "Standardized residuals\n\n\nThe variance of the residuals can be estimated by the mean squared residuals (MSR) \\(= \\frac{SSR}{n - p - 1} = \\hat{\\sigma}^2_{\\epsilon}\\)\nWe can use MSR to compute standardized residuals\n\\[\nstd.res_i = \\frac{e_i}{\\sqrt{MSR}}\n\\]\nStandardized residuals are produced by augment() in the column .std.resid"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#using-standardized-residuals",
    "href": "slides/12-conditions-diagnostics-notes.html#using-standardized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Using standardized residuals",
    "text": "Using standardized residuals\nWe can examine the standardized residuals directly from the output from the augment() function\n\n\n\n\n\n\n\n\n\n\nAn observation is a potential outlier if its standardized residual is beyond \\(\\pm 3\\)"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#digging-in-to-the-data",
    "href": "slides/12-conditions-diagnostics-notes.html#digging-in-to-the-data",
    "title": "Model conditions + diagnostics",
    "section": "Digging in to the data",
    "text": "Digging in to the data\nLet’s look at the value of the response variable to better understand potential outliers"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#studentized-residuals",
    "href": "slides/12-conditions-diagnostics-notes.html#studentized-residuals",
    "title": "Model conditions + diagnostics",
    "section": "Studentized residuals",
    "text": "Studentized residuals\n\n\nMSR is an approximation of the variance of the residuals.\nA more precise calculation of the variance for the \\(i^{th}\\) residual is is \\(Var(e_i) = \\hat{\\sigma}^2_{\\epsilon}(1 - h_{i})\\)\n\nThis is called the studentized residual\n\n\n\n\\[\nr_i = \\frac{e_{i}}{\\sqrt{\\hat{\\sigma}^2_{\\epsilon}(1 - h_{i})}}\n\\]\n\nStandardized and studentized residuals provide similar information about which points are outliers in the response.\n\nStudentized residuals are used to compute Cook’s Distance"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#using-these-measures",
    "href": "slides/12-conditions-diagnostics-notes.html#using-these-measures",
    "title": "Model conditions + diagnostics",
    "section": "Using these measures",
    "text": "Using these measures\n\nStandardized residuals, leverage, and Cook’s Distance should all be examined together\nExamine plots of the measures to identify observations that are outliers, high leverage, and may potentially impact the model."
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#back-to-the-influential-point",
    "href": "slides/12-conditions-diagnostics-notes.html#back-to-the-influential-point",
    "title": "Model conditions + diagnostics",
    "section": "Back to the influential point",
    "text": "Back to the influential point"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points",
    "href": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nFirst consider if the outlier is a result of a data entry error.\nIf not, you may consider dropping an observation if it’s an outlier in the predictor variables if…\n\nIt is meaningful to drop the observation given the context of the problem\nYou intended to build a model on a smaller range of the predictor variables. Mention this in the write up of the results and be careful to avoid extrapolation when making predictions"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points-1",
    "href": "slides/12-conditions-diagnostics-notes.html#what-to-do-with-outliersinfluential-points-1",
    "title": "Model conditions + diagnostics",
    "section": "What to do with outliers/influential points?",
    "text": "What to do with outliers/influential points?\n\n\nIt is generally not good practice to drop observations that ar outliers in the value of the response variable\n\nThese are legitimate observations and should be in the model\nYou can try transformations or increasing the sample size by collecting more data\n\nA general strategy when there are influential points is to fit the model with and without the influential points and compare the outcomes"
  },
  {
    "objectID": "slides/12-conditions-diagnostics-notes.html#recap",
    "href": "slides/12-conditions-diagnostics-notes.html#recap",
    "title": "Model conditions + diagnostics",
    "section": "Recap",
    "text": "Recap\n\nModel conditions\nInfluential points\nModel diagnostics\n\nLeverage\nStudentized residuals\nCook’s Distance"
  },
  {
    "objectID": "slides/01-welcome.html#meet-prof.-tackett",
    "href": "slides/01-welcome.html#meet-prof.-tackett",
    "title": "Welcome to STA 210!",
    "section": "Meet Prof. Tackett!",
    "text": "Meet Prof. Tackett!\n\n\nEducation and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education, curriculum design, and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 2-year-old twins 🙂"
  },
  {
    "objectID": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "href": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet the Teaching Assistants (TAs)!",
    "text": "Meet the Teaching Assistants (TAs)!\n\nSylvia Vincent (PhD): Head TA + Lab leader\nIshrit Gupta (UG): Lab 02 helper\nKareena Legare (UG): Lab 01 helper"
  },
  {
    "objectID": "slides/01-welcome.html#check-in-on-ed-discussion",
    "href": "slides/01-welcome.html#check-in-on-ed-discussion",
    "title": "Welcome to STA 210!",
    "section": "Check-in on Ed Discussion!",
    "text": "Check-in on Ed Discussion!\n\nClick on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/70992/discussion/5951332"
  },
  {
    "objectID": "slides/01-welcome.html#topics",
    "href": "slides/01-welcome.html#topics",
    "title": "Welcome to STA 210!",
    "section": "Topics",
    "text": "Topics\n\nIntroduction to the course\nSyllabus activity\nData exploration (time permitting)"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-regression-analysis",
    "href": "slides/01-welcome.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nRegression analysis is a statistical method used to examine the relationship between a response variable and one or more predictor variables. It is used for predicting future values, understanding relationships between variables, and identifying key predictors. It also helps in modeling trends, assessing the impact of changes, and detecting outliers in data.\n\nSource: ChatGPT (with modification)"
  },
  {
    "objectID": "slides/01-welcome.html#regression-in-practice",
    "href": "slides/01-welcome.html#regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome.html#regression-in-practice-1",
    "href": "slides/01-welcome.html#regression-in-practice-1",
    "title": "Welcome to STA 210!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\\[\n\\text{Lookups} = 23.0 - 0.04 \\times \\text{Page Number}\n\\]\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome.html#what-is-sta-210",
    "href": "slides/01-welcome.html#what-is-sta-210",
    "title": "Welcome to STA 210!",
    "section": "What is STA 210?",
    "text": "What is STA 210?\nLearn how to use linear and and logistic regression models to analyze multivariable relationships and answer questions about real-world phenomena using a data-driven approach.\nThis course emphasizes application over mathematical theory.\nPre-requisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L\n\n\n\n\n\n\n\nNote\n\n\nIf you are interested in the theoretical aspects of regression and/or becoming a statistics major, STA 221 - Regression Analysis: Theory and Applications may be a better fit. Come talk with me after class!"
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 210!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nInference\nModel assessment\nModel assumptions and diagnostics\nDifferent types of predictors\nModel comparison + cross validation\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nInference\nMultinomial logistic regression\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta210-sp25.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/47067\n\nOffice hours\nGradebook\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta210-sp25\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit",
    "href": "slides/01-welcome.html#computing-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 210 Docker Containers\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 210 course organization"
  },
  {
    "objectID": "slides/01-welcome.html#classroom-community",
    "href": "slides/01-welcome.html#classroom-community",
    "title": "Welcome to STA 210!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity",
    "href": "slides/01-welcome.html#syllabus-activity",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nIntroduce yourself to your group members.\nChoose a reporter. This person will share the group’s summary with the class.\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have.\nThe reporter will share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-assignments",
    "href": "slides/01-welcome.html#syllabus-activity-assignments",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: What to expect in the course\nGroup 2: Homework and lab assignments\nGroup 3: Exams Project, Participation\nGroup 4: Academic honesty (except AI policy)\nGroup 5: Artificial intelligence policy\nGroup 6:Late work policy and waiver for extenuating circumstances\nGroup 7: Attendance and lecture recording request\nGroup 8: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-report-out",
    "href": "slides/01-welcome.html#syllabus-activity-report-out",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\n\nGroup 1: What to expect in the course\nGroup 2: Homework and lab assignments\nGroup 3: Exams Project, Participation\nGroup 4: Academic honesty (except AI policy)\nGroup 5: Artificial intelligence policy\nGroup 6:Late work policy and waiver for extenuating circumstances\nGroup 7: Attendance and lecture recording request\nGroup 8: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nFinal project\n15%\n\n\nLabs\n10%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\nTotal\n100%"
  },
  {
    "objectID": "slides/01-welcome.html#five-tips-for-success-in-sta-210",
    "href": "slides/01-welcome.html#five-tips-for-success-in-sta-210",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success in STA 210",
    "text": "Five tips for success in STA 210\n\nComplete all the preparation work before class.\nAsk questions in class, office hours, and on Ed Discussion.\nDo the homework and labs; get started on homework early when possible.\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStay up-to-date on announcements on Ed Discussion and sent via email."
  },
  {
    "objectID": "slides/01-welcome.html#before-next-class",
    "href": "slides/01-welcome.html#before-next-class",
    "title": "Welcome to STA 210!",
    "section": "Before next class",
    "text": "Before next class\n\nReview syllabus\nComplete Prepare for Lecture 02: The big picture\nLabs start on Monday, January 13\nOffice hours start on Monday, January 13"
  },
  {
    "objectID": "slides/01-welcome-notes.html",
    "href": "slides/01-welcome-notes.html",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Education and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education, curriculum design, and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 2-year-old twins 🙂\n\n\n\n\n\n\n\nSylvia Vincent (PhD): Head TA + Lab leader\nIshrit Gupta (UG): Lab 02 helper\nKareena Legare (UG): Lab 01 helper\n\n\n\n\n\nClick on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/70992/discussion/5951332\n\n\n\n\n\n\n\n\n\nIntroduction to the course\nSyllabus activity\nData exploration (time permitting)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#meet-prof.-tackett",
    "href": "slides/01-welcome-notes.html#meet-prof.-tackett",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Education and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education, curriculum design, and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 2-year-old twins 🙂"
  },
  {
    "objectID": "slides/01-welcome-notes.html#meet-the-teaching-assistants-tas",
    "href": "slides/01-welcome-notes.html#meet-the-teaching-assistants-tas",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Sylvia Vincent (PhD): Head TA + Lab leader\nIshrit Gupta (UG): Lab 02 helper\nKareena Legare (UG): Lab 01 helper"
  },
  {
    "objectID": "slides/01-welcome-notes.html#check-in-on-ed-discussion",
    "href": "slides/01-welcome-notes.html#check-in-on-ed-discussion",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Click on the link or scan the QR code to answer the Ed Discussion poll\nhttps://edstem.org/us/courses/70992/discussion/5951332"
  },
  {
    "objectID": "slides/01-welcome-notes.html#topics",
    "href": "slides/01-welcome-notes.html#topics",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Introduction to the course\nSyllabus activity\nData exploration (time permitting)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-regression-analysis",
    "href": "slides/01-welcome-notes.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nRegression analysis is a statistical method used to examine the relationship between a response variable and one or more predictor variables. It is used for predicting future values, understanding relationships between variables, and identifying key predictors. It also helps in modeling trends, assessing the impact of changes, and detecting outliers in data.\n\nSource: ChatGPT (with modification)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#regression-in-practice",
    "href": "slides/01-welcome-notes.html#regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome-notes.html#regression-in-practice-1",
    "href": "slides/01-welcome-notes.html#regression-in-practice-1",
    "title": "Welcome to STA 210!",
    "section": "Regression in practice",
    "text": "Regression in practice\n\n\n\n\n\n\\[\n\\text{Lookups} = 23.0 - 0.04 \\times \\text{Page Number}\n\\]\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-sta-210",
    "href": "slides/01-welcome-notes.html#what-is-sta-210",
    "title": "Welcome to STA 210!",
    "section": "What is STA 210?",
    "text": "What is STA 210?\nLearn how to use linear and and logistic regression models to analyze multivariable relationships and answer questions about real-world phenomena using a data-driven approach.\nThis course emphasizes application over mathematical theory.\nPre-requisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L\n. . .\n\n\n\n\n\n\nNote\n\n\n\nIf you are interested in the theoretical aspects of regression and/or becoming a statistics major, STA 221 - Regression Analysis: Theory and Applications may be a better fit. Come talk with me after class!"
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-learning-objectives",
    "href": "slides/01-welcome-notes.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-topics",
    "href": "slides/01-welcome-notes.html#course-topics",
    "title": "Welcome to STA 210!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nInference\nModel assessment\nModel assumptions and diagnostics\nDifferent types of predictors\nModel comparison + cross validation\n\n\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel assessment\nInference\nMultinomial logistic regression\n\n\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork"
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-toolkit",
    "href": "slides/01-welcome-notes.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta210-sp25.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/47067\n\nOffice hours\nGradebook\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta210-sp25\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome-notes.html#computing-toolkit",
    "href": "slides/01-welcome-notes.html#computing-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 210 Docker Containers\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 210 course organization"
  },
  {
    "objectID": "slides/01-welcome-notes.html#classroom-community",
    "href": "slides/01-welcome-notes.html#classroom-community",
    "title": "Welcome to STA 210!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome-notes.html#accessibility",
    "href": "slides/01-welcome-notes.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity",
    "href": "slides/01-welcome-notes.html#syllabus-activity",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nIntroduce yourself to your group members.\nChoose a reporter. This person will share the group’s summary with the class.\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have.\nThe reporter will share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity-assignments",
    "href": "slides/01-welcome-notes.html#syllabus-activity-assignments",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: What to expect in the course\nGroup 2: Homework and lab assignments\nGroup 3: Exams Project, Participation\nGroup 4: Academic honesty (except AI policy)\nGroup 5: Artificial intelligence policy\nGroup 6:Late work policy and waiver for extenuating circumstances\nGroup 7: Attendance and lecture recording request\nGroup 8: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity-report-out",
    "href": "slides/01-welcome-notes.html#syllabus-activity-report-out",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\n\nGroup 1: What to expect in the course\nGroup 2: Homework and lab assignments\nGroup 3: Exams Project, Participation\nGroup 4: Academic honesty (except AI policy)\nGroup 5: Artificial intelligence policy\nGroup 6:Late work policy and waiver for extenuating circumstances\nGroup 7: Attendance and lecture recording request\nGroup 8: Getting help in the course"
  },
  {
    "objectID": "slides/01-welcome-notes.html#grading",
    "href": "slides/01-welcome-notes.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nFinal project\n15%\n\n\nLabs\n10%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\nTotal\n100%"
  },
  {
    "objectID": "slides/01-welcome-notes.html#five-tips-for-success-in-sta-210",
    "href": "slides/01-welcome-notes.html#five-tips-for-success-in-sta-210",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success in STA 210",
    "text": "Five tips for success in STA 210\n\nComplete all the preparation work before class.\nAsk questions in class, office hours, and on Ed Discussion.\nDo the homework and labs; get started on homework early when possible.\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStay up-to-date on announcements on Ed Discussion and sent via email."
  },
  {
    "objectID": "slides/01-welcome-notes.html#before-next-class",
    "href": "slides/01-welcome-notes.html#before-next-class",
    "title": "Welcome to STA 210!",
    "section": "Before next class",
    "text": "Before next class\n\nReview syllabus\nComplete Prepare for Lecture 02: The big picture\nLabs start on Monday, January 13\nOffice hours start on Monday, January 13"
  },
  {
    "objectID": "slides/03-slr-intro.html#announcements",
    "href": "slides/03-slr-intro.html#announcements",
    "title": "Simple Linear Regression",
    "section": "Announcements",
    "text": "Announcements\n\nNo labs or office hours Monday, January 20 - Martin Luther King Jr. Holiday\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/03-slr-intro.html#topics",
    "href": "slides/03-slr-intro.html#topics",
    "title": "Simple Linear Regression",
    "section": "Topics",
    "text": "Topics\n\n\nUse simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nEstimate the slope and intercept of the regression line using the least squares method.\nInterpret the slope and intercept of the regression line.\nPredict the response given a value of the predictor variable.\nFit linear regression models in R"
  },
  {
    "objectID": "slides/03-slr-intro.html#computation-set-up",
    "href": "slides/03-slr-intro.html#computation-set-up",
    "title": "Simple Linear Regression",
    "section": "Computation set up",
    "text": "Computation set up\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(fivethirtyeight) # for the fandango dataset\nlibrary(knitr)          # for formatting tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-scores",
    "href": "slides/03-slr-intro.html#movie-scores",
    "title": "Simple Linear Regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/03-slr-intro.html#data-prep",
    "href": "slides/03-slr-intro.html#data-prep",
    "title": "Simple Linear Regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the data set as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/03-slr-intro.html#data-overview",
    "href": "slides/03-slr-intro.html#data-overview",
    "title": "Simple Linear Regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"A…\n$ year                       &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ critics                    &lt;int&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,…\n$ audience                   &lt;int&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,…\n$ metacritic                 &lt;int&gt; 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,…\n$ metacritic_user            &lt;dbl&gt; 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8…\n$ imdb                       &lt;dbl&gt; 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4…\n$ fandango_stars             &lt;dbl&gt; 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5…\n$ fandango_ratingvalue       &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0…\n$ rt_norm                    &lt;dbl&gt; 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4…\n$ rt_user_norm               &lt;dbl&gt; 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3…\n$ metacritic_norm            &lt;dbl&gt; 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4…\n$ metacritic_user_nom        &lt;dbl&gt; 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3…\n$ imdb_norm                  &lt;dbl&gt; 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3…\n$ rt_norm_round              &lt;dbl&gt; 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0…\n$ rt_user_norm_round         &lt;dbl&gt; 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0…\n$ metacritic_norm_round      &lt;dbl&gt; 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0…\n$ metacritic_user_norm_round &lt;dbl&gt; 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5…\n$ imdb_norm_round            &lt;dbl&gt; 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5…\n$ metacritic_user_vote_count &lt;int&gt; 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54…\n$ imdb_user_vote_count       &lt;int&gt; 271107, 65709, 103660, 3136, 19560, 39373, …\n$ fandango_votes             &lt;int&gt; 14846, 12640, 12055, 1793, 1021, 397, 252, …\n$ fandango_difference        &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…"
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-scores-data",
    "href": "slides/03-slr-intro.html#movie-scores-data",
    "title": "Simple Linear Regression",
    "section": "Movie scores data",
    "text": "Movie scores data\nThe data set contains the “Tomatometer” score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-ratings-data",
    "href": "slides/03-slr-intro.html#movie-ratings-data",
    "title": "Simple Linear Regression",
    "section": "Movie ratings data",
    "text": "Movie ratings data\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/03-slr-intro.html#why-fit-a-line",
    "href": "slides/03-slr-intro.html#why-fit-a-line",
    "title": "Simple Linear Regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n\nPrediction\n\nWhat is the audience score expected to be for an upcoming movie that received 35% from the critics?\n\n\n\n\nInference\n\nIs the critics score a useful predictor of the audience score? By how much is the audience score expected to change for each additional point in the critics score?"
  },
  {
    "objectID": "slides/03-slr-intro.html#terminology",
    "href": "slides/03-slr-intro.html#terminology",
    "title": "Simple Linear Regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, Y: variable describing the outcome of interest\nPredictor, X: variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model",
    "href": "slides/03-slr-intro.html#regression-model",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mathbf{E(Y|X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model-1",
    "href": "slides/03-slr-intro.html#regression-model-1",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= {\\color{purple} \\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= {\\color{purple} \\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= {\\color{purple} \\mathbf{E(Y|X)}} + \\epsilon \\\\[8pt]\n&= {\\color{purple} \\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mu_{Y|X}\\) is the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model-2",
    "href": "slides/03-slr-intro.html#regression-model-2",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{E(Y|X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#slr-statistical-model-theoretical",
    "href": "slides/03-slr-intro.html#slr-statistical-model-theoretical",
    "title": "Simple Linear Regression",
    "section": "SLR: Statistical model (Theoretical)",
    "text": "SLR: Statistical model (Theoretical)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\).\n\n\\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\]\n\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon_i\\): Error for the \\(i^{th}\\) observation"
  },
  {
    "objectID": "slides/03-slr-intro.html#slr-regression-equation-fitted",
    "href": "slides/03-slr-intro.html#slr-regression-equation-fitted",
    "title": "Simple Linear Regression",
    "section": "SLR: Regression equation (Fitted)",
    "text": "SLR: Regression equation (Fitted)\n\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\n\\]\n\n\n\\(\\hat{\\beta}_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!\n\n\n\nWhy is there no error term in the estimated regression equation?"
  },
  {
    "objectID": "slides/03-slr-intro.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "href": "slides/03-slr-intro.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/03-slr-intro.html#residuals",
    "href": "slides/03-slr-intro.html#residuals",
    "title": "Simple Linear Regression",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#least-squares-line",
    "href": "slides/03-slr-intro.html#least-squares-line",
    "title": "Simple Linear Regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe Ordinary Least Squares (OLS) line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/03-slr-intro.html#steps-to-compute-estimate-hatbeta_0",
    "href": "slides/03-slr-intro.html#steps-to-compute-estimate-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Steps to compute estimate \\(\\hat{\\beta}_0\\)",
    "text": "Steps to compute estimate \\(\\hat{\\beta}_0\\)\n\n\nClick here for full details on estimating \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) for simple linear regression."
  },
  {
    "objectID": "slides/03-slr-intro.html#properties-of-least-squares-regression",
    "href": "slides/03-slr-intro.html#properties-of-least-squares-regression",
    "title": "Simple Linear Regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/03-slr-intro.html#estimating-the-slope",
    "href": "slides/03-slr-intro.html#estimating-the-slope",
    "title": "Simple Linear Regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\\begin{aligned}\ns_X &= 30.1688 \\\\\ns_Y &=  20.0244 \\\\\nr &= 0.7814\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\n\\hat{\\beta}_1 &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\\n&= 0.5187\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#estimating-the-intercept",
    "href": "slides/03-slr-intro.html#estimating-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n\n\\[\\begin{aligned}\n&\\bar{x} = 60.8493 \\\\\n&\\bar{y} = 63.8767 \\\\\n&\\hat{\\beta}_1 = 0.5187\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= 32.3142\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#interpretation",
    "href": "slides/03-slr-intro.html#interpretation",
    "title": "Simple Linear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\n\\widehat{\\text{audience}} = 32.3142 + 0.5187 \\times \\text{critics}\n\\]\n\nAnswer the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n🔗 https://edstem.org/us/courses/70992/discussion/5978732"
  },
  {
    "objectID": "slides/03-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/03-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n\n\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/03-slr-intro.html#making-a-prediction",
    "href": "slides/03-slr-intro.html#making-a-prediction",
    "title": "Simple Linear Regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= 68.6232\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\nCaution\n\n\nUsing the model to predict for values outside the range of the original data is extrapolation. Why do we want to avoid extrapolation?"
  },
  {
    "objectID": "slides/03-slr-intro.html#fit-the-model",
    "href": "slides/03-slr-intro.html#fit-the-model",
    "title": "Simple Linear Regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/03-slr-intro.html#tidy-results",
    "href": "slides/03-slr-intro.html#tidy-results",
    "title": "Simple Linear Regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-intro.html#format-results",
    "href": "slides/03-slr-intro.html#format-results",
    "title": "Simple Linear Regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/03-slr-intro.html#prediction-1",
    "href": "slides/03-slr-intro.html#prediction-1",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/03-slr-intro.html#prediction-2",
    "href": "slides/03-slr-intro.html#prediction-2",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/03-slr-intro.html#recap",
    "href": "slides/03-slr-intro.html#recap",
    "title": "Simple Linear Regression",
    "section": "Recap",
    "text": "Recap\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nUsed the least squares method to estimate the slope and intercept.\nInterpreted the slope and intercept.\nPredicted the response given a value of the predictor variable.\nUsed R to fit the regression line and calculate predictions"
  },
  {
    "objectID": "slides/03-slr-intro.html#for-next-class",
    "href": "slides/03-slr-intro.html#for-next-class",
    "title": "Simple Linear Regression",
    "section": "For next class",
    "text": "For next class\n\nPrepare for Lecture 04: Inference for simple linear regression"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html",
    "href": "slides/03-slr-intro-notes.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "No labs or office hours Monday, January 20 - Martin Luther King Jr. Holiday\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#announcements",
    "href": "slides/03-slr-intro-notes.html#announcements",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "No labs or office hours Monday, January 20 - Martin Luther King Jr. Holiday\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#topics",
    "href": "slides/03-slr-intro-notes.html#topics",
    "title": "Simple Linear Regression",
    "section": "Topics",
    "text": "Topics\n\n\nUse simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nEstimate the slope and intercept of the regression line using the least squares method.\nInterpret the slope and intercept of the regression line.\nPredict the response given a value of the predictor variable.\nFit linear regression models in R"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#computation-set-up",
    "href": "slides/03-slr-intro-notes.html#computation-set-up",
    "title": "Simple Linear Regression",
    "section": "Computation set up",
    "text": "Computation set up\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(fivethirtyeight) # for the fandango dataset\nlibrary(knitr)          # for formatting tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#movie-scores",
    "href": "slides/03-slr-intro-notes.html#movie-scores",
    "title": "Simple Linear Regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#data-prep",
    "href": "slides/03-slr-intro-notes.html#data-prep",
    "title": "Simple Linear Regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the data set as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#data-overview",
    "href": "slides/03-slr-intro-notes.html#data-overview",
    "title": "Simple Linear Regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"A…\n$ year                       &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ critics                    &lt;int&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,…\n$ audience                   &lt;int&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,…\n$ metacritic                 &lt;int&gt; 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,…\n$ metacritic_user            &lt;dbl&gt; 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8…\n$ imdb                       &lt;dbl&gt; 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4…\n$ fandango_stars             &lt;dbl&gt; 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5…\n$ fandango_ratingvalue       &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0…\n$ rt_norm                    &lt;dbl&gt; 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4…\n$ rt_user_norm               &lt;dbl&gt; 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3…\n$ metacritic_norm            &lt;dbl&gt; 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4…\n$ metacritic_user_nom        &lt;dbl&gt; 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3…\n$ imdb_norm                  &lt;dbl&gt; 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3…\n$ rt_norm_round              &lt;dbl&gt; 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0…\n$ rt_user_norm_round         &lt;dbl&gt; 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0…\n$ metacritic_norm_round      &lt;dbl&gt; 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0…\n$ metacritic_user_norm_round &lt;dbl&gt; 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5…\n$ imdb_norm_round            &lt;dbl&gt; 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5…\n$ metacritic_user_vote_count &lt;int&gt; 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54…\n$ imdb_user_vote_count       &lt;int&gt; 271107, 65709, 103660, 3136, 19560, 39373, …\n$ fandango_votes             &lt;int&gt; 14846, 12640, 12055, 1793, 1021, 397, 252, …\n$ fandango_difference        &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#movie-scores-data",
    "href": "slides/03-slr-intro-notes.html#movie-scores-data",
    "title": "Simple Linear Regression",
    "section": "Movie scores data",
    "text": "Movie scores data\nThe data set contains the “Tomatometer” score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#movie-ratings-data",
    "href": "slides/03-slr-intro-notes.html#movie-ratings-data",
    "title": "Simple Linear Regression",
    "section": "Movie ratings data",
    "text": "Movie ratings data\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#why-fit-a-line",
    "href": "slides/03-slr-intro-notes.html#why-fit-a-line",
    "title": "Simple Linear Regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n. . .\n\nPrediction\n\nWhat is the audience score expected to be for an upcoming movie that received 35% from the critics?\n\n. . .\n\nInference\n\nIs the critics score a useful predictor of the audience score? By how much is the audience score expected to change for each additional point in the critics score?"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#terminology",
    "href": "slides/03-slr-intro-notes.html#terminology",
    "title": "Simple Linear Regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, Y: variable describing the outcome of interest\nPredictor, X: variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#regression-model",
    "href": "slides/03-slr-intro-notes.html#regression-model",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mathbf{E(Y|X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#regression-model-1",
    "href": "slides/03-slr-intro-notes.html#regression-model-1",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= {\\color{purple} \\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= {\\color{purple} \\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= {\\color{purple} \\mathbf{E(Y|X)}} + \\epsilon \\\\[8pt]\n&= {\\color{purple} \\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mu_{Y|X}\\) is the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#regression-model-2",
    "href": "slides/03-slr-intro-notes.html#regression-model-2",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{E(Y|X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#slr-statistical-model-theoretical",
    "href": "slides/03-slr-intro-notes.html#slr-statistical-model-theoretical",
    "title": "Simple Linear Regression",
    "section": "SLR: Statistical model (Theoretical)",
    "text": "SLR: Statistical model (Theoretical)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\).\n\n\\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\]\n\n. . .\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon_i\\): Error for the \\(i^{th}\\) observation"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#slr-regression-equation-fitted",
    "href": "slides/03-slr-intro-notes.html#slr-regression-equation-fitted",
    "title": "Simple Linear Regression",
    "section": "SLR: Regression equation (Fitted)",
    "text": "SLR: Regression equation (Fitted)\n\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\n\\]\n\n\n\\(\\hat{\\beta}_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!\n\n. . .\n\nWhy is there no error term in the estimated regression equation?"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "href": "slides/03-slr-intro-notes.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#residuals",
    "href": "slides/03-slr-intro-notes.html#residuals",
    "title": "Simple Linear Regression",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#least-squares-line",
    "href": "slides/03-slr-intro-notes.html#least-squares-line",
    "title": "Simple Linear Regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe Ordinary Least Squares (OLS) line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#steps-to-compute-estimate-hatbeta_0",
    "href": "slides/03-slr-intro-notes.html#steps-to-compute-estimate-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Steps to compute estimate \\(\\hat{\\beta}_0\\)",
    "text": "Steps to compute estimate \\(\\hat{\\beta}_0\\)\n\n\nClick here for full details on estimating \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) for simple linear regression."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#properties-of-least-squares-regression",
    "href": "slides/03-slr-intro-notes.html#properties-of-least-squares-regression",
    "title": "Simple Linear Regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#estimating-the-slope",
    "href": "slides/03-slr-intro-notes.html#estimating-the-slope",
    "title": "Simple Linear Regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\\begin{aligned}\ns_X &= 30.1688 \\\\\ns_Y &=  20.0244 \\\\\nr &= 0.7814\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\n\\hat{\\beta}_1 &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\\n&= 0.5187\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#estimating-the-intercept",
    "href": "slides/03-slr-intro-notes.html#estimating-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n\n\\[\\begin{aligned}\n&\\bar{x} = 60.8493 \\\\\n&\\bar{y} = 63.8767 \\\\\n&\\hat{\\beta}_1 = 0.5187\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= 32.3142\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#interpretation",
    "href": "slides/03-slr-intro-notes.html#interpretation",
    "title": "Simple Linear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\n\\widehat{\\text{audience}} = 32.3142 + 0.5187 \\times \\text{critics}\n\\]\n\nAnswer the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n🔗 https://edstem.org/us/courses/70992/discussion/5978732"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/03-slr-intro-notes.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n. . .\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n. . .\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#making-a-prediction",
    "href": "slides/03-slr-intro-notes.html#making-a-prediction",
    "title": "Simple Linear Regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= 68.6232\n\\end{aligned}\\]\n\n. . .\n\n\n\n\n\n\nCaution\n\n\n\nUsing the model to predict for values outside the range of the original data is extrapolation. Why do we want to avoid extrapolation?"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#fit-the-model",
    "href": "slides/03-slr-intro-notes.html#fit-the-model",
    "title": "Simple Linear Regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience ~ critics, data = movie_scores)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#tidy-results",
    "href": "slides/03-slr-intro-notes.html#tidy-results",
    "title": "Simple Linear Regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#format-results",
    "href": "slides/03-slr-intro-notes.html#format-results",
    "title": "Simple Linear Regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience ~ critics, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#prediction-1",
    "href": "slides/03-slr-intro-notes.html#prediction-1",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#prediction-2",
    "href": "slides/03-slr-intro-notes.html#prediction-2",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#recap",
    "href": "slides/03-slr-intro-notes.html#recap",
    "title": "Simple Linear Regression",
    "section": "Recap",
    "text": "Recap\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nUsed the least squares method to estimate the slope and intercept.\nInterpreted the slope and intercept.\nPredicted the response given a value of the predictor variable.\nUsed R to fit the regression line and calculate predictions"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#for-next-class",
    "href": "slides/03-slr-intro-notes.html#for-next-class",
    "title": "Simple Linear Regression",
    "section": "For next class",
    "text": "For next class\n\nPrepare for Lecture 04: Inference for simple linear regression"
  },
  {
    "objectID": "slides/exam-01-review.html#todays-lab",
    "href": "slides/exam-01-review.html#todays-lab",
    "title": "Exam 01 review",
    "section": "Today’s lab",
    "text": "Today’s lab\n\nWork through Exercises 8 - 16 on\nYou can push your work to your AE 07 repo.\n\nThere is no lab assignment for this week."
  },
  {
    "objectID": "slides/exam-01-review.html#formulas-youre-expected-to-know",
    "href": "slides/exam-01-review.html#formulas-youre-expected-to-know",
    "title": "Exam 01 review",
    "section": "Formulas you’re expected to know",
    "text": "Formulas you’re expected to know\n\nSum of Square Residuals: \\(SSR = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\\)\nRegression standard error: \\(\\hat{\\sigma}_{\\epsilon} = \\sqrt{\\frac{SSR}{n - p - 1}}\\)\nRoot Mean Square Error: \\(RMSE = \\sqrt{\\frac{SSR}{n}}\\)\nTest statistic for \\(\\beta_j\\): \\(= \\frac{\\hat{\\beta}_j - Null}{SE(\\hat{\\beta}_j)}\\)\nConfidence interval for coefficient: \\(\\hat{\\beta}_j \\pm t^* \\times SE(\\hat{\\beta}_j)\\)\n\\(R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\)"
  },
  {
    "objectID": "slides/lab-01.html#tips-for-working-on-lab",
    "href": "slides/lab-01.html#tips-for-working-on-lab",
    "title": "Lab 01",
    "section": "Tips for working on lab",
    "text": "Tips for working on lab\n\nYou do not have to finish the lab in class, they will always be due Thursday. One work strategy is to get through portions that you think will be most challenging (which initially might be the coding component) during lab when a TA can help you on the spot and leave the narrative writing until later.\nDo not pressure each other to finish early (particularly once you start working on teams); use the time wisely to really learn the material and produce a quality report."
  },
  {
    "objectID": "slides/lab-01.html#tips-axis-labels-and-titles",
    "href": "slides/lab-01.html#tips-axis-labels-and-titles",
    "title": "Lab 01",
    "section": "Tips: Axis labels and titles",
    "text": "Tips: Axis labels and titles\n\nBelow is a graph of association between flipper length in millimeters and body mass in grams of three species of penguins in Palmer Station, Antarctica. What are informative title and axis labels for this graph?"
  },
  {
    "objectID": "slides/lab-01.html#tips-code-style",
    "href": "slides/lab-01.html#tips-code-style",
    "title": "Lab 01",
    "section": "Tips: Code style",
    "text": "Tips: Code style\nWhich code chunk would you rather read?\n\n# code chunk 1\npenguins|&gt;filter(!is.na(flipper_length_mm))|&gt;group_by(species)|&gt;summarise(min=min(flipper_length_mm),mean=mean(flipper_length_mm),sd=sd(flipper_length_mm),max=max(flipper_length_mm),n=n())\n\n\n\n\n# code chunk 2\npenguins |&gt; \n  filter(!is.na(flipper_length_mm)) |&gt; \n  group_by(species) |&gt; \n  summarise(min = min(flipper_length_mm), \n            mean = mean(flipper_length_mm), \n            max = max(flipper_length_mm),\n            n = n())"
  },
  {
    "objectID": "slides/lab-01.html#tips-code-style-contd",
    "href": "slides/lab-01.html#tips-code-style-contd",
    "title": "Lab 01",
    "section": "Tips: Code style cont’d",
    "text": "Tips: Code style cont’d\nMake code easier to read and debug by\n\nPutting each element on a different line (start a new line after + and |&gt;)\nPutting spaces before and after operators (+, -, *, =, |&gt; )\nIn general, avoiding long lines of code, i.e. lines longer than 80 characters.\n\nSee the Tidyverse Style Guide for more tips on code styling."
  },
  {
    "objectID": "slides/lab-01.html#when-youre-done-with-lab",
    "href": "slides/lab-01.html#when-youre-done-with-lab",
    "title": "Lab 01",
    "section": "When you’re done with lab",
    "text": "When you’re done with lab\n\nMake sure all your final changes have been pushed to your GitHub repo\nSubmit the PDF of your responses to Gradescope"
  },
  {
    "objectID": "slides/lab-01.html#lab-01-linear-regression",
    "href": "slides/lab-01.html#lab-01-linear-regression",
    "title": "Lab 01",
    "section": "Lab 01: Linear regression",
    "text": "Lab 01: Linear regression\n\nToday’s lab focuses on using linear regression to explore the relationship between air temperature and ice duration for two lakes in Wisconsin, along with the change in ice duration over time.\nThere are markers throughout suggesting when to render, commit, and push changes to GitHub. These are to help you start using version control in your workflow.\nThere are points for having a neatly formatted document and implementing a reproducible workflow\n\n🔗 sta210-sp25.netlify.app/labs/lab-01.html"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#announcements",
    "href": "slides/04-slr-bootstrap.html#announcements",
    "title": "SLR: Simulation-based inference",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Tuesday, January 28 at 11:59pm\n\nReleased after class today"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#ae-03-follow-up-1",
    "href": "slides/04-slr-bootstrap.html#ae-03-follow-up-1",
    "title": "SLR: Simulation-based inference",
    "section": "AE 03 Follow-up",
    "text": "AE 03 Follow-up\nGoal: Use simple linear regression to model the relationship between temperature and daily bike rentals in the winter season"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#topics",
    "href": "slides/04-slr-bootstrap.html#topics",
    "title": "SLR: Simulation-based inference",
    "section": "Topics",
    "text": "Topics\n\nIntroduce inference for a population slope\nFind range of plausible values for the slope using bootstrap confidence intervals"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computational-setup",
    "href": "slides/04-slr-bootstrap.html#computational-setup",
    "title": "SLR: Simulation-based inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#data-houses-in-duke-forest",
    "href": "slides/04-slr-bootstrap.html#data-houses-in-duke-forest",
    "title": "SLR: Simulation-based inference",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#exploratory-data-analysis",
    "href": "slides/04-slr-bootstrap.html#exploratory-data-analysis",
    "title": "SLR: Simulation-based inference",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\nCode\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"sales price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#modeling",
    "href": "slides/04-slr-bootstrap.html#modeling",
    "title": "SLR: Simulation-based inference",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) #neatly format table to 2 digits\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation useful?\n\nSlope: For each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#from-sample-to-population",
    "href": "slides/04-slr-bootstrap.html#from-sample-to-population",
    "title": "SLR: Simulation-based inference",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#statistical-inference",
    "href": "slides/04-slr-bootstrap.html#statistical-inference",
    "title": "SLR: Simulation-based inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference provide methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population we’re interested in"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#inference-for-simple-linear-regression",
    "href": "slides/04-slr-bootstrap.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation-based inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope,\\(\\beta_1\\)"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval",
    "href": "slides/04-slr-bootstrap.html#confidence-interval",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval-for-the-slope-1",
    "href": "slides/04-slr-bootstrap.html#confidence-interval-for-the-slope-1",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#quantify-the-variability-of-the-slope",
    "href": "slides/04-slr-bootstrap.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation-based inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what we’ll do today)\nVia theoretical results and mathematical models (what we’ll do in an upcoming class)\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample, i.e. take sample of size \\(n\\) with replacement\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-1",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-2",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-2",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-3",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-3",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-4",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-4",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-5",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nso on and so forth…"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-samples-1---5",
    "href": "slides/04-slr-bootstrap.html#bootstrap-samples-1---5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-samples-1---100",
    "href": "slides/04-slr-bootstrap.html#bootstrap-samples-1---100",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples",
    "href": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples-1",
    "href": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples-1",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-level",
    "href": "slides/04-slr-bootstrap.html#confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval-1",
    "href": "slides/04-slr-bootstrap.html#confidence-interval-1",
    "title": "SLR: Simulation-based inference",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, sales price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-i",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-i",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" #default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#precision-vs.-accuracy",
    "href": "slides/04-slr-bootstrap.html#precision-vs.-accuracy",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#precision-vs.-accuracy-1",
    "href": "slides/04-slr-bootstrap.html#precision-vs.-accuracy-1",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#changing-confidence-level",
    "href": "slides/04-slr-bootstrap.html#changing-confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#changing-confidence-level-1",
    "href": "slides/04-slr-bootstrap.html#changing-confidence-level-1",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#recap",
    "href": "slides/04-slr-bootstrap.html#recap",
    "title": "SLR: Simulation-based inference",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#for-next-class",
    "href": "slides/04-slr-bootstrap.html#for-next-class",
    "title": "SLR: Simulation-based inference",
    "section": "For next class",
    "text": "For next class\n\nComplete Prepare for Lecture 05: Inference for simple linear regression"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html",
    "href": "slides/04-slr-bootstrap-notes.html",
    "title": "SLR: Simulation-based inference",
    "section": "",
    "text": "HW 01 due Tuesday, January 28 at 11:59pm\n\nReleased after class today"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#announcements",
    "href": "slides/04-slr-bootstrap-notes.html#announcements",
    "title": "SLR: Simulation-based inference",
    "section": "",
    "text": "HW 01 due Tuesday, January 28 at 11:59pm\n\nReleased after class today"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#ae-03-follow-up-1",
    "href": "slides/04-slr-bootstrap-notes.html#ae-03-follow-up-1",
    "title": "SLR: Simulation-based inference",
    "section": "AE 03 Follow-up",
    "text": "AE 03 Follow-up\nGoal: Use simple linear regression to model the relationship between temperature and daily bike rentals in the winter season"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#topics",
    "href": "slides/04-slr-bootstrap-notes.html#topics",
    "title": "SLR: Simulation-based inference",
    "section": "Topics",
    "text": "Topics\n\nIntroduce inference for a population slope\nFind range of plausible values for the slope using bootstrap confidence intervals"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computational-setup",
    "href": "slides/04-slr-bootstrap-notes.html#computational-setup",
    "title": "SLR: Simulation-based inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#data-houses-in-duke-forest",
    "href": "slides/04-slr-bootstrap-notes.html#data-houses-in-duke-forest",
    "title": "SLR: Simulation-based inference",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#exploratory-data-analysis",
    "href": "slides/04-slr-bootstrap-notes.html#exploratory-data-analysis",
    "title": "SLR: Simulation-based inference",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\nCode\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"sales price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#modeling",
    "href": "slides/04-slr-bootstrap-notes.html#modeling",
    "title": "SLR: Simulation-based inference",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) #neatly format table to 2 digits\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n. . .\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation useful?\n\nSlope: For each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#from-sample-to-population",
    "href": "slides/04-slr-bootstrap-notes.html#from-sample-to-population",
    "title": "SLR: Simulation-based inference",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#statistical-inference",
    "href": "slides/04-slr-bootstrap-notes.html#statistical-inference",
    "title": "SLR: Simulation-based inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference provide methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population we’re interested in"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#inference-for-simple-linear-regression",
    "href": "slides/04-slr-bootstrap-notes.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation-based inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope,\\(\\beta_1\\)"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-interval",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-interval",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-interval-for-the-slope-1",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-interval-for-the-slope-1",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n. . .\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#quantify-the-variability-of-the-slope",
    "href": "slides/04-slr-bootstrap-notes.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation-based inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what we’ll do today)\nVia theoretical results and mathematical models (what we’ll do in an upcoming class)\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample, i.e. take sample of size \\(n\\) with replacement\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-1",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-2",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-2",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-3",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-3",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-4",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-4",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-5",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n. . .\nso on and so forth…"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---5",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---100",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---100",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples",
    "href": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples-1",
    "href": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples-1",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-level",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-interval-1",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-interval-1",
    "title": "SLR: Simulation-based inference",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\n\n\n\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, sales price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-i",
    "href": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-i",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" #default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy",
    "href": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n. . ."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy-1",
    "href": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy-1",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#changing-confidence-level",
    "href": "slides/04-slr-bootstrap-notes.html#changing-confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#changing-confidence-level-1",
    "href": "slides/04-slr-bootstrap-notes.html#changing-confidence-level-1",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#recap",
    "href": "slides/04-slr-bootstrap-notes.html#recap",
    "title": "SLR: Simulation-based inference",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#for-next-class",
    "href": "slides/04-slr-bootstrap-notes.html#for-next-class",
    "title": "SLR: Simulation-based inference",
    "section": "For next class",
    "text": "For next class\n\nComplete Prepare for Lecture 05: Inference for simple linear regression"
  },
  {
    "objectID": "slides/lab-03.html#goals",
    "href": "slides/lab-03.html#goals",
    "title": "Lab 03",
    "section": "Goals",
    "text": "Goals\n\nStart final project\nLab 03: Model comparison"
  },
  {
    "objectID": "slides/lab-03.html#final-project",
    "href": "slides/lab-03.html#final-project",
    "title": "Lab 03",
    "section": "Final project",
    "text": "Final project\n\nGoal: Use the methods from STA 210 to analyze data and answer a research question developed by your team\nPrimary deliverables:\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are periodic project milestones throughout the semester to help you work towards the primary deliverables"
  },
  {
    "objectID": "slides/lab-03.html#todays-focus-research-topics",
    "href": "slides/lab-03.html#todays-focus-research-topics",
    "title": "Lab 03",
    "section": "Today’s focus: Research topics",
    "text": "Today’s focus: Research topics\n\nGoals: Identify three potential research topics your team is interested in investigating and draft research questions.\nYou do not need to have a data set at this point\nYou can discuss the topics you put in the student survey to help generate ideas\nSubmission (due Feb 16): All work for the project will be submitted in your team’s GitHub repo. You will receive feedback via an Issue on GitHub to model a workflow often used in practice.\n\n🔗https://sta210-sp25.netlify.app/project"
  },
  {
    "objectID": "slides/lab-03.html#todays-lab",
    "href": "slides/lab-03.html#todays-lab",
    "title": "Lab 03",
    "section": "Today’s lab",
    "text": "Today’s lab\nToday’s lab focuses on using model comparison to choose a model that can be used to describe what makes the best candy.\n\n🔗 https://sta210-sp25.netlify.app/labs/lab-03"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\nweek\ndow\ndate\ntopic\nprepare\nslides\nnotes\nae\nhw\nlab\nproject\ndue\n\n\n\n\n1\nTh\nJan 9\nWelcome to STA 210!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\nJan 13\nLab 00: Getting started\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 14\nThe big picture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 16\nSimple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nM\nJan 20\nNo lab: Martin Luther King Jr. Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 21\nInference: Bootstrap confidence intervals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 23\nInference: Permutation tests\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nM\nJan 27\nLab 01: Simple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 28\nInference: Mathematical models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 due\n\n\n\nTh\nJan 30\nMultiple linear regression (MLR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 01 due, Statistics exprience assigned\n\n\n5\nM\nFeb 3\nLab 02: Inference for regregression + Meet your team!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 4\nModel evaluation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 6\nModel comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 02 due\n\n\n6\nM\nFeb 10\nLab 03: Model comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject research questions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 11\nModel comparison + Inference for MLR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 due\n\n\n\nTh\nFeb 13\nExam 01 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 03 due\n\n\n\nSu\nFeb 16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject research topics due\n\n\n7\nM\nFeb 17\nExam 01 review (finish AE 07)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 18\nExam 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 20\nNo lecture: Exam 01 Take-home\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\nM\nFeb 24\nLab: Project proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 25\nModel conditions + diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 27\nMulticollinearity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject proposal due\n\n\n9\nM\nMar 3\nLab 04: Expanding multiple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 4\nMulticollinearity cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable transformations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 6\nVariable transformations cont'd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 04 due\n\n\n10\nM\nMar 10\nNo lab: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 11\nNo lecture: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 13\nNo lecture: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\nM\nMar 17\nLab: Project exploratory data analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 18\nProbabilities + Odds + Odds ratios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 03 due\n\n\n\nTh\nMar 20\nLogistic regression (LR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject EDA due\n\n\n12\nM\nMar 24\nLab 05: Logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 25\nLR: Prediction + Assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 27\nLR: Model comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13\nM\nMar 31\nLab: Project presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nApr 1\nLR: Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 due\n\n\n\nTh\nApr 3\nMulitnomial logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 05 due\n\n\n14\nM\nApr 7\nLab 06: Multinomial logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nApr 8\nMultinomial: Inference + Prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 10\nCross Validation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 06 due\n\n\n15\nM\nApr 14\nLab: Project peer review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis draft due\n\n\n\nTu\nApr 15\nExam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 05 due, Statistics experience due\n\n\n\nTh\nApr 17\nExam 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\nM\nApr 21\nLab: Project work-day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nApr 22\nWrap up + Looking ahead\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExam period\nWe\nApr 30\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject written report due\n\n\n\nFr\nMay 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject highlights + Repo due\n\n\n\nSa\nMay 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject survey due",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "Below are freely available resources to learn or review the following in R: data wrangling, data visualization, Quarto basics.",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-introduction",
    "href": "computing-r-resources.html#in-depth-introduction",
    "title": "Resources for learning R",
    "section": "In-depth introduction",
    "text": "In-depth introduction\nCoursera: Data Visualization and Transformation with R by Mine Çetinkaya-Rundel and Elijah Meyer\n\nIncludes videos, readings, practice exercise, quizzes, and other resources\nYou can select content within the modules you want to complete.\nFocus on Modules 2 and 3. Review the content in Module 1 as needed.s\nClick here for instructions to register for Coursera for free as a Duke student",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-review",
    "href": "computing-r-resources.html#in-depth-review",
    "title": "Resources for learning R",
    "section": "In-depth review",
    "text": "In-depth review\nData Science with R videos by Mine Çetinkaya-Rundel and Elijah Meyer\n\nVideos from the data science Coursera course\nFocus on videos on visualizing and summarizing data\nYou need to join the Coursera course to access the files from the code along videos.\n\nLearn R: An interactive introduction to data analysis with R\n\nHands-on tutorial that can be completed within the site (no RStudio required)\nFocus on Chapters 4 - 6",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#shorter-review",
    "href": "computing-r-resources.html#shorter-review",
    "title": "Resources for learning R",
    "section": "Shorter review",
    "text": "Shorter review\nR for Data Science (2nd ed) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\nFocus on Chapters 1 - 3, 10",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nTidy Modeling with R by Max Kuhn & Julia Silge\nPosit Cheatsheets\nR workshops by Duke Center for Data and Visualization Sciences",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "ae/ae-01-movies.html",
    "href": "ae/ae-01-movies.html",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups and submit answers on Ed Discussion. This AE does not count towards the Application Exercise grade.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB).\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(DT)"
  },
  {
    "objectID": "ae/ae-01-movies.html#data",
    "href": "ae/ae-01-movies.html#data",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies &lt;- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies |&gt;\n  slice(1:10)\n\n# A tibble: 10 × 15\n   name   rating genre  year released score  votes director writer star  country\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.20e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.30e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# ℹ 4 more variables: budget &lt;dbl&gt;, gross &lt;dbl&gt;, company &lt;chr&gt;, runtime &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-01-movies.html#analysis",
    "href": "ae/ae-01-movies.html#analysis",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Analysis",
    "text": "Analysis\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list &lt;- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\n\nmovies |&gt;\n  filter(genre %in% genre_list) |&gt; \n  group_by(genre,year) |&gt;\n  summarise(avg_gross = mean(gross)) |&gt;\n  ggplot(mapping = aes(x = year, y = avg_gross, color=genre)) +\n    geom_point() + \n    geom_line() +\n    ylab(\"Average Gross Revenue (in US Dollars)\") +\n    ggtitle(\"Gross Revenue Over Time\") +\n    scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do you observe from the plot?\n\n\n\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies |&gt;\n  filter(genre %in% genre_list, budget &gt; 0) |&gt; \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point() +\n  geom_smooth(method=\"lm\",se=FALSE) + \n  xlab(\"Log-transformed Budget\")+\n  ylab(\"Log-transformed Gross Revenue\") +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d()"
  },
  {
    "objectID": "ae/ae-01-movies.html#exercises",
    "href": "ae/ae-01-movies.html#exercises",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nPost your response on ED Discussion.\nhttps://edstem.org/us/courses/70992/discussion/5951333\n[Time permitting] Discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)? Post your group’s response in the AE 01 Movie Budgets comments on Ed Discussion."
  },
  {
    "objectID": "ae/ae-01-movies.html#references",
    "href": "ae/ae-01-movies.html#references",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "References",
    "text": "References\n\ngithub.com/danielgrijalva/movie-stats\nInternet Movie Database"
  },
  {
    "objectID": "ae/ae-01-movies.html#appendix",
    "href": "ae/ae-01-movies.html#appendix",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies |&gt; \n  arrange(genre) |&gt; \n  select(genre) |&gt;\n  distinct() |&gt;\n  datatable()"
  },
  {
    "objectID": "ae/ae-03-slr.html",
    "href": "ae/ae-03-slr.html",
    "title": "AE 03: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started. If you do not see an ae-03 repo, use the link below to create one:\nhttps://classroom.github.com/a/jxxCTVVo\nThis AE does not count towards the participation grade.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-1",
    "href": "ae/ae-03-slr.html#exercise-1",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualizations for the univariate and bivariate exploratory data analysis of daily bike rentals and temperature are below.\n\np1 &lt;- ggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250) + \n  labs(x = \"Daily bike rentals\")\n\np2 &lt;- ggplot(bikeshare, aes(x = temp_orig)) +\n  geom_histogram() + \n  labs(x = \"Temperature (Celsius)\")\n\np3 &lt;- ggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point() + \n  labs(x = \"Temperature (Celsius)\", \n       y = \"Daily bike rentals\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-2",
    "href": "ae/ae-03-slr.html#exercise-2",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nIn the raw data, seasons are coded as 1, 2, 3, 4, numeric values that correspond to winter, spring, summer, and fall respectively. Complete the code below to make season a categorical variable with levels corresponding to season names stored in the original order.\n\nbikeshare &lt;- bikeshare |&gt;\n  mutate(season = case_when(\n    season == 1 ~ \"Winter\", \n    season == 2 ~ \"Spring\", \n    season == 3 ~ \"Summer\", \n    season == 4 ~ \"Fall\"\n  ))"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-3",
    "href": "ae/ae-03-slr.html#exercise-3",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, begin by creating a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-4",
    "href": "ae/ae-03-slr.html#exercise-4",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-5",
    "href": "ae/ae-03-slr.html#exercise-5",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-6",
    "href": "ae/ae-03-slr.html#exercise-6",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing the data from Exercise 5, fit a linear model to predict daily bike rentals using temperature for this season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-7",
    "href": "ae/ae-03-slr.html#exercise-7",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nUse the output to write out the estimated regression equation."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-8",
    "href": "ae/ae-03-slr.html#exercise-8",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nInterpret the slope in the context of the data.\nDoes it make sense to interpret the intercept? If so, interpret the intercept in the context of the data. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-9",
    "href": "ae/ae-03-slr.html#exercise-9",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2024. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html",
    "href": "ae/ae-05-sim-testing.html",
    "title": "AE 05: Permutation test for the slope",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#data",
    "href": "ae/ae-05-sim-testing.html#data",
    "title": "AE 05: Permutation test for the slope",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\nGoal: Use statistical inference to evaluate whether there is a relationship between the age of the house at time of sale and its price."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "href": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "title": "AE 05: Permutation test for the slope",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nLet’s begin by creating a new variable that is the age of the house in 2020.\n\nduke_forest &lt;- duke_forest |&gt;\n  mutate(age_2020 = 2020 - year_built)\n\nNow let’s visualize the relationship between the age of the house in 2020 and the sales price.\n\nggplot(duke_forest, aes(x = age_2020, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Age in 2020 (years)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and age of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#model",
    "href": "ae/ae-05-sim-testing.html#model",
    "title": "AE 05: Permutation test for the slope",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ age_2020, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n690891.015\n68637.793\n10.066\n0.000\n\n\nage_2020\n-2473.935\n1225.191\n-2.019\n0.046"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#hypothesis-test",
    "href": "ae/ae-05-sim-testing.html#hypothesis-test",
    "title": "AE 05: Permutation test for the slope",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\n\n\n\nTip\n\n\n\nFor code chunks with fill-in-the-blank code, change code chunk option to #| eval: true once you’ve filled in the code.\n\n\n\nState the null and alternative hypotheses\nWrite the null and alternative hypotheses in words and mathematical notation.\n\n\nGenerate null distribution using permutation\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(01232025)\n\nnull_dist &lt;- _____ |&gt;\n  specify(______) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = _____, type = \"permute\") |&gt;\n  fit()\n\n\n\nVisualize distribution\n\n# Code for histogram of null distribution\n\n\n\nCalculate the p-value.\n\n# get observed fit \nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ age_2020) |&gt;\n  fit()\n\n# calculate p-value\nget_p_value(\n  ____,\n  obs_stat = ____,\n  direction = \"two-sided\"\n)\n\n\n\nState conclusion\nWrite your conclusion in the context of the data. You can use 0.05 as the decision-making threshold."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#bootstrap-ci-time-permitting",
    "href": "ae/ae-05-sim-testing.html#bootstrap-ci-time-permitting",
    "title": "AE 05: Permutation test for the slope",
    "section": "Bootstrap CI (time permitting)",
    "text": "Bootstrap CI (time permitting)\n\nConstruct the bootstrap CI\nConstruct a 95% bootstrap confidence interval.\n\n\nDraw conclusion\n\nInterpret the interval in the context of the data.\nIs the interval consistent with the conclusion from your hypothesis test? Briefly explain why or why not.\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-05 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html",
    "href": "ae/ae-02-life-expectancy.html",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups. This AE does not count towards the Application Exercise grade.\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#introduction",
    "href": "ae/ae-02-life-expectancy.html#introduction",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "Introduction",
    "text": "Introduction\nThe data set comes from Zarulli et al. (2021), who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThis AE will focus on the following variables:\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nhealth_pct_gdp: Spending on healthcare goods and services, expressed as a percentage of GDP. It excludes capital health expenditures such as buildings, machinery, information technology and stocks of vaccines for emergency or outbreaks.\n\nClick here for the original research paper and a full list of variables in the original data set.\n\nlife_exp &lt;- read_excel(\"data/life-expectancy-data.xlsx\") |&gt; \n  rename(life_exp = `Life_expectancy_at_birth`, \n         health_pct_gdp = `Domestic_general_government_health_expenditure_pct_of_GDP`)\n\n\nlife_exp |&gt;\n  select(life_exp, health_pct_gdp) |&gt;\n  glimpse()\n\nRows: 140\nColumns: 2\n$ life_exp       &lt;dbl&gt; 63.8, 78.2, 59.9, 76.2, 74.6, 83.0, 81.3, 72.5, 71.8, 7…\n$ health_pct_gdp &lt;dbl&gt; 5, 41, 44, 74, 16, 68, 73, 20, 18, 61, 84, 66, 21, 74, …"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#exercises",
    "href": "ae/ae-02-life-expectancy.html#exercises",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "Exercises",
    "text": "Exercises\nWe begin by visualizing the distributions of life expectancy, health expenditure percentage, and the relationship between these two variables.\n\np1 &lt;- ggplot(life_exp, aes(x = life_exp)) +\n  geom_histogram() + \n  labs(x = \"Life expectancy\")\n\np2 &lt;- ggplot(life_exp, aes(x = health_pct_gdp)) +\n  geom_histogram() + \n  labs(x = \"% Health expenditure\")\n\np3 &lt;- ggplot(life_exp, aes(x = health_pct_gdp, y = life_exp)) +\n  geom_point() + \n  labs(x = \"% Health expenditure\", \n       y = \"Life expectancy\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\n\nExercise 1\nDescribe the relationship between life expectancy and healthcare expenditure as a percentage of the GDP. Comment on how we expect the life expectancy to change as the percentage on healthcare expenditure changes.\n\n\nExercise 2\nSuppose you want to fit a model so you can use the healthcare expenditure as a percentage of GDP to predict life expectancy. Would a model of the form\n\\[\\text{life_exp} = \\beta_0 + \\beta_1 ~ \\text{health_pct_gdp} + \\epsilon\\]\nbe a useful model for the data? Why or why not?"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html",
    "href": "ae/ae-07-exam-01-review.html",
    "title": "AE 07: Exam 01 review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-07- to get started.\nRender, commit, and push your responses to GitHub by the end of class."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#packages",
    "href": "ae/ae-07-exam-01-review.html#packages",
    "title": "AE 07: Exam 01 review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#trail-users",
    "href": "ae/ae-07-exam-01-review.html#trail-users",
    "title": "AE 07: Exam 01 review",
    "section": "Trail users",
    "text": "Trail users\nThe Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005. Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\nWe will use regression analysis to predict the number of trail users based on weather and other features describing the day.\nThe variables we’ll focus on for this analysis are\n\nvolume estimated number of trail users that day (number of breaks recorded)\nhightemp daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\ndaytype one of “weekday” or “weekend”\n\nView the data set1 to see the remaining variables.\n\nrail_trail &lt;- read_csv(\"data/rail-trail.csv\")"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "href": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "title": "AE 07: Exam 01 review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nExercise 1\nVisualize, summarize, and describe the distribution of volume.\n\n\nExercise 2\n\nVisualize and describe the relationship between hightemp and volume.\nModify the plot to consider if the relationship between these variables differs by daytype."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#modeling",
    "href": "ae/ae-07-exam-01-review.html#modeling",
    "title": "AE 07: Exam 01 review",
    "section": "Modeling",
    "text": "Modeling\nFit a model using hightemp and daytype to predict the volume for this trail.\n\nExercise 3\n\nWrite the statistical model.\nFit the model and write the estimated regression equation. Neatly display the results using 3 digits and the 90% confidence interval for the coefficients.\n\n\n\nExercise 4\nInterpret the slope of hightemp in the context of the data.\n\n\nExercise 5\n\nDoes it make sense to interpret the intercept? Explain your reasoning.\nIf not, what can we do to make the interpretation meaningful?"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "href": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for coefficients",
    "text": "Inference for coefficients\n\nExercise 6\nThe following code can be used to create a bootstrap distribution for the model coefficients. Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\nset.seed(1234)\n\n1boot_dist &lt;- rail_trail |&gt;\n2  specify(volume ~ hightemp + daytype) |&gt;\n3  generate(reps = 100, type = \"bootstrap\") |&gt;\n4  fit()\n\n\n1\n\n___\n\n2\n\n___\n\n3\n\n___\n\n4\n\n___\n\n\n\n\n\n\nExercise 7\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the coefficient of hightemp using bootstrapping and the percentile method and interpret it in context of the data.\n\n\nExercise 8\nConduct a hypothesis test for the coefficient of hightemp significance level using permutation with 100 reps. State the hypotheses in words and mathematical notation. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\nExercise 9\nNow repeat Exercises 7 and 8 using approaches based on mathematical models. You can reference output from previous exercises and/or write new code as needed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "href": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for prediction",
    "text": "Inference for prediction\n\nExercise 10\nBased on your model, predict the volume for a weekday with high temperature of degrees.\n\n\nExercise 11\nSuppose you’re asked to construct a confidence and a prediction interval for your finding in the previous exercise. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\n\n\nExercise 12\nNow construct the intervals and comment on whether your guess is confirmed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#interaction-terms",
    "href": "ae/ae-07-exam-01-review.html#interaction-terms",
    "title": "AE 07: Exam 01 review",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nExercise 13\nNow fit the model using hightemp and daytype to predict volume such that the effect of hightemp can differ by daytype.\n\n\nExercise 14\n\nWrite the estimated regression equation for weekends.\nWrite the estimated regression equation for weekdays.\n\n\n\nExercise 15\nAccording to this model, does the effect of hightemp differ for weekends vs. weekdays? Explain."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#model-comparison",
    "href": "ae/ae-07-exam-01-review.html#model-comparison",
    "title": "AE 07: Exam 01 review",
    "section": "Model comparison",
    "text": "Model comparison\n\nExercise 16\nWhich model is a better fit for the data - the model with or without the interaction? Show any work to support your choice.\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-07- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#footnotes",
    "href": "ae/ae-07-exam-01-review.html#footnotes",
    "title": "AE 07: Exam 01 review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package.↩︎"
  },
  {
    "objectID": "prepare/prepare-lec02.html",
    "href": "prepare/prepare-lec02.html",
    "title": "Prepare for Lecture 02: The big picture",
    "section": "",
    "text": "📖 Read R for Data Science, Introduction: What you will learn\n📖 Read GitHub for supporting, reusing, contributing, and failing safely\n🎥 Watch Meet the Toolkit: R + RStudio\n🎥 Watch Meet the Toolkit: Quarto"
  },
  {
    "objectID": "prepare/prepare-lec07.html",
    "href": "prepare/prepare-lec07.html",
    "title": "Prepare for Lecture 06: Multiple linear regression",
    "section": "",
    "text": "📖 Read Multiple linear regression, Section 7.1 - 7.4\n📖 Read Multiple linear regression, Section 7.6.1"
  },
  {
    "objectID": "prepare/prepare-lec04.html",
    "href": "prepare/prepare-lec04.html",
    "title": "Prepare for Lecture 04: Inference - bootstrap confidence intervals",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5. 1- 5.3\n📖 Read Bootstrap confidence intervals, Section 5.5"
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, April 15 at 11:59pm.\nThe world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience.\n2️⃣ Make a slide reflecting on your experience.\nYou must complete both parts to receive credit. The statistics experience will count as a homework grade.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcasts / videos must be (1) one podcast or video that is at least 30 minutes or (2) multiple podcasts and/or videos that are at least 30 minutes combined.\nA few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nposit::conf talks (formally called rstudio::conf)\n\n2024 conference\n2023 conference\n2022 conference\n2021 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask Professor Tackett if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\nNote: DataFest will be April 4 - 6 in Penn Pavilion. Click here to learn more.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask Professor Tackett to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Lady Tasting Tea by David Salsburg\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: CURV - connecting, uplifting, and recognizing voices\nCURV is a project by Dr. Jo Hardin at Pomona College to highlight statisticians and data scientists from groups who have been historically marginalized in the discipline.\n\n\n\n\n\n\nFor this statistics experience, you can contribute to the CURV data base. If there is a scholar you would like to suggest for the data base, submit your suggestion as an issue or pull request on the CURV GitHub repo and create a sample CURV page.\nA few guidelines:\n✅ Create a draft of the CURV page for your suggested scholar. For reference, click here for the CURV page for W.E.B. Du Bois. The page must be created in a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nYou can find the Quarto documents for current scholars in the data base in the CURV GitHub repo. You can use one of these as a template to format your page.\n\n\n✅ Make a pull request to the CURV GitHub repo to add the .qmd file for your suggested scholar, OR open an issue with a link to the .qmd file for your suggested scholar. You can ask a member of the teaching team if you have questions about how to do this.\n✅ Include the URL to your pull request or issue in your one-slide reflection.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "href": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "title": "Statistics Experience",
    "section": "Part 2: Reflect on your experience",
    "text": "Part 2: Reflect on your experience\nMake one slide summarizing and reflecting on your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nDescription of the experience\n\nName and brief description of the event/podcast/competition/etc.\n\nSomething you learned\n\nWrite 2 - 4 sentences about something you learned or found particularly interesting or unexpected.\n\nConnection to STA 221\n\nWrite 2 - 4 sentences about how the experience connects to what we’ve done in the course.\n\nCitation or link to web page for event/competition/etc.\n\nNo citation needed if you do an interview.\n\n\nMake sure the slide includes the information mentioned above and is easily readable (i.e. use a reasonable font size!). Creativity on the experience and slide design is encouraged!",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#submission",
    "href": "hw/stats-experience.html#submission",
    "title": "Statistics Experience",
    "section": "Submission",
    "text": "Submission\nThis assignment is due on Tuesday, April 15. Standard homework late policy applies. More submission instructions to come.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03: Multiple linear regression",
    "section": "",
    "text": "Due date\n\n\n\nThis assignment is due on Tuesday, March 18 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-age-of-abalones",
    "href": "hw/hw-03.html#data-age-of-abalones",
    "title": "HW 03: Multiple linear regression",
    "section": "Data: Age of abalones",
    "text": "Data: Age of abalones\nThe data for this analysis contains measurements for abalones, a type of marine snail. These measurements were collected and analyzed by researchers in Warwick et al. (1994). Click here for the publication.\nThe 4177 abalones in this study can be reasonably treated as a random sample.\nThe data are available in the file abalone.csv in the data folder. This analysis will focus on the following variables:\n\nSex: Male (M), Female (F), Infant (I)\nLength: Longest shell measurement (in millimeters)\nDiameter: Measured perpendicular to length (in millimeters)\nHeight : Measured with meat in shell (in millimeters)\nWhole_Weight: Total weight of abalone (in grams)\nAge: Age (in year)\n\nThe goal of the analysis is to use a variety of measurements from abalones to explain variability in the age.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-1",
    "href": "hw/hw-03.html#exercise-1",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit a model using Sex, Length, Diameter, Height and Whole_Weight to understand variability in Age. Neatly display the model using 3 digits.\nCheck the four model conditions - Linearity, Constant Variance, Normality, and Independence. For each condition: (1) state whether or not it is satisfied; (2) explain your response showing any visualizations and/or statistics used to make your assessment.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-2",
    "href": "hw/hw-03.html#exercise-2",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nNow let’s take a look at the model diagnostics.\n\nAre there any influential observations in the data set? Briefly explain, showing any work or output used to make the determination.\nConsider the observation with the highest value for Cook’s distance. What is the value of leverage for this observation? Does this observation have large leverage? Briefly explain, showing any work or output used to make the determination.\nAgain consider the observation with the highest value for Cook’s distance. What is the standardized residual for this observation? Is this observation an outlier? Briefly explain showing any work or output used to make the determination.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-3",
    "href": "hw/hw-03.html#exercise-3",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow let’s look at the relationship between predictors.\n\nCompute the Variance Inflation Factors (VIF) for the model from Exercise 1. Display the results.\nUse the equation for VIF to “manually” compute the VIF for Whole_Weight.\nWhat predictors appear to be collinear?\nSelect a strategy to fit a model that does not have an issue with multicollinearity.\n\nBriefly describe your strategy.\nSelect a final model.\nBriefly explain your selection, showing the work and statistics used to choose a final model.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-2000-u.s.-presidential-election1",
    "href": "hw/hw-03.html#data-2000-u.s.-presidential-election1",
    "title": "HW 03: Multiple linear regression",
    "section": "Data: 2000 U.S. Presidential Election1",
    "text": "Data: 2000 U.S. Presidential Election1\n\nWe will examine data about the 2000 U.S. presidential election between George W. Bush and Al Gore. It was one of the closest elections in history that ultimately came down to the state of Florida. One county in particular, Palm Beach County, was at the center of the controversy due to the design of their ballots - the infamous butterfly ballots. It is believed that many people who intended to vote for Al Gore accidentally voted for Pat Buchanan due to how the spots to mark the candidate were arranged next to the names.\nThe variables in the data are\n\nCounty: County name\nBush2000: Number of votes for George W. Bush\nBuchanan2000: Number of votes for Pat Buchanan\n\nThe data are available in the file florida-votes-2000.csv in the data folder of your repo.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-4",
    "href": "hw/hw-03.html#exercise-4",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe goal is to fit a model that uses the number of votes for Bush to predict the number of votes for Buchanan. Using this model, we’ll investigate whether the data support the claim that votes for Gore may have accidentally gone to Buchanan.\n\nVisualize the relationship between the number of votes for Buchanan versus the number of votes for Bush. Describe what you observe in the visualization, including a description of the relationship between the votes for Buchanan and votes for Bush.\nWhat is the county with the extreme outlier number of votes for Buchanan? Create a new data frame that doesn’t include the outlying county. You will use this updated data frame for the remainder of this exercise and Exercise 5.\nFit a model to predict the number of votes for Buchanan based on the number of votes for Bush in the county.\n\nMake a plot of the standardized residuals versus the fitted values.\nIs the constant variance condition satisfied? Briefly explain.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-5",
    "href": "hw/hw-03.html#exercise-5",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s consider potential models with transformations on the response and/or predictor variables. The four candidate models are the following:\n\n\n\nModel\nResponse variable\nPredictor variable\n\n\n\n\n1 (from previous exercise)\nBuchanan2000\nBush2000\n\n\n2\nlog(Buchanan2000)\nBush2000\n\n\n3\nBuchanan2000\nlog(Bush2000)\n\n\n4\nlog(Buchanan2000)\nlog(Bush2000)\n\n\n\nWhich model best fits the data? Briefly explain, showing any work and output used to determine the response. (Note: Use the data set without the outlying county to find the candidate models.)",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-6",
    "href": "hw/hw-03.html#exercise-6",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nUse the model you chose in the previous exercise to compute the predicted number of votes for Buchanan in the outlying county identified in Exercise 4. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nCompute the 95% prediction interval for this county. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nIt is assumed that some of the votes for Buchanan in that county were actually intended to be for Gore. Based on your results in the previous question, does your model support this claim?\n\nIf no, briefly explain.\nIf yes, about how many votes were possibly intended for Gore? Show any calculations and output used to determine your answer. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#footnotes",
    "href": "hw/hw-03.html#footnotes",
    "title": "HW 03: Multiple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis analysis was motivated by exercises in Ledolter (2003).↩︎",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "In STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\n\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#pre-requisites",
    "href": "overview.html#pre-requisites",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#teaching-assistants",
    "href": "overview.html#teaching-assistants",
    "title": "STA 210 - Regression Analysis",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\nName\nRole\n\n\nSylvia Vincent\nHead TA\nLab 01L leader\nLab 02L leader\n\n\nIshrit Gupta\nLab 02L leader\n\n\nKareena Legare\nLab 01L helper\n\n\n\nSee Canvas for office hours times and locations.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "labs/lab-05.html",
    "href": "labs/lab-05.html",
    "title": "Lab 05",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-00.html",
    "href": "labs/lab-00.html",
    "title": "Lab 00: Getting Started",
    "section": "",
    "text": "Important\n\n\n\nPlease complete all today’s lab tasks before leaving lab today.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#rstudio",
    "href": "labs/lab-00.html#rstudio",
    "title": "Lab 00: Getting Started",
    "section": "RStudio",
    "text": "RStudio\n\n\n\n\n\n\nNote\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface.\n\n\n\nReserve RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers. You will log in using your NetID credentials.\nClick “Reserve STA 210” to reserve an RStudio container. Be sure you reserve the container labeled STA 210 to ensure you have the computing set up you need for the class.\n\nYou only need to reserve a container once per semester.\n\n\nOpen RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA210 to log into the Docker container. You should now see the RStudio environment.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#git-and-github",
    "href": "labs/lab-00.html#git-and-github",
    "title": "Lab 00: Getting Started",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nIn addition to R and RStudio, we will use git and GitHub for version control and collaboration.\n\n\n\n\n\n\nNote\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\n\nSign up for GitHub account\nYou will need a GitHub account to access the assignments, project, and in-class exercises for the course.\n\nIf you do not have a GitHub account, go to https://github.com and sign up for an account.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for advice on choosing a username.\n\n\n\nIf you already have a GitHub account, you can move on to the next step.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#connect-rstudio-and-github",
    "href": "labs/lab-00.html#connect-rstudio-and-github",
    "title": "Lab 00: Getting Started",
    "section": "Connect RStudio and GitHub",
    "text": "Connect RStudio and GitHub\nNow that you have RStudio and a GitHub account, we will configure git so that RStudio and GitHub communicate with one another.\n\nSet up your SSH Key\nYou will authenticate GitHub using SSH. An outline of the authentication steps is below; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nStep 0: Open your STA 210 RStudio container.\nStep 1: Type credentials::ssh_setup_github() into the console on the bottom left of the RStudio environment.\nStep 2: R will ask “No SSH key found. Generate one now?” Click 1 for yes.\nStep 3: You will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” Click 1 for yes.\nStep 4: You may be asked to provide your username and password to log into GitHub. This would be the ones associated with your account that you set up. After entering this information, paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta210)\n\n\n\nConfigure git\nThe last thing we need to do is configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\")\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Maria Tackett\",\n  user.email = \"maria.tackett@duke.edu\")\n\nIt may look like nothing happened but you are now ready interact between GitHub and RStudio!",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#getting-started",
    "href": "labs/lab-00.html#getting-started",
    "title": "Lab 00: Getting Started",
    "section": "Getting started",
    "text": "Getting started\n\nClick here to create your individual lab-00 repo: https://classroom.github.com/a/h6Hs0ztf\nClick to open your lab-00 repo.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File → New Project → Version Control → Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-00.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#update-the-quarto-document",
    "href": "labs/lab-00.html#update-the-quarto-document",
    "title": "Lab 00: Getting Started",
    "section": "Update the Quarto document",
    "text": "Update the Quarto document\n\nTask 1: Change the author name at the top of the document to your name. Render the document. You will see your name at the top of the rendered PDF.\nTask 2: The plot shows the relationship between the daily temperature and number of bike rentals in Washington, D.C.’s Capital Bikeshare in 2012.\n\n\n\n\n\n\n\n\n\n\nWrite 1 - 2 observations from the plot. Render the document. You will see your response in the rendered PDF.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#commit-and-push-changes-to-github",
    "href": "labs/lab-00.html#commit-and-push-changes-to-github",
    "title": "Lab 00: Getting Started",
    "section": "Commit and push changes to GitHub",
    "text": "Commit and push changes to GitHub\n\nOnce you have made your final updates, go to the Git pane in your RStudio instance. This is a tab in the top right corner of the RStudio window.\nCheck the appropriate boxes on every file in the Git pane. All checked files will be sent to GitHub.\nNext, write a meaningful commit message (for instance, “updated author name”) in the Commit message box.\nClick Commit. Note that every commit needs to have a commit message associated with it.\nNow that you have made an update and committed this change, click Push to send the changes to GitHub.\nGo to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Lab 03: Model comparison",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due on Thursday, February 13 at 11:59pm.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#introduction",
    "href": "labs/lab-03.html#introduction",
    "title": "Lab 03: Model comparison",
    "section": "Introduction",
    "text": "Introduction\nIn today’s lab you will analyze data about candy that was collected from an online experiment conducted at FiveThirtyEight.\n\nLearning goals\nBy the end of the lab you will be able to\n\ntransform and create new variables\ncompare models\ncontinue developing a collaborative workflow with your teammates",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#workflow-using-git-and-github-as-a-team",
    "href": "labs/lab-03.html#workflow-using-git-and-github-as-a-team",
    "title": "Lab 03: Model comparison",
    "section": "Workflow: Using Git and GitHub as a team",
    "text": "Workflow: Using Git and GitHub as a team\n\n\n\n\n\n\nImportant\n\n\n\nThere are no Team Member markers in this lab; however, you should use a similar workflow as in Lab 02. Only one person should type in the group’s .qmd file at a time. Once that person has finished typing the group’s responses, they should render, commit, and push the changes to GitHub. All other teammates can pull to see the updates in RStudio.\nEvery teammate must have at least one commit in the lab. Everyone is expected to contribute to discussion even when they are not typing.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-1",
    "href": "labs/lab-03.html#exercise-1",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nVisualize the relationship between the response variable winpercent and one potential quantitative predictor. Write an observation from the graph.\nVisualize the relationship between the response variable and one potential categorical predictor. Write an observation from the graph.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-2",
    "href": "labs/lab-03.html#exercise-2",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 2",
    "text": "Exercise 2\nSplit the data into training (80%) and testing sets (20%). Use a seed of 210.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-3",
    "href": "labs/lab-03.html#exercise-3",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe will do some feature engineering1 to transform and create new variables to consider for the model. Conduct the following steps to the training data set.\n\nCreate a categorical variable that breaks sugarpercent into quartiles:\n\n“Q1” If sugarpercent \\(&lt;\\) the \\(25^{th}\\) percentile.\n“Q2” if \\(25^{th}\\) percentile \\(\\leq\\) sugarpercent \\(&lt;\\) \\(50^{th}\\) percentile.\n“Q3” if \\(50^{th}\\) percentile \\(\\leq\\) sugarpercent \\(&lt;\\) \\(75^{th}\\) percentile.\n“Q4” if sugarpercent \\(\\geq\\) \\(75^{th}\\) percentile.\n\nMultiply pricepercent * 100, so the variable ranges from 0 - 100% instead of 0 - 1.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou will use these variables whenever sugarpercent and pricepercent are referenced in the remainder of the lab.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-4",
    "href": "labs/lab-03.html#exercise-4",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFit a model using sugarpercent, pricepercent, chocolate, peanutalmondy, the interaction between pricepercent and chocolate, and the interaction between chocolate and peanutalmondy to predict winpercent. Neatly display the model using 3 digits.\nInterpret the intercept in the context of the data.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-5",
    "href": "labs/lab-03.html#exercise-5",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 5",
    "text": "Exercise 5\nUse the model from the previous exercise to interpret the following in the context of the data:\n\nCoefficient of sugarpercent = Q3.\nCoefficient of pricepercent:chocolateTRUE\nEffect of peanutalmondy for chocolate candy",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-6",
    "href": "labs/lab-03.html#exercise-6",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 6",
    "text": "Exercise 6\nLet’s consider another model. Use the training data to fit a model that meets the following criteria:\n\nIncludes variables chocolate, pricepercent, crispedricewafer, peanutyalmondy, sugarpercent\nUpdate pricepercent so it ranges from 0 to 100 (instead of 0 to 1)\nMakes sugarpercent a factor where the levels equal the four quartiles: 0 - 0.25, 0.25 - 0.50, 0.50 - 0.75, 0.75 - 1\nIncludes the interaction between pricepercent and peanutyalmondy",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-7",
    "href": "labs/lab-03.html#exercise-7",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nConsider the model from Exercise 4 as “Model 1” and the model fit in Exercise 6 as “Model 2”. Use the glance() function to calculate \\(Adj. R^2\\) for both models.\nCompute RMSE for the both models.\nWhich model would you choose based on the results from parts (a) and (b)? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-8",
    "href": "labs/lab-03.html#exercise-8",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 8",
    "text": "Exercise 8\nNow let’s use the testing data to evaluate the performance of the model selected in the previous exercise.\n\nCompute RMSE on the testing data for the model selected in Exercise 7.\nInterpret RMSE in the context of the data.\nHow does this RMSE compare to the value from Exercise 7? Is this what you expected? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#exercise-9",
    "href": "labs/lab-03.html#exercise-9",
    "title": "Lab 03: Model comparison",
    "section": "Exercise 9",
    "text": "Exercise 9\nUse the model you selected to describe what generally makes a good candy, as measured by the win percentage.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-03.html#footnotes",
    "href": "labs/lab-03.html#footnotes",
    "title": "Lab 03: Model comparison",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“Feature engineering entails reformatting predictor values to make them easier for a model to use effectively. This includes transformations and encodings of the data to best represent their important characteristics.” -from Tidy Modeling with R↩︎",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due on Thursday, February 6 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#learning-goals",
    "href": "labs/lab-02.html#learning-goals",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab you will…\n\nuse mathematical models to conduct inference for the slope.\nassess conditions for linear regression.\ndevelop a collaborative workflow in GitHub.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-1",
    "href": "labs/lab-02.html#exercise-1",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the relationship between the aftertaste grade and total cup points. Write two observations from the plot.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-2",
    "href": "labs/lab-02.html#exercise-2",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 2",
    "text": "Exercise 2\nFit the linear model using the aftertaste grade to understand variability in the total cup points. Neatly display the model using three digits and include the 98% confidence interval for the model coefficients in the output.\n\nTeam Member 1: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 1- 2.\nTeam Member 2: It’s your turn! Type the team’s response to exercises 3 - 5.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-3",
    "href": "labs/lab-02.html#exercise-3",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nInterpret the slope in the context of the data.\nAssume you are a coffee drinker. Would you drink a coffee represented by the intercept? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-4",
    "href": "labs/lab-02.html#exercise-4",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 4",
    "text": "Exercise 4\nYou can obtain the predicted values and other observation-level statistics from the model using the augment() function. Create a data frame called coffee_aug by putting the name of your model in the code below.\n\n#|eval: false\ncoffee_aug &lt;- augment(_____)\n\n\nWrite code to “manually” compute the residuals. The predicted values are in the column .fitted of coffee_aug. Save the residuals but do not print them out.\nWrite code to compute the regression standard error, \\(\\hat{\\sigma}_\\epsilon\\) using the residuals from part (a).\nState the definition of the regression standard error in the context of the data.\n\n\n\n\n\n\n\nTip\n\n\n\nYou can check your answer to part (b) by using the code below to obtain \\(\\hat{\\sigma}_\\epsilon\\)\n\nglance(model_name)$sigma\n\n\n\n\nExercise 5\nDo the data provide evidence of a statistically significant linear relationship between aftertaste grade and total cup points? Conduct a hypothesis test using mathematical models to answer this question.\n\nState the null and alternative hypotheses in words and in mathematical notation.\nWhat is the test statistic? State what the test statistic means in the context of this problem.\nWhat distribution was used to calculate the p-value? Be specific.\nState the conclusion in the context of the data using a threshold of \\(\\alpha = 0.02\\) to make your decision.\n\n\nTeam Member 2: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 3 - 5.\nTeam Member 3: It’s your turn! Type the team’s response to exercises 6 - 8.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-6",
    "href": "labs/lab-02.html#exercise-6",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nWhat is the critical value used to calculate the confidence interval displayed in Exercise 2? Show the code and output used to get your response.\nIs the confidence interval consistent with the conclusions from the hypothesis test? Briefly explain why or why not.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-7",
    "href": "labs/lab-02.html#exercise-7",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCalculate the 98% confidence interval for the mean total cup points grade for coffees with aftertaste grade of 8.25. Interpret this value in the context of the data.\nOne coffee produced by the Ethiopia Commodity Exchange has an aftertaste of 8.25. Calculate the the 98% prediction interval for the total cup points grade for this coffee. Interpret this value in the context of the data.\nHow do the intervals in parts (a) and (b) compare? If there are differences in the predictions and/or intervals, briefly explain why.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-8",
    "href": "labs/lab-02.html#exercise-8",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 8",
    "text": "Exercise 8\nWe have conducted the inference in the previous exercises making some inherent assumptions about the data. Therefore, we will check some model conditions to assess whether the assumptions and hold and the reliability of the inferential results. To do so, we will use the data frame coffee_aug from Exercise 4 that includes the residuals, predicted values, and other observation-level statistics from the model.\n\nMake a scatterplot of the residuals (.resid) vs. fitted values (.fitted). Use geom_hline() to add a horizontal dotted line at \\(residuals = 0\\).\n\n\n\n\n\n\n\nNote\n\n\n\nThe linearity condition is satisfied if there is random scatter of the residuals (no distinguishable pattern or structure) in the plot of residuals vs. fitted values.\n\nThe constant variance condition is satisfied if the vertical spread of the residuals is relatively equal across the plot.\n\n\n\nIs the linearity condition satisfied? Briefly explain why or why not.\nIs the constant variance condition satisfied? Briefly explain why or why not.\n\n\nTeam Member 3: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 6 - 8.\nTeam Member 4: It’s your turn! Type the team’s response to exercises 9 - 10.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-9",
    "href": "labs/lab-02.html#exercise-9",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 9",
    "text": "Exercise 9\n\n\n\n\n\n\nNote\n\n\n\nThe normality condition is satisfied if the distribution of the residuals is approximately normal. This condition can be relaxed if the sample size is sufficiently large \\((n &gt; 30)\\).\n\n\n\nMake a histogram or density plot of the residuals (.resid).\nIs the normality condition satisfied? Briefly explain why or why not. If not, can it be relaxed for this data set? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#exercise-10",
    "href": "labs/lab-02.html#exercise-10",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Exercise 10",
    "text": "Exercise 10\n\n\n\n\n\n\nNote\n\n\n\nThe independence condition means that knowing one residual will not provide information about another. We often check this by assessing whether the observations are independent based on what we know about the subject matter and how the data were collected.\nThis condition is sometimes difficult to fully assess, so we just want to consider whether it is reasonably satisfied based on the information and data available.\n\n\nIs the independence condition satisfied for these data? Briefly explain why or why not.\n\nTeam Member 4: Render, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and the rest of the team can see the completed lab.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the team’s completed lab!",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-02.html#footnotes",
    "href": "labs/lab-02.html#footnotes",
    "title": "Lab 02: Inference for regression using mathematical models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDon’t trust yourself to keep your hands off the keyboard? Put them in your pocket or cross your arms. No matter how silly it might feel, resist the urge to touch your keyboard until otherwise instructed!↩︎",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01: Linear regression",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due on Thursday, January 30 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-01.html#learning-goals",
    "href": "labs/lab-01.html#learning-goals",
    "title": "Lab 01: Linear regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab you will…\n\nFit and interpret a linear regression models in R.\nUse simulation-based inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-04.html",
    "href": "labs/lab-04.html",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "",
    "text": "Due date\n\n\n\nThis lab is due on Thursday, March 6 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-1",
    "href": "labs/lab-04.html#exercise-1",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWe’ll begin by rescaling the response and some of the predictor variables.\n\nRescale the response variable total_rev_menwomen and the primary predictor variable total_exp_menwomen, so that they are in terms of $100K (100 thousand dollars). Name the new variables rev100k and exp100k, respectively.\nRescale the predictor variable ef_total_count , so it is in terms of thousands of students. Name the new variable students_1k.\nBriefly explain why we might we rescale these variables instead of using them in the original units.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-2",
    "href": "labs/lab-04.html#exercise-2",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nBefore modeling, let’s do some exploratory data analysis.\n\nMake a visualization of the relationship between revenue and expenditures. Use the plot to describe the relationship between the two variables.\nHigher values of both expenditures and revenues are associated with greater variability. Transform both variables using a log transformation, to deal with the potential violation of an assumption of linear regression. Name the variables log_exp and log_rev, respectively.\nLarger values of expenditures and revenues seem to follow a slightly different trend and are associated with two sports - football and basketball. Create an indicator variable that takes value 1 if the sport is basketball or football and 0 otherwise. Name the variable bball_football.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-3",
    "href": "labs/lab-04.html#exercise-3",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nVisualize the relationship between log_rev and log_exp.\nFrom the visualization, you may notice a lot of observations form a straight diagonal line, indicating a perfect one-to-one relationship between expenses and revenues. Provide a possible interpretation of this phenomenon.\nDo you think it is reasonable to include observations displaying this exact relationship? Briefly explain.\nCreate a new data frame filtering out the observations for which expenditures and revenues are exactly equal. Call the new data frame sports_nolinear.\n\nYou will use sports_nolinear for the remainder of the assignment.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-4",
    "href": "labs/lab-04.html#exercise-4",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nUse sports_nolinear to fit a regression model with the log-transformed revenue as the response variable and the following predictors: log-transformed expenditures, student enrollment, institution type, sports type, participation in athletics for men, participation in athletics for women, the basketball/football indicator you created in a previous exercise, and the interaction between the log-transformed expenditures and the basketball/football indicator.\nNeatly display the model using 3 digits.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-5",
    "href": "labs/lab-04.html#exercise-5",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nConsider the regression model from the previous exercise.\n\nWhat type of institution and sport correspond to the intercept?\nYou’ll notice that one coefficient has a missing value. Why is the coefficient missing? What is the technical name of this phenomenon?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-6",
    "href": "labs/lab-04.html#exercise-6",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nFor the sake of interpretability, it is useful to have a regression model in which no coefficients are missing, and the coefficients for each sport indicator represent the baseline level for such sport. To address this issue, use the code below to fit another regression model that uses the same predictors as before, making sure to drop the unnecessary variables and the intercept (by the the -1 in the formula) to achieve this.\n\nsports_fit_2 &lt;- lm(log_rev ~ -1 + sports + students_1k + sector_name +\n             sum_partic_men + sum_partic_women + log_exp + \n             log_exp*bball_football - bball_football,\n          data = sports_nolinear)\n\nWhich type of institution was chosen to be the baseline in this model?",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-7",
    "href": "labs/lab-04.html#exercise-7",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nNow that we have an interpretable model, let us assess the model fit and perform diagnostics to verify whether our linear regression assumptions are reasonable for this data.\nAs a first step, provide some overall measures of model fit and comment on whether it seems to have an acceptable predictive power on the response of interest.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-8",
    "href": "labs/lab-04.html#exercise-8",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nNext, let’s take a look at the residuals for the model.\nBecause there are multiple sports at every institution, we may be concerned the residuals within an institution are correlated with each other (thus violating the independence assumption).\nDue to the large number of institutions, we will look at randomly selected subset of 20 institutions to evaluate this.\n\nTake a random sample of 20 institutions. Use set.seed(210) to make your results reproducible.\nPlot the residuals versus fitted values, faceted by institution.\nBased on the faceted plot, do the errors appear to be correlated within institutions? Briefly explain your response.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for more detail, code, and examples of faceting in ggplot2.\nYou may need to change the size of the figure so that the faceted lot is fully visible. You can do so using the options #| fig-width and #| fig-height in the code chunk.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-9",
    "href": "labs/lab-04.html#exercise-9",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nAfter an examination of all the residuals, we notice a few things:\n\nThere seems to be two groups of observations.\nInstitutions with larger fitted values correspond to lower variance in the residuals compared to the others.\nThere are institutions with lower fitted values that have large negative residuals, potentially indicating outliers and/or influential points.\n\nWe are concerned that these observations may indicate some model misspecification (i.e., the model does not accurately reflect the trends in the data). Therefore, we take a look at the residuals a different way. We plot the standardized residual versus the fitted values, color the points based Cook’s distance, and use shape to indicate whether the sport is basketball or football.\n\nDescribe what you observe from the plot and how your observations compare to the list above.\nDo you think this model is an appropriate fit for the data or is the model misspecified? Briefly explain.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-04.html#exercise-10",
    "href": "labs/lab-04.html#exercise-10",
    "title": "Lab 04: Expanding Multiple Linear Regression",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nBased on this model (regardless of your answer to the previous exercise), which variables seem to be useful in explaining the variability in the revenue from collegiate sports?\nInterpret the coefficient for one useful quantitative predictor in terms of the log-transformed revenue.\nInterpret the coefficient for one useful categorical predictor in terms of the log-transformed revenue.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-06.html",
    "href": "labs/lab-06.html",
    "title": "Lab 06",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "hw/hw-05.html",
    "href": "hw/hw-05.html",
    "title": "HW 05",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 05"
    ]
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, January 28 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions",
    "href": "hw/hw-01.html#instructions",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nType your responses to each question in your Quarto document. Write all narrative using complete sentences and include informative axis labels and titles on visualizations. Use a reproducible workflow by periodically rendering the Quarto document, writing an informative commit message, and pushing the updated .qmd and .pdf files to GitHub.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "href": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "title": "HW 01: Simple linear regression",
    "section": "Part 1: Exploratory data analysis",
    "text": "Part 1: Exploratory data analysis\n\nExercise 1\nCreate a histogram of the distribution of the predictor variable bachelors and calculate appropriate summary statistics. Use the visualization and summary statistics to describe the distribution. Include an informative title and axis labels on the plot.\n\n\nExercise 2\nLet’s view the data in another way. Use the code below to make a map of the United States with the color of the counties filled in based on the percent of residents 25 years old and older who have a Bachelor’s degree. Fill in title and axis labels.\nThen use the plot answer the following:\n\nWhat are 2 observations you have from the map?\nWhat is a feature that is apparent in the map that wasn’t as easily apparent from the histogram in the previous exercise? What is a feature that is apparent in the histogram that is not as easily apparent from the map?\n\n\n\n#| fig.show: hide \n#| message: false \n\ncounty_map_data &lt;- left_join(county_data_sample, map_data_sample) \n\nggplot(data = map_data_all) + \n  geom_polygon(aes(x = long, y = lat, group = group), \n    fill = \"lightgray\", color = \"white\" \n    ) + \n  geom_polygon(data = county_map_data, aes(x = long, y = lat, group = group, \n    fill = bachelors) \n    ) + \n  labs( \n    x = \"Longitude\", \n    y = \"Latitude\", \n    fill = \"_____\", \n    title = \"_____\" \n  ) + \n  scale_fill_viridis_c(labels = label_percent(scale = 1)) + \n  coord_quickmap() \n\n\n\nExercise 3\nCreate a visualization of the relationship between bachelors and median_household_income and calculate the correlation. Use the visualization and correlation to describe the relationship between the two variables.\n\nThis is a good place to render, commit, and push changes to your hw-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 1 - 3”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-2-modeling",
    "href": "hw/hw-01.html#part-2-modeling",
    "title": "HW 01: Simple linear regression",
    "section": "Part 2: Modeling",
    "text": "Part 2: Modeling\n\nExercise 4\nWe will use a linear regression model to describe the relationship between bachelors and median_household_income.\nWrite the form of the statistical (theoretical) model we will use for this task using mathematical notation. Use variable names (bachelors and median_household_income) in the equation for your model1.\n\n\n\n\n\n\nTip\n\n\n\nWrite median household income in LaTex as\n\\text{median\\_household\\_income}\nto make it properly render in the .pdf document.\n\n\n\n\nExercise 5\n\nFit the regression line corresponding to the statistical model in the previous exercise. Neatly display the model output using 3 digits.\nWrite the equation of the fitted model using mathematical notation. Use variable names (bachelors and median_household_income) in the equation.\n\n\n\nExercise 6\n\nInterpret the slope in the context of the data.\nIs it useful to interpret the intercept for this data? If so, write the interpretation in the context of the data. Otherwise, briefly explain why not.\n\n\nThis is a good place to render, commit, and push changes to your hw-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 4 -6”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "href": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "title": "HW 01: Simple linear regression",
    "section": "Part 3: Inference for the U.S.",
    "text": "Part 3: Inference for the U.S.\nWe will use the data from these 600 randomly selected counties to draw conclusions about the relationship between the percent of adults age 25 and older with a bachelor’s degree and median household income for the over 3,000 counties in the United States.\n\nExercise 7\n\nWhat is the population in this analysis? What is the sample?\nIs it reasonable to treat the sample in this analysis as representative of the population? Briefly explain why or why not.\n\n\n\nExercise 8\nNext, compute a 98% bootstrap confidence interval for the slope. Use set.seed(2025) and 1000 iterations. Show all relevant code and output used to compute the interval.\nWrite the 98% confidence interval using 3 digits.\n\n\nExercise 9\n\nInterpret the interval from the previous exercise in the context of the data.\nSuppose you wanted to evaluate the claim that there is no linear relationship between the percent of adults age 25 and older with a bachelor’s degree and median household income for counties in the United States. In other words, you want to evaluate the claim that \\(\\beta_1 = 0\\) in the model written in Exercise 4.\nDoes the confidence interval from the previous exercise support this claim? Briefly explain why or why not.\n\n\nNow is a good time to render your document again if you haven’t done so recently, commit (with an informative commit message), and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#footnotes",
    "href": "hw/hw-01.html#footnotes",
    "title": "HW 01: Simple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nClick here for a guide on writing mathematical symbols using LaTex.↩︎",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, February 11 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nThere are some observations that have missing data for any of the variables of interest .\n\nRemove observations that have missing data for any of the variables of interest - Size, Theme, Pages, and Amazon_Price. Your updated data set will have 374 observations.\nWhat is a disadvantage of dropping observations that have missing values, instead of using a method to impute, i.e., fill in, the missing data? How might dropping these observations impact the generalizability of conclusions?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nVisualize the distributions of the predictor variables Size and Pages. Neatly arrange the plots using the patchwork package.\nUse the plots in part (a) to write an observation about each distribution.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe distribution of Theme is shown below. The bars are ordered by the frequency they occur in the data set.\n\nlegos |&gt;\n  count(Theme) |&gt;\nggplot(aes(x = fct_reorder(Theme, n), y = n)) +\n  geom_col() + \n    labs(title = \"Lego Set Theme\", \n         x = \"Theme\", \n         y = \"Number of LEGO sets\") + \n  coord_flip()\n\n\n\n\n\n\n\n\n\nWhat is one reason we may want to avoid putting the variable Theme in a model as is?\nWe will create a new variable that collapses some of the levels of Theme. Make a new variable called Theme_Col that has levels for the top four most frequent themes, then the category Other for all other themes.\nHow many observations are in each level for the new variable created in part (b)?\n\n\n\n\n\n\n\nNote\n\n\n\nYou will use Theme_Col, the collapsed Theme variable, for the remainder of the assignment.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFit a model using Size, Pages, and Theme_Col to predict Amazon_Price. Fit the model such that the intercept has a meaningful interpretation. Neatly display the model using three digits.\nInterpret the intercept in the context of the data.\nThe model output suggests that as the number of pages in the instruction booklet increases, the price of the set on Amazon is expected to increase. On the surface, it does not seem that the number of pages in the booklet would be a major predictor of the price on Amazon. What do you think this variable is actually measuring or is actually representing?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s consider a model that allows for different effects of pages based on theme.\n\nMake a plot that can be used to visualize the effect of pages on the Amazon.com price based on the theme.\nBased on the plot in part (a), does the effect of the number of pages appear to differ based on theme? Briefly explain why or why not.\nModify the model from Exercise 4 such that the effect of the number of pages differs based on the theme. The intercept should still have a meaningful interpretation. Neatly display the model using three digits.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nDescribe the effect of pages for the baseline level in the context of the data.\nDescribe the effect of pages for LEGOS in the Star Wars theme in the context of the data.\nBased on the p-values, do the data provide evidence that the effect of pages differs based on theme? Briefly explain. You can use a threshold of 0.05 for your assessment.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-7",
    "href": "hw/hw-02.html#exercise-7",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCompute RMSE for the model in Exercise 5. Interpret this value in the context of the data.\nCompute \\(R^2\\) for the model in Exercise 5. Interpret this value in the context of the data.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#perceived-threat-of-covid-19",
    "href": "hw/hw-02.html#perceived-threat-of-covid-19",
    "title": "HW 02: Multiple linear regression",
    "section": "Perceived threat of COVID-19",
    "text": "Perceived threat of COVID-19\n\n\n\n\n\n\nImportant\n\n\n\nUse the following paper for Exercises 8 and 9.\n\n\nGarbe, Rau, and Toppe (2020) aimed to examine the relationship between personality traits, perceived threat of Covid-19 and stockpiling toilet paper. For this study, researchers conducted an online survey March 23 - 29, 2020 and used the results to fit multiple linear regression models to draw conclusions about their research questions. From their survey, they collected data on adults across 35 countries. Given the small number of responses from people outside of the United States, Canada, and Europe, only responses from people in these three locations were included in the regression analysis.\nLet’s consider their results for the model looking at the effect on perceived threat of Covid-19. The model can be found on page 6 of the paper. The perceived threat of Covid was quantified using the responses to the following survey question:\n\nHow threatened do you feel by Coronavirus? [Users select on a 10-point visual analogue scale (Not at all threatened to Extremely Threatened)]\n\nAs stated on page 5 of the paper “To ease interpretation, continuous variables were z-standardized and categorical variables were dummy-coded in all models.”\nClick here to access a PDF of the paper.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-8",
    "href": "hw/hw-02.html#exercise-8",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nInterpret the coefficient of Age (0.072) in the context of the analysis.\nInterpret the coefficient of Place of residence in the context of the analysis. You can assume Emotionality = 0 in the interpretation.\nThe model includes an interaction between Place of residence and Emotionality. The authors describe Emotionality as a measure of “fearfulness, anxiety, dependence, sentimentality”. What does the coefficient for the interaction (0.101) mean in the context of the data?\n\n\n\n\n\n\n\nImportant\n\n\n\nThe following are general questions about linear regression. They are not specific to any of the previous analyses.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-9",
    "href": "hw/hw-02.html#exercise-9",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nProve that the maximum value of \\(R^2\\) must be less than 1 if the data set contains observations such that there are different observed values of the response for the same value of the predictor (e.g., the data set contains observations \\((x_i, y_i)\\) and \\((x_j, y_j)\\) such that \\(x_i = x_j\\) and \\(y_i \\neq y_j\\) .",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-10",
    "href": "hw/hw-02.html#exercise-10",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nIn lecture we discussed how the distribution of the error terms (and thus the distribution of the response variable \\(Y\\)) for a given value of the predictor \\(X\\) has a variance of \\(\\sigma^2_{\\epsilon}\\). Therefore, we are assuming this variance is the same for all values of the predictor when we conduct inference.\nBriefly explain why this assumption is important when we conduct inference based on mathematical models but is not necessary for conducting simulation-based inference.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#footnotes",
    "href": "hw/hw-02.html#footnotes",
    "title": "HW 02: Multiple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercise 9 is based on an exercise in Montgomery, Peck, and Vining (2021) .↩︎",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "prepare/prepare-lec10.html",
    "href": "prepare/prepare-lec10.html",
    "title": "Prepare for Lecture 10: Inference + Model conditions",
    "section": "",
    "text": "📖 Read Model conditions"
  },
  {
    "objectID": "prepare/prepare-lec05.html",
    "href": "prepare/prepare-lec05.html",
    "title": "Prepare for Lecture 05: Inference - permutation tests",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5. 1- 5.3\n📖 Read Inference for simple linear regression, Section 5.6 - 5.8"
  },
  {
    "objectID": "prepare/prepare-lec06.html",
    "href": "prepare/prepare-lec06.html",
    "title": "Prepare for Lecture 06: Inference - Mathematical models",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5.9"
  },
  {
    "objectID": "prepare/prepare-lec03.html",
    "href": "prepare/prepare-lec03.html",
    "title": "Prepare for Lecture 03: Simple linear regression",
    "section": "",
    "text": "📖 Read Simple linear regression, Section 4.1 - 4.6\n📖 Read Simple linear regression, Section 4.8"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html",
    "href": "ae/ae-04-bootstrap.html",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#data",
    "href": "ae/ae-04-bootstrap.html#data",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "href": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#model",
    "href": "ae/ae-04-bootstrap.html#model",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n\n\n2. Take n_iter bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn_iter = 100\nset.seed(091222)\n\nboot_fits &lt;- ______ |&gt;\n  specify(______) |&gt;\n  generate(reps = ____, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n# Code for histogram\n\n\n\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = _____, \n  level = ____,\n  type = \"percentile\"\n)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nModify the code from Step 3 to create a 90% confidence interval.\n\n# Code for the 90% confidence interval\n\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\n# Code for the 99% confidence interval\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-04 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html",
    "href": "ae/ae-08-multicollinearity.html",
    "title": "AE 08: Multicollinearity",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-08 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(rms) #calculate VIF"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-1",
    "href": "ae/ae-08-multicollinearity.html#exercise-1",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit the regression model using high temperature, average temperature, season, and precipitation to predict volume.\nAre there any coefficients that may be not what you expected?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-2",
    "href": "ae/ae-08-multicollinearity.html#exercise-2",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the formula\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nto calculate the VIF for avgtemp."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-3",
    "href": "ae/ae-08-multicollinearity.html#exercise-3",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 3",
    "text": "Exercise 3\nBased on the VIF from the previous exercise, does avgtemp have a linear dependency with one or more other predictors? Explain."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-4",
    "href": "ae/ae-08-multicollinearity.html#exercise-4",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nUse the vif function to compute VIF for all the predictors in Exercise 1.\nAre there predictors with near-linear dependencies? If so, which ones?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-5",
    "href": "ae/ae-08-multicollinearity.html#exercise-5",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s address the issue of multicollinearity. Choose a strategy to address the multicollinearity. Apply it, then use relevant statistics to select a final model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html",
    "href": "ae/ae-06-model-compare.html",
    "title": "AE 06: Model comparison",
    "section": "",
    "text": "Important\n\n\n\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#data",
    "href": "ae/ae-06-model-compare.html#data",
    "title": "AE 06: Model comparison",
    "section": "Data",
    "text": "Data\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\nDay: Day of the week (includes every day but Monday)\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-1",
    "href": "ae/ae-06-model-compare.html#exercise-1",
    "title": "AE 06: Model comparison",
    "section": "Exercise 1",
    "text": "Exercise 1\nSplit the data into training (80%) and testing (20%) sets. Use seed 2025."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-2",
    "href": "ae/ae-06-model-compare.html#exercise-2",
    "title": "AE 06: Model comparison",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the training data to fit a model using Party, Age, and Meal to predict tips. Compute the \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-3",
    "href": "ae/ae-06-model-compare.html#exercise-3",
    "title": "AE 06: Model comparison",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow fit a model predicting tips using Party, Age, and Meal, such that the effect of party can differ by Meal. Compute \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-4",
    "href": "ae/ae-06-model-compare.html#exercise-4",
    "title": "AE 06: Model comparison",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich model do you choose - the model from Exercise 2 or Exercise 3? Why?\nCompute RMSE for the selected model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-5",
    "href": "ae/ae-06-model-compare.html#exercise-5",
    "title": "AE 06: Model comparison",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s use the testing data to assess the performance of the model selected in Exercise 4.\n\nCompute the predicted tips for the testing data. Add the predictions to the testing data set.\nCompute RMSE and \\(R^2\\) for the testing data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-6",
    "href": "ae/ae-06-model-compare.html#exercise-6",
    "title": "AE 06: Model comparison",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nHow do RMSE compare between the training and testing data?\nHow does \\(R^2\\) compare between the training and testing data?\nIs this what you expect? Why?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-7",
    "href": "ae/ae-06-model-compare.html#exercise-7",
    "title": "AE 06: Model comparison",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhy can we use \\(R^2\\) as an assessment of performance on the testing data even if we can’t use it to compare models?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "href": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "title": "AE 06: Model comparison",
    "section": "To submit the AE:",
    "text": "To submit the AE:\n\n\n\n\n\n\nImportant\n\n\n\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-09-prob-odds.html",
    "href": "ae/ae-09-prob-odds.html",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-09 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-1",
    "href": "ae/ae-09-prob-odds.html#exercise-1",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nWhat is the probability a randomly selected respondent has heard a lot about AI?\nWhat are the odds a randomly selected respondent has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-2",
    "href": "ae/ae-09-prob-odds.html#exercise-2",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the probability a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?\nWhat are the odds a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-3",
    "href": "ae/ae-09-prob-odds.html#exercise-3",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 3",
    "text": "Exercise 3\nMake a plot to visualize the relationship between how much a respondent has heard about AI and being concerned with increased use of AI in daily life. Use the plot to describe the relationship between the two variables."
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-4",
    "href": "ae/ae-09-prob-odds.html#exercise-4",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard nothing about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard a little about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-5",
    "href": "ae/ae-09-prob-odds.html#exercise-5",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe can use a logistic regression model to understand the relationship between how much someone has heard about AI and whether they are concerned about increased use of AI in daily life. (We will discuss this in detail next class, but will get a preview for now.)\nLet \\(p\\) be the probability a randomly selected respondent is concerned about increased use of AI in daily life. The statistical model is\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{p_i}{1-p_i}\\Big) = \\beta_0 &+ \\beta_1\\boldsymbol{1}(ai\\_heard_i = \\text{A little}) \\\\ &+ \\beta_2\\mathbf{1}(ai\\_heard_i = \\text{Nothing}) \\\\  &+ \\beta_3\\mathbf{1}(ai\\_heard_i = \\text{Refused})\n\\end{aligned}\n\\]\nThe code and output to fit this model is shown below:\n\nai_concern_fit &lt;- glm(ai_concern ~ ai_heard, data = pew_data,\n                      family = \"binomial\")\ntidy(ai_concern_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.065\n0.031\n-2.082\n0.037\n\n\nai_heardA little\n0.383\n0.040\n9.504\n0.000\n\n\nai_heardNothing at all\n-0.276\n0.079\n-3.505\n0.000\n\n\nai_heardRefused\n-0.697\n0.459\n-1.520\n0.129\n\n\n\n\n\n\nInterpret the intercept in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardA little in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardNothing at all in the context of the data in terms of the odds of being concerned about the increased use of AI in daily life. How does this compare to your response to Exercise 4?\n\n\n\n\n\n\n\nSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours on the course Canvas site.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may me at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-canvas",
    "href": "support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "slides/lab-02.html#goals",
    "href": "slides/lab-02.html#goals",
    "title": "Lab 02",
    "section": "Goals",
    "text": "Goals\n\nMeet your team!\nTeam agreement\nLab 02: Coffee ratings"
  },
  {
    "objectID": "slides/lab-02.html#meet-your-team",
    "href": "slides/lab-02.html#meet-your-team",
    "title": "Lab 02",
    "section": "Meet your team!",
    "text": "Meet your team!\n\nClick here to find your team.\nSit with your team."
  },
  {
    "objectID": "slides/lab-02.html#team-name-agreement",
    "href": "slides/lab-02.html#team-name-agreement",
    "title": "Lab 02",
    "section": "Team name + agreement",
    "text": "Team name + agreement\n\nCome up with a team name. You can’t have the same name as another group in the class, so be creative!\n\nYour TA will get your team name by the end of lab.\n\nFill out the team agreement. The goals of the agreement are to…\n\nGain a common understanding of the team’s goals and expectations for collaboration\nMake a plan for team communication\nMake a plan for working outside of lab"
  },
  {
    "objectID": "slides/lab-02.html#team-workflow",
    "href": "slides/lab-02.html#team-workflow",
    "title": "Lab 02",
    "section": "Team workflow",
    "text": "Team workflow\n\nOnly one team member should type at a time. There are markers in today’s lab to help you determine whose turn it is to type.\n\nEvery team member should still be engaged in discussion for all questions, even if it’s not your turn type.\n\nDon’t forget to pull to get your teammates’ updates before making changes to the .qmd file.\n\n\n\n\n\n\nImportant\n\n\nOnly one submission per team on Gradescope. Read the submission instructions carefully!"
  },
  {
    "objectID": "slides/lab-02.html#team-workflow-in-action",
    "href": "slides/lab-02.html#team-workflow-in-action",
    "title": "Lab 02",
    "section": "Team workflow, in action",
    "text": "Team workflow, in action\n\nComplete the “Workflow: Using Git and GitHub as a team” section of the lab in your teams.\nRaise your hand if you have any questions about the workflow.\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lab-02.html#tips-for-working-on-a-team",
    "href": "slides/lab-02.html#tips-for-working-on-a-team",
    "title": "Lab 02",
    "section": "Tips for working on a team",
    "text": "Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other."
  },
  {
    "objectID": "slides/lab-02.html#todays-lab",
    "href": "slides/lab-02.html#todays-lab",
    "title": "Lab 02",
    "section": "Today’s lab",
    "text": "Today’s lab\nToday’s lab focuses on using statistical inference based on mathematical models to explore the relationship between coffee’s properties and the overall quality rating.\n\n🔗 https://sta210-sp25.netlify.app/labs/lab-02"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html",
    "href": "slides/15-transformations-contd-notes.html",
    "title": "Variable transformations cont’d",
    "section": "",
    "text": "Lab 04 due TODAY at 11:59pm\nHW 03 due Tuesday March 18 at 11:59pm\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 17\n\n\n\n\nHave a good spring break! 😎"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#announcements",
    "href": "slides/15-transformations-contd-notes.html#announcements",
    "title": "Variable transformations cont’d",
    "section": "",
    "text": "Lab 04 due TODAY at 11:59pm\nHW 03 due Tuesday March 18 at 11:59pm\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 17\n\n\n\n\nHave a good spring break! 😎"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#computing-set-up",
    "href": "slides/15-transformations-contd-notes.html#computing-set-up",
    "title": "Variable transformations cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#topics",
    "href": "slides/15-transformations-contd-notes.html#topics",
    "title": "Variable transformations cont’d",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the predictor"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#math-rules",
    "href": "slides/15-transformations-contd-notes.html#math-rules",
    "title": "Variable transformations cont’d",
    "section": "Math rules",
    "text": "Math rules\n\\[\n\\begin{aligned}\n\\log(ab) &= \\log(a) + \\log(b) \\\\[8pt]\n\\log\\big(\\frac{a}{b}\\big) &= \\log(a) - \\log(b)\\\\[15pt]\ne^{a + b + c} &= e^ae^be^c \\\\[8pt]\ne^{a - b} &= \\frac{e^a}{e^b}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#data-life-expectancy-in-140-countries",
    "href": "slides/15-transformations-contd-notes.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations cont’d",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#variables",
    "href": "slides/15-transformations-contd-notes.html#variables",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#variables-1",
    "href": "slides/15-transformations-contd-notes.html#variables-1",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare goods and services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#review-model-with-logy",
    "href": "slides/15-transformations-contd-notes.html#review-model-with-logy",
    "title": "Variable transformations cont’d",
    "section": "Review: Model with log(Y)",
    "text": "Review: Model with log(Y)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n7.096\n0.324\n21.895\n0\n\n\nincome_inequality\n-0.065\n0.011\n-5.714\n0\n\n\neducationHigh\n1.117\n0.218\n5.121\n0\n\n\n\n\n\n\nFor each additional point in the income inequality index, a country’s health expenditures are expected to multiply by 0.937 \\((e^{-0.065})\\), holding education constant."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#compare-residual-plots",
    "href": "slides/15-transformations-contd-notes.html#compare-residual-plots",
    "title": "Variable transformations cont’d",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#variability-in-life-expectancy",
    "href": "slides/15-transformations-contd-notes.html#variability-in-life-expectancy",
    "title": "Variable transformations cont’d",
    "section": "Variability in life expectancy",
    "text": "Variability in life expectancy\nLet’s consider a model using a country’s healthcare expenditure, income inequality, and education to predict its life expectancy"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#original-model",
    "href": "slides/15-transformations-contd-notes.html#original-model",
    "title": "Variable transformations cont’d",
    "section": "Original model",
    "text": "Original model\n\nlife_exp_fit &lt;- lm(life_exp ~ health_expenditure + income_inequality + education, \n                   data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n78.575\n1.775\n44.274\n0.000\n\n\nhealth_expenditure\n0.001\n0.000\n4.522\n0.000\n\n\nincome_inequality\n-0.484\n0.061\n-7.900\n0.000\n\n\neducationHigh\n2.020\n1.168\n1.730\n0.086"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#original-model-residuals",
    "href": "slides/15-transformations-contd-notes.html#original-model-residuals",
    "title": "Variable transformations cont’d",
    "section": "Original model: Residuals",
    "text": "Original model: Residuals"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#residuals-vs.-predictors",
    "href": "slides/15-transformations-contd-notes.html#residuals-vs.-predictors",
    "title": "Variable transformations cont’d",
    "section": "Residuals vs. predictors",
    "text": "Residuals vs. predictors\n\n\n\n\n\n\n\n\n\n. . .\n\nThere is a non-linear relationship is between health expenditure and life expectancy."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#log-transformation-on-x",
    "href": "slides/15-transformations-contd-notes.html#log-transformation-on-x",
    "title": "Variable transformations cont’d",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\nTry a transformation on \\(X\\) if the scatterplot in EDA shows non-linear relationship and residuals vs. fitted looks parabolic"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#eda",
    "href": "slides/15-transformations-contd-notes.html#eda",
    "title": "Variable transformations cont’d",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-with-transformation-on-x_j",
    "href": "slides/15-transformations-contd-notes.html#model-with-transformation-on-x_j",
    "title": "Variable transformations cont’d",
    "section": "Model with Transformation on \\(X_j\\)",
    "text": "Model with Transformation on \\(X_j\\)\nWhen we fit a model with predictor \\(\\log(X_j)\\), we fit a model of the form\n\\[\nY = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_j\\log(X_j) + \\dots \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nThe estimated regression model is\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-interpretation",
    "href": "slides/15-transformations-contd-notes.html#model-interpretation",
    "title": "Variable transformations cont’d",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = \\log(x_{ij}) = \\dots = x_{ip} = 0\\) , \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\), on average.\n\n\\(\\log(x_{ij}) = 0\\) when \\(x_{ij} = 1\\)\n\nCoefficient of \\(X_j\\): When \\(x_{ij}\\) is multiplied by a factor of \\(C\\), \\(y_i\\) is expected to change by \\(\\hat{\\beta}_j\\log(C)\\) units, on average, holding all else constant.\n\nExample: When \\(x_{ij}\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_j\\log(2)\\) units, on average, holding all else constant."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-with-logx",
    "href": "slides/15-transformations-contd-notes.html#model-with-logx",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X)",
    "text": "Model with log(X)\n\nlife_exp_logx_fit &lt;- lm(life_exp ~ log(health_expenditure) + income_inequality \n                        + education, data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n59.151\n3.184\n18.576\n0.000\n\n\nlog(health_expenditure)\n3.092\n0.396\n7.814\n0.000\n\n\nincome_inequality\n-0.362\n0.058\n-6.225\n0.000\n\n\neducationHigh\n-0.168\n1.103\n-0.152\n0.879\n\n\n\n\n\n\n\n\nInterpret the intercept in the context of the data.\nInterpret the effect of health expenditure in the context of the data.\nInterpret the effect of education in the context of the data."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#model-with-logx-residuals",
    "href": "slides/15-transformations-contd-notes.html#model-with-logx-residuals",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X): Residuals",
    "text": "Model with log(X): Residuals"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#comparing-residual-plots",
    "href": "slides/15-transformations-contd-notes.html#comparing-residual-plots",
    "title": "Variable transformations cont’d",
    "section": "Comparing residual plots",
    "text": "Comparing residual plots"
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#learn-more",
    "href": "slides/15-transformations-contd-notes.html#learn-more",
    "title": "Variable transformations cont’d",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/15-transformations-contd-notes.html#recap",
    "href": "slides/15-transformations-contd-notes.html#recap",
    "title": "Variable transformations cont’d",
    "section": "Recap",
    "text": "Recap\n\nIntroduced log-transformation on the predictor\nIdentified linear models"
  },
  {
    "objectID": "slides/15-transformations-contd.html#announcements",
    "href": "slides/15-transformations-contd.html#announcements",
    "title": "Variable transformations cont’d",
    "section": "Announcements",
    "text": "Announcements\n\nLab 04 due TODAY at 11:59pm\nHW 03 due Tuesday March 18 at 11:59pm\nNext project milestone: Exploratory data analysis due March 20\n\nWork on it in lab March 17\n\n\n\n\nHave a good spring break! 😎"
  },
  {
    "objectID": "slides/15-transformations-contd.html#computing-set-up",
    "href": "slides/15-transformations-contd.html#computing-set-up",
    "title": "Variable transformations cont’d",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/15-transformations-contd.html#topics",
    "href": "slides/15-transformations-contd.html#topics",
    "title": "Variable transformations cont’d",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the predictor"
  },
  {
    "objectID": "slides/15-transformations-contd.html#math-rules",
    "href": "slides/15-transformations-contd.html#math-rules",
    "title": "Variable transformations cont’d",
    "section": "Math rules",
    "text": "Math rules\n\\[\n\\begin{aligned}\n\\log(ab) &= \\log(a) + \\log(b) \\\\[8pt]\n\\log\\big(\\frac{a}{b}\\big) &= \\log(a) - \\log(b)\\\\[15pt]\ne^{a + b + c} &= e^ae^be^c \\\\[8pt]\ne^{a - b} &= \\frac{e^a}{e^b}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/15-transformations-contd.html#data-life-expectancy-in-140-countries",
    "href": "slides/15-transformations-contd.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations cont’d",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/15-transformations-contd.html#variables",
    "href": "slides/15-transformations-contd.html#variables",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/15-transformations-contd.html#variables-1",
    "href": "slides/15-transformations-contd.html#variables-1",
    "title": "Variable transformations cont’d",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare goods and services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/15-transformations-contd.html#review-model-with-logy",
    "href": "slides/15-transformations-contd.html#review-model-with-logy",
    "title": "Variable transformations cont’d",
    "section": "Review: Model with log(Y)",
    "text": "Review: Model with log(Y)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n7.096\n0.324\n21.895\n0\n\n\nincome_inequality\n-0.065\n0.011\n-5.714\n0\n\n\neducationHigh\n1.117\n0.218\n5.121\n0\n\n\n\n\n\n\nFor each additional point in the income inequality index, a country’s health expenditures are expected to multiply by 0.937 \\((e^{-0.065})\\), holding education constant."
  },
  {
    "objectID": "slides/15-transformations-contd.html#compare-residual-plots",
    "href": "slides/15-transformations-contd.html#compare-residual-plots",
    "title": "Variable transformations cont’d",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/15-transformations-contd.html#variability-in-life-expectancy",
    "href": "slides/15-transformations-contd.html#variability-in-life-expectancy",
    "title": "Variable transformations cont’d",
    "section": "Variability in life expectancy",
    "text": "Variability in life expectancy\nLet’s consider a model using a country’s healthcare expenditure, income inequality, and education to predict its life expectancy"
  },
  {
    "objectID": "slides/15-transformations-contd.html#original-model",
    "href": "slides/15-transformations-contd.html#original-model",
    "title": "Variable transformations cont’d",
    "section": "Original model",
    "text": "Original model\n\nlife_exp_fit &lt;- lm(life_exp ~ health_expenditure + income_inequality + education, \n                   data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n78.575\n1.775\n44.274\n0.000\n\n\nhealth_expenditure\n0.001\n0.000\n4.522\n0.000\n\n\nincome_inequality\n-0.484\n0.061\n-7.900\n0.000\n\n\neducationHigh\n2.020\n1.168\n1.730\n0.086"
  },
  {
    "objectID": "slides/15-transformations-contd.html#original-model-residuals",
    "href": "slides/15-transformations-contd.html#original-model-residuals",
    "title": "Variable transformations cont’d",
    "section": "Original model: Residuals",
    "text": "Original model: Residuals"
  },
  {
    "objectID": "slides/15-transformations-contd.html#residuals-vs.-predictors",
    "href": "slides/15-transformations-contd.html#residuals-vs.-predictors",
    "title": "Variable transformations cont’d",
    "section": "Residuals vs. predictors",
    "text": "Residuals vs. predictors\n\n\n\nThere is a non-linear relationship is between health expenditure and life expectancy."
  },
  {
    "objectID": "slides/15-transformations-contd.html#log-transformation-on-x",
    "href": "slides/15-transformations-contd.html#log-transformation-on-x",
    "title": "Variable transformations cont’d",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\nTry a transformation on \\(X\\) if the scatterplot in EDA shows non-linear relationship and residuals vs. fitted looks parabolic"
  },
  {
    "objectID": "slides/15-transformations-contd.html#eda",
    "href": "slides/15-transformations-contd.html#eda",
    "title": "Variable transformations cont’d",
    "section": "EDA",
    "text": "EDA"
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-with-transformation-on-x_j",
    "href": "slides/15-transformations-contd.html#model-with-transformation-on-x_j",
    "title": "Variable transformations cont’d",
    "section": "Model with Transformation on \\(X_j\\)",
    "text": "Model with Transformation on \\(X_j\\)\nWhen we fit a model with predictor \\(\\log(X_j)\\), we fit a model of the form\n\\[\nY = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_j\\log(X_j) + \\dots \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\nThe estimated regression model is\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]"
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-interpretation",
    "href": "slides/15-transformations-contd.html#model-interpretation",
    "title": "Variable transformations cont’d",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = \\log(x_{ij}) = \\dots = x_{ip} = 0\\) , \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\), on average.\n\n\\(\\log(x_{ij}) = 0\\) when \\(x_{ij} = 1\\)\n\nCoefficient of \\(X_j\\): When \\(x_{ij}\\) is multiplied by a factor of \\(C\\), \\(y_i\\) is expected to change by \\(\\hat{\\beta}_j\\log(C)\\) units, on average, holding all else constant.\n\nExample: When \\(x_{ij}\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_j\\log(2)\\) units, on average, holding all else constant."
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-with-logx",
    "href": "slides/15-transformations-contd.html#model-with-logx",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X)",
    "text": "Model with log(X)\n\nlife_exp_logx_fit &lt;- lm(life_exp ~ log(health_expenditure) + income_inequality \n                        + education, data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n59.151\n3.184\n18.576\n0.000\n\n\nlog(health_expenditure)\n3.092\n0.396\n7.814\n0.000\n\n\nincome_inequality\n-0.362\n0.058\n-6.225\n0.000\n\n\neducationHigh\n-0.168\n1.103\n-0.152\n0.879\n\n\n\n\n\n\n\n\nInterpret the intercept in the context of the data.\nInterpret the effect of health expenditure in the context of the data.\nInterpret the effect of education in the context of the data."
  },
  {
    "objectID": "slides/15-transformations-contd.html#model-with-logx-residuals",
    "href": "slides/15-transformations-contd.html#model-with-logx-residuals",
    "title": "Variable transformations cont’d",
    "section": "Model with log(X): Residuals",
    "text": "Model with log(X): Residuals"
  },
  {
    "objectID": "slides/15-transformations-contd.html#comparing-residual-plots",
    "href": "slides/15-transformations-contd.html#comparing-residual-plots",
    "title": "Variable transformations cont’d",
    "section": "Comparing residual plots",
    "text": "Comparing residual plots"
  },
  {
    "objectID": "slides/15-transformations-contd.html#learn-more",
    "href": "slides/15-transformations-contd.html#learn-more",
    "title": "Variable transformations cont’d",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/15-transformations-contd.html#recap",
    "href": "slides/15-transformations-contd.html#recap",
    "title": "Variable transformations cont’d",
    "section": "Recap",
    "text": "Recap\n\nIntroduced log-transformation on the predictor\nIdentified linear models"
  },
  {
    "objectID": "slides/15-transformations-contd.html#references",
    "href": "slides/15-transformations-contd.html#references",
    "title": "Variable transformations cont’d",
    "section": "References",
    "text": "References\n\n\n\n\nZarulli, Virginia, Elizaveta Sopina, Veronica Toffolutti, and Adam Lenart. 2021. “Health Care System Efficiency and Life Expectancy: A 140-Country Study.” Edited by Srinivas Goli. PLOS ONE 16 (7): e0253450. https://doi.org/10.1371/journal.pone.0253450."
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html",
    "href": "slides/13-multicollinearity-notes.html",
    "title": "Multicollinearity",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm on Canvas\nProject proposal due TODAY at 11:59pm\nTeam Feedback (email from Teammates) due Tuesday, March 4 at 11:59pm\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#announcements",
    "href": "slides/13-multicollinearity-notes.html#announcements",
    "title": "Multicollinearity",
    "section": "",
    "text": "Exam corrections (optional) due Tuesday, March 4 at 11:59pm on Canvas\nProject proposal due TODAY at 11:59pm\nTeam Feedback (email from Teammates) due Tuesday, March 4 at 11:59pm\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#computing-set-up",
    "href": "slides/13-multicollinearity-notes.html#computing-set-up",
    "title": "Multicollinearity",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#topics",
    "href": "slides/13-multicollinearity-notes.html#topics",
    "title": "Multicollinearity",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#data-trail-users",
    "href": "slides/13-multicollinearity-notes.html#data-trail-users",
    "title": "Multicollinearity",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#variables",
    "href": "slides/13-multicollinearity-notes.html#variables",
    "title": "Multicollinearity",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors",
    "href": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\nWe can create a pairwise plot matrix using the ggpairs function from the GGally R package\n\nrail_trail |&gt;\n  select(hightemp, avgtemp, season, precip) |&gt;\n  ggpairs()"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors-1",
    "href": "slides/13-multicollinearity-notes.html#eda-relationship-between-predictors-1",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-correlation-matrix",
    "href": "slides/13-multicollinearity-notes.html#eda-correlation-matrix",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\nWe can. use corrplot() in the corrplot R package to make a matrix of pairwise correlations between quantitative predictors\n\ncorrelations &lt;- rail_trail |&gt;\n  select(hightemp, avgtemp, precip) |&gt;\n  cor()\n\ncorrplot(correlations, method = \"number\")"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#eda-correlation-matrix-1",
    "href": "slides/13-multicollinearity-notes.html#eda-correlation-matrix-1",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\n\n\n\n\n\n\n\n\n\n\nWhat might be a potential concern with a model that uses high temperature, average temperature, season, and precipitation to predict volume?"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#multicollinearity-1",
    "href": "slides/13-multicollinearity-notes.html#multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\n\nIdeally the predictors are completely independent of one another\nIn practice, there is typically some relationship between predictors but it is often not a major issue in the model\nIf there predictors are perfectly correlated, we cannot find values of \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\) that best fit the model\nIf predictors are strongly correlated, we can find \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\), but there may be other issues with the model\nMulticollinearity: predictors are strongly correlated with each other\n\n\n\n\nSource: Montgomery, Peck, and Vining (2021)"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#sources-of-multicollinearity",
    "href": "slides/13-multicollinearity-notes.html#sources-of-multicollinearity",
    "title": "Multicollinearity",
    "section": "Sources of multicollinearity",
    "text": "Sources of multicollinearity\n\n\nData collection method - only sample from a subspace of the region of predictors\nConstraints in the population - e.g., predictors family income and size of house\nChoice of model - e.g., adding high order or interaction terms to the model\nOverdefined model - have more predictors than observations"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#example-issue-with-multicollinearity",
    "href": "slides/13-multicollinearity-notes.html#example-issue-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Example: Issue with multicollinearity",
    "text": "Example: Issue with multicollinearity\nLet’s assume the true population regression equation is \\(y = 3 + 4x\\)\n. . .\nSuppose we try estimating that equation using a model with variables \\(x\\) and \\(z = x/10\\)\n\\[\n\\begin{aligned}\\hat{y}&= \\hat{\\beta}_0 + \\hat{\\beta}_1x  + \\hat{\\beta}_2z\\\\\n&= \\hat{\\beta}_0 + \\hat{\\beta}_1x  + \\hat{\\beta}_2\\frac{x}{10}\\\\\n&= \\hat{\\beta}_0 + \\bigg(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10}\\bigg)x\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#example-issue-with-mulitcollinearity",
    "href": "slides/13-multicollinearity-notes.html#example-issue-with-mulitcollinearity",
    "title": "Multicollinearity",
    "section": "Example: Issue with mulitcollinearity",
    "text": "Example: Issue with mulitcollinearity\n\\[\\hat{y} = \\hat{\\beta}_0 + \\bigg(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10}\\bigg)x\\]\n\nWe can set \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_2\\) to any two numbers such that \\(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10} = 4\\)\nTherefore, we are unable to choose the “best” combination of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_2\\)"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#variance-inflation-factor",
    "href": "slides/13-multicollinearity-notes.html#variance-inflation-factor",
    "title": "Multicollinearity",
    "section": "Variance inflation factor",
    "text": "Variance inflation factor\n\nThe variance inflation factor (VIF) is a measure of the collinearity between predictor \\(x_j\\) and all other predictors in the model\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by all the other predictors"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#detecting-multicollinearity",
    "href": "slides/13-multicollinearity-notes.html#detecting-multicollinearity",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nCommon practice uses threshold \\(VIF &gt; 10\\) as indication of concerning multicollinearity (some say VIF &gt; 5 is worth investigation)\nVariables with similar values of VIF are typically the ones correlated with each other\nUse the vif() function in the rms R package to calculate VIF\n\n\nlibrary(rms)\n\ntrail_fit &lt;- lm(volume ~ hightemp + avgtemp + precip, data = rail_trail)\n\nvif(trail_fit)\n\nhightemp  avgtemp   precip \n7.161882 7.597154 1.193431"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#how-multicollinearity-impacts-model",
    "href": "slides/13-multicollinearity-notes.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\n\nWhen we have perfect collinearities, we are unable to get estimates for the coefficients\nWhen we have almost perfect collinearities (i.e. highly correlated predictor variables), the standard errors for our regression coefficients inflate\n\nIn other words, we lose precision in our estimates of the regression coefficients\nThis impedes our ability to use the model for inference\n\nIt is also difficult to interpret the model coefficients"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#dealing-with-multicollinearity",
    "href": "slides/13-multicollinearity-notes.html#dealing-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/13-multicollinearity-notes.html#recap",
    "href": "slides/13-multicollinearity-notes.html#recap",
    "title": "Multicollinearity",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multicollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity.html#announcements",
    "href": "slides/13-multicollinearity.html#announcements",
    "title": "Multicollinearity",
    "section": "Announcements",
    "text": "Announcements\n\nExam corrections (optional) due Tuesday, March 4 at 11:59pm on Canvas\nProject proposal due TODAY at 11:59pm\nTeam Feedback (email from Teammates) due Tuesday, March 4 at 11:59pm\nDataFest: April 4 - 6 - https://dukestatsci.github.io/datafest/"
  },
  {
    "objectID": "slides/13-multicollinearity.html#computing-set-up",
    "href": "slides/13-multicollinearity.html#computing-set-up",
    "title": "Multicollinearity",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\nlibrary(GGally)   # for pairwise plot matrix\nlibrary(corrplot) # for correlation matrix\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/13-multicollinearity.html#topics",
    "href": "slides/13-multicollinearity.html#topics",
    "title": "Multicollinearity",
    "section": "Topics",
    "text": "Topics\n\nMulticollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity.html#data-trail-users",
    "href": "slides/13-multicollinearity.html#data-trail-users",
    "title": "Multicollinearity",
    "section": "Data: Trail users",
    "text": "Data: Trail users\n\nThe Pioneer Valley Planning Commission (PVPC) collected data at the beginning a trail in Florence, MA for ninety days from April 5, 2005 to November 15, 2005\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n# A tibble: 5 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60  0     Weekday \n2    419       73    61   Summer       6.30  0.290 Weekday \n3    397       74    63   Spring       7.5   0.320 Weekday \n4    385       95    78   Summer       2.60  0     Weekend \n5    200       44    48   Spring      10     0.140 Weekday \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/13-multicollinearity.html#variables",
    "href": "slides/13-multicollinearity.html#variables",
    "title": "Multicollinearity",
    "section": "Variables",
    "text": "Variables\nOutcome:\n\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\nprecip measure of precipitation (in inches)"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-relationship-between-predictors",
    "href": "slides/13-multicollinearity.html#eda-relationship-between-predictors",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors\nWe can create a pairwise plot matrix using the ggpairs function from the GGally R package\n\nrail_trail |&gt;\n  select(hightemp, avgtemp, season, precip) |&gt;\n  ggpairs()"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-relationship-between-predictors-1",
    "href": "slides/13-multicollinearity.html#eda-relationship-between-predictors-1",
    "title": "Multicollinearity",
    "section": "EDA: Relationship between predictors",
    "text": "EDA: Relationship between predictors"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-correlation-matrix",
    "href": "slides/13-multicollinearity.html#eda-correlation-matrix",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\nWe can. use corrplot() in the corrplot R package to make a matrix of pairwise correlations between quantitative predictors\n\ncorrelations &lt;- rail_trail |&gt;\n  select(hightemp, avgtemp, precip) |&gt;\n  cor()\n\ncorrplot(correlations, method = \"number\")"
  },
  {
    "objectID": "slides/13-multicollinearity.html#eda-correlation-matrix-1",
    "href": "slides/13-multicollinearity.html#eda-correlation-matrix-1",
    "title": "Multicollinearity",
    "section": "EDA: Correlation matrix",
    "text": "EDA: Correlation matrix\n\n\nWhat might be a potential concern with a model that uses high temperature, average temperature, season, and precipitation to predict volume?"
  },
  {
    "objectID": "slides/13-multicollinearity.html#multicollinearity-1",
    "href": "slides/13-multicollinearity.html#multicollinearity-1",
    "title": "Multicollinearity",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\n\nIdeally the predictors are completely independent of one another\nIn practice, there is typically some relationship between predictors but it is often not a major issue in the model\nIf there predictors are perfectly correlated, we cannot find values of \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\) that best fit the model\nIf predictors are strongly correlated, we can find \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\), but there may be other issues with the model\nMulticollinearity: predictors are strongly correlated with each other\n\n\n\n\nSource: Montgomery, Peck, and Vining (2021)"
  },
  {
    "objectID": "slides/13-multicollinearity.html#sources-of-multicollinearity",
    "href": "slides/13-multicollinearity.html#sources-of-multicollinearity",
    "title": "Multicollinearity",
    "section": "Sources of multicollinearity",
    "text": "Sources of multicollinearity\n\n\nData collection method - only sample from a subspace of the region of predictors\nConstraints in the population - e.g., predictors family income and size of house\nChoice of model - e.g., adding high order or interaction terms to the model\nOverdefined model - have more predictors than observations"
  },
  {
    "objectID": "slides/13-multicollinearity.html#example-issue-with-multicollinearity",
    "href": "slides/13-multicollinearity.html#example-issue-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Example: Issue with multicollinearity",
    "text": "Example: Issue with multicollinearity\nLet’s assume the true population regression equation is \\(y = 3 + 4x\\)\n\nSuppose we try estimating that equation using a model with variables \\(x\\) and \\(z = x/10\\)\n\\[\n\\begin{aligned}\\hat{y}&= \\hat{\\beta}_0 + \\hat{\\beta}_1x  + \\hat{\\beta}_2z\\\\\n&= \\hat{\\beta}_0 + \\hat{\\beta}_1x  + \\hat{\\beta}_2\\frac{x}{10}\\\\\n&= \\hat{\\beta}_0 + \\bigg(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10}\\bigg)x\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/13-multicollinearity.html#example-issue-with-mulitcollinearity",
    "href": "slides/13-multicollinearity.html#example-issue-with-mulitcollinearity",
    "title": "Multicollinearity",
    "section": "Example: Issue with mulitcollinearity",
    "text": "Example: Issue with mulitcollinearity\n\\[\\hat{y} = \\hat{\\beta}_0 + \\bigg(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10}\\bigg)x\\]\n\nWe can set \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_2\\) to any two numbers such that \\(\\hat{\\beta}_1 + \\frac{\\hat{\\beta}_2}{10} = 4\\)\nTherefore, we are unable to choose the “best” combination of \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_2\\)"
  },
  {
    "objectID": "slides/13-multicollinearity.html#variance-inflation-factor",
    "href": "slides/13-multicollinearity.html#variance-inflation-factor",
    "title": "Multicollinearity",
    "section": "Variance inflation factor",
    "text": "Variance inflation factor\n\nThe variance inflation factor (VIF) is a measure of the collinearity between predictor \\(x_j\\) and all other predictors in the model\n\n\\[\nVIF_{j} = \\frac{1}{1 - R^2_j}\n\\]\nwhere \\(R^2_j\\) is the proportion of variation in \\(x_j\\) that is explained by all the other predictors"
  },
  {
    "objectID": "slides/13-multicollinearity.html#detecting-multicollinearity",
    "href": "slides/13-multicollinearity.html#detecting-multicollinearity",
    "title": "Multicollinearity",
    "section": "Detecting multicollinearity",
    "text": "Detecting multicollinearity\n\nCommon practice uses threshold \\(VIF &gt; 10\\) as indication of concerning multicollinearity (some say VIF &gt; 5 is worth investigation)\nVariables with similar values of VIF are typically the ones correlated with each other\nUse the vif() function in the rms R package to calculate VIF\n\n\nlibrary(rms)\n\ntrail_fit &lt;- lm(volume ~ hightemp + avgtemp + precip, data = rail_trail)\n\nvif(trail_fit)\n\nhightemp  avgtemp   precip \n7.161882 7.597154 1.193431"
  },
  {
    "objectID": "slides/13-multicollinearity.html#how-multicollinearity-impacts-model",
    "href": "slides/13-multicollinearity.html#how-multicollinearity-impacts-model",
    "title": "Multicollinearity",
    "section": "How multicollinearity impacts model",
    "text": "How multicollinearity impacts model\n\n\nWhen we have perfect collinearities, we are unable to get estimates for the coefficients\nWhen we have almost perfect collinearities (i.e. highly correlated predictor variables), the standard errors for our regression coefficients inflate\n\nIn other words, we lose precision in our estimates of the regression coefficients\nThis impedes our ability to use the model for inference\n\nIt is also difficult to interpret the model coefficients"
  },
  {
    "objectID": "slides/13-multicollinearity.html#dealing-with-multicollinearity",
    "href": "slides/13-multicollinearity.html#dealing-with-multicollinearity",
    "title": "Multicollinearity",
    "section": "Dealing with multicollinearity",
    "text": "Dealing with multicollinearity\n\n\nCollect more data (often not feasible given practical constraints)\nRedefine the correlated predictors to keep the information from predictors but eliminate collinearity\n\ne.g., if \\(x_1, x_2, x_3\\) are correlated, use a new variable \\((x_1 + x_2) / x_3\\) in the model\n\nFor categorical predictors, avoid using levels with very few observations as the baseline\nRemove one of the correlated variables\n\nBe careful about substantially reducing predictive power of the model"
  },
  {
    "objectID": "slides/13-multicollinearity.html#recap",
    "href": "slides/13-multicollinearity.html#recap",
    "title": "Multicollinearity",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multicollinearity\n\nDefinition\nHow it impacts the model\nHow to detect it\nWhat to do about it"
  },
  {
    "objectID": "slides/13-multicollinearity.html#references",
    "href": "slides/13-multicollinearity.html#references",
    "title": "Multicollinearity",
    "section": "References",
    "text": "References\n\n\n\n\nMontgomery, Douglas C, Elizabeth A Peck, and G Geoffrey Vining. 2021. Introduction to Linear Regression Analysis. John Wiley & Sons."
  },
  {
    "objectID": "slides/lab-00.html#meet-your-tas",
    "href": "slides/lab-00.html#meet-your-tas",
    "title": "Welcome to STA 210 labs!",
    "section": "Meet your TAs!",
    "text": "Meet your TAs!"
  },
  {
    "objectID": "slides/lab-00.html#meet-each-other",
    "href": "slides/lab-00.html#meet-each-other",
    "title": "Welcome to STA 210 labs!",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\nGet into groups of 2 or 3\nIntroduce yourself: Name, year, major (or academic interest), a highlight from winter break or something you’re looking forward to this semester\nIntroduce your partner to the class\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab-00.html#what-to-expect-in-lab",
    "href": "slides/lab-00.html#what-to-expect-in-lab",
    "title": "Welcome to STA 210 labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the lab assignment (~ 5 - 10 minutes)\nReview lecture content, as needed (~ 10 minutes)\nWork on the lab assignment (individual in the beginning and with teams for the remainder of the semester)\nStarting with Lab 01, you will find the starter materials for lab in your repo in the course GitHub organization."
  },
  {
    "objectID": "slides/lab-00.html#todays-lab",
    "href": "slides/lab-00.html#todays-lab",
    "title": "Welcome to STA 210 labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on setting up the computing for the course and completing the class survey. Click the link below for the Lab 00 instructions. The instructions are available on the course website.\nYour TA will demonstrate the steps to set up computing and interact with RStudio and GitHub.\n\n🔗 sta210-sp25.netlify.app/labs/lab-00.html"
  },
  {
    "objectID": "slides/lab-04.html#goals",
    "href": "slides/lab-04.html#goals",
    "title": "Lab 04",
    "section": "Goals",
    "text": "Goals\n\nProject\nMid-semester survey\nLab 05: Expanding multiple linear regression"
  },
  {
    "objectID": "slides/lab-04.html#final-project",
    "href": "slides/lab-04.html#final-project",
    "title": "Lab 04",
    "section": "Final project",
    "text": "Final project\n\nFeedback on your project proposal is posted as an Issue in your project repo\nPlease let your lab TA know if you have any questions\nNext milestone: Exploratory Data Analysis due March 20\n\nTime to work on it in next lab"
  },
  {
    "objectID": "slides/lab-04.html#mid-semester-feedback",
    "href": "slides/lab-04.html#mid-semester-feedback",
    "title": "Lab 04",
    "section": "Mid-semester feedback",
    "text": "Mid-semester feedback\n\nPurpose: To give the teaching team feedback on what is working well (or not as well) in helping you learn the course content\nThe feedback is anonymous and will not be graded\nIt will be available until Thursday, March 6 at 11:59pm\n\nPlease take a few minutes to fill it out during lab today\n\n\n🔗 https://duke.qualtrics.com/jfe/form/SV_eJKzmGyGpSPNQai\nWe (the teaching team) appreciate your feedback!"
  },
  {
    "objectID": "slides/lab-04.html#todays-lab",
    "href": "slides/lab-04.html#todays-lab",
    "title": "Lab 04",
    "section": "Today’s lab",
    "text": "Today’s lab\nThis lab focuses on\n\nmodeling complex data using variable transformations, categorical predictors and interactions, and various model specifications.\nevaluating model diagnostics and conditions.\n\n🔗 https://sta210-sp25.netlify.app/labs/lab-04"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html",
    "href": "slides/06-slr-math-models-notes.html",
    "title": "SLR: Mathematical models for inference",
    "section": "",
    "text": "HW 01 due TODAY at 11:59pm\nLab 01 due Thursday at 11:59pm\n\nQuestions?\n\nStatistics experience - due Mon, Nov 20 at 11:59pm"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#announcements",
    "href": "slides/06-slr-math-models-notes.html#announcements",
    "title": "SLR: Mathematical models for inference",
    "section": "",
    "text": "HW 01 due TODAY at 11:59pm\nLab 01 due Thursday at 11:59pm\n\nQuestions?\n\nStatistics experience - due Mon, Nov 20 at 11:59pm"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#course-policy-reminders",
    "href": "slides/06-slr-math-models-notes.html#course-policy-reminders",
    "title": "SLR: Mathematical models for inference",
    "section": "Course policy reminders",
    "text": "Course policy reminders\n\nLate work\n\nHW and labs accepted up to 2 days late.\n5% deduction for each 24-hour period the assignment is late.\n\nOne time late waiver\n\nCan use on HW and individual labs\n\nLowest HW and lowest lab grade dropped at the end of the semester."
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#topics",
    "href": "slides/06-slr-math-models-notes.html#topics",
    "title": "SLR: Mathematical models for inference",
    "section": "Topics",
    "text": "Topics\n\nDefine mathematical models to conduct inference for the slope\nUse mathematical models to\n\ncalculate confidence interval for the slope\nconduct a hypothesis test for the slope\nconstruct intervals for predictions"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#computational-setup",
    "href": "slides/06-slr-math-models-notes.html#computational-setup",
    "title": "SLR: Mathematical models for inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#the-regression-model-revisited",
    "href": "slides/06-slr-math-models-notes.html#the-regression-model-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#inference-revisited",
    "href": "slides/06-slr-math-models-notes.html#inference-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we’ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#mathematical-representation-of-the-model",
    "href": "slides/06-slr-math-models-notes.html#mathematical-representation-of-the-model",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= \\text{Model} + \\text{Error} \\\\[8pt]\n&= f(X) + \\epsilon \\\\[8pt]\n&= E(Y|X) + \\epsilon \\\\[8pt]\n&= \\mu_{Y|X} + \\epsilon \\\\[8pt]\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n. . .\n\nindependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#side-note-expected-value-and-variance",
    "href": "slides/06-slr-math-models-notes.html#side-note-expected-value-and-variance",
    "title": "SLR: Mathematical models for inference",
    "section": "Side note: Expected value and variance",
    "text": "Side note: Expected value and variance\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants.\n\nExpected value\n\\[\nE(aX+b) = E(aX) + E(b) = aE(X) + b\n\\]\n\nVariance\n\\[\nVar(aX + b) = a^2Var(X)\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#mathematical-representation-visualized",
    "href": "slides/06-slr-math-models-notes.html#mathematical-representation-visualized",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#regression-standard-error",
    "href": "slides/06-slr-math-models-notes.html#regression-standard-error",
    "title": "SLR: Mathematical models for inference",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error, the average distance between the observed values and the regression line\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n. . .\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#standard-error-of-hatbeta_1",
    "href": "slides/06-slr-math-models-notes.html#standard-error-of-hatbeta_1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\nThe standard error of \\(\\hat{\\beta}_1\\) quantifies the sampling variability in the estimated slopes\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n. . .\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#hypothesis-test-for-the-slope",
    "href": "slides/06-slr-math-models-notes.html#hypothesis-test-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test for the slope",
    "text": "Hypothesis test for the slope\nHypotheses: \\(H_0: \\beta_1 = 0\\) vs. \\(H_A: \\beta_1 \\ne 0\\)\n. . .\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\nT = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n. . .\np-value: Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n - 2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#hypothesis-test-test-statistic",
    "href": "slides/06-slr-math-models-notes.html#hypothesis-test-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Test statistic",
    "text": "Hypothesis test: Test statistic\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\nT = \\frac{\\hat{\\beta}_1 - 0}{SE_{\\hat{\\beta}_1}} = \\frac{159.48 - 0}{18.17} = 8.78\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#interpreting-the-test-statistic",
    "href": "slides/06-slr-math-models-notes.html#interpreting-the-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the test statistic",
    "text": "Interpreting the test statistic\n\nThe test statistic is 8.78. What is the best interpretation?\n\nThe estimated slope of 159.48 is 8.78 standard errors away from the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above 0, the hypothesized mean.\nThe estimated slope of 159.48 is 8.78 standard errors away from 0, the hypothesized mean."
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#hypothesis-test-p-value",
    "href": "slides/06-slr-math-models-notes.html#hypothesis-test-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#hypothesis-test-p-value-1",
    "href": "slides/06-slr-math-models-notes.html#hypothesis-test-p-value-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\nA more exact p-value\n\n2 * pt(q = 8.78, df = 96, lower.tail = FALSE)\n\n[1] 6.19602e-14"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#interpreting-the-p-value",
    "href": "slides/06-slr-math-models-notes.html#interpreting-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the p-value",
    "text": "Interpreting the p-value\n\nWhat does the p-value mean in the context of the data?\n\nThe probability there is no linear relationship between area and price is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is a linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 or more extreme is approximately 0."
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#understanding-the-p-value",
    "href": "slides/06-slr-math-models-notes.html#understanding-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#hypothesis-test-conclusion-in-context",
    "href": "slides/06-slr-math-models-notes.html#hypothesis-test-conclusion-in-context",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Conclusion, in context",
    "text": "Hypothesis test: Conclusion, in context\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\n\nThe data provide convincing evidence that the population slope \\(\\beta_1\\) is different from 0.\nThe data provide convincing evidence of a linear relationship between area and price of houses in Duke Forest."
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#confidence-interval-for-the-slope",
    "href": "slides/06-slr-math-models-notes.html#confidence-interval-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n. . .\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE_{\\hat{\\beta}_1}\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#confidence-interval-critical-value",
    "href": "slides/06-slr-math-models-notes.html#confidence-interval-critical-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(duke_forest) - 2)\n\n[1] 1.984984\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(duke_forest) - 2)\n\n[1] 1.660881\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(duke_forest) - 2)\n\n[1] 2.628016"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#ci-for-the-slope-calculation",
    "href": "slides/06-slr-math-models-notes.html#ci-for-the-slope-calculation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Calculation",
    "text": "95% CI for the slope: Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\\hat{\\beta}_1 = 159.48 \\hspace{15mm} t^* = 1.98 \\hspace{15mm} SE_{\\hat{\\beta}_1} = 18.17\\]\n. . .\n\\[\n159.48 \\pm 1.98 \\times 18.17 = (123.50, 195.46)\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#ci-for-the-slope-computation",
    "href": "slides/06-slr-math-models-notes.html#ci-for-the-slope-computation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Computation",
    "text": "95% CI for the slope: Computation\n\ntidy(df_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n10847.77\n222456.88\n\n\narea\n159.48\n18.17\n8.78\n0.00\n123.41\n195.55"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#intervals-for-predictions-1",
    "href": "slides/06-slr-math-models-notes.html#intervals-for-predictions-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Intervals for predictions",
    "text": "Intervals for predictions\n\nSuppose we want to answer the question “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\nWe said reporting a single estimate for the slope is not wise, and we should report a plausible range instead\nSimilarly, reporting a single prediction for a new value is not wise, and we should report a plausible range instead"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#two-types-of-predictions",
    "href": "slides/06-slr-math-models-notes.html#two-types-of-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Two types of predictions",
    "text": "Two types of predictions\n\nPrediction for the mean: “What is the average predicted sale price of Duke Forest houses that are 2,800 square feet?”\nPrediction for an individual observation: “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\n\n. . .\n\nWhich would you expect to be more variable? The average prediction or the prediction for an individual observation? Based on your answer, how would you expect the widths of plausible ranges for these two predictions to compare?"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#uncertainty-in-predictions",
    "href": "slides/06-slr-math-models-notes.html#uncertainty-in-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Uncertainty in predictions",
    "text": "Uncertainty in predictions\nConfidence interval for the mean outcome: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE}_{\\hat{\\boldsymbol{\\mu}}}}}\\]\n. . .\nPrediction interval for an individual observation: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE_{\\hat{y}}}}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#standard-errors",
    "href": "slides/06-slr-math-models-notes.html#standard-errors",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\n. . .\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{1 + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#standard-errors-1",
    "href": "slides/06-slr-math-models-notes.html#standard-errors-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\mathbf{\\color{purple}{\\Large{1}}} + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#confidence-interval",
    "href": "slides/06-slr-math-models-notes.html#confidence-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval",
    "text": "Confidence interval\nThe 95% confidence interval for the mean outcome:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_house, interval = \"confidence\", level = 0.95) |&gt;\n  kable()\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n563205.5\n529351\n597060.1\n\n\n\n\n\n. . .\nWe are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between $529,351 and $597,060."
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#prediction-interval",
    "href": "slides/06-slr-math-models-notes.html#prediction-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Prediction interval",
    "text": "Prediction interval\nThe 95% prediction interval for an individual outcome:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_house, interval = \"prediction\", level = 0.95) |&gt;\n  kable()\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n563205.5\n226438.3\n899972.7\n\n\n\n\n\n. . .\nWe are 95% confident that predicted sale price of a Duke Forest house that is 2,800 square feet is between $226,438 and $899,973."
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#comparing-intervals",
    "href": "slides/06-slr-math-models-notes.html#comparing-intervals",
    "title": "SLR: Mathematical models for inference",
    "section": "Comparing intervals",
    "text": "Comparing intervals"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#extrapolation",
    "href": "slides/06-slr-math-models-notes.html#extrapolation",
    "title": "SLR: Mathematical models for inference",
    "section": "Extrapolation",
    "text": "Extrapolation\nUsing the model to predict for values outside the range of the original data is extrapolation.\n. . .\n\n\n\nCalculate the prediction interval for the sale price of a “tiny house” in Duke Forest that is 225 square feet.\n\n\n\n\n\n\n\n\n\n. . .\nNo, thanks!"
  },
  {
    "objectID": "slides/06-slr-math-models-notes.html#next-class",
    "href": "slides/06-slr-math-models-notes.html#next-class",
    "title": "SLR: Mathematical models for inference",
    "section": "Next class",
    "text": "Next class\n\nMultiple linear regression\nPrepare for Lecture 07"
  },
  {
    "objectID": "slides/06-slr-math-models.html#announcements",
    "href": "slides/06-slr-math-models.html#announcements",
    "title": "SLR: Mathematical models for inference",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due TODAY at 11:59pm\nLab 01 due Thursday at 11:59pm\n\nQuestions?\n\nStatistics experience - due Mon, Nov 20 at 11:59pm"
  },
  {
    "objectID": "slides/06-slr-math-models.html#course-policy-reminders",
    "href": "slides/06-slr-math-models.html#course-policy-reminders",
    "title": "SLR: Mathematical models for inference",
    "section": "Course policy reminders",
    "text": "Course policy reminders\n\nLate work\n\nHW and labs accepted up to 2 days late.\n5% deduction for each 24-hour period the assignment is late.\n\nOne time late waiver\n\nCan use on HW and individual labs\n\nLowest HW and lowest lab grade dropped at the end of the semester."
  },
  {
    "objectID": "slides/06-slr-math-models.html#topics",
    "href": "slides/06-slr-math-models.html#topics",
    "title": "SLR: Mathematical models for inference",
    "section": "Topics",
    "text": "Topics\n\nDefine mathematical models to conduct inference for the slope\nUse mathematical models to\n\ncalculate confidence interval for the slope\nconduct a hypothesis test for the slope\nconstruct intervals for predictions"
  },
  {
    "objectID": "slides/06-slr-math-models.html#computational-setup",
    "href": "slides/06-slr-math-models.html#computational-setup",
    "title": "SLR: Mathematical models for inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/06-slr-math-models.html#the-regression-model-revisited",
    "href": "slides/06-slr-math-models.html#the-regression-model-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/06-slr-math-models.html#inference-revisited",
    "href": "slides/06-slr-math-models.html#inference-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we’ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/06-slr-math-models.html#mathematical-representation-of-the-model",
    "href": "slides/06-slr-math-models.html#mathematical-representation-of-the-model",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= \\text{Model} + \\text{Error} \\\\[8pt]\n&= f(X) + \\epsilon \\\\[8pt]\n&= E(Y|X) + \\epsilon \\\\[8pt]\n&= \\mu_{Y|X} + \\epsilon \\\\[8pt]\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n\n\nindependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/06-slr-math-models.html#side-note-expected-value-and-variance",
    "href": "slides/06-slr-math-models.html#side-note-expected-value-and-variance",
    "title": "SLR: Mathematical models for inference",
    "section": "Side note: Expected value and variance",
    "text": "Side note: Expected value and variance\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants.\n\nExpected value\n\\[\nE(aX+b) = E(aX) + E(b) = aE(X) + b\n\\]\n\nVariance\n\\[\nVar(aX + b) = a^2Var(X)\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#mathematical-representation-visualized",
    "href": "slides/06-slr-math-models.html#mathematical-representation-visualized",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#regression-standard-error",
    "href": "slides/06-slr-math-models.html#regression-standard-error",
    "title": "SLR: Mathematical models for inference",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error, the average distance between the observed values and the regression line\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-error-of-hatbeta_1",
    "href": "slides/06-slr-math-models.html#standard-error-of-hatbeta_1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\nThe standard error of \\(\\hat{\\beta}_1\\) quantifies the sampling variability in the estimated slopes\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-for-the-slope",
    "href": "slides/06-slr-math-models.html#hypothesis-test-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test for the slope",
    "text": "Hypothesis test for the slope\nHypotheses: \\(H_0: \\beta_1 = 0\\) vs. \\(H_A: \\beta_1 \\ne 0\\)\n\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\nT = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\n\np-value: Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n - 2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-test-statistic",
    "href": "slides/06-slr-math-models.html#hypothesis-test-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Test statistic",
    "text": "Hypothesis test: Test statistic\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\nT = \\frac{\\hat{\\beta}_1 - 0}{SE_{\\hat{\\beta}_1}} = \\frac{159.48 - 0}{18.17} = 8.78\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#interpreting-the-test-statistic",
    "href": "slides/06-slr-math-models.html#interpreting-the-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the test statistic",
    "text": "Interpreting the test statistic\n\nThe test statistic is 8.78. What is the best interpretation?\n\nThe estimated slope of 159.48 is 8.78 standard errors away from the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above 0, the hypothesized mean.\nThe estimated slope of 159.48 is 8.78 standard errors away from 0, the hypothesized mean."
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-p-value",
    "href": "slides/06-slr-math-models.html#hypothesis-test-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-p-value-1",
    "href": "slides/06-slr-math-models.html#hypothesis-test-p-value-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\nA more exact p-value\n\n2 * pt(q = 8.78, df = 96, lower.tail = FALSE)\n\n[1] 6.19602e-14"
  },
  {
    "objectID": "slides/06-slr-math-models.html#interpreting-the-p-value",
    "href": "slides/06-slr-math-models.html#interpreting-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the p-value",
    "text": "Interpreting the p-value\n\nWhat does the p-value mean in the context of the data?\n\nThe probability there is no linear relationship between area and price is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is a linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 or more extreme is approximately 0."
  },
  {
    "objectID": "slides/06-slr-math-models.html#understanding-the-p-value",
    "href": "slides/06-slr-math-models.html#understanding-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "href": "slides/06-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Conclusion, in context",
    "text": "Hypothesis test: Conclusion, in context\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\n\nThe data provide convincing evidence that the population slope \\(\\beta_1\\) is different from 0.\nThe data provide convincing evidence of a linear relationship between area and price of houses in Duke Forest."
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval-for-the-slope",
    "href": "slides/06-slr-math-models.html#confidence-interval-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE_{\\hat{\\beta}_1}\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval-critical-value",
    "href": "slides/06-slr-math-models.html#confidence-interval-critical-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(duke_forest) - 2)\n\n[1] 1.984984\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(duke_forest) - 2)\n\n[1] 1.660881\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(duke_forest) - 2)\n\n[1] 2.628016"
  },
  {
    "objectID": "slides/06-slr-math-models.html#ci-for-the-slope-calculation",
    "href": "slides/06-slr-math-models.html#ci-for-the-slope-calculation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Calculation",
    "text": "95% CI for the slope: Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\\hat{\\beta}_1 = 159.48 \\hspace{15mm} t^* = 1.98 \\hspace{15mm} SE_{\\hat{\\beta}_1} = 18.17\\]\n\n\\[\n159.48 \\pm 1.98 \\times 18.17 = (123.50, 195.46)\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#ci-for-the-slope-computation",
    "href": "slides/06-slr-math-models.html#ci-for-the-slope-computation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Computation",
    "text": "95% CI for the slope: Computation\n\ntidy(df_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n10847.77\n222456.88\n\n\narea\n159.48\n18.17\n8.78\n0.00\n123.41\n195.55"
  },
  {
    "objectID": "slides/06-slr-math-models.html#intervals-for-predictions-1",
    "href": "slides/06-slr-math-models.html#intervals-for-predictions-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Intervals for predictions",
    "text": "Intervals for predictions\n\nSuppose we want to answer the question “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\nWe said reporting a single estimate for the slope is not wise, and we should report a plausible range instead\nSimilarly, reporting a single prediction for a new value is not wise, and we should report a plausible range instead"
  },
  {
    "objectID": "slides/06-slr-math-models.html#two-types-of-predictions",
    "href": "slides/06-slr-math-models.html#two-types-of-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Two types of predictions",
    "text": "Two types of predictions\n\nPrediction for the mean: “What is the average predicted sale price of Duke Forest houses that are 2,800 square feet?”\nPrediction for an individual observation: “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\n\n\n\nWhich would you expect to be more variable? The average prediction or the prediction for an individual observation? Based on your answer, how would you expect the widths of plausible ranges for these two predictions to compare?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#uncertainty-in-predictions",
    "href": "slides/06-slr-math-models.html#uncertainty-in-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Uncertainty in predictions",
    "text": "Uncertainty in predictions\nConfidence interval for the mean outcome: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE}_{\\hat{\\boldsymbol{\\mu}}}}}\\]\n\nPrediction interval for an individual observation: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE_{\\hat{y}}}}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-errors",
    "href": "slides/06-slr-math-models.html#standard-errors",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\n\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{1 + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-errors-1",
    "href": "slides/06-slr-math-models.html#standard-errors-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\mathbf{\\color{purple}{\\Large{1}}} + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval",
    "href": "slides/06-slr-math-models.html#confidence-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval",
    "text": "Confidence interval\nThe 95% confidence interval for the mean outcome:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_house, interval = \"confidence\", level = 0.95) |&gt;\n  kable()\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n563205.5\n529351\n597060.1\n\n\n\n\n\n\nWe are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between $529,351 and $597,060."
  },
  {
    "objectID": "slides/06-slr-math-models.html#prediction-interval",
    "href": "slides/06-slr-math-models.html#prediction-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Prediction interval",
    "text": "Prediction interval\nThe 95% prediction interval for an individual outcome:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_house, interval = \"prediction\", level = 0.95) |&gt;\n  kable()\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n563205.5\n226438.3\n899972.7\n\n\n\n\n\n\nWe are 95% confident that predicted sale price of a Duke Forest house that is 2,800 square feet is between $226,438 and $899,973."
  },
  {
    "objectID": "slides/06-slr-math-models.html#comparing-intervals",
    "href": "slides/06-slr-math-models.html#comparing-intervals",
    "title": "SLR: Mathematical models for inference",
    "section": "Comparing intervals",
    "text": "Comparing intervals"
  },
  {
    "objectID": "slides/06-slr-math-models.html#extrapolation",
    "href": "slides/06-slr-math-models.html#extrapolation",
    "title": "SLR: Mathematical models for inference",
    "section": "Extrapolation",
    "text": "Extrapolation\nUsing the model to predict for values outside the range of the original data is extrapolation.\n\n\n\n\nCalculate the prediction interval for the sale price of a “tiny house” in Duke Forest that is 225 square feet.\n\n\n\n\n\n\n\n\n\n\nNo, thanks!"
  },
  {
    "objectID": "slides/06-slr-math-models.html#next-class",
    "href": "slides/06-slr-math-models.html#next-class",
    "title": "SLR: Mathematical models for inference",
    "section": "Next class",
    "text": "Next class\n\nMultiple linear regression\nPrepare for Lecture 07"
  },
  {
    "objectID": "slides/02-big-picture-notes.html",
    "href": "slides/02-big-picture-notes.html",
    "title": "The big picture",
    "section": "",
    "text": "Office hours start this week\n\nSee office hours schedule on Canvas\n\nComplete Lab 00 tasks\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#announcements",
    "href": "slides/02-big-picture-notes.html#announcements",
    "title": "The big picture",
    "section": "",
    "text": "Office hours start this week\n\nSee office hours schedule on Canvas\n\nComplete Lab 00 tasks\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#topics",
    "href": "slides/02-big-picture-notes.html#topics",
    "title": "The big picture",
    "section": "Topics",
    "text": "Topics\n\nData analysis life cycle\nReproducible data analysis\nAnalyzing multivariable relationships\n\n\n\n\n\nSource: R for Data Science with additions from The Art of Statistics: How to Learn from Data.\n\n\n\n\n\n\nSource:R for Data Science"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#reproducibility-checklist",
    "href": "slides/02-big-picture-notes.html#reproducibility-checklist",
    "title": "The big picture",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n. . .\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n. . .\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#why-is-reproducibility-important",
    "href": "slides/02-big-picture-notes.html#why-is-reproducibility-important",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#why-is-reproducibility-important-1",
    "href": "slides/02-big-picture-notes.html#why-is-reproducibility-important-1",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\n\n\n\n\n\n\nOriginally reported “the intervention, compared with usual care, resulted in a fewer number of mean COPD-related hospitalizations and emergency department visits at 6 months per participant.”\nThere were actually more COPD-related hospitalizations and emergency department visits in the intervention group compared to the control group\nMixed up the intervention vs. control group using “0/1” coding\n\n\n\n\n\nhttps://jamanetwork.com/journals/jama/fullarticle/2752474"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#toolkit",
    "href": "slides/02-big-picture-notes.html#toolkit",
    "title": "The big picture",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#r-and-rstudio",
    "href": "slides/02-big-picture-notes.html#r-and-rstudio",
    "title": "The big picture",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#rstudio-ide",
    "href": "slides/02-big-picture-notes.html#rstudio-ide",
    "title": "The big picture",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#quarto",
    "href": "slides/02-big-picture-notes.html#quarto",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#quarto-1",
    "href": "slides/02-big-picture-notes.html#quarto-1",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#how-will-we-use-quarto",
    "href": "slides/02-big-picture-notes.html#how-will-we-use-quarto",
    "title": "The big picture",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#what-is-versioning",
    "href": "slides/02-big-picture-notes.html#what-is-versioning",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#what-is-versioning-1",
    "href": "slides/02-big-picture-notes.html#what-is-versioning-1",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#why-do-we-need-version-control",
    "href": "slides/02-big-picture-notes.html#why-do-we-need-version-control",
    "title": "The big picture",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#git-and-github",
    "href": "slides/02-big-picture-notes.html#git-and-github",
    "title": "The big picture",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\n\n\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#education-and-life-expectancy",
    "href": "slides/02-big-picture-notes.html#education-and-life-expectancy",
    "title": "The big picture",
    "section": "Education and life expectancy",
    "text": "Education and life expectancy\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#variable-definitions",
    "href": "slides/02-big-picture-notes.html#variable-definitions",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (Gini coefficient)."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#variable-definitions-1",
    "href": "slides/02-big-picture-notes.html#variable-definitions-1",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#terminology",
    "href": "slides/02-big-picture-notes.html#terminology",
    "title": "The big picture",
    "section": "Terminology",
    "text": "Terminology\n\nlife_exp is the response variable\n\nvariable whose variation we want to understand / variable we wish to predict\nalso known as outcome or dependent variable\n\n\n. . .\n\nincome_inequality, education are the predictor variables\n\nvariables used to account for variation in the response\nalso known as explanatory, independent, or input variables"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#univariate-exploratory-data-analysis",
    "href": "slides/02-big-picture-notes.html#univariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#bivariate-exploratory-data-analysis",
    "href": "slides/02-big-picture-notes.html#bivariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#function-between-response-and-predictors",
    "href": "slides/02-big-picture-notes.html#function-between-response-and-predictors",
    "title": "The big picture",
    "section": "Function between response and predictors",
    "text": "Function between response and predictors\n\n\\[\\text{life_exp} = f(\\text{income_inequality}, \\text{education}) + \\epsilon\\]\n\n\nGoal: Determine \\(f\\)\nHow do we determine \\(f\\)?\n\nMake an assumption about the functional form \\(f\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#determine-f",
    "href": "slides/02-big-picture-notes.html#determine-f",
    "title": "The big picture",
    "section": "Determine \\(f\\)",
    "text": "Determine \\(f\\)\n\nChoose the functional form of \\(f\\), i.e., choose the appropriate model given the response variable\n\n\nSuppose \\(f\\) takes the form of a linear model\n\\[y = f(\\mathbf{X}) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p + \\epsilon\\]\n\n. . .\n\nUse the data to fit (or train) the model, i.e, compute estimates of the model parameters, denoted \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality",
    "href": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality",
    "text": "life_exp vs. income_inequality\n\n\n\n\n\n\n\n\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education",
    "href": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education",
    "text": "life_exp vs. income_inequality + education\n\n\n\n\n\n\n\n\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#statistical-model-vs.-regression-equation",
    "href": "slides/02-big-picture-notes.html#statistical-model-vs.-regression-equation",
    "title": "The big picture",
    "section": "Statistical model vs. regression equation",
    "text": "Statistical model vs. regression equation\nStatistical model (also known as the data-generating model)\n\n\\[{\\small \\text{life_exp} = \\beta_0 + \\beta_1 ~\\text{income_inequality} + \\beta_2 ~\\text{education} + \\epsilon}\\]\n\nModels the process for generating values of the response in the population (function + error), i.e., the population-level model.\n\n. . .\nRegression equation (also known as the fitted model)\nEstimate of the function using the sample data\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education-with-interaction",
    "href": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education-with-interaction",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education (with interaction)",
    "text": "life_exp vs. income_inequality + education (with interaction)\n\n\n\n\n\n\n\n\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education} + \\hat{\\beta}_3 ~ \\text{income_inequality} \\times \\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#why-fit-a-model",
    "href": "slides/02-big-picture-notes.html#why-fit-a-model",
    "title": "The big picture",
    "section": "Why fit a model?",
    "text": "Why fit a model?\n\nPrediction: Expected value of the response variable for given values of the predictor variables\nInference: Conclusion about the relationship between the response and predictor variables\n\n. . .\n\n\nWhat is an example of a prediction question that can be answered using the model of life_exp vs. income_inequality and education?\nWhat is an example of an inference question that can be answered using the model of life_exp vs.income_inequality and education?"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#recap",
    "href": "slides/02-big-picture-notes.html#recap",
    "title": "The big picture",
    "section": "Recap",
    "text": "Recap\n\nReproducibility\n\nIt is best practice conduct all data analysis in a reproducible way\nWe will implement a reproducible workflow using R, Quarto, and git/GitHub\n\n\n\n\nMultivariable relationships\n\nWe can use exploratory data analysis to describe the relationship between two variables\nWe make an assumption about the relationship between variables when doing linear regression\nThe two main objectives for fitting a linear regression model are (1) prediction and (2) inference"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#for-next-time",
    "href": "slides/02-big-picture-notes.html#for-next-time",
    "title": "The big picture",
    "section": "For next time",
    "text": "For next time\n\nComplete Lec 03 - Simple linear regression prepare\nBring fully-charged laptop or device with keyboard for in-class application exercise (AE)"
  },
  {
    "objectID": "slides/02-big-picture.html#announcements",
    "href": "slides/02-big-picture.html#announcements",
    "title": "The big picture",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours start this week\n\nSee office hours schedule on Canvas\n\nComplete Lab 00 tasks\nIntroduction to R workshops at Duke library\n\nData wrangling with dplyr - Thu, Jan 16 at 12pm\nData visualization with ggplot2 - Thu, Jan 23 at 12pm"
  },
  {
    "objectID": "slides/02-big-picture.html#topics",
    "href": "slides/02-big-picture.html#topics",
    "title": "The big picture",
    "section": "Topics",
    "text": "Topics\n\nData analysis life cycle\nReproducible data analysis\nAnalyzing multivariable relationships"
  },
  {
    "objectID": "slides/02-big-picture.html#reproducibility-checklist",
    "href": "slides/02-big-picture.html#reproducibility-checklist",
    "title": "The big picture",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/02-big-picture.html#why-is-reproducibility-important",
    "href": "slides/02-big-picture.html#why-is-reproducibility-important",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/02-big-picture.html#why-is-reproducibility-important-1",
    "href": "slides/02-big-picture.html#why-is-reproducibility-important-1",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\n\n\n\n\n\n\nOriginally reported “the intervention, compared with usual care, resulted in a fewer number of mean COPD-related hospitalizations and emergency department visits at 6 months per participant.”\nThere were actually more COPD-related hospitalizations and emergency department visits in the intervention group compared to the control group\nMixed up the intervention vs. control group using “0/1” coding\n\n\n\n\n\nhttps://jamanetwork.com/journals/jama/fullarticle/2752474"
  },
  {
    "objectID": "slides/02-big-picture.html#toolkit",
    "href": "slides/02-big-picture.html#toolkit",
    "title": "The big picture",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/02-big-picture.html#r-and-rstudio",
    "href": "slides/02-big-picture.html#r-and-rstudio",
    "title": "The big picture",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/02-big-picture.html#rstudio-ide",
    "href": "slides/02-big-picture.html#rstudio-ide",
    "title": "The big picture",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto",
    "href": "slides/02-big-picture.html#quarto",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto-1",
    "href": "slides/02-big-picture.html#quarto-1",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/02-big-picture.html#how-will-we-use-quarto",
    "href": "slides/02-big-picture.html#how-will-we-use-quarto",
    "title": "The big picture",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning",
    "href": "slides/02-big-picture.html#what-is-versioning",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning-1",
    "href": "slides/02-big-picture.html#what-is-versioning-1",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/02-big-picture.html#why-do-we-need-version-control",
    "href": "slides/02-big-picture.html#why-do-we-need-version-control",
    "title": "The big picture",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/02-big-picture.html#git-and-github",
    "href": "slides/02-big-picture.html#git-and-github",
    "title": "The big picture",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/02-big-picture.html#education-and-life-expectancy",
    "href": "slides/02-big-picture.html#education-and-life-expectancy",
    "title": "The big picture",
    "section": "Education and life expectancy",
    "text": "Education and life expectancy\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/02-big-picture.html#variable-definitions",
    "href": "slides/02-big-picture.html#variable-definitions",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (Gini coefficient)."
  },
  {
    "objectID": "slides/02-big-picture.html#variable-definitions-1",
    "href": "slides/02-big-picture.html#variable-definitions-1",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima."
  },
  {
    "objectID": "slides/02-big-picture.html#terminology",
    "href": "slides/02-big-picture.html#terminology",
    "title": "The big picture",
    "section": "Terminology",
    "text": "Terminology\n\nlife_exp is the response variable\n\nvariable whose variation we want to understand / variable we wish to predict\nalso known as outcome or dependent variable\n\n\n\n\nincome_inequality, education are the predictor variables\n\nvariables used to account for variation in the response\nalso known as explanatory, independent, or input variables"
  },
  {
    "objectID": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture.html#function-between-response-and-predictors",
    "href": "slides/02-big-picture.html#function-between-response-and-predictors",
    "title": "The big picture",
    "section": "Function between response and predictors",
    "text": "Function between response and predictors\n\n\\[\\text{life_exp} = f(\\text{income_inequality}, \\text{education}) + \\epsilon\\]\n\n\nGoal: Determine \\(f\\)\nHow do we determine \\(f\\)?\n\nMake an assumption about the functional form \\(f\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-big-picture.html#determine-f",
    "href": "slides/02-big-picture.html#determine-f",
    "title": "The big picture",
    "section": "Determine \\(f\\)",
    "text": "Determine \\(f\\)\n\nChoose the functional form of \\(f\\), i.e., choose the appropriate model given the response variable\n\n\nSuppose \\(f\\) takes the form of a linear model\n\\[y = f(\\mathbf{X}) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p + \\epsilon\\]\n\n\n\nUse the data to fit (or train) the model, i.e, compute estimates of the model parameters, denoted \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\)"
  },
  {
    "objectID": "slides/02-big-picture.html#life_exp-vs.-income_inequality",
    "href": "slides/02-big-picture.html#life_exp-vs.-income_inequality",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality",
    "text": "life_exp vs. income_inequality\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education",
    "href": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education",
    "text": "life_exp vs. income_inequality + education\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "href": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "title": "The big picture",
    "section": "Statistical model vs. regression equation",
    "text": "Statistical model vs. regression equation\nStatistical model (also known as the data-generating model)\n\n\\[{\\small \\text{life_exp} = \\beta_0 + \\beta_1 ~\\text{income_inequality} + \\beta_2 ~\\text{education} + \\epsilon}\\]\n\nModels the process for generating values of the response in the population (function + error), i.e., the population-level model.\n\n\nRegression equation (also known as the fitted model)\nEstimate of the function using the sample data\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education-with-interaction",
    "href": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education-with-interaction",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education (with interaction)",
    "text": "life_exp vs. income_inequality + education (with interaction)\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education} + \\hat{\\beta}_3 ~ \\text{income_inequality} \\times \\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#why-fit-a-model",
    "href": "slides/02-big-picture.html#why-fit-a-model",
    "title": "The big picture",
    "section": "Why fit a model?",
    "text": "Why fit a model?\n\nPrediction: Expected value of the response variable for given values of the predictor variables\nInference: Conclusion about the relationship between the response and predictor variables\n\n\n\n\nWhat is an example of a prediction question that can be answered using the model of life_exp vs. income_inequality and education?\nWhat is an example of an inference question that can be answered using the model of life_exp vs.income_inequality and education?"
  },
  {
    "objectID": "slides/02-big-picture.html#recap",
    "href": "slides/02-big-picture.html#recap",
    "title": "The big picture",
    "section": "Recap",
    "text": "Recap\n\nReproducibility\n\nIt is best practice conduct all data analysis in a reproducible way\nWe will implement a reproducible workflow using R, Quarto, and git/GitHub\n\n\n\n\nMultivariable relationships\n\nWe can use exploratory data analysis to describe the relationship between two variables\nWe make an assumption about the relationship between variables when doing linear regression\nThe two main objectives for fitting a linear regression model are (1) prediction and (2) inference"
  },
  {
    "objectID": "slides/02-big-picture.html#for-next-time",
    "href": "slides/02-big-picture.html#for-next-time",
    "title": "The big picture",
    "section": "For next time",
    "text": "For next time\n\nComplete Lec 03 - Simple linear regression prepare\nBring fully-charged laptop or device with keyboard for in-class application exercise (AE)"
  },
  {
    "objectID": "slides/02-big-picture.html#references",
    "href": "slides/02-big-picture.html#references",
    "title": "The big picture",
    "section": "References",
    "text": "References\n\n\n\n\nAlexander, Rohan. 2023. “Telling Stories with Data,” June. https://doi.org/10.1201/9781003229407.\n\n\nOstblom, Joel, and Tiffany Timbers. 2022. “Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice.” Journal of Statistics and Data Science Education 30 (3): 241–50. https://doi.org/10.1080/26939169.2022.2074922.\n\n\nZarulli, Virginia, Elizaveta Sopina, Veronica Toffolutti, and Adam Lenart. 2021. “Health Care System Efficiency and Life Expectancy: A 140-Country Study.” Edited by Srinivas Goli. PLOS ONE 16 (7): e0253450. https://doi.org/10.1371/journal.pone.0253450."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html",
    "href": "slides/14-variable-transformations-notes.html",
    "title": "Variable transformations",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#computing-set-up",
    "href": "slides/14-variable-transformations-notes.html#computing-set-up",
    "title": "Variable transformations",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#topics",
    "href": "slides/14-variable-transformations-notes.html#topics",
    "title": "Variable transformations",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the response\nLog-transformation on the predictor"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#data-life-expectancy-in-140-countries",
    "href": "slides/14-variable-transformations-notes.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#variables",
    "href": "slides/14-variable-transformations-notes.html#variables",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#variables-1",
    "href": "slides/14-variable-transformations-notes.html#variables-1",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare goods and services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#exploratory-data-analysis",
    "href": "slides/14-variable-transformations-notes.html#exploratory-data-analysis",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#exploratory-data-analysis-1",
    "href": "slides/14-variable-transformations-notes.html#exploratory-data-analysis-1",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nThe goal is to use income inequality and education to understand variability in health expenditure"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#original-model",
    "href": "slides/14-variable-transformations-notes.html#original-model",
    "title": "Variable transformations",
    "section": "Original model",
    "text": "Original model\n\nhealth_fit &lt;- lm(health_expenditure ~ income_inequality + education, \n                     data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2070.599\n534.653\n3.873\n0.000\n\n\nincome_inequality\n-64.346\n18.626\n-3.455\n0.001\n\n\neducationHigh\n1039.298\n359.736\n2.889\n0.004"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#original-model-residuals-vs.-fitted",
    "href": "slides/14-variable-transformations-notes.html#original-model-residuals-vs.-fitted",
    "title": "Variable transformations",
    "section": "Original model: Residuals vs. fitted",
    "text": "Original model: Residuals vs. fitted\n\n\n\n\n\n\n\n\n\n\nWhat model assumption(s) appear to be violated?"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#consider-different-transformations",
    "href": "slides/14-variable-transformations-notes.html#consider-different-transformations",
    "title": "Variable transformations",
    "section": "Consider different transformations…",
    "text": "Consider different transformations…"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#identifying-a-need-to-transform-y",
    "href": "slides/14-variable-transformations-notes.html#identifying-a-need-to-transform-y",
    "title": "Variable transformations",
    "section": "Identifying a need to transform Y",
    "text": "Identifying a need to transform Y\n\n\nTypically, a “fan-shaped” residual plot indicates the need for a transformation of the response variable Y\n\nThere are multiple ways to transform a variable, e.g., \\(Y^{1/2}\\), \\(1/Y\\), \\(\\log(Y)\\) . These are called variance stabilizing transformations\n\\(\\log(Y)\\) the most straightforward to interpret, so we use that transformation when possible\n\n\n\n\nWhen building a model:\n\nChoose a transformation and build the model on the transformed data\nReassess the residual plots\nIf the residuals plots did not sufficiently improve, try a new transformation!"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#log-transformation-on-y",
    "href": "slides/14-variable-transformations-notes.html#log-transformation-on-y",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\n\nIf we apply a log transformation to the response variable, we want to estimate the parameters for the statistical model\n\n\\[\n\\log(Y) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\nThe regression equation is\n\n\\[\\widehat{\\log(Y)} = \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\dots + \\hat{\\beta}_pX_p\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#log-transformation-on-y-1",
    "href": "slides/14-variable-transformations-notes.html#log-transformation-on-y-1",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\nWe fit the model in terms of \\(\\log(\\mathbf{Y})\\) but want to interpret the model in terms of the original variable \\(Y\\) , so we need to write the regression equation in terms of \\(Y\\)\n\\[\n\\begin{aligned}\n&\\widehat{\\log(Y)} = \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\dots + \\hat{\\beta}_pX_p\n\\\\[8pt]\n\\Rightarrow \\quad &\\hat{Y} = e^{(\\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\dots + \\hat{\\beta}_pX_p)}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#math-rules",
    "href": "slides/14-variable-transformations-notes.html#math-rules",
    "title": "Variable transformations",
    "section": "Math rules",
    "text": "Math rules\n\\[\n\\begin{aligned}\n\\log(ab) &= \\log(a) + \\log(b) \\\\[8pt]\n\\log\\big(\\frac{a}{b}\\big) &= \\log(a) - \\log(b)\\\\[15pt]\ne^{a + b + c} &= e^ae^be^c \\\\[8pt]\ne^{a - b} &= \\frac{e^a}{e^b}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-interpretation",
    "href": "slides/14-variable-transformations-notes.html#model-interpretation",
    "title": "Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\\begin{align}\\hat{y_i} &= e^{(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_Px_{ip})} \\\\\n&= e^{\\hat{\\beta}_0}e^{\\hat{\\beta}_1x_{i1}}\\dots e^{\\hat{\\beta}_px_{ip}}\\end{align}\\]\n. . .\n\nIntercept: When \\(x_{i1} = \\dots = x_{ip} =0\\), \\(y_i\\) is expected to be \\(e^{\\hat{\\beta}_0}\\)\nCoefficient of \\(X_j\\): For every one unit increase in \\(x_{ij}\\), \\(y_{i}\\) is expected to multiply by a factor of \\(e^{\\hat{\\beta}_j}\\), holding all else constant."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-with-logy",
    "href": "slides/14-variable-transformations-notes.html#model-with-logy",
    "title": "Variable transformations",
    "section": "Model with log(Y)",
    "text": "Model with log(Y)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n7.096\n0.324\n21.895\n0\n\n\nincome_inequality\n-0.065\n0.011\n-5.714\n0\n\n\neducationHigh\n1.117\n0.218\n5.121\n0\n\n\n\n\n\n\n\nInterpret each of the following in terms of health expenditure\n\nIntercept\nincome_inequality\neducation"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-with-logy-residuals",
    "href": "slides/14-variable-transformations-notes.html#model-with-logy-residuals",
    "title": "Variable transformations",
    "section": "Model with log(Y): Residuals",
    "text": "Model with log(Y): Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#compare-residual-plots",
    "href": "slides/14-variable-transformations-notes.html#compare-residual-plots",
    "title": "Variable transformations",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#variability-in-life-expectancy",
    "href": "slides/14-variable-transformations-notes.html#variability-in-life-expectancy",
    "title": "Variable transformations",
    "section": "Variability in life expectancy",
    "text": "Variability in life expectancy\nNow let’s consider a model using a country’s healthcare expenditure, income inequality, and education to predict its life expectancy"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#original-model-1",
    "href": "slides/14-variable-transformations-notes.html#original-model-1",
    "title": "Variable transformations",
    "section": "Original model",
    "text": "Original model\n\nlife_exp_fit &lt;- lm(life_exp ~ health_expenditure + income_inequality + education, \n                   data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n78.575\n1.775\n44.274\n0.000\n\n\nhealth_expenditure\n0.001\n0.000\n4.522\n0.000\n\n\nincome_inequality\n-0.484\n0.061\n-7.900\n0.000\n\n\neducationHigh\n2.020\n1.168\n1.730\n0.086"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#original-model-residuals",
    "href": "slides/14-variable-transformations-notes.html#original-model-residuals",
    "title": "Variable transformations",
    "section": "Original model: Residuals",
    "text": "Original model: Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#residuals-vs.-predictors",
    "href": "slides/14-variable-transformations-notes.html#residuals-vs.-predictors",
    "title": "Variable transformations",
    "section": "Residuals vs. predictors",
    "text": "Residuals vs. predictors\n\n\n\n\n\n\n\n\n\n. . .\n\nThere is a non-linear relationship is between health expenditure and life expectancy."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#log-transformation-on-x",
    "href": "slides/14-variable-transformations-notes.html#log-transformation-on-x",
    "title": "Variable transformations",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\nTry a transformation on \\(X\\) if the scatterplot in EDA shows non-linear relationship and residuals vs. predictor make parabola"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-with-transformation-on-x_j",
    "href": "slides/14-variable-transformations-notes.html#model-with-transformation-on-x_j",
    "title": "Variable transformations",
    "section": "Model with Transformation on \\(X_j\\)",
    "text": "Model with Transformation on \\(X_j\\)\nIf we fit a model with predictor \\(\\log(X_j)\\), we fit a model of the form\n\\[\nY = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_j\\log(X_j) + \\dots \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\\]\n. . .\nThe estimated regression model is\n\\[\n\\begin{aligned}\n&\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\dots + \\hat{\\beta}_j\\log(X_j) + \\dots \\hat{\\beta}_pX_p \\\\[8pt]\n\\Rightarrow \\quad &\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-interpretation-1",
    "href": "slides/14-variable-transformations-notes.html#model-interpretation-1",
    "title": "Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = \\log(x_{ij}) = \\dots = x_{ip} = 0\\) , \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\), on average, holding all else constant.\n\n\\(\\log(x_{ij}) = 0\\) when \\(x_{ij} = 1\\)\n\nCoefficient of \\(X_j\\): When \\(x_{ij}\\) is multiplied by a factor of \\(C\\), \\(y_i\\) is expected to change by \\(\\hat{\\beta}_1\\log(C)\\) units, on average, holding all else constant.\n\nExample: When \\(x_{ij}\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_1\\log(2)\\) units, on average, holding all else constant."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-with-logx",
    "href": "slides/14-variable-transformations-notes.html#model-with-logx",
    "title": "Variable transformations",
    "section": "Model with log(X)",
    "text": "Model with log(X)\n\nlife_exp_logx_fit &lt;- lm(life_exp ~ log(health_expenditure) + income_inequality + education, \n                        data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n59.151\n3.184\n18.576\n0.000\n\n\nlog(health_expenditure)\n3.092\n0.396\n7.814\n0.000\n\n\nincome_inequality\n-0.362\n0.058\n-6.225\n0.000\n\n\neducationHigh\n-0.168\n1.103\n-0.152\n0.879\n\n\n\n\n\n\n\n\nInterpret the intercept in the context of the data.\nInterpret the effect of health expenditure in the context of the data.\nInterpret the effect of education in the context of the data."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#model-with-logx-residuals",
    "href": "slides/14-variable-transformations-notes.html#model-with-logx-residuals",
    "title": "Variable transformations",
    "section": "Model with log(X): Residuals",
    "text": "Model with log(X): Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#learn-more",
    "href": "slides/14-variable-transformations-notes.html#learn-more",
    "title": "Variable transformations",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/14-variable-transformations-notes.html#recap",
    "href": "slides/14-variable-transformations-notes.html#recap",
    "title": "Variable transformations",
    "section": "Recap",
    "text": "Recap\n\nLog-transformation on the response\nLog-transformation on the predictor"
  },
  {
    "objectID": "slides/14-variable-transformations.html#computing-set-up",
    "href": "slides/14-variable-transformations.html#computing-set-up",
    "title": "Variable transformations",
    "section": "Computing set up",
    "text": "Computing set up\n\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(patchwork)\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/14-variable-transformations.html#topics",
    "href": "slides/14-variable-transformations.html#topics",
    "title": "Variable transformations",
    "section": "Topics",
    "text": "Topics\n\nLog-transformation on the response\nLog-transformation on the predictor"
  },
  {
    "objectID": "slides/14-variable-transformations.html#data-life-expectancy-in-140-countries",
    "href": "slides/14-variable-transformations.html#data-life-expectancy-in-140-countries",
    "title": "Variable transformations",
    "section": "Data: Life expectancy in 140 countries",
    "text": "Data: Life expectancy in 140 countries\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThere are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/14-variable-transformations.html#variables",
    "href": "slides/14-variable-transformations.html#variables",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic income_inequality. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (based on Gini coefficient). (from Zarulli et al. (2021))"
  },
  {
    "objectID": "slides/14-variable-transformations.html#variables-1",
    "href": "slides/14-variable-transformations.html#variables-1",
    "title": "Variable transformations",
    "section": "Variables",
    "text": "Variables\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima.\n\nhealth_expend: Per capita current spending on on healthcare goods and services, expressed in respective currency - international Purchasing Power Parity (PPP) dollar (from the World Health Organization)"
  },
  {
    "objectID": "slides/14-variable-transformations.html#exploratory-data-analysis",
    "href": "slides/14-variable-transformations.html#exploratory-data-analysis",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis"
  },
  {
    "objectID": "slides/14-variable-transformations.html#exploratory-data-analysis-1",
    "href": "slides/14-variable-transformations.html#exploratory-data-analysis-1",
    "title": "Variable transformations",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nThe goal is to use income inequality and education to understand variability in health expenditure"
  },
  {
    "objectID": "slides/14-variable-transformations.html#original-model",
    "href": "slides/14-variable-transformations.html#original-model",
    "title": "Variable transformations",
    "section": "Original model",
    "text": "Original model\n\nhealth_fit &lt;- lm(health_expenditure ~ income_inequality + education, \n                     data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n2070.599\n534.653\n3.873\n0.000\n\n\nincome_inequality\n-64.346\n18.626\n-3.455\n0.001\n\n\neducationHigh\n1039.298\n359.736\n2.889\n0.004"
  },
  {
    "objectID": "slides/14-variable-transformations.html#original-model-residuals-vs.-fitted",
    "href": "slides/14-variable-transformations.html#original-model-residuals-vs.-fitted",
    "title": "Variable transformations",
    "section": "Original model: Residuals vs. fitted",
    "text": "Original model: Residuals vs. fitted\n\n\nWhat model assumption(s) appear to be violated?"
  },
  {
    "objectID": "slides/14-variable-transformations.html#consider-different-transformations",
    "href": "slides/14-variable-transformations.html#consider-different-transformations",
    "title": "Variable transformations",
    "section": "Consider different transformations…",
    "text": "Consider different transformations…"
  },
  {
    "objectID": "slides/14-variable-transformations.html#identifying-a-need-to-transform-y",
    "href": "slides/14-variable-transformations.html#identifying-a-need-to-transform-y",
    "title": "Variable transformations",
    "section": "Identifying a need to transform Y",
    "text": "Identifying a need to transform Y\n\n\nTypically, a “fan-shaped” residual plot indicates the need for a transformation of the response variable Y\n\nThere are multiple ways to transform a variable, e.g., \\(Y^{1/2}\\), \\(1/Y\\), \\(\\log(Y)\\) . These are called variance stabilizing transformations\n\\(\\log(Y)\\) the most straightforward to interpret, so we use that transformation when possible\n\n\n\n\nWhen building a model:\n\nChoose a transformation and build the model on the transformed data\nReassess the residual plots\nIf the residuals plots did not sufficiently improve, try a new transformation!"
  },
  {
    "objectID": "slides/14-variable-transformations.html#log-transformation-on-y",
    "href": "slides/14-variable-transformations.html#log-transformation-on-y",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\n\nIf we apply a log transformation to the response variable, we want to estimate the parameters for the statistical model\n\n\\[\n\\log(Y) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n\\]\n\nThe regression equation is\n\n\\[\\widehat{\\log(Y)} = \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\dots + \\hat{\\beta}_pX_p\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations.html#log-transformation-on-y-1",
    "href": "slides/14-variable-transformations.html#log-transformation-on-y-1",
    "title": "Variable transformations",
    "section": "Log transformation on \\(Y\\)",
    "text": "Log transformation on \\(Y\\)\nWe fit the model in terms of \\(\\log(\\mathbf{Y})\\) but want to interpret the model in terms of the original variable \\(Y\\) , so we need to write the regression equation in terms of \\(Y\\)\n\\[\n\\begin{aligned}\n&\\widehat{\\log(Y)} = \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\dots + \\hat{\\beta}_pX_p\n\\\\[8pt]\n\\Rightarrow \\quad &\\hat{Y} = e^{(\\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\hat{\\beta}_2X_2 + \\dots + \\hat{\\beta}_pX_p)}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations.html#math-rules",
    "href": "slides/14-variable-transformations.html#math-rules",
    "title": "Variable transformations",
    "section": "Math rules",
    "text": "Math rules\n\\[\n\\begin{aligned}\n\\log(ab) &= \\log(a) + \\log(b) \\\\[8pt]\n\\log\\big(\\frac{a}{b}\\big) &= \\log(a) - \\log(b)\\\\[15pt]\ne^{a + b + c} &= e^ae^be^c \\\\[8pt]\ne^{a - b} &= \\frac{e^a}{e^b}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-interpretation",
    "href": "slides/14-variable-transformations.html#model-interpretation",
    "title": "Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\\begin{align}\\hat{y_i} &= e^{(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\dots + \\hat{\\beta}_Px_{ip})} \\\\\n&= e^{\\hat{\\beta}_0}e^{\\hat{\\beta}_1x_{i1}}\\dots e^{\\hat{\\beta}_px_{ip}}\\end{align}\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = x_{ip} =0\\), \\(y_i\\) is expected to be \\(e^{\\hat{\\beta}_0}\\)\nCoefficient of \\(X_j\\): For every one unit increase in \\(x_{ij}\\), \\(y_{i}\\) is expected to multiply by a factor of \\(e^{\\hat{\\beta}_j}\\), holding all else constant."
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-with-logy",
    "href": "slides/14-variable-transformations.html#model-with-logy",
    "title": "Variable transformations",
    "section": "Model with log(Y)",
    "text": "Model with log(Y)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n7.096\n0.324\n21.895\n0\n\n\nincome_inequality\n-0.065\n0.011\n-5.714\n0\n\n\neducationHigh\n1.117\n0.218\n5.121\n0\n\n\n\n\n\n\n\nInterpret each of the following in terms of health expenditure\n\nIntercept\nincome_inequality\neducation"
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-with-logy-residuals",
    "href": "slides/14-variable-transformations.html#model-with-logy-residuals",
    "title": "Variable transformations",
    "section": "Model with log(Y): Residuals",
    "text": "Model with log(Y): Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations.html#compare-residual-plots",
    "href": "slides/14-variable-transformations.html#compare-residual-plots",
    "title": "Variable transformations",
    "section": "Compare residual plots",
    "text": "Compare residual plots"
  },
  {
    "objectID": "slides/14-variable-transformations.html#variability-in-life-expectancy",
    "href": "slides/14-variable-transformations.html#variability-in-life-expectancy",
    "title": "Variable transformations",
    "section": "Variability in life expectancy",
    "text": "Variability in life expectancy\nNow let’s consider a model using a country’s healthcare expenditure, income inequality, and education to predict its life expectancy"
  },
  {
    "objectID": "slides/14-variable-transformations.html#original-model-1",
    "href": "slides/14-variable-transformations.html#original-model-1",
    "title": "Variable transformations",
    "section": "Original model",
    "text": "Original model\n\nlife_exp_fit &lt;- lm(life_exp ~ health_expenditure + income_inequality + education, \n                   data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n78.575\n1.775\n44.274\n0.000\n\n\nhealth_expenditure\n0.001\n0.000\n4.522\n0.000\n\n\nincome_inequality\n-0.484\n0.061\n-7.900\n0.000\n\n\neducationHigh\n2.020\n1.168\n1.730\n0.086"
  },
  {
    "objectID": "slides/14-variable-transformations.html#original-model-residuals",
    "href": "slides/14-variable-transformations.html#original-model-residuals",
    "title": "Variable transformations",
    "section": "Original model: Residuals",
    "text": "Original model: Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations.html#residuals-vs.-predictors",
    "href": "slides/14-variable-transformations.html#residuals-vs.-predictors",
    "title": "Variable transformations",
    "section": "Residuals vs. predictors",
    "text": "Residuals vs. predictors\n\n\n\nThere is a non-linear relationship is between health expenditure and life expectancy."
  },
  {
    "objectID": "slides/14-variable-transformations.html#log-transformation-on-x",
    "href": "slides/14-variable-transformations.html#log-transformation-on-x",
    "title": "Variable transformations",
    "section": "Log Transformation on \\(X\\)",
    "text": "Log Transformation on \\(X\\)\nTry a transformation on \\(X\\) if the scatterplot in EDA shows non-linear relationship and residuals vs. predictor make parabola"
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-with-transformation-on-x_j",
    "href": "slides/14-variable-transformations.html#model-with-transformation-on-x_j",
    "title": "Variable transformations",
    "section": "Model with Transformation on \\(X_j\\)",
    "text": "Model with Transformation on \\(X_j\\)\nIf we fit a model with predictor \\(\\log(X_j)\\), we fit a model of the form\n\\[\nY = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_j\\log(X_j) + \\dots \\beta_pX_p + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\\]\n\nThe estimated regression model is\n\\[\n\\begin{aligned}\n&\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\dots + \\hat{\\beta}_j\\log(X_j) + \\dots \\hat{\\beta}_pX_p \\\\[8pt]\n\\Rightarrow \\quad &\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-interpretation-1",
    "href": "slides/14-variable-transformations.html#model-interpretation-1",
    "title": "Variable transformations",
    "section": "Model interpretation",
    "text": "Model interpretation\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_j\\log(x_{ij}) + \\dots + \\hat{\\beta}_px_{ip}\n\\]\n\n\nIntercept: When \\(x_{i1} = \\dots = \\log(x_{ij}) = \\dots = x_{ip} = 0\\) , \\(y_i\\) is expected to be \\(\\hat{\\beta}_0\\), on average, holding all else constant.\n\n\\(\\log(x_{ij}) = 0\\) when \\(x_{ij} = 1\\)\n\nCoefficient of \\(X_j\\): When \\(x_{ij}\\) is multiplied by a factor of \\(C\\), \\(y_i\\) is expected to change by \\(\\hat{\\beta}_1\\log(C)\\) units, on average, holding all else constant.\n\nExample: When \\(x_{ij}\\) is multiplied by a factor of 2, \\(y_i\\) is expected to increase by \\(\\hat{\\beta}_1\\log(2)\\) units, on average, holding all else constant."
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-with-logx",
    "href": "slides/14-variable-transformations.html#model-with-logx",
    "title": "Variable transformations",
    "section": "Model with log(X)",
    "text": "Model with log(X)\n\nlife_exp_logx_fit &lt;- lm(life_exp ~ log(health_expenditure) + income_inequality + education, \n                        data = health_data)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n59.151\n3.184\n18.576\n0.000\n\n\nlog(health_expenditure)\n3.092\n0.396\n7.814\n0.000\n\n\nincome_inequality\n-0.362\n0.058\n-6.225\n0.000\n\n\neducationHigh\n-0.168\n1.103\n-0.152\n0.879\n\n\n\n\n\n\n\n\nInterpret the intercept in the context of the data.\nInterpret the effect of health expenditure in the context of the data.\nInterpret the effect of education in the context of the data."
  },
  {
    "objectID": "slides/14-variable-transformations.html#model-with-logx-residuals",
    "href": "slides/14-variable-transformations.html#model-with-logx-residuals",
    "title": "Variable transformations",
    "section": "Model with log(X): Residuals",
    "text": "Model with log(X): Residuals"
  },
  {
    "objectID": "slides/14-variable-transformations.html#learn-more",
    "href": "slides/14-variable-transformations.html#learn-more",
    "title": "Variable transformations",
    "section": "Learn more",
    "text": "Learn more\nSee Log Transformations in Linear Regression for more details about interpreting regression models with log-transformed variables."
  },
  {
    "objectID": "slides/14-variable-transformations.html#recap",
    "href": "slides/14-variable-transformations.html#recap",
    "title": "Variable transformations",
    "section": "Recap",
    "text": "Recap\n\nLog-transformation on the response\nLog-transformation on the predictor"
  },
  {
    "objectID": "slides/14-variable-transformations.html#references",
    "href": "slides/14-variable-transformations.html#references",
    "title": "Variable transformations",
    "section": "References",
    "text": "References\n\n\n\n\nZarulli, Virginia, Elizaveta Sopina, Veronica Toffolutti, and Adam Lenart. 2021. “Health Care System Efficiency and Life Expectancy: A 140-Country Study.” Edited by Srinivas Goli. PLOS ONE 16 (7): e0253450. https://doi.org/10.1371/journal.pone.0253450."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html",
    "href": "slides/16-prob-odds-notes.html",
    "title": "Probabilities, odds, odds ratios",
    "section": "",
    "text": "HW 03 due TODAY at 11:59pm\nExploratory data analysis due March 20\n\nNext milestone: Project presentations March 31 in lab\n\nStatistics experience due April 15"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#announcements",
    "href": "slides/16-prob-odds-notes.html#announcements",
    "title": "Probabilities, odds, odds ratios",
    "section": "",
    "text": "HW 03 due TODAY at 11:59pm\nExploratory data analysis due March 20\n\nNext milestone: Project presentations March 31 in lab\n\nStatistics experience due April 15"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#topics",
    "href": "slides/16-prob-odds-notes.html#topics",
    "title": "Probabilities, odds, odds ratios",
    "section": "Topics",
    "text": "Topics\n\nLogistic regression for binary response variable\nRelationship between odds and probabilities\nOdds ratios"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#computational-setup",
    "href": "slides/16-prob-odds-notes.html#computational-setup",
    "title": "Probabilities, odds, odds ratios",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(Stat2Data) #contains sleep data set\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#types-of-outcome-variables",
    "href": "slides/16-prob-odds-notes.html#types-of-outcome-variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Types of outcome variables",
    "text": "Types of outcome variables\nQuantitative outcome variable:\n\nSales price of a house in Duke Forest\nModel: Expected sales price given the number of bedrooms, lot size, etc.\n\n. . .\nCategorical outcome variable:\n\nIndicator of being high risk of getting coronary heart disease in the next 10 years\nModel: Probability an adult is high risk of heart disease in the next 10 years given their age, total cholesterol, etc."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#models-for-categorical-outcomes",
    "href": "slides/16-prob-odds-notes.html#models-for-categorical-outcomes",
    "title": "Probabilities, odds, odds ratios",
    "section": "Models for categorical outcomes",
    "text": "Models for categorical outcomes\n\n\nLogistic regression\n2 Outcomes\n1: Yes, 0: No\n\nMultinomial logistic regression\n3+ Outcomes\n1: Democrat, 2: Republican, 3: Independent"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#example-win-probability",
    "href": "slides/16-prob-odds-notes.html#example-win-probability",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example: Win probability",
    "text": "Example: Win probability\n\n\n\nESPN Analytics win probability for Duke vs. Louisville (March 15, 2025)"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/16-prob-odds-notes.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 were surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 2\n     Age Sleep7\n   &lt;int&gt;  &lt;int&gt;\n 1    16      1\n 2    17      0\n 3    18      0\n 4    17      1\n 5    15      0\n 6    17      0\n 7    17      1\n 8    16      1\n 9    16      1\n10    18      0\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#plot-the-data",
    "href": "slides/16-prob-odds-notes.html#plot-the-data",
    "title": "Probabilities, odds, odds ratios",
    "section": "Plot the data",
    "text": "Plot the data\n\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#lets-fit-a-linear-regression-model",
    "href": "slides/16-prob-odds-notes.html#lets-fit-a-linear-regression-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#lets-use-proportions",
    "href": "slides/16-prob-odds-notes.html#lets-use-proportions",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#what-happens-if-we-zoom-out",
    "href": "slides/16-prob-odds-notes.html#what-happens-if-we-zoom-out",
    "title": "Probabilities, odds, odds ratios",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n\n\n\n\n\n\n\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#lets-try-another-model",
    "href": "slides/16-prob-odds-notes.html#lets-try-another-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n\n\n\n\n\n\n\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#the-code",
    "href": "slides/16-prob-odds-notes.html#the-code",
    "title": "Probabilities, odds, odds ratios",
    "section": "The code",
    "text": "The code\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#different-types-of-models",
    "href": "slides/16-prob-odds-notes.html#different-types-of-models",
    "title": "Probabilities, odds, odds ratios",
    "section": "Different types of models",
    "text": "Different types of models\n\n\n\n\n\n\n\n\nMethod\nOutcome\nModel\n\n\n\n\nLinear regression\nQuantitative\n\\(y_i = \\beta_0 + \\beta_1~ x_i\\)\n\n\nLinear regression (transform Y)\nQuantitative\n\\(\\log(y_i) = \\beta_0 + \\beta_1~ x_i\\)\n\n\nLogistic regression\nBinary\n\\(\\log\\big(\\frac{p_i}{1-p_i}\\big) = \\beta_0 + \\beta_1 ~ x_i\\)"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#linear-vs.-logistic-regression",
    "href": "slides/16-prob-odds-notes.html#linear-vs.-logistic-regression",
    "title": "Probabilities, odds, odds ratios",
    "section": "Linear vs. logistic regression",
    "text": "Linear vs. logistic regression\n\nState whether a linear regression model or logistic regression model is more appropriate for each scenario.\n\nUse age and political party to predict if a randomly selected person will vote in the next election.\nUse budget and run time (in minutes) to predict a movie’s total revenue.\nUse age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#data-concern-about-rising-ai",
    "href": "slides/16-prob-odds-notes.html#data-concern-about-rising-ai",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data: Concern about rising AI",
    "text": "Data: Concern about rising AI\nThis data comes from the 2023 Pew Research Center’s American Trends Panel. The survey aims to capture public opinion about a variety of topics including politics, religion, and technology, among others. We will use data from 11201 respondents in Wave 132 of the survey conducted July 31 - August 6, 2023.\n\nThe goal of this analysis is to understand the relationship between age, how much someone has heard about artificial intelligence (AI), and concern about the increased use of AI in daily life.\n\nA more complete analysis on this topic can be found in the Pew Research Center article Growing public concern about the role of artificial intelligence in daily life by Alec Tyson and Emma Kikuchi."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#variables",
    "href": "slides/16-prob-odds-notes.html#variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_concern: Whether a respondent said they are “more concerned than excited” about in the increased use of AI in daily life (1: yes, 0: no)\n\n\n\n\nSource: Pew Research"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#variables-1",
    "href": "slides/16-prob-odds-notes.html#variables-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_heard : Response to the question “How much have you heard or read about AI?”\n\nA lot\nA little\nNothing at all\nRefused\n\nage_cat: Age category\n\n18-29\n30-49\n50-64\n65+\nRefused"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#data-prep",
    "href": "slides/16-prob-odds-notes.html#data-prep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data prep",
    "text": "Data prep\n\n# change variable names and recode categories\npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = if_else(CNCEXC_W132 == 2, 1, 0),\n         age_cat = case_when(F_AGECAT == 1 ~ \"18-29\",\n                             F_AGECAT == 2 ~ \"30-49\",\n                             F_AGECAT == 3 ~ \"50-64\",\n                             F_AGECAT == 4 ~ \"65+\",\n                             TRUE ~ \"Refused\"), \n         ai_heard = case_when(AI_HEARD_W132 == 1 ~ \"A lot\",\n                              AI_HEARD_W132 == 2 ~ \"A little\",\n                              AI_HEARD_W132 == 3 ~ \"Nothing at all\",\n                              TRUE ~ \"Refused\"\n                              ))\n\n# Make factors and  relevel \npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = factor(ai_concern),\n         age_cat = factor(age_cat), \n         ai_heard = factor(ai_heard, levels = c(\"A lot\", \"A little\", \"Nothing at all\", \"Refused\"))\n  )"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#univariate-eda",
    "href": "slides/16-prob-odds-notes.html#univariate-eda",
    "title": "Probabilities, odds, odds ratios",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#binary-response-variable",
    "href": "slides/16-prob-odds-notes.html#binary-response-variable",
    "title": "Probabilities, odds, odds ratios",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes (success), } 0: \\text{ no (failure)}\\)\n\\(p\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{p}{1-p}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{p}{1-p}\\big)\\): log odds\nGo from \\(p\\) to \\(\\log\\big(\\frac{p}{1-p}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#example",
    "href": "slides/16-prob-odds-notes.html#example",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example",
    "text": "Example\n\nSuppose there is a 70% chance it will rain tomorrow\n\nProbability it will rain is \\(\\mathbf{p = 0.7}\\)\nProbability it won’t rain is \\(\\mathbf{1 - p = 0.3}\\)\nOdds it will rain are 7 to 3, 7:3, \\(\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}\\)"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#concerned-about-ai-in-daily-life",
    "href": "slides/16-prob-odds-notes.html#concerned-about-ai-in-daily-life",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concerned about AI in daily life?",
    "text": "Concerned about AI in daily life?\n\npew_data |&gt;\n  count(ai_concern) |&gt;\n  mutate(p = round(n / sum(n), 3))\n\n# A tibble: 2 × 3\n  ai_concern     n     p\n  &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n1 0           5245 0.468\n2 1           5956 0.532\n\n\n\n. . .\n\\(P(\\text{Concerned about AI}) = P(Y = 1) = p = 0.532\\)\n. . .\n\\(P(\\text{Not concerned about AI}) = P(Y = 0) = 1 - p = 0.468\\)\n. . .\n\\(\\text{Odds of being concerned about AI} = \\frac{0.532}{0.468} = 1.137\\)"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#from-odds-to-probabilities",
    "href": "slides/16-prob-odds-notes.html#from-odds-to-probabilities",
    "title": "Probabilities, odds, odds ratios",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nodds\n\\[\\text{odds} = \\frac{p}{1-p}\\]\n\nprobability\n\\[p = \\frac{\\text{odds}}{1 + \\text{odds}}\\]"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#concern-about-ai-vs.-age",
    "href": "slides/16-prob-odds-notes.html#concern-about-ai-vs.-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concern about AI vs. age",
    "text": "Concern about AI vs. age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#compare-the-odds-for-two-groups",
    "href": "slides/16-prob-odds-notes.html#compare-the-odds-for-two-groups",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n. . .\nWe want to compare concern about increased use of AI in daily life between individuals who are 18-29 years old to those who are 65+ years old"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#compare-the-odds-for-two-groups-1",
    "href": "slides/16-prob-odds-notes.html#compare-the-odds-for-two-groups-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nWe’ll use the odds to compare the two groups\n\\[\n\\text{odds} = \\frac{P(\\text{success})}{P(\\text{failure})} = \\frac{\\text{# of successes}}{\\text{# of failures}}\n\\]"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#compare-the-odds-for-two-groups-2",
    "href": "slides/16-prob-odds-notes.html#compare-the-odds-for-two-groups-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\n\nOdds of being concerned with increased use of AI in daily life for 18-29 year olds: \\(\\frac{416}{550} = 0.756\\)\nOdds of being concerned with increased use of AI in daily life for those who are 65+ years old: \\(\\frac{2013}{1376} = 1.463\\)\nBased on this, we see that individuals 65+ years old are more likely to be concerned about the increased use of AI in daily life than 18-29 year olds."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#odds-ratio-or",
    "href": "slides/16-prob-odds-notes.html#odds-ratio-or",
    "title": "Probabilities, odds, odds ratios",
    "section": "Odds ratio (OR)",
    "text": "Odds ratio (OR)\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nLet’s summarize the relationship between the two groups. To do so, we’ll use the odds ratio (OR).\n\\[\nOR = \\frac{\\text{odds}_1}{\\text{odds}_2}\n\\]"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#or-ai-concern-by-age",
    "href": "slides/16-prob-odds-notes.html#or-ai-concern-by-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "OR: AI concern by age",
    "text": "OR: AI concern by age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\\[OR = \\frac{\\text{odds}_{18-29}}{\\text{odds}_{65+}} = \\frac{0.756}{1.463} = \\mathbf{0.517}\\]\n. . .\nThe odds an 18-29 year old is concerned about increased use of AI in daily life are 0.517 times the odds a 65+ year old is concerned."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#more-natural-interpretation",
    "href": "slides/16-prob-odds-notes.html#more-natural-interpretation",
    "title": "Probabilities, odds, odds ratios",
    "section": "More natural interpretation",
    "text": "More natural interpretation\n\nIt’s more natural to interpret the odds ratio with a statement with the odds ratio greater than 1.\nThe odds a 65+ year old is concerned about increased use of AI in daily life are 1.934 (1/0.517) times the odds an 18-29 year old is concerned."
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#code-to-make-table",
    "href": "slides/16-prob-odds-notes.html#code-to-make-table",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern)\n\n# A tibble: 10 × 3\n   age_cat ai_concern     n\n   &lt;fct&gt;   &lt;fct&gt;      &lt;int&gt;\n 1 18-29   0            550\n 2 18-29   1            416\n 3 30-49   0           1898\n 4 30-49   1           1681\n 5 50-64   0           1398\n 6 50-64   1           1818\n 7 65+     0           1376\n 8 65+     1           2013\n 9 Refused 0             23\n10 Refused 1             28"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#code-to-make-table-1",
    "href": "slides/16-prob-odds-notes.html#code-to-make-table-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n)\n\n# A tibble: 5 × 3\n  age_cat   `0`   `1`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt;\n1 18-29     550   416\n2 30-49    1898  1681\n3 50-64    1398  1818\n4 65+      1376  2013\n5 Refused    23    28"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#code-to-make-table-2",
    "href": "slides/16-prob-odds-notes.html#code-to-make-table-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable()\n\n\n\n\nage_cat\n0\n1\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#code-to-make-table-3",
    "href": "slides/16-prob-odds-notes.html#code-to-make-table-3",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable(col.names = c(\"Age\", \"Not concerned\", \"Concerned\"))\n\n\n\n\nAge\nNot concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/16-prob-odds-notes.html#recap",
    "href": "slides/16-prob-odds-notes.html#recap",
    "title": "Probabilities, odds, odds ratios",
    "section": "Recap",
    "text": "Recap\n\nIntroduced logistic regression for binary response variable\nShowed the relationship between odds and probabilities\nIntroduced odds ratios"
  },
  {
    "objectID": "slides/16-prob-odds.html#announcements",
    "href": "slides/16-prob-odds.html#announcements",
    "title": "Probabilities, odds, odds ratios",
    "section": "Announcements",
    "text": "Announcements\n\nHW 03 due TODAY at 11:59pm\nExploratory data analysis due March 20\n\nNext milestone: Project presentations March 31 in lab\n\nStatistics experience due April 15"
  },
  {
    "objectID": "slides/16-prob-odds.html#topics",
    "href": "slides/16-prob-odds.html#topics",
    "title": "Probabilities, odds, odds ratios",
    "section": "Topics",
    "text": "Topics\n\nLogistic regression for binary response variable\nRelationship between odds and probabilities\nOdds ratios"
  },
  {
    "objectID": "slides/16-prob-odds.html#computational-setup",
    "href": "slides/16-prob-odds.html#computational-setup",
    "title": "Probabilities, odds, odds ratios",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(Stat2Data) #contains sleep data set\n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())"
  },
  {
    "objectID": "slides/16-prob-odds.html#types-of-outcome-variables",
    "href": "slides/16-prob-odds.html#types-of-outcome-variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Types of outcome variables",
    "text": "Types of outcome variables\nQuantitative outcome variable:\n\nSales price of a house in Duke Forest\nModel: Expected sales price given the number of bedrooms, lot size, etc.\n\n\nCategorical outcome variable:\n\nIndicator of being high risk of getting coronary heart disease in the next 10 years\nModel: Probability an adult is high risk of heart disease in the next 10 years given their age, total cholesterol, etc."
  },
  {
    "objectID": "slides/16-prob-odds.html#models-for-categorical-outcomes",
    "href": "slides/16-prob-odds.html#models-for-categorical-outcomes",
    "title": "Probabilities, odds, odds ratios",
    "section": "Models for categorical outcomes",
    "text": "Models for categorical outcomes\n\n\nLogistic regression\n2 Outcomes\n1: Yes, 0: No\n\nMultinomial logistic regression\n3+ Outcomes\n1: Democrat, 2: Republican, 3: Independent"
  },
  {
    "objectID": "slides/16-prob-odds.html#example-win-probability",
    "href": "slides/16-prob-odds.html#example-win-probability",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example: Win probability",
    "text": "Example: Win probability\n\nESPN Analytics win probability for Duke vs. Louisville (March 15, 2025)"
  },
  {
    "objectID": "slides/16-prob-odds.html#do-teenagers-get-7-hours-of-sleep",
    "href": "slides/16-prob-odds.html#do-teenagers-get-7-hours-of-sleep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Do teenagers get 7+ hours of sleep?",
    "text": "Do teenagers get 7+ hours of sleep?\n\n\nStudents in grades 9 - 12 were surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\nSleep7\n1: yes\n0: no\n\n\n\n# A tibble: 446 × 2\n     Age Sleep7\n   &lt;int&gt;  &lt;int&gt;\n 1    16      1\n 2    17      0\n 3    18      0\n 4    17      1\n 5    15      0\n 6    17      0\n 7    17      1\n 8    16      1\n 9    16      1\n10    18      0\n# ℹ 436 more rows"
  },
  {
    "objectID": "slides/16-prob-odds.html#plot-the-data",
    "href": "slides/16-prob-odds.html#plot-the-data",
    "title": "Probabilities, odds, odds ratios",
    "section": "Plot the data",
    "text": "Plot the data\n\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")"
  },
  {
    "objectID": "slides/16-prob-odds.html#lets-fit-a-linear-regression-model",
    "href": "slides/16-prob-odds.html#lets-fit-a-linear-regression-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s fit a linear regression model",
    "text": "Let’s fit a linear regression model\nOutcome: \\(Y\\) = 1: yes, 0: no"
  },
  {
    "objectID": "slides/16-prob-odds.html#lets-use-proportions",
    "href": "slides/16-prob-odds.html#lets-use-proportions",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s use proportions",
    "text": "Let’s use proportions\nOutcome: Probability of getting 7+ hours of sleep"
  },
  {
    "objectID": "slides/16-prob-odds.html#what-happens-if-we-zoom-out",
    "href": "slides/16-prob-odds.html#what-happens-if-we-zoom-out",
    "title": "Probabilities, odds, odds ratios",
    "section": "What happens if we zoom out?",
    "text": "What happens if we zoom out?\nOutcome: Probability of getting 7+ hours of sleep\n\n🛑 This model produces predictions outside of 0 and 1."
  },
  {
    "objectID": "slides/16-prob-odds.html#lets-try-another-model",
    "href": "slides/16-prob-odds.html#lets-try-another-model",
    "title": "Probabilities, odds, odds ratios",
    "section": "Let’s try another model",
    "text": "Let’s try another model\n\n✅ This model (called a logistic regression model) only produces predictions between 0 and 1."
  },
  {
    "objectID": "slides/16-prob-odds.html#the-code",
    "href": "slides/16-prob-odds.html#the-code",
    "title": "Probabilities, odds, odds ratios",
    "section": "The code",
    "text": "The code\n\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)"
  },
  {
    "objectID": "slides/16-prob-odds.html#different-types-of-models",
    "href": "slides/16-prob-odds.html#different-types-of-models",
    "title": "Probabilities, odds, odds ratios",
    "section": "Different types of models",
    "text": "Different types of models\n\n\n\n\n\n\n\n\nMethod\nOutcome\nModel\n\n\n\n\nLinear regression\nQuantitative\n\\(y_i = \\beta_0 + \\beta_1~ x_i\\)\n\n\nLinear regression (transform Y)\nQuantitative\n\\(\\log(y_i) = \\beta_0 + \\beta_1~ x_i\\)\n\n\nLogistic regression\nBinary\n\\(\\log\\big(\\frac{p_i}{1-p_i}\\big) = \\beta_0 + \\beta_1 ~ x_i\\)"
  },
  {
    "objectID": "slides/16-prob-odds.html#linear-vs.-logistic-regression",
    "href": "slides/16-prob-odds.html#linear-vs.-logistic-regression",
    "title": "Probabilities, odds, odds ratios",
    "section": "Linear vs. logistic regression",
    "text": "Linear vs. logistic regression\n\nState whether a linear regression model or logistic regression model is more appropriate for each scenario.\n\nUse age and political party to predict if a randomly selected person will vote in the next election.\nUse budget and run time (in minutes) to predict a movie’s total revenue.\nUse age and sex to calculate the probability a randomly selected adult will visit Duke Health in the next year."
  },
  {
    "objectID": "slides/16-prob-odds.html#data-concern-about-rising-ai",
    "href": "slides/16-prob-odds.html#data-concern-about-rising-ai",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data: Concern about rising AI",
    "text": "Data: Concern about rising AI\nThis data comes from the 2023 Pew Research Center’s American Trends Panel. The survey aims to capture public opinion about a variety of topics including politics, religion, and technology, among others. We will use data from 11201 respondents in Wave 132 of the survey conducted July 31 - August 6, 2023.\n\nThe goal of this analysis is to understand the relationship between age, how much someone has heard about artificial intelligence (AI), and concern about the increased use of AI in daily life.\n\nA more complete analysis on this topic can be found in the Pew Research Center article Growing public concern about the role of artificial intelligence in daily life by Alec Tyson and Emma Kikuchi."
  },
  {
    "objectID": "slides/16-prob-odds.html#variables",
    "href": "slides/16-prob-odds.html#variables",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_concern: Whether a respondent said they are “more concerned than excited” about in the increased use of AI in daily life (1: yes, 0: no)\n\n\nSource: Pew Research"
  },
  {
    "objectID": "slides/16-prob-odds.html#variables-1",
    "href": "slides/16-prob-odds.html#variables-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Variables",
    "text": "Variables\n\nai_heard : Response to the question “How much have you heard or read about AI?”\n\nA lot\nA little\nNothing at all\nRefused\n\nage_cat: Age category\n\n18-29\n30-49\n50-64\n65+\nRefused"
  },
  {
    "objectID": "slides/16-prob-odds.html#data-prep",
    "href": "slides/16-prob-odds.html#data-prep",
    "title": "Probabilities, odds, odds ratios",
    "section": "Data prep",
    "text": "Data prep\n\n# change variable names and recode categories\npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = if_else(CNCEXC_W132 == 2, 1, 0),\n         age_cat = case_when(F_AGECAT == 1 ~ \"18-29\",\n                             F_AGECAT == 2 ~ \"30-49\",\n                             F_AGECAT == 3 ~ \"50-64\",\n                             F_AGECAT == 4 ~ \"65+\",\n                             TRUE ~ \"Refused\"), \n         ai_heard = case_when(AI_HEARD_W132 == 1 ~ \"A lot\",\n                              AI_HEARD_W132 == 2 ~ \"A little\",\n                              AI_HEARD_W132 == 3 ~ \"Nothing at all\",\n                              TRUE ~ \"Refused\"\n                              ))\n\n# Make factors and  relevel \npew_data &lt;- pew_data |&gt;\n  mutate(ai_concern = factor(ai_concern),\n         age_cat = factor(age_cat), \n         ai_heard = factor(ai_heard, levels = c(\"A lot\", \"A little\", \"Nothing at all\", \"Refused\"))\n  )"
  },
  {
    "objectID": "slides/16-prob-odds.html#univariate-eda",
    "href": "slides/16-prob-odds.html#univariate-eda",
    "title": "Probabilities, odds, odds ratios",
    "section": "Univariate EDA",
    "text": "Univariate EDA"
  },
  {
    "objectID": "slides/16-prob-odds.html#binary-response-variable",
    "href": "slides/16-prob-odds.html#binary-response-variable",
    "title": "Probabilities, odds, odds ratios",
    "section": "Binary response variable",
    "text": "Binary response variable\n\n\n\\(Y = 1: \\text{ yes (success), } 0: \\text{ no (failure)}\\)\n\\(p\\): probability that \\(Y=1\\), i.e., \\(P(Y = 1)\\)\n\\(\\frac{p}{1-p}\\): odds that \\(Y = 1\\)\n\\(\\log\\big(\\frac{p}{1-p}\\big)\\): log odds\nGo from \\(p\\) to \\(\\log\\big(\\frac{p}{1-p}\\big)\\) using the logit transformation"
  },
  {
    "objectID": "slides/16-prob-odds.html#example",
    "href": "slides/16-prob-odds.html#example",
    "title": "Probabilities, odds, odds ratios",
    "section": "Example",
    "text": "Example\n\nSuppose there is a 70% chance it will rain tomorrow\n\nProbability it will rain is \\(\\mathbf{p = 0.7}\\)\nProbability it won’t rain is \\(\\mathbf{1 - p = 0.3}\\)\nOdds it will rain are 7 to 3, 7:3, \\(\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}\\)"
  },
  {
    "objectID": "slides/16-prob-odds.html#concerned-about-ai-in-daily-life",
    "href": "slides/16-prob-odds.html#concerned-about-ai-in-daily-life",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concerned about AI in daily life?",
    "text": "Concerned about AI in daily life?\n\npew_data |&gt;\n  count(ai_concern) |&gt;\n  mutate(p = round(n / sum(n), 3))\n\n# A tibble: 2 × 3\n  ai_concern     n     p\n  &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n1 0           5245 0.468\n2 1           5956 0.532\n\n\n\n\n\\(P(\\text{Concerned about AI}) = P(Y = 1) = p = 0.532\\)\n\n\n\\(P(\\text{Not concerned about AI}) = P(Y = 0) = 1 - p = 0.468\\)\n\n\n\\(\\text{Odds of being concerned about AI} = \\frac{0.532}{0.468} = 1.137\\)"
  },
  {
    "objectID": "slides/16-prob-odds.html#from-odds-to-probabilities",
    "href": "slides/16-prob-odds.html#from-odds-to-probabilities",
    "title": "Probabilities, odds, odds ratios",
    "section": "From odds to probabilities",
    "text": "From odds to probabilities\n\n\nodds\n\\[\\text{odds} = \\frac{p}{1-p}\\]\n\nprobability\n\\[p = \\frac{\\text{odds}}{1 + \\text{odds}}\\]"
  },
  {
    "objectID": "slides/16-prob-odds.html#concern-about-ai-vs.-age",
    "href": "slides/16-prob-odds.html#concern-about-ai-vs.-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "Concern about AI vs. age",
    "text": "Concern about AI vs. age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/16-prob-odds.html#compare-the-odds-for-two-groups",
    "href": "slides/16-prob-odds.html#compare-the-odds-for-two-groups",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\nWe want to compare concern about increased use of AI in daily life between individuals who are 18-29 years old to those who are 65+ years old"
  },
  {
    "objectID": "slides/16-prob-odds.html#compare-the-odds-for-two-groups-1",
    "href": "slides/16-prob-odds.html#compare-the-odds-for-two-groups-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nWe’ll use the odds to compare the two groups\n\\[\n\\text{odds} = \\frac{P(\\text{success})}{P(\\text{failure})} = \\frac{\\text{# of successes}}{\\text{# of failures}}\n\\]"
  },
  {
    "objectID": "slides/16-prob-odds.html#compare-the-odds-for-two-groups-2",
    "href": "slides/16-prob-odds.html#compare-the-odds-for-two-groups-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Compare the odds for two groups",
    "text": "Compare the odds for two groups\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\n\nOdds of being concerned with increased use of AI in daily life for 18-29 year olds: \\(\\frac{416}{550} = 0.756\\)\nOdds of being concerned with increased use of AI in daily life for those who are 65+ years old: \\(\\frac{2013}{1376} = 1.463\\)\nBased on this, we see that individuals 65+ years old are more likely to be concerned about the increased use of AI in daily life than 18-29 year olds."
  },
  {
    "objectID": "slides/16-prob-odds.html#odds-ratio-or",
    "href": "slides/16-prob-odds.html#odds-ratio-or",
    "title": "Probabilities, odds, odds ratios",
    "section": "Odds ratio (OR)",
    "text": "Odds ratio (OR)\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\nLet’s summarize the relationship between the two groups. To do so, we’ll use the odds ratio (OR).\n\\[\nOR = \\frac{\\text{odds}_1}{\\text{odds}_2}\n\\]"
  },
  {
    "objectID": "slides/16-prob-odds.html#or-ai-concern-by-age",
    "href": "slides/16-prob-odds.html#or-ai-concern-by-age",
    "title": "Probabilities, odds, odds ratios",
    "section": "OR: AI concern by age",
    "text": "OR: AI concern by age\n\n\n\n\n\nAge\nNot Concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28\n\n\n\n\n\n\\[OR = \\frac{\\text{odds}_{18-29}}{\\text{odds}_{65+}} = \\frac{0.756}{1.463} = \\mathbf{0.517}\\]\n\nThe odds an 18-29 year old is concerned about increased use of AI in daily life are 0.517 times the odds a 65+ year old is concerned."
  },
  {
    "objectID": "slides/16-prob-odds.html#more-natural-interpretation",
    "href": "slides/16-prob-odds.html#more-natural-interpretation",
    "title": "Probabilities, odds, odds ratios",
    "section": "More natural interpretation",
    "text": "More natural interpretation\n\nIt’s more natural to interpret the odds ratio with a statement with the odds ratio greater than 1.\nThe odds a 65+ year old is concerned about increased use of AI in daily life are 1.934 (1/0.517) times the odds an 18-29 year old is concerned."
  },
  {
    "objectID": "slides/16-prob-odds.html#code-to-make-table",
    "href": "slides/16-prob-odds.html#code-to-make-table",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern)\n\n# A tibble: 10 × 3\n   age_cat ai_concern     n\n   &lt;fct&gt;   &lt;fct&gt;      &lt;int&gt;\n 1 18-29   0            550\n 2 18-29   1            416\n 3 30-49   0           1898\n 4 30-49   1           1681\n 5 50-64   0           1398\n 6 50-64   1           1818\n 7 65+     0           1376\n 8 65+     1           2013\n 9 Refused 0             23\n10 Refused 1             28"
  },
  {
    "objectID": "slides/16-prob-odds.html#code-to-make-table-1",
    "href": "slides/16-prob-odds.html#code-to-make-table-1",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n)\n\n# A tibble: 5 × 3\n  age_cat   `0`   `1`\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt;\n1 18-29     550   416\n2 30-49    1898  1681\n3 50-64    1398  1818\n4 65+      1376  2013\n5 Refused    23    28"
  },
  {
    "objectID": "slides/16-prob-odds.html#code-to-make-table-2",
    "href": "slides/16-prob-odds.html#code-to-make-table-2",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable()\n\n\n\n\nage_cat\n0\n1\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/16-prob-odds.html#code-to-make-table-3",
    "href": "slides/16-prob-odds.html#code-to-make-table-3",
    "title": "Probabilities, odds, odds ratios",
    "section": "Code to make table",
    "text": "Code to make table\n\npew_data |&gt;\n  count(age_cat, ai_concern) |&gt;\n  pivot_wider(names_from = ai_concern, values_from = n) |&gt;\n  kable(col.names = c(\"Age\", \"Not concerned\", \"Concerned\"))\n\n\n\n\nAge\nNot concerned\nConcerned\n\n\n\n\n18-29\n550\n416\n\n\n30-49\n1898\n1681\n\n\n50-64\n1398\n1818\n\n\n65+\n1376\n2013\n\n\nRefused\n23\n28"
  },
  {
    "objectID": "slides/16-prob-odds.html#recap",
    "href": "slides/16-prob-odds.html#recap",
    "title": "Probabilities, odds, odds ratios",
    "section": "Recap",
    "text": "Recap\n\nIntroduced logistic regression for binary response variable\nShowed the relationship between odds and probabilities\nIntroduced odds ratios"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html",
    "href": "slides/10-mlr-inference-conditions-notes.html",
    "title": "MLR: Model comparison + Inference",
    "section": "",
    "text": "HW 02 due TODAY at 11:59pm\nLab 03 due Thursday, February 13 at 11:59pm\nProject topics due Sunday, February 16 at 11:59pm\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#announcements",
    "href": "slides/10-mlr-inference-conditions-notes.html#announcements",
    "title": "MLR: Model comparison + Inference",
    "section": "",
    "text": "HW 02 due TODAY at 11:59pm\nLab 03 due Thursday, February 13 at 11:59pm\nProject topics due Sunday, February 16 at 11:59pm\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#exam-01",
    "href": "slides/10-mlr-inference-conditions-notes.html#exam-01",
    "title": "MLR: Model comparison + Inference",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35-40 points\ntake-home: 10 - 15 points\n\nIn-class (35 -40 pts): 75 minutes during February 18 lecture\nTake-home (10 -15 pts): released after class on Tuesday\nIf you miss any part of the exam for an excused absence (with academic dean’s note or other official documentation), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#tips-for-studying",
    "href": "slides/10-mlr-inference-conditions-notes.html#tips-for-studying",
    "title": "MLR: Model comparison + Inference",
    "section": "Tips for studying",
    "text": "Tips for studying\n\nReview exercises in AEs and assignments, asking “why” as you review your process and reasoning\n\ne.g., Why do we include “holding all else constant” in interpretations?\n\nFocus on understanding not memorization\nExplain concepts / process to others\nAsk questions in office hours\nReview lecture recordings as needed"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#topics",
    "href": "slides/10-mlr-inference-conditions-notes.html#topics",
    "title": "MLR: Model comparison + Inference",
    "section": "Topics",
    "text": "Topics\n\n\nModel comparison AE\nInference for multiple linear regression"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#computational-setup",
    "href": "slides/10-mlr-inference-conditions-notes.html#computational-setup",
    "title": "MLR: Model comparison + Inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(countdown)\nlibrary(rms)\n\nLoading required package: Hmisc\n\nAttaching package: 'Hmisc'\n\nThe following object is masked from 'package:parsnip':\n\n    translate\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#rmse",
    "href": "slides/10-mlr-inference-conditions-notes.html#rmse",
    "title": "MLR: Model comparison + Inference",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#r2-and-adjusted-r2",
    "href": "slides/10-mlr-inference-conditions-notes.html#r2-and-adjusted-r2",
    "title": "MLR: Model comparison + Inference",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n. . .\n\\[Adj. R^2 = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#modeling-workflow",
    "href": "slides/10-mlr-inference-conditions-notes.html#modeling-workflow",
    "title": "MLR: Model comparison + Inference",
    "section": "Modeling workflow",
    "text": "Modeling workflow\n\nSplit data into training and test sets.\nFit, evaluate, and compare candidate models. Choose a final model based on summary of cross validation results.\nRefit the model using the entire training set and do “final” evaluation on the test set (make sure you have not overfit the model).\n\nAdjust as needed if there is evidence of overfit.\n\nUse model fit on training set for inference and prediction."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#data-rail_trail",
    "href": "slides/10-mlr-inference-conditions-notes.html#data-rail_trail",
    "title": "MLR: Model comparison + Inference",
    "section": "Data: rail_trail",
    "text": "Data: rail_trail\n\n\nThe Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005.\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n\nRows: 90 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): season, day_type\ndbl (5): volume, hightemp, avgtemp, cloudcover, precip\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 8 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60 0      Weekday \n2    419       73    61   Summer       6.30 0.290  Weekday \n3    397       74    63   Spring       7.5  0.320  Weekday \n4    385       95    78   Summer       2.60 0      Weekend \n5    200       44    48   Spring      10    0.140  Weekday \n6    375       69    61.5 Spring       6.60 0.0200 Weekday \n7    417       66    52.5 Spring       2.40 0      Weekday \n8    629       66    52   Spring       0    0      Weekend \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#variables",
    "href": "slides/10-mlr-inference-conditions-notes.html#variables",
    "title": "MLR: Model comparison + Inference",
    "section": "Variables",
    "text": "Variables\nResponse:\nvolume estimated number of trail users that day (number of breaks recorded)\n. . .\nPredictors\n\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\ncloudcover measure of cloud cover (in oktas)\nprecip measure of precipitation (in inches)\nday_type one of “weekday” or “weekend”"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#review-simple-linear-regression-slr",
    "href": "slides/10-mlr-inference-conditions-notes.html#review-simple-linear-regression-slr",
    "title": "MLR: Model comparison + Inference",
    "section": "Review: Simple linear regression (SLR)",
    "text": "Review: Simple linear regression (SLR)\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#slr-model-summary",
    "href": "slides/10-mlr-inference-conditions-notes.html#slr-model-summary",
    "title": "MLR: Model comparison + Inference",
    "section": "SLR model summary",
    "text": "SLR model summary\n\nrt_slr_fit &lt;- lm(volume ~ hightemp, data = rail_trail)\n\ntidy(rt_slr_fit) |&gt; kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-17.08\n59.40\n-0.29\n0.77\n\n\nhightemp\n5.70\n0.85\n6.72\n0.00"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#slr-hypothesis-test",
    "href": "slides/10-mlr-inference-conditions-notes.html#slr-hypothesis-test",
    "title": "MLR: Model comparison + Inference",
    "section": "SLR hypothesis test",
    "text": "SLR hypothesis test\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-17.08\n59.40\n-0.29\n0.77\n\n\nhightemp\n5.70\n0.85\n6.72\n0.00\n\n\n\n\n\n\nSet hypotheses: \\(H_0: \\beta_1 = 0\\) vs. \\(H_a: \\beta_1 \\ne 0\\)\n\n. . .\n\nCalculate test statistic and p-value: The test statistic is \\(t= 6.72\\) . The p-value is calculated using a \\(t\\) distribution with 88 degrees of freedom. The p-value is \\(\\approx 0\\) .\n\n. . .\n\nState the conclusion: The p-value is small, so we reject \\(H_0\\). The data provide strong evidence that high temperature is a helpful predictor for the number of daily riders, i.e. there is a linear relationship between high temperature and number of daily riders."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#multiple-linear-regression",
    "href": "slides/10-mlr-inference-conditions-notes.html#multiple-linear-regression",
    "title": "MLR: Model comparison + Inference",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nrt_mlr_main_fit &lt;- lm(volume ~ hightemp + season, data = rail_trail)\n\ntidy(rt_mlr_main_fit) |&gt; kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#multiple-linear-regression-1",
    "href": "slides/10-mlr-inference-conditions-notes.html#multiple-linear-regression-1",
    "title": "MLR: Model comparison + Inference",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nThe multiple linear regression model assumes \\[Y|X_1, X_2,  \\ldots, X_p \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p, \\sigma_\\epsilon^2)\\]\n\n. . .\nFor a given observation \\((x_{i1}, x_{i2}, \\ldots, x_{ip}, y_i)\\), we can rewrite the previous statement as\n\\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\epsilon_{i} \\hspace{10mm} \\epsilon_i \\sim N(0,\\sigma_{\\epsilon}^2)\\]"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#estimating-sigma_epsilon",
    "href": "slides/10-mlr-inference-conditions-notes.html#estimating-sigma_epsilon",
    "title": "MLR: Model comparison + Inference",
    "section": "Estimating \\(\\sigma_\\epsilon\\)",
    "text": "Estimating \\(\\sigma_\\epsilon\\)\nFor a given observation \\((x_{i1}, x_{i2}, \\ldots,x_{ip}, y_i)\\) the residual is \\[e_i = y_{i} - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_{2} x_{i2} + \\dots + \\hat{\\beta}_p x_{ip})\\]\n\n. . .\nThe estimated value of the regression standard error , \\(\\sigma_{\\epsilon}\\), is\n\\[\\hat{\\sigma}_\\epsilon  = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n-p-1}}\\]\n. . .\nAs with SLR, we use \\(\\hat{\\sigma}_{\\epsilon}\\) to calculate \\(SE(\\hat{\\beta}_j)\\), the standard error of the coefficient for predictor \\(x_j\\). See Matrix Form of Linear Regression for more detail."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#mlr-hypothesis-test-hightemp",
    "href": "slides/10-mlr-inference-conditions-notes.html#mlr-hypothesis-test-hightemp",
    "title": "MLR: Model comparison + Inference",
    "section": "MLR hypothesis test: hightemp",
    "text": "MLR hypothesis test: hightemp\n\nSet hypotheses: \\(H_0: \\beta_{hightemp} = 0\\) vs. \\(H_a: \\beta_{hightemp} \\ne 0\\), given season is in the model\n\n. . .\n\nCalculate test statistic and p-value: The test statistic is \\(t = 6.43\\). The p-value is calculated using a \\(t\\) distribution with 86 \\((n - p - 1)\\) degrees of freedom. The p-value is \\(\\approx 0\\).\n\n. . .\n\nState the conclusion: The p-value is small, so we reject \\(H_0\\). The data provide strong evidence that high temperature for the day is a useful predictor in a model that already contains the season as a predictor for number of daily riders."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#interaction-terms",
    "href": "slides/10-mlr-inference-conditions-notes.html#interaction-terms",
    "title": "MLR: Model comparison + Inference",
    "section": "Interaction terms",
    "text": "Interaction terms\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-10.53\n166.80\n-0.06\n0.95\n\n\nhightemp\n5.48\n2.95\n1.86\n0.07\n\n\nseasonSpring\n-293.95\n190.33\n-1.54\n0.13\n\n\nseasonSummer\n354.18\n255.08\n1.39\n0.17\n\n\nhightemp:seasonSpring\n4.88\n3.26\n1.50\n0.14\n\n\nhightemp:seasonSummer\n-4.54\n3.75\n-1.21\n0.23\n\n\n\n\n\n\n\nDo the data provide evidence of a significant interaction effect? Comment on the significance of the interaction terms."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#confidence-interval-for-beta_j-1",
    "href": "slides/10-mlr-inference-conditions-notes.html#confidence-interval-for-beta_j-1",
    "title": "MLR: Model comparison + Inference",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nThe \\(C\\%\\) confidence interval for \\(\\beta_j\\) \\[\\hat{\\beta}_j \\pm t^* SE(\\hat{\\beta}_j)\\] where \\(t^*\\) follows a \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom.\nGenerically: We are \\(C\\%\\) confident that the interval LB to UB contains the population coefficient of \\(x_j\\).\nIn context: We are \\(C\\%\\) confident that for every one unit increase in \\(x_j\\), \\(y\\) changes by LB to UB units, on average, holding all else constant."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#confidence-interval-for-beta_j-2",
    "href": "slides/10-mlr-inference-conditions-notes.html#confidence-interval-for-beta_j-2",
    "title": "MLR: Model comparison + Inference",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\ntidy(rt_mlr_main_fit, conf.int = TRUE, conf.level = 0.95) |&gt;\n  kable(digits= 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n-267.68\n17.22\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n5.21\n9.87\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n-63.10\n73.36\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11\n-171.68\n18.00"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#ci-for-hightemp",
    "href": "slides/10-mlr-inference-conditions-notes.html#ci-for-hightemp",
    "title": "MLR: Model comparison + Inference",
    "section": "CI for hightemp",
    "text": "CI for hightemp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n-267.68\n17.22\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n5.21\n9.87\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n-63.10\n73.36\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11\n-171.68\n18.00\n\n\n\n\n\n\nWe are 95% confident that for every degree Fahrenheit the day is warmer, the number of riders increases by 5.21 to 9.87, on average, holding season constant."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#ci-for-seasonspring",
    "href": "slides/10-mlr-inference-conditions-notes.html#ci-for-seasonspring",
    "title": "MLR: Model comparison + Inference",
    "section": "CI for seasonSpring",
    "text": "CI for seasonSpring\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n-267.68\n17.22\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n5.21\n9.87\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n-63.10\n73.36\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11\n-171.68\n18.00\n\n\n\n\n\n\nWe are 95% confident that the number of riders on a Spring day is lower by 63.1 to higher by 73.4 compared to a Fall day, on average, holding high temperature for the day constant.\n. . .\n\nIs season a significant predictor of the number of riders, after accounting for high temperature?"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#large-sample-sizes",
    "href": "slides/10-mlr-inference-conditions-notes.html#large-sample-sizes",
    "title": "MLR: Model comparison + Inference",
    "section": "Large sample sizes",
    "text": "Large sample sizes\n\n\n\n\n\n\n\nCaution\n\n\n\nIf the sample size is large enough, the test will likely result in rejecting \\(H_0: \\beta_j = 0\\) even \\(x_j\\) has a very small effect on \\(y\\).\n\n\nConsider the practical significance of the result not just the statistical significance.\nUse the confidence interval to draw conclusions instead of relying only p-values."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#small-sample-sizes",
    "href": "slides/10-mlr-inference-conditions-notes.html#small-sample-sizes",
    "title": "MLR: Model comparison + Inference",
    "section": "Small sample sizes",
    "text": "Small sample sizes\n\n\n\n\n\n\n\nCaution\n\n\n\nIf the sample size is small, there may not be enough evidence to reject \\(H_0: \\beta_j=0\\).\n\n\nWhen you fail to reject the null hypothesis, DON’T immediately conclude that the variable has no association with the response.\nThere may be a linear association that is just not strong enough to detect given your data, or there may be a non-linear association."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#recap",
    "href": "slides/10-mlr-inference-conditions-notes.html#recap",
    "title": "MLR: Model comparison + Inference",
    "section": "Recap",
    "text": "Recap\n\nReviewed model comparison\nIntroduced inference for multiple linear regression"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions-notes.html#next-class",
    "href": "slides/10-mlr-inference-conditions-notes.html#next-class",
    "title": "MLR: Model comparison + Inference",
    "section": "Next class",
    "text": "Next class\n\nExam 01 review"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#announcements",
    "href": "slides/10-mlr-inference-conditions.html#announcements",
    "title": "MLR: Model comparison + Inference",
    "section": "Announcements",
    "text": "Announcements\n\nHW 02 due TODAY at 11:59pm\nLab 03 due Thursday, February 13 at 11:59pm\nProject topics due Sunday, February 16 at 11:59pm\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#exam-01",
    "href": "slides/10-mlr-inference-conditions.html#exam-01",
    "title": "MLR: Model comparison + Inference",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35-40 points\ntake-home: 10 - 15 points\n\nIn-class (35 -40 pts): 75 minutes during February 18 lecture\nTake-home (10 -15 pts): released after class on Tuesday\nIf you miss any part of the exam for an excused absence (with academic dean’s note or other official documentation), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#tips-for-studying",
    "href": "slides/10-mlr-inference-conditions.html#tips-for-studying",
    "title": "MLR: Model comparison + Inference",
    "section": "Tips for studying",
    "text": "Tips for studying\n\nReview exercises in AEs and assignments, asking “why” as you review your process and reasoning\n\ne.g., Why do we include “holding all else constant” in interpretations?\n\nFocus on understanding not memorization\nExplain concepts / process to others\nAsk questions in office hours\nReview lecture recordings as needed"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#topics",
    "href": "slides/10-mlr-inference-conditions.html#topics",
    "title": "MLR: Model comparison + Inference",
    "section": "Topics",
    "text": "Topics\n\n\nModel comparison AE\nInference for multiple linear regression"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#computational-setup",
    "href": "slides/10-mlr-inference-conditions.html#computational-setup",
    "title": "MLR: Model comparison + Inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(countdown)\nlibrary(rms)\n\nLoading required package: Hmisc\n\nAttaching package: 'Hmisc'\n\nThe following object is masked from 'package:parsnip':\n\n    translate\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#rmse",
    "href": "slides/10-mlr-inference-conditions.html#rmse",
    "title": "MLR: Model comparison + Inference",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#r2-and-adjusted-r2",
    "href": "slides/10-mlr-inference-conditions.html#r2-and-adjusted-r2",
    "title": "MLR: Model comparison + Inference",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n\n\\[Adj. R^2 = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#modeling-workflow",
    "href": "slides/10-mlr-inference-conditions.html#modeling-workflow",
    "title": "MLR: Model comparison + Inference",
    "section": "Modeling workflow",
    "text": "Modeling workflow\n\nSplit data into training and test sets.\nFit, evaluate, and compare candidate models. Choose a final model based on summary of cross validation results.\nRefit the model using the entire training set and do “final” evaluation on the test set (make sure you have not overfit the model).\n\nAdjust as needed if there is evidence of overfit.\n\nUse model fit on training set for inference and prediction."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#data-rail_trail",
    "href": "slides/10-mlr-inference-conditions.html#data-rail_trail",
    "title": "MLR: Model comparison + Inference",
    "section": "Data: rail_trail",
    "text": "Data: rail_trail\n\n\nThe Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005.\nData collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\n\n\n\n\nRows: 90 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): season, day_type\ndbl (5): volume, hightemp, avgtemp, cloudcover, precip\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 8 × 7\n  volume hightemp avgtemp season cloudcover precip day_type\n   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   \n1    501       83    66.5 Summer       7.60 0      Weekday \n2    419       73    61   Summer       6.30 0.290  Weekday \n3    397       74    63   Spring       7.5  0.320  Weekday \n4    385       95    78   Summer       2.60 0      Weekend \n5    200       44    48   Spring      10    0.140  Weekday \n6    375       69    61.5 Spring       6.60 0.0200 Weekday \n7    417       66    52.5 Spring       2.40 0      Weekday \n8    629       66    52   Spring       0    0      Weekend \n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#variables",
    "href": "slides/10-mlr-inference-conditions.html#variables",
    "title": "MLR: Model comparison + Inference",
    "section": "Variables",
    "text": "Variables\nResponse:\nvolume estimated number of trail users that day (number of breaks recorded)\n\nPredictors\n\n\nhightemp daily high temperature (in degrees Fahrenheit)\navgtemp average of daily low and daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\ncloudcover measure of cloud cover (in oktas)\nprecip measure of precipitation (in inches)\nday_type one of “weekday” or “weekend”"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#review-simple-linear-regression-slr",
    "href": "slides/10-mlr-inference-conditions.html#review-simple-linear-regression-slr",
    "title": "MLR: Model comparison + Inference",
    "section": "Review: Simple linear regression (SLR)",
    "text": "Review: Simple linear regression (SLR)\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#slr-model-summary",
    "href": "slides/10-mlr-inference-conditions.html#slr-model-summary",
    "title": "MLR: Model comparison + Inference",
    "section": "SLR model summary",
    "text": "SLR model summary\n\nrt_slr_fit &lt;- lm(volume ~ hightemp, data = rail_trail)\n\ntidy(rt_slr_fit) |&gt; kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-17.08\n59.40\n-0.29\n0.77\n\n\nhightemp\n5.70\n0.85\n6.72\n0.00"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#slr-hypothesis-test",
    "href": "slides/10-mlr-inference-conditions.html#slr-hypothesis-test",
    "title": "MLR: Model comparison + Inference",
    "section": "SLR hypothesis test",
    "text": "SLR hypothesis test\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-17.08\n59.40\n-0.29\n0.77\n\n\nhightemp\n5.70\n0.85\n6.72\n0.00\n\n\n\n\n\n\nSet hypotheses: \\(H_0: \\beta_1 = 0\\) vs. \\(H_a: \\beta_1 \\ne 0\\)\n\n\n\nCalculate test statistic and p-value: The test statistic is \\(t= 6.72\\) . The p-value is calculated using a \\(t\\) distribution with 88 degrees of freedom. The p-value is \\(\\approx 0\\) .\n\n\n\n\nState the conclusion: The p-value is small, so we reject \\(H_0\\). The data provide strong evidence that high temperature is a helpful predictor for the number of daily riders, i.e. there is a linear relationship between high temperature and number of daily riders."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#multiple-linear-regression",
    "href": "slides/10-mlr-inference-conditions.html#multiple-linear-regression",
    "title": "MLR: Model comparison + Inference",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\n\nrt_mlr_main_fit &lt;- lm(volume ~ hightemp + season, data = rail_trail)\n\ntidy(rt_mlr_main_fit) |&gt; kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#multiple-linear-regression-1",
    "href": "slides/10-mlr-inference-conditions.html#multiple-linear-regression-1",
    "title": "MLR: Model comparison + Inference",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nThe multiple linear regression model assumes \\[Y|X_1, X_2,  \\ldots, X_p \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p, \\sigma_\\epsilon^2)\\]\n\n\nFor a given observation \\((x_{i1}, x_{i2}, \\ldots, x_{ip}, y_i)\\), we can rewrite the previous statement as\n\\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\epsilon_{i} \\hspace{10mm} \\epsilon_i \\sim N(0,\\sigma_{\\epsilon}^2)\\]"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#estimating-sigma_epsilon",
    "href": "slides/10-mlr-inference-conditions.html#estimating-sigma_epsilon",
    "title": "MLR: Model comparison + Inference",
    "section": "Estimating \\(\\sigma_\\epsilon\\)",
    "text": "Estimating \\(\\sigma_\\epsilon\\)\nFor a given observation \\((x_{i1}, x_{i2}, \\ldots,x_{ip}, y_i)\\) the residual is \\[e_i = y_{i} - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_{2} x_{i2} + \\dots + \\hat{\\beta}_p x_{ip})\\]\n\n\nThe estimated value of the regression standard error , \\(\\sigma_{\\epsilon}\\), is\n\\[\\hat{\\sigma}_\\epsilon  = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n-p-1}}\\]\n\n\nAs with SLR, we use \\(\\hat{\\sigma}_{\\epsilon}\\) to calculate \\(SE(\\hat{\\beta}_j)\\), the standard error of the coefficient for predictor \\(x_j\\). See Matrix Form of Linear Regression for more detail."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#mlr-hypothesis-test-hightemp",
    "href": "slides/10-mlr-inference-conditions.html#mlr-hypothesis-test-hightemp",
    "title": "MLR: Model comparison + Inference",
    "section": "MLR hypothesis test: hightemp",
    "text": "MLR hypothesis test: hightemp\n\nSet hypotheses: \\(H_0: \\beta_{hightemp} = 0\\) vs. \\(H_a: \\beta_{hightemp} \\ne 0\\), given season is in the model\n\n\n\nCalculate test statistic and p-value: The test statistic is \\(t = 6.43\\). The p-value is calculated using a \\(t\\) distribution with 86 \\((n - p - 1)\\) degrees of freedom. The p-value is \\(\\approx 0\\).\n\n\n\n\nState the conclusion: The p-value is small, so we reject \\(H_0\\). The data provide strong evidence that high temperature for the day is a useful predictor in a model that already contains the season as a predictor for number of daily riders."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#interaction-terms",
    "href": "slides/10-mlr-inference-conditions.html#interaction-terms",
    "title": "MLR: Model comparison + Inference",
    "section": "Interaction terms",
    "text": "Interaction terms\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-10.53\n166.80\n-0.06\n0.95\n\n\nhightemp\n5.48\n2.95\n1.86\n0.07\n\n\nseasonSpring\n-293.95\n190.33\n-1.54\n0.13\n\n\nseasonSummer\n354.18\n255.08\n1.39\n0.17\n\n\nhightemp:seasonSpring\n4.88\n3.26\n1.50\n0.14\n\n\nhightemp:seasonSummer\n-4.54\n3.75\n-1.21\n0.23\n\n\n\n\n\n\n\nDo the data provide evidence of a significant interaction effect? Comment on the significance of the interaction terms."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#confidence-interval-for-beta_j-1",
    "href": "slides/10-mlr-inference-conditions.html#confidence-interval-for-beta_j-1",
    "title": "MLR: Model comparison + Inference",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\n\nThe \\(C\\%\\) confidence interval for \\(\\beta_j\\) \\[\\hat{\\beta}_j \\pm t^* SE(\\hat{\\beta}_j)\\] where \\(t^*\\) follows a \\(t\\) distribution with \\(n - p - 1\\) degrees of freedom.\nGenerically: We are \\(C\\%\\) confident that the interval LB to UB contains the population coefficient of \\(x_j\\).\nIn context: We are \\(C\\%\\) confident that for every one unit increase in \\(x_j\\), \\(y\\) changes by LB to UB units, on average, holding all else constant."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#confidence-interval-for-beta_j-2",
    "href": "slides/10-mlr-inference-conditions.html#confidence-interval-for-beta_j-2",
    "title": "MLR: Model comparison + Inference",
    "section": "Confidence interval for \\(\\beta_j\\)",
    "text": "Confidence interval for \\(\\beta_j\\)\n\ntidy(rt_mlr_main_fit, conf.int = TRUE, conf.level = 0.95) |&gt;\n  kable(digits= 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n-267.68\n17.22\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n5.21\n9.87\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n-63.10\n73.36\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11\n-171.68\n18.00"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#ci-for-hightemp",
    "href": "slides/10-mlr-inference-conditions.html#ci-for-hightemp",
    "title": "MLR: Model comparison + Inference",
    "section": "CI for hightemp",
    "text": "CI for hightemp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n-267.68\n17.22\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n5.21\n9.87\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n-63.10\n73.36\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11\n-171.68\n18.00\n\n\n\n\n\n\nWe are 95% confident that for every degree Fahrenheit the day is warmer, the number of riders increases by 5.21 to 9.87, on average, holding season constant."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#ci-for-seasonspring",
    "href": "slides/10-mlr-inference-conditions.html#ci-for-seasonspring",
    "title": "MLR: Model comparison + Inference",
    "section": "CI for seasonSpring",
    "text": "CI for seasonSpring\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-125.23\n71.66\n-1.75\n0.08\n-267.68\n17.22\n\n\nhightemp\n7.54\n1.17\n6.43\n0.00\n5.21\n9.87\n\n\nseasonSpring\n5.13\n34.32\n0.15\n0.88\n-63.10\n73.36\n\n\nseasonSummer\n-76.84\n47.71\n-1.61\n0.11\n-171.68\n18.00\n\n\n\n\n\n\nWe are 95% confident that the number of riders on a Spring day is lower by 63.1 to higher by 73.4 compared to a Fall day, on average, holding high temperature for the day constant.\n\n\nIs season a significant predictor of the number of riders, after accounting for high temperature?"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#large-sample-sizes",
    "href": "slides/10-mlr-inference-conditions.html#large-sample-sizes",
    "title": "MLR: Model comparison + Inference",
    "section": "Large sample sizes",
    "text": "Large sample sizes\n\n\n\n\n\n\n\nCaution\n\n\nIf the sample size is large enough, the test will likely result in rejecting \\(H_0: \\beta_j = 0\\) even \\(x_j\\) has a very small effect on \\(y\\).\n\n\nConsider the practical significance of the result not just the statistical significance.\nUse the confidence interval to draw conclusions instead of relying only p-values."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#small-sample-sizes",
    "href": "slides/10-mlr-inference-conditions.html#small-sample-sizes",
    "title": "MLR: Model comparison + Inference",
    "section": "Small sample sizes",
    "text": "Small sample sizes\n\n\n\n\n\n\n\nCaution\n\n\nIf the sample size is small, there may not be enough evidence to reject \\(H_0: \\beta_j=0\\).\n\n\nWhen you fail to reject the null hypothesis, DON’T immediately conclude that the variable has no association with the response.\nThere may be a linear association that is just not strong enough to detect given your data, or there may be a non-linear association."
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#recap",
    "href": "slides/10-mlr-inference-conditions.html#recap",
    "title": "MLR: Model comparison + Inference",
    "section": "Recap",
    "text": "Recap\n\nReviewed model comparison\nIntroduced inference for multiple linear regression"
  },
  {
    "objectID": "slides/10-mlr-inference-conditions.html#next-class",
    "href": "slides/10-mlr-inference-conditions.html#next-class",
    "title": "MLR: Model comparison + Inference",
    "section": "Next class",
    "text": "Next class\n\nExam 01 review"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html",
    "href": "slides/11-exam-01-review-notes.html",
    "title": "Exam 01 review",
    "section": "",
    "text": "Lab 03 due TODAY at 11:59pm\nProject topics due Sunday, February 16 at 11:59pm\nMonday’s lab: Exam 01 office hours\nNo office hours February 19 - 20"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#announcements",
    "href": "slides/11-exam-01-review-notes.html#announcements",
    "title": "Exam 01 review",
    "section": "",
    "text": "Lab 03 due TODAY at 11:59pm\nProject topics due Sunday, February 16 at 11:59pm\nMonday’s lab: Exam 01 office hours\nNo office hours February 19 - 20"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#exam-01",
    "href": "slides/11-exam-01-review-notes.html#exam-01",
    "title": "Exam 01 review",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35 points\ntake-home: 15 points\n\nIn-class: 75 minutes during February 18 lecture\nTake-home: due February 20 at 9pm (no lecture on Thursday)\nIf you miss any part of the exam for an excused absence (with academic dean’s note), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#outline-of-in-class-portion",
    "href": "slides/11-exam-01-review-notes.html#outline-of-in-class-portion",
    "title": "Exam 01 review",
    "section": "Outline of in-class portion",
    "text": "Outline of in-class portion\n\nClosed-book, closed-note.\nPotential question types:\n\nMultiple choice\nShort answer (no more than 3 sentences)\nTrue/ False.\n\nIf false, write 1 - 2 sentence justification about why it is false.\n\nEvaluate a response.\n\nAnalysis output included in the exam\nJust need a pen or pencil. No calculator permitted on exam."
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#outline-of-take-home-portion",
    "href": "slides/11-exam-01-review-notes.html#outline-of-take-home-portion",
    "title": "Exam 01 review",
    "section": "Outline of take-home portion",
    "text": "Outline of take-home portion\n\nReleased: Tuesday, February 18 right after class\nDue: Thursday, February 20 at 9pm (no lecture February 20)\nSimilar in format to a lab/ HW\n\nWill receive Exam questions in README of GitHub repo\nFormatting + using a reproducible workflow will be part of grade\n\nSubmit a PDF of responses to GitHub"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#tips-for-studying",
    "href": "slides/11-exam-01-review-notes.html#tips-for-studying",
    "title": "Exam 01 review",
    "section": "Tips for studying",
    "text": "Tips for studying\n\nReview exercises in AEs and assignments, asking “why” as you review your process and reasoning\n\ne.g., Why do we include “holding all else constant” in interpretations?\n\nFocus on understanding not memorization\nExplain concepts / process to others\nAsk questions in office hours\nReview lecture recordings as needed"
  },
  {
    "objectID": "slides/11-exam-01-review-notes.html#content-weeks-1---6",
    "href": "slides/11-exam-01-review-notes.html#content-weeks-1---6",
    "title": "Exam 01 review",
    "section": "Content: Weeks 1 - 6",
    "text": "Content: Weeks 1 - 6\n\n\n\nExploratory data analysis\nFitting and interpreting simple linear regression models\nStatistical models and regression equations\nSimulation-based inference\nMathematical models for inference\n\n\n\nFitting and interpreting multiple linear regression\nPrediction\nDifferent types of predictors\nModel evaluation and comparison"
  },
  {
    "objectID": "slides/11-exam-01-review.html#announcements",
    "href": "slides/11-exam-01-review.html#announcements",
    "title": "Exam 01 review",
    "section": "Announcements",
    "text": "Announcements\n\nLab 03 due TODAY at 11:59pm\nProject topics due Sunday, February 16 at 11:59pm\nMonday’s lab: Exam 01 office hours\nNo office hours February 19 - 20"
  },
  {
    "objectID": "slides/11-exam-01-review.html#exam-01",
    "href": "slides/11-exam-01-review.html#exam-01",
    "title": "Exam 01 review",
    "section": "Exam 01",
    "text": "Exam 01\n\n50 points total\n\nin-class: 35 points\ntake-home: 15 points\n\nIn-class: 75 minutes during February 18 lecture\nTake-home: due February 20 at 9pm (no lecture on Thursday)\nIf you miss any part of the exam for an excused absence (with academic dean’s note), your Exam 02 score will be counted twice"
  },
  {
    "objectID": "slides/11-exam-01-review.html#outline-of-in-class-portion",
    "href": "slides/11-exam-01-review.html#outline-of-in-class-portion",
    "title": "Exam 01 review",
    "section": "Outline of in-class portion",
    "text": "Outline of in-class portion\n\nClosed-book, closed-note.\nPotential question types:\n\nMultiple choice\nShort answer (no more than 3 sentences)\nTrue/ False.\n\nIf false, write 1 - 2 sentence justification about why it is false.\n\nEvaluate a response.\n\nAnalysis output included in the exam\nJust need a pen or pencil. No calculator permitted on exam."
  },
  {
    "objectID": "slides/11-exam-01-review.html#outline-of-take-home-portion",
    "href": "slides/11-exam-01-review.html#outline-of-take-home-portion",
    "title": "Exam 01 review",
    "section": "Outline of take-home portion",
    "text": "Outline of take-home portion\n\nReleased: Tuesday, February 18 right after class\nDue: Thursday, February 20 at 9pm (no lecture February 20)\nSimilar in format to a lab/ HW\n\nWill receive Exam questions in README of GitHub repo\nFormatting + using a reproducible workflow will be part of grade\n\nSubmit a PDF of responses to GitHub"
  },
  {
    "objectID": "slides/11-exam-01-review.html#tips-for-studying",
    "href": "slides/11-exam-01-review.html#tips-for-studying",
    "title": "Exam 01 review",
    "section": "Tips for studying",
    "text": "Tips for studying\n\nReview exercises in AEs and assignments, asking “why” as you review your process and reasoning\n\ne.g., Why do we include “holding all else constant” in interpretations?\n\nFocus on understanding not memorization\nExplain concepts / process to others\nAsk questions in office hours\nReview lecture recordings as needed"
  },
  {
    "objectID": "slides/11-exam-01-review.html#content-weeks-1---6",
    "href": "slides/11-exam-01-review.html#content-weeks-1---6",
    "title": "Exam 01 review",
    "section": "Content: Weeks 1 - 6",
    "text": "Content: Weeks 1 - 6\n\n\n\nExploratory data analysis\nFitting and interpreting simple linear regression models\nStatistical models and regression equations\nSimulation-based inference\nMathematical models for inference\n\n\n\nFitting and interpreting multiple linear regression\nPrediction\nDifferent types of predictors\nModel evaluation and comparison"
  },
  {
    "objectID": "slides/07-mlr-notes.html",
    "href": "slides/07-mlr-notes.html",
    "title": "Multiple linear regression (MLR)",
    "section": "",
    "text": "Lab 01 due TODAY at 11:59pm\nTeam labs start on Monday\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/07-mlr-notes.html#announcements",
    "href": "slides/07-mlr-notes.html#announcements",
    "title": "Multiple linear regression (MLR)",
    "section": "",
    "text": "Lab 01 due TODAY at 11:59pm\nTeam labs start on Monday\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/07-mlr-notes.html#computational-setup",
    "href": "slides/07-mlr-notes.html#computational-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(colorblindr)\nlibrary(palmerpenguins)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/07-mlr-notes.html#data-palmer-penguins",
    "href": "slides/07-mlr-notes.html#data-palmer-penguins",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Palmer penguins",
    "text": "Data: Palmer penguins\nThe penguins data set contains data for penguins found on three islands in the Palmer Archipelago, Antarctica. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. These data can be found in the palmerpenguins R package.\n. . .\n\n\n# A tibble: 342 × 4\n   body_mass_g flipper_length_mm bill_length_mm species\n         &lt;int&gt;             &lt;int&gt;          &lt;dbl&gt; &lt;fct&gt;  \n 1        3750               181           39.1 Adelie \n 2        3800               186           39.5 Adelie \n 3        3250               195           40.3 Adelie \n 4        3450               193           36.7 Adelie \n 5        3650               190           39.3 Adelie \n 6        3625               181           38.9 Adelie \n 7        4675               195           39.2 Adelie \n 8        3475               193           34.1 Adelie \n 9        4250               190           42   Adelie \n10        3300               186           37.8 Adelie \n# ℹ 332 more rows"
  },
  {
    "objectID": "slides/07-mlr-notes.html#variables",
    "href": "slides/07-mlr-notes.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\nbill_length_mm: Bill length in millimeters\nflipper_length_mm: Flipper length in millimeters\nspecies: Adelie, Gentoo, or Chinstrap species\n\nResponse: body_mass_g: Body mass in grams\n\nThe goal of this analysis is to use the bill length, flipper length, and species to predict body mass."
  },
  {
    "objectID": "slides/07-mlr-notes.html#response-body_mass_g",
    "href": "slides/07-mlr-notes.html#response-body_mass_g",
    "title": "Multiple linear regression (MLR)",
    "section": "Response: body_mass_g",
    "text": "Response: body_mass_g\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmin\nmedian\nmax\niqr\n\n\n\n\n2700\n4050\n6300\n1200"
  },
  {
    "objectID": "slides/07-mlr-notes.html#predictors",
    "href": "slides/07-mlr-notes.html#predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/07-mlr-notes.html#response-vs.-predictors",
    "href": "slides/07-mlr-notes.html#response-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\n\n\n\n\n\n\n\n\n. . .\n\nWhy do we want to use a single model with all the predictors instead of 3 separate models?"
  },
  {
    "objectID": "slides/07-mlr-notes.html#multiple-linear-regression-mlr",
    "href": "slides/07-mlr-notes.html#multiple-linear-regression-mlr",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\widehat{\\text{body_mass_g}} ~ =\n\\hat{\\beta}_0 & + \\hat{\\beta}_1 \\times \\text{flipper_length_mm} \\\\ & + \\hat{\\beta}_2 \\times  \\text{species}_1  \\\\\n&+\\hat{\\beta}_3 \\times \\text{species}_2  \\\\ &+ \\hat{\\beta}_4 \\times \\text{bill_length_mm}\n\\end{aligned}\n\\]\nSimilar to simple linear regression, this model assumes that at each combination of the predictor variables, the values body_mass_g follow a Normal distribution."
  },
  {
    "objectID": "slides/07-mlr-notes.html#multiple-linear-regression-1",
    "href": "slides/07-mlr-notes.html#multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nRecall: The simple linear regression model assumes\n\\[\nY|X\\sim N(\\beta_0 + \\beta_1 X, \\sigma_{\\epsilon}^2)\n\\]\n. . .\nSimilarly: The multiple linear regression model assumes\n\\[\nY|X_1, X_2, \\ldots, X_p \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p, \\sigma_{\\epsilon}^2)\n\\]"
  },
  {
    "objectID": "slides/07-mlr-notes.html#multiple-linear-regression-2",
    "href": "slides/07-mlr-notes.html#multiple-linear-regression-2",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nAt any combination of the predictors, the mean value of the response \\(Y\\), is\n\\[\nE(Y|X_1, \\ldots, X_p) = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_2 + \\dots + \\beta_p X_p\n\\]\n. . .\nUsing multiple linear regression, we can estimate the mean response for any combination of predictors\n\\[\n\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{1} + \\hat{\\beta}_2 X_2 + \\dots + \\hat{\\beta}_p X_{p}\n\\]"
  },
  {
    "objectID": "slides/07-mlr-notes.html#model-fit",
    "href": "slides/07-mlr-notes.html#model-fit",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit",
    "text": "Model fit\n\npenguin_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + \n                bill_length_mm, data = penguins)\n\ntidy(penguin_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000"
  },
  {
    "objectID": "slides/07-mlr-notes.html#model-equation",
    "href": "slides/07-mlr-notes.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\widehat{\\text{body_mass_g}} =  -3904.387 &+27.429 \\times \\text{flipper_length_mm}\\\\\n& -748.562 \\times \\text{Chinstrap}\\\\  \n&+ 90.435 \\times \\text{Gentoo}\\\\\n&+ 61.736 \\times \\text{bill_length_mm}\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWe will talk about why there are two terms in the model for species shortly!"
  },
  {
    "objectID": "slides/07-mlr-notes.html#interpreting-hatbeta_j",
    "href": "slides/07-mlr-notes.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n. . .\n\nExample: The estimated coefficient for flipper_length_mm is 27.429. This means for each additional millimeter in a penguin’s flipper length, its body mass is expected to be greater by 27.429 grams, on average, holding species and bill length constant."
  },
  {
    "objectID": "slides/07-mlr-notes.html#prediction",
    "href": "slides/07-mlr-notes.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted body mass for a Gentoo penguin with a flipper length of 200 millimeters and bill length of 45 millimeters?\n\n\n\n-3904.387 + 27.429 * 200 - 748.562 * 0 + 90.435 * 1 + 61.736 * 45\n\n[1] 4449.968\n\n\n\n. . .\nThe predicted body mass for a Gentoo penguin with a flipper length of 200 millimeters and bill length of 45 millimeters is 4449.968 grams."
  },
  {
    "objectID": "slides/07-mlr-notes.html#prediction-revisited",
    "href": "slides/07-mlr-notes.html#prediction-revisited",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction, revisited",
    "text": "Prediction, revisited\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_penguin &lt;- tibble(\n  flipper_length_mm  = 200, \n  species = \"Gentoo\", \n  bill_length_mm = 45\n)\n\npredict(penguin_fit, new_penguin)\n\n       1 \n4449.955 \n\n\n\n\n\n\n\n\nNote\n\n\n\nDifference in predicted value due to rounding the coefficients on the previous slide."
  },
  {
    "objectID": "slides/07-mlr-notes.html#confidence-interval-for-hatmu_y",
    "href": "slides/07-mlr-notes.html#confidence-interval-for-hatmu_y",
    "title": "Multiple linear regression (MLR)",
    "section": "Confidence interval for \\(\\hat{\\mu}_y\\)",
    "text": "Confidence interval for \\(\\hat{\\mu}_y\\)\n\nCalculate a 90% confidence interval for the estimated mean body mass a Gentoo penguins with a flipper length of 200 millimeters and bill length of 45 millimeters.\n\n\n\npredict(penguin_fit, new_penguin, interval = \"confidence\", \n        level = 0.90) |&gt; \n  kable(digits = 3)\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n4449.955\n4355.238\n4544.671"
  },
  {
    "objectID": "slides/07-mlr-notes.html#prediction-interval-for-haty",
    "href": "slides/07-mlr-notes.html#prediction-interval-for-haty",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction interval for \\(\\hat{y}\\)",
    "text": "Prediction interval for \\(\\hat{y}\\)\n\nCalculate a 90% prediction interval for the estimated body mass for an individual Gentoo penguin with a flipper length of 200 millimeters and bill length of 45 millimeters.\n\n\n\npredict(penguin_fit, new_penguin, interval = \"prediction\", \n        level = 0.90) |&gt;\n  kable(digits = 3)\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n4449.955\n3881.035\n5018.875"
  },
  {
    "objectID": "slides/07-mlr-notes.html#cautions",
    "href": "slides/07-mlr-notes.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/07-mlr-notes.html#indicator-variables",
    "href": "slides/07-mlr-notes.html#indicator-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(k\\) categories (levels)\nWe can make \\(k\\) indicator variables - one indicator for each category\nAn indicator variable takes values 1 or 0\n\n1 if the observation belongs to that category\n0 if the observation does not belong to that category"
  },
  {
    "objectID": "slides/07-mlr-notes.html#indicator-variables-for-species",
    "href": "slides/07-mlr-notes.html#indicator-variables-for-species",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables for species",
    "text": "Indicator variables for species\n\npenguins &lt;- penguins |&gt;\n  mutate(\n    adelie = if_else(species == \"Adelie\", 1, 0),\n    chinstrap = if_else(species == \"Chinstrap\", 1, 0),\n    gentoo = if_else(species == \"Gentoo\", 1, 0)\n  )\n\n. . .\n\n\n# A tibble: 3 × 4\n  species   adelie chinstrap gentoo\n  &lt;fct&gt;      &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie         1         0      0\n2 Gentoo         0         0      1\n3 Chinstrap      0         1      0"
  },
  {
    "objectID": "slides/07-mlr-notes.html#indicators-in-the-model",
    "href": "slides/07-mlr-notes.html#indicators-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicators in the model",
    "text": "Indicators in the model\n\nWe will use \\(k-1\\) of the indicator variables in the model.\nThe baseline is the category that doesn’t have a term in the model. This is also called the reference level.\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant.\nThis approach is also called dummy coding.\n\n. . .\n\npenguins |&gt;\n  select(species, chinstrap, gentoo) |&gt;\n  slice(1, 152, 283)\n\n# A tibble: 3 × 3\n  species   chinstrap gentoo\n  &lt;fct&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie            0      0\n2 Gentoo            0      1\n3 Chinstrap         1      0"
  },
  {
    "objectID": "slides/07-mlr-notes.html#interpreting-species",
    "href": "slides/07-mlr-notes.html#interpreting-species",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting species",
    "text": "Interpreting species\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n-4945.450\n-2863.324\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753\n\n\n\n\n\n\n\n. . .\n\n\nThe baseline category is Adelie.\nPenguins from the Chinstrap species are expected to have a body mass that is 748.562 grams less, on average, compared to penguins from the Adelie species, holding flipper length and bill length constant.\n\n\n. . .\n\nInterpret the coefficient of Gentoo in the context of the data."
  },
  {
    "objectID": "slides/07-mlr-notes.html#interpreting-the-intercept",
    "href": "slides/07-mlr-notes.html#interpreting-the-intercept",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting the intercept",
    "text": "Interpreting the intercept\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n-4945.450\n-2863.324\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753\n\n\n\n\n\n. . .\n\n\nThe intercept -3904.387 is not meaningful. Let’s transform some variables to make this intercept meaningful."
  },
  {
    "objectID": "slides/07-mlr-notes.html#centering",
    "href": "slides/07-mlr-notes.html#centering",
    "title": "Multiple linear regression (MLR)",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\n\n\\[\nX_{cent} = X  - C\n\\]\n\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to center the quantitative predictors? What is are the units of centered variables?"
  },
  {
    "objectID": "slides/07-mlr-notes.html#centering-1",
    "href": "slides/07-mlr-notes.html#centering-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Centering",
    "text": "Centering\nUse the scale() function with center = TRUE and scale = FALSE to mean-center variables\n\npenguins &lt;- penguins |&gt;\n  mutate(flipper_length_cent = scale(flipper_length_mm, center = TRUE, scale = FALSE), \n         bill_length_cent = scale(bill_length_mm, center = TRUE, scale = FALSE))"
  },
  {
    "objectID": "slides/07-mlr-notes.html#original-vs.-mean-centered-variable",
    "href": "slides/07-mlr-notes.html#original-vs.-mean-centered-variable",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. mean-centered variable",
    "text": "Original vs. mean-centered variable\n\n\nOriginal variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n200.915\n14.062\n\n\n\n\n\n\nMean-centered variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n0\n14.062\n\n\n\n\n\n\n\n\n. . ."
  },
  {
    "objectID": "slides/07-mlr-notes.html#using-mean-centered-variables-in-the-model",
    "href": "slides/07-mlr-notes.html#using-mean-centered-variables-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Using mean-centered variables in the model",
    "text": "Using mean-centered variables in the model\n\nHow do you expect the model to change if we use flipper_length_cent and bill_length_cent in the model?\n\n. . .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4318.066\n45.674\n94.542\n0.000\n4228.225\n4407.908\n\n\nflipper_length_cent\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_cent\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753"
  },
  {
    "objectID": "slides/07-mlr-notes.html#original-vs.-mean-centered-model",
    "href": "slides/07-mlr-notes.html#original-vs.-mean-centered-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. mean-centered model",
    "text": "Original vs. mean-centered model\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-3904.387\n\n\nflipper_length_mm\n27.429\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_mm\n61.736\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n4318.066\n\n\nflipper_length_cent\n27.429\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_cent\n61.736\n\n\n\n\n\n\n\n\nWhat has changed? What is the same?"
  },
  {
    "objectID": "slides/07-mlr-notes.html#standardizing",
    "href": "slides/07-mlr-notes.html#standardizing",
    "title": "Multiple linear regression (MLR)",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\n\n\\[\nX_{std} = \\frac{X - \\bar{X}}{S_X}\n\\]\n\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to standardize the quantitative predictors? What is are the units of standardized variables?"
  },
  {
    "objectID": "slides/07-mlr-notes.html#standardizing-1",
    "href": "slides/07-mlr-notes.html#standardizing-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Standardizing",
    "text": "Standardizing\nUse the scale() function with center = TRUE and scale = TRUE to standardized variables\n\n\npenguins &lt;- penguins |&gt;\n  mutate(flipper_length_std = scale(flipper_length_mm, center = TRUE, scale = TRUE), \n         bill_length_std = scale(bill_length_mm, center = TRUE, scale = TRUE))"
  },
  {
    "objectID": "slides/07-mlr-notes.html#original-vs.-standardized-variable",
    "href": "slides/07-mlr-notes.html#original-vs.-standardized-variable",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. standardized variable",
    "text": "Original vs. standardized variable\n\n\nOriginal variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n200.915\n14.062\n\n\n\n\n\n\nStandardized variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n0\n1\n\n\n\n\n\n\n\n\n. . ."
  },
  {
    "objectID": "slides/07-mlr-notes.html#using-standardized-variables-in-the-model",
    "href": "slides/07-mlr-notes.html#using-standardized-variables-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Using standardized variables in the model",
    "text": "Using standardized variables in the model\n\nHow do you expect the model to change if we use flipper_length_std and bill_length_std in the model?\n\n. . .\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4318.066\n45.674\n94.542\n0.000\n4228.225\n4407.908\n\n\nflipper_length_std\n385.696\n44.654\n8.638\n0.000\n297.862\n473.531\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_std\n337.055\n38.902\n8.664\n0.000\n260.533\n413.577"
  },
  {
    "objectID": "slides/07-mlr-notes.html#original-vs.-standardized-model",
    "href": "slides/07-mlr-notes.html#original-vs.-standardized-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. standardized model",
    "text": "Original vs. standardized model\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-3904.387\n\n\nflipper_length_mm\n27.429\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_mm\n61.736\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n4318.066\n\n\nflipper_length_std\n385.696\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_std\n337.055\n\n\n\n\n\n\n\n\nWhat has changed? What is the same?"
  },
  {
    "objectID": "slides/07-mlr-notes.html#interaction-terms-1",
    "href": "slides/07-mlr-notes.html#interaction-terms-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/07-mlr-notes.html#bill-length-versus-species",
    "href": "slides/07-mlr-notes.html#bill-length-versus-species",
    "title": "Multiple linear regression (MLR)",
    "section": "Bill length versus species",
    "text": "Bill length versus species\nIf the lines are not parallel, there is indication of a potential interaction effect, i.e., the slope of bill length may differ based on the species."
  },
  {
    "objectID": "slides/07-mlr-notes.html#interaction-term-in-model",
    "href": "slides/07-mlr-notes.html#interaction-term-in-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\npenguin_int_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + bill_length_mm + species * bill_length_mm,\n      data = penguins)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4297.905\n645.054\n-6.663\n0.000\n\n\nflipper_length_mm\n27.263\n3.175\n8.586\n0.000\n\n\nspeciesChinstrap\n1146.287\n726.217\n1.578\n0.115\n\n\nspeciesGentoo\n54.716\n619.934\n0.088\n0.930\n\n\nbill_length_mm\n72.692\n10.642\n6.831\n0.000\n\n\nspeciesChinstrap:bill_length_mm\n-41.035\n16.104\n-2.548\n0.011\n\n\nspeciesGentoo:bill_length_mm\n-1.163\n14.436\n-0.081\n0.936"
  },
  {
    "objectID": "slides/07-mlr-notes.html#interpreting-interaction-terms",
    "href": "slides/07-mlr-notes.html#interpreting-interaction-terms",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of bill length on the body mass is 41.035 less when the penguin is from the Chinstrap species compared to the effect for the Adelie species, holding all else constant.\nInterpreting bill_length_mm for Chinstrap: For each additional millimeter in bill length, we expect the body mass of Chinstrap penguins to increase by 31.657 grams (72.692 - 41.035), holding all else constant."
  },
  {
    "objectID": "slides/07-mlr-notes.html#summary",
    "href": "slides/07-mlr-notes.html#summary",
    "title": "Multiple linear regression (MLR)",
    "section": "Summary",
    "text": "Summary\n\n\nIn general, how do\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?"
  },
  {
    "objectID": "slides/07-mlr-notes.html#recap",
    "href": "slides/07-mlr-notes.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multiple linear regression\nInterpreted coefficients in the multiple linear regression model\nCalculated predictions and associated intervals for multiple linear regression models\nMean-centered and standardized quantitative predictors\nUsed indicator variables for categorical predictors\nUsed interaction terms"
  },
  {
    "objectID": "slides/07-mlr.html#announcements",
    "href": "slides/07-mlr.html#announcements",
    "title": "Multiple linear regression (MLR)",
    "section": "Announcements",
    "text": "Announcements\n\nLab 01 due TODAY at 11:59pm\nTeam labs start on Monday\nClick here to learn more about the Academic Resource Center\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/07-mlr.html#computational-setup",
    "href": "slides/07-mlr.html#computational-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(colorblindr)\nlibrary(palmerpenguins)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/07-mlr.html#data-palmer-penguins",
    "href": "slides/07-mlr.html#data-palmer-penguins",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Palmer penguins",
    "text": "Data: Palmer penguins\nThe penguins data set contains data for penguins found on three islands in the Palmer Archipelago, Antarctica. Data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. These data can be found in the palmerpenguins R package.\n\n\n\n# A tibble: 342 × 4\n   body_mass_g flipper_length_mm bill_length_mm species\n         &lt;int&gt;             &lt;int&gt;          &lt;dbl&gt; &lt;fct&gt;  \n 1        3750               181           39.1 Adelie \n 2        3800               186           39.5 Adelie \n 3        3250               195           40.3 Adelie \n 4        3450               193           36.7 Adelie \n 5        3650               190           39.3 Adelie \n 6        3625               181           38.9 Adelie \n 7        4675               195           39.2 Adelie \n 8        3475               193           34.1 Adelie \n 9        4250               190           42   Adelie \n10        3300               186           37.8 Adelie \n# ℹ 332 more rows"
  },
  {
    "objectID": "slides/07-mlr.html#variables",
    "href": "slides/07-mlr.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\nbill_length_mm: Bill length in millimeters\nflipper_length_mm: Flipper length in millimeters\nspecies: Adelie, Gentoo, or Chinstrap species\n\nResponse: body_mass_g: Body mass in grams\n\nThe goal of this analysis is to use the bill length, flipper length, and species to predict body mass."
  },
  {
    "objectID": "slides/07-mlr.html#response-body_mass_g",
    "href": "slides/07-mlr.html#response-body_mass_g",
    "title": "Multiple linear regression (MLR)",
    "section": "Response: body_mass_g",
    "text": "Response: body_mass_g\n\n\n\n\n\n\nmin\nmedian\nmax\niqr\n\n\n\n\n2700\n4050\n6300\n1200"
  },
  {
    "objectID": "slides/07-mlr.html#predictors",
    "href": "slides/07-mlr.html#predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/07-mlr.html#response-vs.-predictors",
    "href": "slides/07-mlr.html#response-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors\n\n\n\nWhy do we want to use a single model with all the predictors instead of 3 separate models?"
  },
  {
    "objectID": "slides/07-mlr.html#multiple-linear-regression-mlr",
    "href": "slides/07-mlr.html#multiple-linear-regression-mlr",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\widehat{\\text{body_mass_g}} ~ =\n\\hat{\\beta}_0 & + \\hat{\\beta}_1 \\times \\text{flipper_length_mm} \\\\ & + \\hat{\\beta}_2 \\times  \\text{species}_1  \\\\\n&+\\hat{\\beta}_3 \\times \\text{species}_2  \\\\ &+ \\hat{\\beta}_4 \\times \\text{bill_length_mm}\n\\end{aligned}\n\\]\nSimilar to simple linear regression, this model assumes that at each combination of the predictor variables, the values body_mass_g follow a Normal distribution."
  },
  {
    "objectID": "slides/07-mlr.html#multiple-linear-regression-1",
    "href": "slides/07-mlr.html#multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nRecall: The simple linear regression model assumes\n\\[\nY|X\\sim N(\\beta_0 + \\beta_1 X, \\sigma_{\\epsilon}^2)\n\\]\n\nSimilarly: The multiple linear regression model assumes\n\\[\nY|X_1, X_2, \\ldots, X_p \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p, \\sigma_{\\epsilon}^2)\n\\]"
  },
  {
    "objectID": "slides/07-mlr.html#multiple-linear-regression-2",
    "href": "slides/07-mlr.html#multiple-linear-regression-2",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nAt any combination of the predictors, the mean value of the response \\(Y\\), is\n\\[\nE(Y|X_1, \\ldots, X_p) = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_2 + \\dots + \\beta_p X_p\n\\]\n\nUsing multiple linear regression, we can estimate the mean response for any combination of predictors\n\\[\n\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{1} + \\hat{\\beta}_2 X_2 + \\dots + \\hat{\\beta}_p X_{p}\n\\]"
  },
  {
    "objectID": "slides/07-mlr.html#model-fit",
    "href": "slides/07-mlr.html#model-fit",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit",
    "text": "Model fit\n\npenguin_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + \n                bill_length_mm, data = penguins)\n\ntidy(penguin_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000"
  },
  {
    "objectID": "slides/07-mlr.html#model-equation",
    "href": "slides/07-mlr.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\widehat{\\text{body_mass_g}} =  -3904.387 &+27.429 \\times \\text{flipper_length_mm}\\\\\n& -748.562 \\times \\text{Chinstrap}\\\\  \n&+ 90.435 \\times \\text{Gentoo}\\\\\n&+ 61.736 \\times \\text{bill_length_mm}\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\nWe will talk about why there are two terms in the model for species shortly!"
  },
  {
    "objectID": "slides/07-mlr.html#interpreting-hatbeta_j",
    "href": "slides/07-mlr.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(Y\\) when \\(X_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n\n\nExample: The estimated coefficient for flipper_length_mm is 27.429. This means for each additional millimeter in a penguin’s flipper length, its body mass is expected to be greater by 27.429 grams, on average, holding species and bill length constant."
  },
  {
    "objectID": "slides/07-mlr.html#prediction",
    "href": "slides/07-mlr.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted body mass for a Gentoo penguin with a flipper length of 200 millimeters and bill length of 45 millimeters?\n\n\n\n-3904.387 + 27.429 * 200 - 748.562 * 0 + 90.435 * 1 + 61.736 * 45\n\n[1] 4449.968\n\n\n\n\nThe predicted body mass for a Gentoo penguin with a flipper length of 200 millimeters and bill length of 45 millimeters is 4449.968 grams."
  },
  {
    "objectID": "slides/07-mlr.html#prediction-revisited",
    "href": "slides/07-mlr.html#prediction-revisited",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction, revisited",
    "text": "Prediction, revisited\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_penguin &lt;- tibble(\n  flipper_length_mm  = 200, \n  species = \"Gentoo\", \n  bill_length_mm = 45\n)\n\npredict(penguin_fit, new_penguin)\n\n       1 \n4449.955 \n\n\n\n\n\n\n\n\nNote\n\n\nDifference in predicted value due to rounding the coefficients on the previous slide."
  },
  {
    "objectID": "slides/07-mlr.html#confidence-interval-for-hatmu_y",
    "href": "slides/07-mlr.html#confidence-interval-for-hatmu_y",
    "title": "Multiple linear regression (MLR)",
    "section": "Confidence interval for \\(\\hat{\\mu}_y\\)",
    "text": "Confidence interval for \\(\\hat{\\mu}_y\\)\n\nCalculate a 90% confidence interval for the estimated mean body mass a Gentoo penguins with a flipper length of 200 millimeters and bill length of 45 millimeters.\n\n\n\npredict(penguin_fit, new_penguin, interval = \"confidence\", \n        level = 0.90) |&gt; \n  kable(digits = 3)\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n4449.955\n4355.238\n4544.671"
  },
  {
    "objectID": "slides/07-mlr.html#prediction-interval-for-haty",
    "href": "slides/07-mlr.html#prediction-interval-for-haty",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction interval for \\(\\hat{y}\\)",
    "text": "Prediction interval for \\(\\hat{y}\\)\n\nCalculate a 90% prediction interval for the estimated body mass for an individual Gentoo penguin with a flipper length of 200 millimeters and bill length of 45 millimeters.\n\n\n\npredict(penguin_fit, new_penguin, interval = \"prediction\", \n        level = 0.90) |&gt;\n  kable(digits = 3)\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n4449.955\n3881.035\n5018.875"
  },
  {
    "objectID": "slides/07-mlr.html#cautions",
    "href": "slides/07-mlr.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/07-mlr.html#indicator-variables",
    "href": "slides/07-mlr.html#indicator-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(k\\) categories (levels)\nWe can make \\(k\\) indicator variables - one indicator for each category\nAn indicator variable takes values 1 or 0\n\n1 if the observation belongs to that category\n0 if the observation does not belong to that category"
  },
  {
    "objectID": "slides/07-mlr.html#indicator-variables-for-species",
    "href": "slides/07-mlr.html#indicator-variables-for-species",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables for species",
    "text": "Indicator variables for species\n\npenguins &lt;- penguins |&gt;\n  mutate(\n    adelie = if_else(species == \"Adelie\", 1, 0),\n    chinstrap = if_else(species == \"Chinstrap\", 1, 0),\n    gentoo = if_else(species == \"Gentoo\", 1, 0)\n  )\n\n\n\n\n# A tibble: 3 × 4\n  species   adelie chinstrap gentoo\n  &lt;fct&gt;      &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie         1         0      0\n2 Gentoo         0         0      1\n3 Chinstrap      0         1      0"
  },
  {
    "objectID": "slides/07-mlr.html#indicators-in-the-model",
    "href": "slides/07-mlr.html#indicators-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicators in the model",
    "text": "Indicators in the model\n\nWe will use \\(k-1\\) of the indicator variables in the model.\nThe baseline is the category that doesn’t have a term in the model. This is also called the reference level.\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant.\nThis approach is also called dummy coding.\n\n\n\npenguins |&gt;\n  select(species, chinstrap, gentoo) |&gt;\n  slice(1, 152, 283)\n\n# A tibble: 3 × 3\n  species   chinstrap gentoo\n  &lt;fct&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie            0      0\n2 Gentoo            0      1\n3 Chinstrap         1      0"
  },
  {
    "objectID": "slides/07-mlr.html#interpreting-species",
    "href": "slides/07-mlr.html#interpreting-species",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting species",
    "text": "Interpreting species\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n-4945.450\n-2863.324\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753\n\n\n\n\n\n\n\n\n\n\nThe baseline category is Adelie.\nPenguins from the Chinstrap species are expected to have a body mass that is 748.562 grams less, on average, compared to penguins from the Adelie species, holding flipper length and bill length constant.\n\n\n\n\n\nInterpret the coefficient of Gentoo in the context of the data."
  },
  {
    "objectID": "slides/07-mlr.html#interpreting-the-intercept",
    "href": "slides/07-mlr.html#interpreting-the-intercept",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting the intercept",
    "text": "Interpreting the intercept\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n-3904.387\n529.257\n-7.377\n0.000\n-4945.450\n-2863.324\n\n\nflipper_length_mm\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_mm\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753\n\n\n\n\n\n\n\n\nThe intercept -3904.387 is not meaningful. Let’s transform some variables to make this intercept meaningful."
  },
  {
    "objectID": "slides/07-mlr.html#centering",
    "href": "slides/07-mlr.html#centering",
    "title": "Multiple linear regression (MLR)",
    "section": "Centering",
    "text": "Centering\n\nCentering a quantitative predictor means shifting every value by some constant \\(C\\)\n\n\\[\nX_{cent} = X  - C\n\\]\n\nOne common type of centering is mean-centering, in which every value of a predictor is shifted by its mean\nOnly quantitative predictors are centered\nCenter all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to center the quantitative predictors? What is are the units of centered variables?"
  },
  {
    "objectID": "slides/07-mlr.html#centering-1",
    "href": "slides/07-mlr.html#centering-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Centering",
    "text": "Centering\nUse the scale() function with center = TRUE and scale = FALSE to mean-center variables\n\npenguins &lt;- penguins |&gt;\n  mutate(flipper_length_cent = scale(flipper_length_mm, center = TRUE, scale = FALSE), \n         bill_length_cent = scale(bill_length_mm, center = TRUE, scale = FALSE))"
  },
  {
    "objectID": "slides/07-mlr.html#original-vs.-mean-centered-variable",
    "href": "slides/07-mlr.html#original-vs.-mean-centered-variable",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. mean-centered variable",
    "text": "Original vs. mean-centered variable\n\n\nOriginal variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n200.915\n14.062\n\n\n\n\n\n\nMean-centered variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n0\n14.062"
  },
  {
    "objectID": "slides/07-mlr.html#using-mean-centered-variables-in-the-model",
    "href": "slides/07-mlr.html#using-mean-centered-variables-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Using mean-centered variables in the model",
    "text": "Using mean-centered variables in the model\n\nHow do you expect the model to change if we use flipper_length_cent and bill_length_cent in the model?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4318.066\n45.674\n94.542\n0.000\n4228.225\n4407.908\n\n\nflipper_length_cent\n27.429\n3.176\n8.638\n0.000\n21.182\n33.675\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_cent\n61.736\n7.126\n8.664\n0.000\n47.720\n75.753"
  },
  {
    "objectID": "slides/07-mlr.html#original-vs.-mean-centered-model",
    "href": "slides/07-mlr.html#original-vs.-mean-centered-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. mean-centered model",
    "text": "Original vs. mean-centered model\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-3904.387\n\n\nflipper_length_mm\n27.429\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_mm\n61.736\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n4318.066\n\n\nflipper_length_cent\n27.429\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_cent\n61.736\n\n\n\n\n\n\n\nWhat has changed? What is the same?"
  },
  {
    "objectID": "slides/07-mlr.html#standardizing",
    "href": "slides/07-mlr.html#standardizing",
    "title": "Multiple linear regression (MLR)",
    "section": "Standardizing",
    "text": "Standardizing\n\nStandardizing a quantitative predictor mean shifting every value by the mean and dividing by the standard deviation of that variable\n\n\\[\nX_{std} = \\frac{X - \\bar{X}}{S_X}\n\\]\n\nOnly quantitative predictors are standardized\nStandardize all quantitative predictors in the model for ease of interpretation\n\n\nWhat is one reason one might want to standardize the quantitative predictors? What is are the units of standardized variables?"
  },
  {
    "objectID": "slides/07-mlr.html#standardizing-1",
    "href": "slides/07-mlr.html#standardizing-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Standardizing",
    "text": "Standardizing\nUse the scale() function with center = TRUE and scale = TRUE to standardized variables\n\n\npenguins &lt;- penguins |&gt;\n  mutate(flipper_length_std = scale(flipper_length_mm, center = TRUE, scale = TRUE), \n         bill_length_std = scale(bill_length_mm, center = TRUE, scale = TRUE))"
  },
  {
    "objectID": "slides/07-mlr.html#original-vs.-standardized-variable",
    "href": "slides/07-mlr.html#original-vs.-standardized-variable",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. standardized variable",
    "text": "Original vs. standardized variable\n\n\nOriginal variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n200.915\n14.062\n\n\n\n\n\n\nStandardized variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean\nSD\n\n\n\n\n0\n1"
  },
  {
    "objectID": "slides/07-mlr.html#using-standardized-variables-in-the-model",
    "href": "slides/07-mlr.html#using-standardized-variables-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Using standardized variables in the model",
    "text": "Using standardized variables in the model\n\nHow do you expect the model to change if we use flipper_length_std and bill_length_std in the model?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n4318.066\n45.674\n94.542\n0.000\n4228.225\n4407.908\n\n\nflipper_length_std\n385.696\n44.654\n8.638\n0.000\n297.862\n473.531\n\n\nspeciesChinstrap\n-748.562\n81.534\n-9.181\n0.000\n-908.943\n-588.182\n\n\nspeciesGentoo\n90.435\n88.647\n1.020\n0.308\n-83.937\n264.807\n\n\nbill_length_std\n337.055\n38.902\n8.664\n0.000\n260.533\n413.577"
  },
  {
    "objectID": "slides/07-mlr.html#original-vs.-standardized-model",
    "href": "slides/07-mlr.html#original-vs.-standardized-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. standardized model",
    "text": "Original vs. standardized model\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n-3904.387\n\n\nflipper_length_mm\n27.429\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_mm\n61.736\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n4318.066\n\n\nflipper_length_std\n385.696\n\n\nspeciesChinstrap\n-748.562\n\n\nspeciesGentoo\n90.435\n\n\nbill_length_std\n337.055\n\n\n\n\n\n\n\nWhat has changed? What is the same?"
  },
  {
    "objectID": "slides/07-mlr.html#interaction-terms-1",
    "href": "slides/07-mlr.html#interaction-terms-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/07-mlr.html#bill-length-versus-species",
    "href": "slides/07-mlr.html#bill-length-versus-species",
    "title": "Multiple linear regression (MLR)",
    "section": "Bill length versus species",
    "text": "Bill length versus species\nIf the lines are not parallel, there is indication of a potential interaction effect, i.e., the slope of bill length may differ based on the species."
  },
  {
    "objectID": "slides/07-mlr.html#interaction-term-in-model",
    "href": "slides/07-mlr.html#interaction-term-in-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\npenguin_int_fit &lt;- lm(body_mass_g ~ flipper_length_mm + species + bill_length_mm + species * bill_length_mm,\n      data = penguins)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-4297.905\n645.054\n-6.663\n0.000\n\n\nflipper_length_mm\n27.263\n3.175\n8.586\n0.000\n\n\nspeciesChinstrap\n1146.287\n726.217\n1.578\n0.115\n\n\nspeciesGentoo\n54.716\n619.934\n0.088\n0.930\n\n\nbill_length_mm\n72.692\n10.642\n6.831\n0.000\n\n\nspeciesChinstrap:bill_length_mm\n-41.035\n16.104\n-2.548\n0.011\n\n\nspeciesGentoo:bill_length_mm\n-1.163\n14.436\n-0.081\n0.936"
  },
  {
    "objectID": "slides/07-mlr.html#interpreting-interaction-terms",
    "href": "slides/07-mlr.html#interpreting-interaction-terms",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of bill length on the body mass is 41.035 less when the penguin is from the Chinstrap species compared to the effect for the Adelie species, holding all else constant.\nInterpreting bill_length_mm for Chinstrap: For each additional millimeter in bill length, we expect the body mass of Chinstrap penguins to increase by 31.657 grams (72.692 - 41.035), holding all else constant."
  },
  {
    "objectID": "slides/07-mlr.html#summary",
    "href": "slides/07-mlr.html#summary",
    "title": "Multiple linear regression (MLR)",
    "section": "Summary",
    "text": "Summary\n\n\nIn general, how do\nindicators for categorical predictors impact the model equation?\ninteraction terms impact the model equation?"
  },
  {
    "objectID": "slides/07-mlr.html#recap",
    "href": "slides/07-mlr.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multiple linear regression\nInterpreted coefficients in the multiple linear regression model\nCalculated predictions and associated intervals for multiple linear regression models\nMean-centered and standardized quantitative predictors\nUsed indicator variables for categorical predictors\nUsed interaction terms"
  },
  {
    "objectID": "slides/09-model-compare-notes.html",
    "href": "slides/09-model-compare-notes.html",
    "title": "Model comparison",
    "section": "",
    "text": "Lab 02 due TODAY at 11:59pm\nHW 02 due Tuesday, February 11 at 11:59pm\nLecture recordings available until start of exam on February 18\n\nSee link on menu of course website\n\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#announcements",
    "href": "slides/09-model-compare-notes.html#announcements",
    "title": "Model comparison",
    "section": "",
    "text": "Lab 02 due TODAY at 11:59pm\nHW 02 due Tuesday, February 11 at 11:59pm\nLecture recordings available until start of exam on February 18\n\nSee link on menu of course website\n\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#topics",
    "href": "slides/09-model-compare-notes.html#topics",
    "title": "Model comparison",
    "section": "Topics",
    "text": "Topics\n\n\nANOVA for multiple linear regression and sum of squares\nComparing models with \\(Adj. R^2\\)\nOccam’s razor and parsimony\nCross validation"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#computational-setup",
    "href": "slides/09-model-compare-notes.html#computational-setup",
    "title": "Model comparison",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#data-restaurant-tips",
    "href": "slides/09-model-compare-notes.html#data-restaurant-tips",
    "title": "Model comparison",
    "section": "Data: Restaurant tips",
    "text": "Data: Restaurant tips\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\n\n\n# A tibble: 169 × 4\n     Tip Party Meal   Age   \n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n 1  2.99     1 Dinner Yadult\n 2  2        1 Dinner Yadult\n 3  5        1 Dinner SenCit\n 4  4        3 Dinner Middle\n 5 10.3      2 Dinner SenCit\n 6  4.85     2 Dinner Middle\n 7  5        4 Dinner Yadult\n 8  4        3 Dinner Middle\n 9  5        2 Dinner Middle\n10  1.58     1 Dinner SenCit\n# ℹ 159 more rows"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#variables",
    "href": "slides/09-model-compare-notes.html#variables",
    "title": "Model comparison",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nParty: Number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\nPayment: Payment type (Cash, Credit, Credit/CashTip)\n\n\nResponse: Tip: Amount of tip"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#response-tip",
    "href": "slides/09-model-compare-notes.html#response-tip",
    "title": "Model comparison",
    "section": "Response: Tip",
    "text": "Response: Tip"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#predictors",
    "href": "slides/09-model-compare-notes.html#predictors",
    "title": "Model comparison",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#relevel-categorical-predictors",
    "href": "slides/09-model-compare-notes.html#relevel-categorical-predictors",
    "title": "Model comparison",
    "section": "Relevel categorical predictors",
    "text": "Relevel categorical predictors\n\ntips &lt;- tips |&gt;\n  mutate(\n    Meal = fct_relevel(Meal, \"Lunch\", \"Dinner\", \"Late Night\"),\n    Age  = fct_relevel(Age, \"Yadult\", \"Middle\", \"SenCit\")\n  )"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#predictors-again",
    "href": "slides/09-model-compare-notes.html#predictors-again",
    "title": "Model comparison",
    "section": "Predictors, again",
    "text": "Predictors, again"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#response-vs.-predictors",
    "href": "slides/09-model-compare-notes.html#response-vs.-predictors",
    "title": "Model comparison",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#fit-and-summarize-model",
    "href": "slides/09-model-compare-notes.html#fit-and-summarize-model",
    "title": "Model comparison",
    "section": "Fit and summarize model",
    "text": "Fit and summarize model\n\ntip_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(Tip ~ Party + Age, data = tips)\n\ntidy(tip_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.170\n0.366\n-0.465\n0.643\n\n\nParty\n1.837\n0.124\n14.758\n0.000\n\n\nAgeMiddle\n1.009\n0.408\n2.475\n0.014\n\n\nAgeSenCit\n1.388\n0.485\n2.862\n0.005\n\n\n\n\n\n. . .\n\n\nIs this model useful for explaining variation in tips?"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#rmse",
    "href": "slides/09-model-compare-notes.html#rmse",
    "title": "Model comparison",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#analysis-of-variance-anova",
    "href": "slides/09-model-compare-notes.html#analysis-of-variance-anova",
    "title": "Model comparison",
    "section": "Analysis of variance (ANOVA)",
    "text": "Analysis of variance (ANOVA)\nAnalysis of Variance (ANOVA): Technique to partition variability in Y by the sources of variability"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#anova",
    "href": "slides/09-model-compare-notes.html#anova",
    "title": "Model comparison",
    "section": "ANOVA",
    "text": "ANOVA\n\nMain Idea: Decompose the total variation in the response into\n\nthe variation that can be explained by the each of the variables in the model\nthe variation that can’t be explained by the model (left in the residuals)\n\nIf the variation that can be explained by the variables in the model is greater than the variation in the residuals, this signals that the model might be “valuable” (at least one of the \\(\\beta\\)’s not equal to 0)"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#sum-of-squares",
    "href": "slides/09-model-compare-notes.html#sum-of-squares",
    "title": "Model comparison",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\nClick here to see why this equality holds."
  },
  {
    "objectID": "slides/09-model-compare-notes.html#r2",
    "href": "slides/09-model-compare-notes.html#r2",
    "title": "Model comparison",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n. . .\n\\[\nR^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST} = 1 - \\frac{686.44}{1913.11} = 0.641\n\\]"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#two-potential-models",
    "href": "slides/09-model-compare-notes.html#two-potential-models",
    "title": "Model comparison",
    "section": "Two potential models",
    "text": "Two potential models\nLet’s consider two models:\n\nModel 1: Party, Age\nModel 2: Party, Age, Payment\n\n. . .\n\n Which model is a better fit for the data?"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#r-squared-r2",
    "href": "slides/09-model-compare-notes.html#r-squared-r2",
    "title": "Model comparison",
    "section": "R-squared, \\(R^2\\)",
    "text": "R-squared, \\(R^2\\)\n\n\\(R^2\\) will always increase as we add more variables to the model (let’s see why)\nIf we add enough variables, we can always achieve \\(R^2=100\\%\\)\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables (assuming we’re comparing nested models)"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#adjusted-r2",
    "href": "slides/09-model-compare-notes.html#adjusted-r2",
    "title": "Model comparison",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model\nDiffers from \\(R^2\\) by using the mean squares (sumsq/df) rather than sums of squares and therefore adjusting for the number of predictor variables\nThe penalty for added model complexity attempts to strike a balance between underfitting (too few predictors in the model) and overfitting (too many predictors in the model)\nGoal: Parsimony"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#r2-and-adjusted-r2",
    "href": "slides/09-model-compare-notes.html#r2-and-adjusted-r2",
    "title": "Model comparison",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n. . .\n\\[Adj. R^2 = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#using-r2-and-adjusted-r2",
    "href": "slides/09-model-compare-notes.html#using-r2-and-adjusted-r2",
    "title": "Model comparison",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#comparing-models-with-adj.-r2",
    "href": "slides/09-model-compare-notes.html#comparing-models-with-adj.-r2",
    "title": "Model comparison",
    "section": "Comparing models with \\(Adj. R^2\\)",
    "text": "Comparing models with \\(Adj. R^2\\)\n\n\n\ntip_fit_1 &lt;- lm(Tip ~ Party + Age , \n    data = tips)\n\nglance(tip_fit_1) |&gt; \n  select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.641         0.635\n\n\n\n\ntip_fit_2 &lt;- lm(Tip ~ Party + Age + Payment, \n      data = tips)\n\nglance(tip_fit_2) |&gt; \n  select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.644         0.633\n\n\n\n\n\n\n\nWhich model would we choose based on \\(R^2\\)?\nWhich model would we choose based on Adjusted \\(R^2\\)?"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#parsimony-and-occams-razor",
    "href": "slides/09-model-compare-notes.html#parsimony-and-occams-razor",
    "title": "Model comparison",
    "section": "Parsimony and Occam’s razor",
    "text": "Parsimony and Occam’s razor\n\nThe principle of parsimony is attributed to William of Occam (early 14th-century English nominalist philosopher), who insisted that, given a set of equally good explanations for a given phenomenon, the correct explanation is the simplest explanation1\nCalled Occam’s razor because he “shaved” his explanations down to the bare minimum\nParsimony in modeling:\n\n\nmodels should have as few parameters as possible\nlinear models should be preferred to non-linear models\nexperiments relying on few assumptions should be preferred to those relying on many\nmodels should be pared down until they are minimal adequate\nsimple explanations should be preferred to complex explanations"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#in-pursuit-of-occams-razor",
    "href": "slides/09-model-compare-notes.html#in-pursuit-of-occams-razor",
    "title": "Model comparison",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\nOccam’s razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\nModel selection follows this principle\nWe only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\nIn other words, we prefer the simplest best model, i.e. parsimonious model"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#alternate-views",
    "href": "slides/09-model-compare-notes.html#alternate-views",
    "title": "Model comparison",
    "section": "Alternate views",
    "text": "Alternate views\n\nSometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.\n\nRadford Neal - Bayesian Learning for Neural Networks2"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#evaluating-models-training-vs.-testing-sets",
    "href": "slides/09-model-compare-notes.html#evaluating-models-training-vs.-testing-sets",
    "title": "Model comparison",
    "section": "Evaluating models: training vs. testing sets",
    "text": "Evaluating models: training vs. testing sets\n\n\nThe training set (i.e., the data used to fit the model) does not have the capacity to be a good arbiter of performance.\nIt is not an independent piece of information; predicting the training set can only reflect what the model already knows.\nSuppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.\nWe can reserve some data for a testing set that can be used to evaluate the model performance"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#training-and-testing-sets",
    "href": "slides/09-model-compare-notes.html#training-and-testing-sets",
    "title": "Model comparison",
    "section": "Training and testing sets",
    "text": "Training and testing sets\nCreate training and testing sets using functions from the resample R package (part of tidymodels)\nStep 1: Create an initial split:\n\nset.seed(210)\ntips_split &lt;- initial_split(tips, prop = 0.75) #prop = 3/4 by default\n\n. . .\nStep 2: Save training data\n\ntips_train &lt;- training(tips_split)\ndim(tips_train)\n\n[1] 126  13\n\n\n. . .\nStep 3: Save testing data\n\ntips_test &lt;- testing(tips_split)\ndim(tips_test)\n\n[1] 43 13"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#recap",
    "href": "slides/09-model-compare-notes.html#recap",
    "title": "Model comparison",
    "section": "Recap",
    "text": "Recap\n\nANOVA for multiple linear regression and sum of squares\nComparing models with\n\n\\(R^2\\) vs. \\(Adj. R^2\\)\nAIC and BIC\n\nOccam’s razor and parsimony\nTraining and testing data"
  },
  {
    "objectID": "slides/09-model-compare-notes.html#footnotes",
    "href": "slides/09-model-compare-notes.html#footnotes",
    "title": "Model comparison",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: The R Book by Michael J. Crawley.↩︎\nSuggested blog post: Occam by Andrew Gelman↩︎"
  },
  {
    "objectID": "slides/09-model-compare.html#announcements",
    "href": "slides/09-model-compare.html#announcements",
    "title": "Model comparison",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due TODAY at 11:59pm\nHW 02 due Tuesday, February 11 at 11:59pm\nLecture recordings available until start of exam on February 18\n\nSee link on menu of course website\n\nStatistics experience due Tuesday, April 15"
  },
  {
    "objectID": "slides/09-model-compare.html#topics",
    "href": "slides/09-model-compare.html#topics",
    "title": "Model comparison",
    "section": "Topics",
    "text": "Topics\n\n\nANOVA for multiple linear regression and sum of squares\nComparing models with \\(Adj. R^2\\)\nOccam’s razor and parsimony\nCross validation"
  },
  {
    "objectID": "slides/09-model-compare.html#computational-setup",
    "href": "slides/09-model-compare.html#computational-setup",
    "title": "Model comparison",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/09-model-compare.html#data-restaurant-tips",
    "href": "slides/09-model-compare.html#data-restaurant-tips",
    "title": "Model comparison",
    "section": "Data: Restaurant tips",
    "text": "Data: Restaurant tips\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\n\n\n# A tibble: 169 × 4\n     Tip Party Meal   Age   \n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n 1  2.99     1 Dinner Yadult\n 2  2        1 Dinner Yadult\n 3  5        1 Dinner SenCit\n 4  4        3 Dinner Middle\n 5 10.3      2 Dinner SenCit\n 6  4.85     2 Dinner Middle\n 7  5        4 Dinner Yadult\n 8  4        3 Dinner Middle\n 9  5        2 Dinner Middle\n10  1.58     1 Dinner SenCit\n# ℹ 159 more rows"
  },
  {
    "objectID": "slides/09-model-compare.html#variables",
    "href": "slides/09-model-compare.html#variables",
    "title": "Model comparison",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nParty: Number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\nPayment: Payment type (Cash, Credit, Credit/CashTip)\n\n\nResponse: Tip: Amount of tip"
  },
  {
    "objectID": "slides/09-model-compare.html#response-tip",
    "href": "slides/09-model-compare.html#response-tip",
    "title": "Model comparison",
    "section": "Response: Tip",
    "text": "Response: Tip"
  },
  {
    "objectID": "slides/09-model-compare.html#predictors",
    "href": "slides/09-model-compare.html#predictors",
    "title": "Model comparison",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/09-model-compare.html#relevel-categorical-predictors",
    "href": "slides/09-model-compare.html#relevel-categorical-predictors",
    "title": "Model comparison",
    "section": "Relevel categorical predictors",
    "text": "Relevel categorical predictors\n\ntips &lt;- tips |&gt;\n  mutate(\n    Meal = fct_relevel(Meal, \"Lunch\", \"Dinner\", \"Late Night\"),\n    Age  = fct_relevel(Age, \"Yadult\", \"Middle\", \"SenCit\")\n  )"
  },
  {
    "objectID": "slides/09-model-compare.html#predictors-again",
    "href": "slides/09-model-compare.html#predictors-again",
    "title": "Model comparison",
    "section": "Predictors, again",
    "text": "Predictors, again"
  },
  {
    "objectID": "slides/09-model-compare.html#response-vs.-predictors",
    "href": "slides/09-model-compare.html#response-vs.-predictors",
    "title": "Model comparison",
    "section": "Response vs. predictors",
    "text": "Response vs. predictors"
  },
  {
    "objectID": "slides/09-model-compare.html#fit-and-summarize-model",
    "href": "slides/09-model-compare.html#fit-and-summarize-model",
    "title": "Model comparison",
    "section": "Fit and summarize model",
    "text": "Fit and summarize model\n\ntip_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(Tip ~ Party + Age, data = tips)\n\ntidy(tip_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.170\n0.366\n-0.465\n0.643\n\n\nParty\n1.837\n0.124\n14.758\n0.000\n\n\nAgeMiddle\n1.009\n0.408\n2.475\n0.014\n\n\nAgeSenCit\n1.388\n0.485\n2.862\n0.005\n\n\n\n\n\n\n\n\nIs this model useful for explaining variation in tips?"
  },
  {
    "objectID": "slides/09-model-compare.html#rmse",
    "href": "slides/09-model-compare.html#rmse",
    "title": "Model comparison",
    "section": "RMSE",
    "text": "RMSE\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n\\]\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nThe value of RMSE is more useful for comparing across models than evaluating a single model"
  },
  {
    "objectID": "slides/09-model-compare.html#analysis-of-variance-anova",
    "href": "slides/09-model-compare.html#analysis-of-variance-anova",
    "title": "Model comparison",
    "section": "Analysis of variance (ANOVA)",
    "text": "Analysis of variance (ANOVA)\nAnalysis of Variance (ANOVA): Technique to partition variability in Y by the sources of variability"
  },
  {
    "objectID": "slides/09-model-compare.html#anova",
    "href": "slides/09-model-compare.html#anova",
    "title": "Model comparison",
    "section": "ANOVA",
    "text": "ANOVA\n\nMain Idea: Decompose the total variation in the response into\n\nthe variation that can be explained by the each of the variables in the model\nthe variation that can’t be explained by the model (left in the residuals)\n\nIf the variation that can be explained by the variables in the model is greater than the variation in the residuals, this signals that the model might be “valuable” (at least one of the \\(\\beta\\)’s not equal to 0)"
  },
  {
    "objectID": "slides/09-model-compare.html#sum-of-squares",
    "href": "slides/09-model-compare.html#sum-of-squares",
    "title": "Model comparison",
    "section": "Sum of Squares",
    "text": "Sum of Squares\n\n\\[\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n\\]\n\n\nClick here to see why this equality holds."
  },
  {
    "objectID": "slides/09-model-compare.html#r2",
    "href": "slides/09-model-compare.html#r2",
    "title": "Model comparison",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\nThe coefficient of determination \\(R^2\\) is the proportion of variation in the response, \\(Y\\), that is explained by the regression model\n\n\\[\nR^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST} = 1 - \\frac{686.44}{1913.11} = 0.641\n\\]"
  },
  {
    "objectID": "slides/09-model-compare.html#two-potential-models",
    "href": "slides/09-model-compare.html#two-potential-models",
    "title": "Model comparison",
    "section": "Two potential models",
    "text": "Two potential models\nLet’s consider two models:\n\nModel 1: Party, Age\nModel 2: Party, Age, Payment\n\n\n\n Which model is a better fit for the data?"
  },
  {
    "objectID": "slides/09-model-compare.html#r-squared-r2",
    "href": "slides/09-model-compare.html#r-squared-r2",
    "title": "Model comparison",
    "section": "R-squared, \\(R^2\\)",
    "text": "R-squared, \\(R^2\\)\n\n\\(R^2\\) will always increase as we add more variables to the model (let’s see why)\nIf we add enough variables, we can always achieve \\(R^2=100\\%\\)\nIf we only use \\(R^2\\) to choose a best fit model, we will be prone to choose the model with the most predictor variables (assuming we’re comparing nested models)"
  },
  {
    "objectID": "slides/09-model-compare.html#adjusted-r2",
    "href": "slides/09-model-compare.html#adjusted-r2",
    "title": "Model comparison",
    "section": "Adjusted \\(R^2\\)",
    "text": "Adjusted \\(R^2\\)\n\n\nAdjusted \\(R^2\\): measure that includes a penalty for unnecessary predictor variables\nSimilar to \\(R^2\\), it is a measure of the amount of variation in the response that is explained by the regression model\nDiffers from \\(R^2\\) by using the mean squares (sumsq/df) rather than sums of squares and therefore adjusting for the number of predictor variables\nThe penalty for added model complexity attempts to strike a balance between underfitting (too few predictors in the model) and overfitting (too many predictors in the model)\nGoal: Parsimony"
  },
  {
    "objectID": "slides/09-model-compare.html#r2-and-adjusted-r2",
    "href": "slides/09-model-compare.html#r2-and-adjusted-r2",
    "title": "Model comparison",
    "section": "\\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "\\(R^2\\) and Adjusted \\(R^2\\)\n\\[R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}\\]\n\n\n\\[Adj. R^2 = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}\\]\nwhere\n\n\\(n\\) is the number of observations used to fit the model\n\\(p\\) is the number of terms (not including the intercept) in the model"
  },
  {
    "objectID": "slides/09-model-compare.html#using-r2-and-adjusted-r2",
    "href": "slides/09-model-compare.html#using-r2-and-adjusted-r2",
    "title": "Model comparison",
    "section": "Using \\(R^2\\) and Adjusted \\(R^2\\)",
    "text": "Using \\(R^2\\) and Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\nUse \\(R^2\\) when describing the relationship between the response and predictor variables"
  },
  {
    "objectID": "slides/09-model-compare.html#comparing-models-with-adj.-r2",
    "href": "slides/09-model-compare.html#comparing-models-with-adj.-r2",
    "title": "Model comparison",
    "section": "Comparing models with \\(Adj. R^2\\)",
    "text": "Comparing models with \\(Adj. R^2\\)\n\n\n\ntip_fit_1 &lt;- lm(Tip ~ Party + Age , \n    data = tips)\n\nglance(tip_fit_1) |&gt; \n  select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.641         0.635\n\n\n\n\ntip_fit_2 &lt;- lm(Tip ~ Party + Age + Payment, \n      data = tips)\n\nglance(tip_fit_2) |&gt; \n  select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.644         0.633\n\n\n\n\n\n\nWhich model would we choose based on \\(R^2\\)?\nWhich model would we choose based on Adjusted \\(R^2\\)?"
  },
  {
    "objectID": "slides/09-model-compare.html#parsimony-and-occams-razor",
    "href": "slides/09-model-compare.html#parsimony-and-occams-razor",
    "title": "Model comparison",
    "section": "Parsimony and Occam’s razor",
    "text": "Parsimony and Occam’s razor\n\nThe principle of parsimony is attributed to William of Occam (early 14th-century English nominalist philosopher), who insisted that, given a set of equally good explanations for a given phenomenon, the correct explanation is the simplest explanation1\nCalled Occam’s razor because he “shaved” his explanations down to the bare minimum\nParsimony in modeling:\n\n\nmodels should have as few parameters as possible\nlinear models should be preferred to non-linear models\nexperiments relying on few assumptions should be preferred to those relying on many\nmodels should be pared down until they are minimal adequate\nsimple explanations should be preferred to complex explanations\n\n\n\nSource: The R Book by Michael J. Crawley."
  },
  {
    "objectID": "slides/09-model-compare.html#in-pursuit-of-occams-razor",
    "href": "slides/09-model-compare.html#in-pursuit-of-occams-razor",
    "title": "Model comparison",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\nOccam’s razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\nModel selection follows this principle\nWe only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\nIn other words, we prefer the simplest best model, i.e. parsimonious model"
  },
  {
    "objectID": "slides/09-model-compare.html#alternate-views",
    "href": "slides/09-model-compare.html#alternate-views",
    "title": "Model comparison",
    "section": "Alternate views",
    "text": "Alternate views\n\nSometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.\n\nRadford Neal - Bayesian Learning for Neural Networks1\n\nSuggested blog post: Occam by Andrew Gelman"
  },
  {
    "objectID": "slides/09-model-compare.html#evaluating-models-training-vs.-testing-sets",
    "href": "slides/09-model-compare.html#evaluating-models-training-vs.-testing-sets",
    "title": "Model comparison",
    "section": "Evaluating models: training vs. testing sets",
    "text": "Evaluating models: training vs. testing sets\n\n\nThe training set (i.e., the data used to fit the model) does not have the capacity to be a good arbiter of performance.\nIt is not an independent piece of information; predicting the training set can only reflect what the model already knows.\nSuppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.\nWe can reserve some data for a testing set that can be used to evaluate the model performance"
  },
  {
    "objectID": "slides/09-model-compare.html#training-and-testing-sets",
    "href": "slides/09-model-compare.html#training-and-testing-sets",
    "title": "Model comparison",
    "section": "Training and testing sets",
    "text": "Training and testing sets\nCreate training and testing sets using functions from the resample R package (part of tidymodels)\nStep 1: Create an initial split:\n\nset.seed(210)\ntips_split &lt;- initial_split(tips, prop = 0.75) #prop = 3/4 by default\n\n\nStep 2: Save training data\n\ntips_train &lt;- training(tips_split)\ndim(tips_train)\n\n[1] 126  13\n\n\n\n\nStep 3: Save testing data\n\ntips_test &lt;- testing(tips_split)\ndim(tips_test)\n\n[1] 43 13"
  },
  {
    "objectID": "slides/09-model-compare.html#recap",
    "href": "slides/09-model-compare.html#recap",
    "title": "Model comparison",
    "section": "Recap",
    "text": "Recap\n\nANOVA for multiple linear regression and sum of squares\nComparing models with\n\n\\(R^2\\) vs. \\(Adj. R^2\\)\nAIC and BIC\n\nOccam’s razor and parsimony\nTraining and testing data"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 for Duke Container Manager\n\n\nCourse GitHub organization\n🔗 for GitHub\n\n\nCourse Canvas site\n🔗 for Canvas\n\n\nDiscussion forum\n🔗 to Ed Discussion\n\n\nAssignment submission\n🔗 to Gradescope",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 3:05 - 4:20pm\nOld Chemistry 116\n\n\nLab 01\nMon 3:05 - 4:20pm\nOld Chemistry 001\n\n\nLab 02\nMon 4:40 - 5:55pm\nPerkins Link #5\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nSylvia Vincent\nHead TA\nLab 01L leader\n\n\nIshrit Gupta\nLab 02L leader\n\n\nKareena Legare\nLab 01L helper\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 3:05 - 4:20pm\nOld Chemistry 116\n\n\nLab 01\nMon 3:05 - 4:20pm\nOld Chemistry 001\n\n\nLab 02\nMon 4:40 - 5:55pm\nPerkins Link #5\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nSylvia Vincent\nHead TA\nLab 01L leader\n\n\nIshrit Gupta\nLab 02L leader\n\n\nKareena Legare\nLab 01L helper\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "STA 210 Syllabus",
    "section": "Course description",
    "text": "Course description\nIn STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\nPrerequisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "STA 210 Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "STA 210 Syllabus",
    "section": "Course materials",
    "text": "Course materials\nWhile there is no official textbook for the course; readings will primarily be made available as they are assigned. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "STA 210 Syllabus",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can find instructions to do so here. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, https://sta210-sp25.netlify.app.\nLinks to Zoom meetings may be found in Canvas. Periodic announcements will be sent via email and will also be available through Ed Discussion and Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "STA 210 Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings and other preparation work.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#getting-help-in-the-course",
    "href": "syllabus.html#getting-help-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "Getting help in the course",
    "text": "Getting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-expect-in-the-course",
    "href": "syllabus.html#what-to-expect-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "What to expect in the course",
    "text": "What to expect in the course\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities during the lectures and labs. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or any device with internet and a keyboard to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\n\n\nTeams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the group activities, labs and the final project. You will be asked to complete teamwork evaluations and self-reflections throughout the semester. Failure to adequately contribute to an assignment can result in a penalty to your score relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as one of several metrics of each team member’s relative contribution for each project.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "STA 210 Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on six components: application exercises, homework, labs, exams, project, and teamwork.\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository in the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks and explain concepts. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-notes in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding and application through analysis and computational tasks. The exams will be based on content in reading assignments, lectures, application exercises, homework, and lab assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work through a written report and presentation. More information about the project will be provided during the semester. You can learn more on the final project page.\n\n\nParticipation (Application exercises + teamwork)\n\nApplication exercises\nYou will get the most out of the course if you actively participate in class and when working with your team. Parts of some lectures will be dedicated to working on Application Exercises (AEs). AEs are submitted by pushing your work to the relevant GitHub repo.\nAEs will be graded based on making a good-faith effort to attempt all questions covered in class. You are welcome to, but not required, to work on AEs beyond lecture.\nSuccessful effort on at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nTeamwork\nGiven the collaborative nature of statistics and data science work, teamwork will be a key part of this course. You will work in teams for in-class activities, lab assignments, and the final course project. There will be periodic peer and self-evaluations to reflect on the team’s collaboration. These evaluations will be counted as part of the participation grade.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 210 Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nFinal project\n15%\n\n\nLabs\n10%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "STA 210 Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email me at maria.tackett@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/RPkWfBB4vf\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "STA 210 Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-and-wellness-support",
    "href": "syllabus.html#academic-and-wellness-support",
    "title": "STA 210 Syllabus",
    "section": "Academic and wellness support",
    "text": "Academic and wellness support\n\nAcademic Resource Center\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.\n\n\nCAPS\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "STA 210 Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 8: Classes begin\nJanuary 20: Martin Luther King Jr. Day holiday.\nJanuary 22: Drop/Add ends\nMarch 10 - 14: Spring break\nMarch 26: Last day to withdraw with “W”\nNovember 27 - 29: Thanksgiving recess\nApril 23: Classes end\nApril 24 - 27: Reading period\nApril 28 - May 3: Final exam period\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 210 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Sunday, February 16\nProject proposal due Thursday, February 27\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments due Monday, March 31 (in lab)\nAnalysis draft + peer review due Monday, April 14 (peer review in lab)\nWritten report due Wednesday, April 30\nProject highlights due Friday, May 2\nReproducibility + organization due Friday, May 2\nFinal project survey due Saturday, May 3",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-milestones",
    "href": "project.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Sunday, February 16\nProject proposal due Thursday, February 27\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments due Monday, March 31 (in lab)\nAnalysis draft + peer review due Monday, April 14 (peer review in lab)\nWritten report due Wednesday, April 30\nProject highlights due Friday, May 2\nReproducibility + organization due Friday, May 2\nFinal project survey due Saturday, May 3",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the primary deliverables.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#research-topics",
    "href": "project.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified right now.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic. (Note: These are draft questions at this point. You will finalize the questions in the next stage of the project.)\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. (Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.)\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Sunday, February 16 at 11:59pm. There is no Gradescope submission.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research topics. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must use the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Topics milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Data processing\n\nDescription of data processing you need to do to prepare for analysis, such as joining multiple data sets, handling missing data, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, February 27 at 11:59pm.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (5 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data, any data processing, and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (3 - 4 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (2 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (1 point): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#eda",
    "href": "project.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about 4 - 6 pages (It is OK to be over this page limit at this stage in the project.)\n\n\n\n\n\n\nTip\n\n\n\nYou can save space by suppressing code, warnings, and messages by including the following in the YAML:\nexecute:\n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation",
    "href": "project.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results (if applicable)\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation-comments",
    "href": "project.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#draft-report-peer-review",
    "href": "project.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#written-report",
    "href": "project.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\n\n\nResults\n\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-highlights",
    "href": "project.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights\nThis is an opportunity to share your final analysis results with your peers! You will post highlights in Canvas discussion forum using one fo the following formats:\n\nA detailed abstract\nSlides summarizing your project results\nShort video summarizing your project results\n\nMore detail about these highlight formats and posting in Canvas to come.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#reproducibility-organization",
    "href": "project.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-topics.qmd & research-topics.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and team members’ names.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#final-project-survey",
    "href": "project.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey\nYou will complete a short survey about the project. More details to come.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#peer-teamwork-evaluation",
    "href": "project.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#overall-grading",
    "href": "project.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#late-work-policy",
    "href": "project.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  }
]