{
  "hash": "e4d629040504b4b7ae87dc33e6b4fbbf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Final project\n---\n\n\n\n\n\n\n## Project milestones\n\n[Research questions](#research-questions) due Thursday, September 26\n\n[Project proposal](#project-proposal) due Thursday, October 3\n\n[Exploratory data analysis](#eda) due Thursday, October 31\n\n[Presentation](#presentation) + [Presentation comments](#presentation-comments) Monday, November 11 (in lab)\n\n[Analysis draft + peer review](#draft-report-peer-review) Monday, November 25 (peer review in lab)\n\n[Round 1 submission (optional)](#round1-submission) due Friday, December 6\n\n[Written report](#written-report) due Thursday, December 12 at 9pm\n\n[Reproducibility + organization](#reproducibility-organization) due Thursday, December 12 at 9pm\n\n## Introduction\n\n**TL;DR**: *Pick a data set and do a regression analysis. That is your final project.*\n\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\n\nChoose the data based on your group's interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\n\n**All analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.**\n\n### Logistics\n\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\n1.  an in-person presentation about the exploratory data analysis and initial modeling\n\n2.  a written, reproducible final report detailing your analysis\n\n3.  a GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the final deliverables.\n\n## Research questions {#research-questions}\n\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing potential research questions; you do not need to have a data set identified at this point.\n\nDevelop three potential research questions. Include the following for <u>each</u> question:\n\n1.  A statement of the research question.\n2.  The target population of interest for this question.\n3.  A statement about your motivation for investigating this research question and why this question is important.\n4.  Ideas about the type of data you might use to answer this question. *Note: These are your ideas about the type of data you could use. You do not need to have a data set at this point.*\n\n### Submission\n\nWrite your responses in `research-questions.qmd` in your team's project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, **Thursday, September 26 at 11:59pm.**\n\n## Project proposal {#project-proposal}\n\nThe purpose of the project proposal is for your team to identify the data set you're interested in analyzing to investigate one of your potential research questions. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you're unsure where to find data, you can use the list of potential data sources on the [Tips + resources](https://sta221-fa24.netlify.app/project-tips) page as a starting point.\n\n::: callout-important\nYou must the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n:::\n\nThe data set must meet the following criteria:\n\n-   At least 500 observations\n\n-   At least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\n    -   e.g., identifier variables such as \"name\", \"ID number\", etc. are <u>not</u> useful predictor variables.\n\n    -   e.g., if you have multiple columns with the same information (e.g. \"state abbreviation\" and \"state name\"), then they are not unique predictors.\n\n-   At least one variable that can be identified as a reasonable response variable.\n\n    -   The response variable can be quantitative or categorical.\n\n-   A mix of quantitative and categorical variables that can be used as predictors.\n\n-   May not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n::: callout-warning\n### Types of data sets to avoid\n\n-   Data that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\n\n-   Data sets in which there is no information about how the data were originally collected\n\n-   Data sets in which there are missing or unclear definitions about the observations and/or variables\n:::\n\n**Ask a member of the teaching team if you're unsure whether your data set meets the criteria.**\n\nThe proposal will include the following sections:\n\n### Section 1: Introduction\n\n::: callout-tip\nReuse and iterate on the work from the Research Questions milestone.\n:::\n\n-   An introduction to the subject matter you're investigating (citing any relevant literature)\n\n-   Statement of a well-developed research question.\n\n-   The motivation for your research question and why it is important\n\n-   Your team's hypotheses regarding the research question\n\n    -   This is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n### Section 2: Data description\n\n-   The source of the data set\n\n-   A description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\n\n-   A description of the observations and general characteristics being measured\n\n### Section 3: Initial exploratory data analysis\n\n-   Description of data cleaning you need to do to prepare for analysis (can focus on the response variable for now), such as joining data sets, imputing missing values, variable transformation, creating a new variable, etc.\n\n-   Visualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n### Section 4: Analysis approach\n\n-   a description of the potential predictor variables of interest\n\n-   regression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n### Data dictionary (aka code book)\n\nSubmit a data dictionary for all the variables in your data set in the `README` of the `data` folder. You do <u>not</u> need to include the data dictionary in the PDF document.\n\n### Submission\n\nWrite your narrative and analysis for Sections 1 - 4 in the `proposal.qmd` file in your team's GitHub repo. Put the data set and the data dictionary in the `data` folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, **Thursday, October 3 at 11:59pm.**\n\n### Grading\n\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\n\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\n-   **Excellent (9 - 10 points) :** All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data and exploration of the response variable as descrbied above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\n\n-   **Strong (7 - 8 points)**: Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\n\n-   **Satisfactory (5 - 6 points):** Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\n\n-   **Needs Improvement (4 or fewer points points):** Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.\n\n## Exploratory data analysis {#eda}\n\n::: callout-tip\nReuse and iterate on the work from the previous milestones.\n:::\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\n\nBelow is a brief description of the sections to include in this step:\n\n### Introduction\n\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n### Exploratory data analysis\n\nThis section includes the following:\n\n-   Description of the data set and key variables.\n\n-   Exploratory data analysis of the response variable and key predictor variables.\n\n    -   Univariate EDA of the response and key predictor variables.\n    -   Bivariate EDA of the response and key predictor variables\n    -   Potential interaction effects.\n\n### Submission\n\nWrite your draft introduction and exploratory data analysis in the `written-report.qmd` file in your team's GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, **Thursday, October 31 at 11:59pm.**\n\n## Presentation {#presentation}\n\n<!-- ::: callout-important -->\n\n<!-- Presentations will take place in class during labs December 5 & 7. -->\n\n<!-- [Click here](https://prodduke-my.sharepoint.com/:x:/g/personal/mt324_duke_edu/Ed8d7gVI8-lMrmgJpFpTEjYB2UXUTyZNDMOgQYpO4YOJJg?e=CieZZL) for the presentation order. -->\n\n<!-- ::: -->\n\n<!-- In addition to the written report, your team will also do an in-person presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity. -->\n\n<!-- You can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that's easy to collaborate with, e.g., Google Slides. -->\n\n<!-- You can also use Quarto to make your slides! While we won't be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It's no different than writing other documents with Quarto, so the learning curve will not be steep! -->\n\n<!-- **The presentation must be no longer than 6 minutes.** It is fine if the presentation is shorter than 6 minutes, but it cannot exceed 6 minutes due to the limited time during lab. -->\n\n<!-- **Every team member is expected to speak in the presentation.** Part of the grade will be whether every team member had a meaningful speaking role in the presentation. -->\n\n<!-- ### Slides -->\n\n<!-- The slide deck should have no more than 6 content slides + 1 title slide. Here is a [suggested]{.underline} outline as you think through the slides; you do [not]{.underline} have to use this exact format for the 6 slides. -->\n\n<!-- -   Title Slide -->\n\n<!-- -   Slide 1: Introduce the topic and motivation -->\n\n<!-- -   Slide 2: Introduce the data -->\n\n<!-- -   Slide 3: Highlights from EDA -->\n\n<!-- -   Slide 4: Final model -->\n\n<!-- -   Slide 5: Interesting findings from the model -->\n\n<!-- -   Slide 6: Conclusions + future work -->\n\n<!-- ### Grading criteria -->\n\n<!-- The presentation grade will be based on the following criteira: -->\n\n<!-- -   Content: The group told a unified story using the appropriate regression analysis. -->\n\n<!-- -   Slides: The presentation slides were organized, included clear and informative visualizations, and were easily readable. -->\n\n<!-- -   Professionalism: The group's communication style was clear and professional. -->\n\n<!-- -   Time Management: Team divided the time well and stayed within the 6 minute time limit, with each team member making a meaning contribution to the presentation. (assessed by the teaching team only). -->\n\n<!-- 80% of the presentation grade will be the average of the teaching scores and 20% will be the average of the peer scores. -->\n\n<!-- ::: callout-important -->\n\n<!-- You can submit the presentation slides in two ways: -->\n\n<!-- -   Put a PDF of the slides in the `presentation` folder in your team's GitHub repo. -->\n\n<!-- -   Put the URL to your slides in the `README` of the `presentation` folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides. -->\n\n<!-- **Slides must be submitted by the start of your lab on December 5 or 7.** You will [not]{.underline} submit the slides on Gradescope. -->\n\n<!-- ::: -->\n\n<!-- ## **Presentation comments** {#presentation-comments} -->\n\n<!-- ::: callout-important -->\n\n<!-- [Click here](https://prodduke-my.sharepoint.com/:x:/g/personal/mt324_duke_edu/Ed8d7gVI8-lMrmgJpFpTEjYB2UXUTyZNDMOgQYpO4YOJJg?e=jxx4e4) to find the teams you're scoring and a link to the feedback form. -->\n\n<!-- This portion of the project will be assessed individually. -->\n\n<!-- ::: -->\n\n<!-- You will provide feedback on two teams' presentations. You can find your assigned teams and the link to the feedback from [here](https://prodduke-my.sharepoint.com/:x:/g/personal/mt324_duke_edu/Ed8d7gVI8-lMrmgJpFpTEjYB2UXUTyZNDMOgQYpO4YOJJg?e=CieZZL). Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores. -->\n\n<!-- The grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day (December 5 for Tuesday labs, December 7 for Thursday labs). -->\n\n## Analysis + peer review {#draft-report-peer-review}\n\n<!-- The purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations. -->\n\n<!-- ### Draft report -->\n\n<!-- ::: callout-important -->\n\n<!-- ## Due dates -->\n\n<!-- Draft is due i**n your project GitHub repo at** **9am** on -->\n\n<!-- -   Tuesday, November 14 (Tuesday labs) -->\n\n<!-- -   Thursday, November 16 (Thursday labs) -->\n\n<!-- ::: -->\n\n<!-- Write the draft in the **written-report.qmd** file in your project repo. You do [**not**]{.underline} need to submit the draft on Gradescope. -->\n\n<!-- Below is a brief description of the sections to focus on in the draft: -->\n\n<!-- #### Introduction and data -->\n\n<!-- This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won't fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships. -->\n\n<!-- #### Methodology -->\n\n<!-- This section includes a brief description of your modeling process. Explain the reasoning for the type of model you're fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process. -->\n\n<!-- #### Results -->\n\n<!-- In this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics. -->\n\n<!-- This section also includes initial interpretations and conclusions drawn from the model. -->\n\n<!-- #### Grading -->\n\n<!-- The draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written-report.qmd file in our GitHub repo by the deadline. -->\n\n<!-- ### Peer review -->\n\n<!-- ::: callout-important -->\n\n<!-- Peer review comments are due in GitHub at 11:59pm on -->\n\n<!-- -   Wednesday, November 15 (Tuesday labs) -->\n\n<!-- -   Friday, November 17 (Thursday labs) -->\n\n<!-- ::: -->\n\n<!-- Critically reviewing others' work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams's projects to review. Each team should push their draft to their GitHub repo by the 9am on the day their lab's draft is due. The lab that week will be dedicate to the peer review, so your team will have time to review and provide quality feedback to two other teams. -->\n\n<!-- During the peer review process, you will be provided read-only access to your partner teams' GitHub repos. Provide your review in the form of GitHub issues to your partner team's GitHub repo using the issue template provided in the repo. -->\n\n<!-- #### Steps for peer review -->\n\n<!-- ## Peer review assignments -->\n\n<!-- [Click here](https://prodduke-my.sharepoint.com/:x:/g/personal/mt324_duke_edu/Eez-RT2TVd9Cs_aLCOffbDcB2W7VnGmcZs0myTmdiy2qvA?e=WBpJx2) to see which project your team is reviewing. You'll spend about 30 minutes reviewing each project. -->\n\n<!-- When you get to lab, you should have access to the GitHub repos for the teams you're reviewing. In GitHub, search the repositories for `project`, and you should see the repos for the projects you're reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review. -->\n\n<!-- For each team you're reviewing: -->\n\n<!-- -   Open that team's repo, read the project draft, and browse the rest of the repo. -->\n\n<!-- -   Go to the **Issues** tab in that repo, click on **New issue**, and click on **Get started** for the Peer Review issue. Fill out this issue. You will answer the the following questions: -->\n\n<!--     -   Describe the goal of the project. -->\n\n<!--     -   Describe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected? -->\n\n<!--     -   Consider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA. -->\n\n<!--     -   Describe the statistical methods and analysis approach used. -->\n\n<!--     -   Provide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling. -->\n\n<!--     -   What aspect of this project are you most interested in and would like to see highlighted in the presentation? -->\n\n<!--     -   Provide constructive feedback on any issues with file and/or code organization. -->\n\n<!--     -   (Optional) Any further comments or feedback? -->\n\n<!-- #### Grading -->\n\n<!-- The peer review will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team's report: the research context and motivation, exploratory data analysis, modeling, interpretations, and conclusions. -->\n\n## Round 1 submission (optional) {#round1-submission}\n\n<!-- ::: callout-important -->\n\n<!-- ## Due date -->\n\n<!-- Friday, December 1 at 11:59pm on GitHub (all teams) -->\n\n<!-- Reports submitted after this date will not receive preliminary feedback. -->\n\n<!-- ::: -->\n\n<!-- The Round 1 submission is an opportunity to receive detailed feedback on your analysis and [written report](#written-report) before the final submission. Therefore, to make the feedback most useful, ***you must submit a complete written report to receive feedback.*** You will also be notified of the grade you would receive at that point. You will have the option to keep the grade (and thus you don't need to turn in an updated report) or resubmit the written report by the final submission deadline to receive a new grade. -->\n\n<!-- #### **To submit the Round 1 submission:** -->\n\n<!-- 1.  Push the updated `written-report.qmd` and `written-report.pdf` to your GitHub repo. -->\n\n<!-- 2.  Open an issue with the title \"Round 1 Submission\". You can use the template issue in the GitHub repo. Make sure I am tagged in the issue (`@matackett`), so I receive an email notification of your Round 1 submission. See [Creating an issue from a repository](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue#creating-an-issue-from-a-repository) for instructions on opening an issue. Please ask a member of the teaching team for assistance if you need help opening the issue. -->\n\n<!-- Note that this is optional, so there is [**no**]{.underline}grade penalty for not turning in a Round 1 submission. Due to time constraints at the end of the semester, only high-level feedback will be given for the reports submitted at the final written report deadline on December 13. -->\n\n## Written report {#written-report}\n\n<!-- Your written report must be completed in the `written-report.qmd` file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits. -->\n\n<!-- Before you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed. -->\n\n<!-- **You will submit the PDF of your final report on GitHub.** -->\n\n<!-- The PDF you submit must match the .qmd in your GitHub repository *exactly*. The mandatory components of the report are below. You are free to add additional sections as necessary. **The report, including tables and visualizations, must be no more than 10 pages long.** There is no minimum page requirement; however, you should comprehensively address all of the analysis and report. -->\n\n<!-- Be selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis. -->\n\n<!-- You are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit. -->\n\n<!-- ### Introduction and data -->\n\n<!-- This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won't fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships. -->\n\n<!-- #### Grading criteria -->\n\n<!-- The research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics. -->\n\n<!-- ### Methodology -->\n\n<!-- This section includes a brief description of your modeling process. Explain the reasoning for the type of model you're fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process. -->\n\n<!-- #### Grading criteria -->\n\n<!-- The analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the variables in the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content. -->\n\n<!-- ### Results -->\n\n<!-- This is where you will output the final model with any relevant model fit statistics, conditions, and diagnostics. -->\n\n<!-- Describe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader. -->\n\n<!-- #### Grading criteria -->\n\n<!-- The model fit is clearly assessed, and interesting findings from the model are clearly described. The model conditions and diagnostics are thoroughly and accurately assessed for their model. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model's predictive power is thoroughly assessed. -->\n\n<!-- ### Discussion + Conclusion -->\n\n<!-- In this section you'll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work. -->\n\n<!-- #### Grading criteria -->\n\n<!-- Overall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described. -->\n\n<!-- ### Organization + formatting -->\n\n<!-- This is an assessment of the overall presentation and formatting of the written report. -->\n\n<!-- #### Grading criteria -->\n\n<!-- The report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted and labeled. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages. -->\n\n<!-- #### Submission -->\n\n<!-- ::: callout-important -->\n\n<!-- The written report is due on **Wednesday, December 13 at 11:59pm**. -->\n\n<!-- To submit your report, `written-report.qmd` and the rendered `written-report.pdf` to your team's GitHub repo by the deadline. You will [**not**]{.underline} submit the report on Gradescope. -->\n\n<!-- *The version of the report in the repo by Wednesday, December 13 will be the one that is graded.* -->\n\n<!-- ::: -->\n\n## Reproducibility + organization {#reproducibility-organization}\n\n<!-- All written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized. -->\n\n<!-- The GitHub repo should have the following structure: -->\n\n<!-- -   `README`: Short project description and data dictionary -->\n\n<!-- -   `written-report.qmd` & `written-report.pdf`: Final written report -->\n\n<!-- -   `proposal.qmd` & `proposal.pdf`: Project proposal -->\n\n<!-- -   `/data`: Folder that contains the data set for the final project. -->\n\n<!-- -   `project.Rproj`: File specifying the RStudio project -->\n\n<!-- -   `/presentation`: Folder with the presentation slides or link to slides. -->\n\n<!-- -   `.gitignore`: File that lists all files that are in the local RStudio project but not the GitHub repo -->\n\n<!-- -   `/.github`: Folder for peer review issue template -->\n\n<!-- Points for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the `README` should be easily readable. -->\n\n<!-- ::: callout-important -->\n\n<!-- The repo must be ready for grading by Wednesday, December 13 at 11:59pm. -->\n\n<!-- ::: -->\n\n## Peer teamwork evaluation\n\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.\n\n## Overall grading\n\nThe grade breakdown is as follows:\n\n| Total                          | 100 pts |\n|--------------------------------|---------|\n| Research question              | 3 pts   |\n| Project proposal               | 10 pts  |\n| Exploratory data analysis      | 15 pts  |\n| Presentation                   | 10 pts  |\n| Presentation comments          | 2 pts   |\n| Draft report + peer review     | 15 pts  |\n| Written report                 | 40 pts  |\n| Reproducibility + organization | 5 pts   |\n\n### Grading summary\n\nGrading of the project will take into account the following:\n\n-   Content - What is the quality of research and/or policy question and relevancy of data to those questions?\n\n-   Correctness - Are statistical procedures carried out and explained correctly?\n\n-   Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations?\n\n-   Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n-   *90%-100%*: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n\n-   *80%-89%*: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n\n-   *70%-79%*: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n\n-   *60%-69%*: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\n\n-   *Below 60%*: Student is not making a sufficient effort.\n\n## Late work policy\n\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\n\n**Be sure to turn in your work early to avoid any technological mishaps.**\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}