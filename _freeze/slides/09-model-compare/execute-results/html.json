{
  "hash": "dd9e70e9a794565b230adfb7ff2cf196",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model comparison\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2025-02-06\"\nfooter: \"[ðŸ”— STA 210 - Spring 2025](https://sta210-sp25.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs: \n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    include-before: [ '<script type=\"text/x-mathjax-config\">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']\n  html: \n    output-file: 09-model-compare-notes.html\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n\n\n\n## Announcements\n\n-   Lab 02 due TODAY at 11:59pm\n\n-   HW 02 due Tuesday, February 11 at 11:59pm\n\n-   Lecture recordings available until start of exam on February 18\n\n    -   See link on menu of course website\n\n-   [Statistics experience](../hw/stats-experience.html) due Tuesday, April 15\n\n## Topics\n\n::: nonincremental\n-   ANOVA for multiple linear regression and sum of squares\n-   Comparing models with $Adj. R^2$\n-   Occam's razor and parsimony\n-   Cross validation\n:::\n\n## Computational setup\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n\n\n# Introduction\n\n## Data: Restaurant tips\n\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 169 Ã— 4\n     Tip Party Meal   Age   \n   <dbl> <dbl> <chr>  <chr> \n 1  2.99     1 Dinner Yadult\n 2  2        1 Dinner Yadult\n 3  5        1 Dinner SenCit\n 4  4        3 Dinner Middle\n 5 10.3      2 Dinner SenCit\n 6  4.85     2 Dinner Middle\n 7  5        4 Dinner Yadult\n 8  4        3 Dinner Middle\n 9  5        2 Dinner Middle\n10  1.58     1 Dinner SenCit\n# â„¹ 159 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Variables\n\n**Predictors**:\n\n::: nonincremental\n-   `Party`: Number of people in the party\n-   `Meal`: Time of day (Lunch, Dinner, Late Night)\n-   `Age`: Age category of person paying the bill (Yadult, Middle, SenCit)\n-   `Payment`: Payment type (Cash, Credit, Credit/CashTip)\n:::\n\n**Response**: `Tip`: Amount of tip\n\n## Response: `Tip`\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-model-compare_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n\n## Predictors\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-model-compare_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n\n## Relevel categorical predictors\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntips <- tips |>\n  mutate(\n    Meal = fct_relevel(Meal, \"Lunch\", \"Dinner\", \"Late Night\"),\n    Age  = fct_relevel(Age, \"Yadult\", \"Middle\", \"SenCit\")\n  )\n```\n:::\n\n\n\n\n## Predictors, again\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-model-compare_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n\n## Response vs. predictors\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-model-compare_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n## Fit and summarize model {.midi}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntip_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(Tip ~ Party + Age, data = tips)\n\ntidy(tip_fit) |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -0.170|     0.366|    -0.465|   0.643|\n|Party       |    1.837|     0.124|    14.758|   0.000|\n|AgeMiddle   |    1.009|     0.408|     2.475|   0.014|\n|AgeSenCit   |    1.388|     0.485|     2.862|   0.005|\n\n\n:::\n:::\n\n\n\n\n. . .\n\n<br>\n\n::: question\nIs this model useful for explaining variation in tips?\n:::\n\n## RMSE\n\n$$\nRMSE = \\sqrt{\\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n}} = \\sqrt{\\frac{\\sum_{i=1}^ne_i^2}{n}}\n$$\n\n::: incremental\n-   Ranges between 0 (perfect predictor) and infinity (terrible predictor)\n\n-   Same units as the response variable\n\n-   The value of RMSE is more useful for comparing across models than evaluating a single model\n:::\n\n## Analysis of variance (ANOVA)\n\n**Analysis of Variance (ANOVA)**: Technique to partition variability in Y by the sources of variability\n\n![](images/clipboard-3964457409-01.png)\n\n## ANOVA\n\n-   **Main Idea:** Decompose the total variation in the response into\n    -   the variation that can be explained by the each of the variables in the model\n\n    -   the variation that **can't** be explained by the model (left in the residuals)\n-   If the variation that can be explained by the variables in the model is greater than the variation in the residuals, this signals that the model might be \"valuable\" (at least one of the $\\beta$'s not equal to 0)\n\n## Sum of Squares\n\n<br>\n\n$$\n\\begin{aligned}\n\\color{#407E99}{SST} \\hspace{5mm}&= &\\color{#993399}{SSM} &\\hspace{5mm} +  &\\color{#8BB174}{SSR} \\\\[10pt]\n\\color{#407E99}{\\sum_{i=1}^n(y_i - \\bar{y})^2} \\hspace{5mm}&= &\\color{#993399}{\\sum_{i = 1}^{n}(\\hat{y}_i - \\bar{y})^2} &\\hspace{5mm}+ &\\color{#8BB174}{\\sum_{i = 1}^{n}(y_i - \\hat{y}_i)^2}\n\\end{aligned}\n$$\n\n::: aside\n[Click here](https://introregression.netlify.app/98-appendix#sum-of-squares) to see why this equality holds.\n:::\n\n## $R^2$\n\nThe **coefficient of determination** $R^2$ is the proportion of variation in the response, $Y$, that is explained by the regression model\n\n. . .\n\n$$\nR^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST} = 1 - \\frac{686.44}{1913.11} = 0.641\n$$\n\n# Model comparison\n\n## Two potential models\n\nLet's consider two models:\n\n-   Model 1: `Party`, `Age`\n-   Model 2: `Party`, `Age`, `Payment`\n\n. . .\n\n<center><b> Which model is a better fit for the data? </b></center>\n\n## R-squared, $R^2$\n\n-   $R^2$ will always increase as we add more variables to the model (let's see why)\n\n-   If we add enough variables, we can always achieve $R^2=100\\%$\n\n-   If we only use $R^2$ to choose a best fit model, we will be prone to choose the model with the most predictor variables (assuming we're comparing nested models)\n\n## Adjusted $R^2$\n\n::: incremental\n-   **Adjusted** $R^2$: measure that includes a penalty for unnecessary predictor variables\n-   Similar to $R^2$, it is a measure of the amount of variation in the response that is explained by the regression model\n-   Differs from $R^2$ by using the mean squares (sumsq/df) rather than sums of squares and therefore adjusting for the number of predictor variables\n-   The penalty for added model complexity attempts to strike a balance between underfitting (too few predictors in the model) and overfitting (too many predictors in the model)\n-   Goal: **Parsimony**\n:::\n\n## $R^2$ and Adjusted $R^2$\n\n$$R^2 = \\frac{SSM}{SST} = 1 - \\frac{SSR}{SST}$$\n\n<br>\n\n. . .\n\n$$Adj. R^2 = 1 - \\frac{SSR/(n-p-1)}{SST/(n-1)}$$\n\nwhere\n\n-   $n$ is the number of observations used to fit the model\n\n-   $p$ is the number of terms (not including the intercept) in the model\n\n## Using $R^2$ and Adjusted $R^2$\n\n-   Adjusted $R^2$ can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\n-   Use $R^2$ when describing the relationship between the response and predictor variables\n\n## Comparing models with $Adj. R^2$ {.smaller}\n\n::::: columns\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntip_fit_1 <- lm(Tip ~ Party + Age , \n    data = tips)\n\nglance(tip_fit_1) |> \n  select(r.squared, adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 2\n  r.squared adj.r.squared\n      <dbl>         <dbl>\n1     0.641         0.635\n```\n\n\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntip_fit_2 <- lm(Tip ~ Party + Age + Payment, \n      data = tips)\n\nglance(tip_fit_2) |> \n  select(r.squared, adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 2\n  r.squared adj.r.squared\n      <dbl>         <dbl>\n1     0.644         0.633\n```\n\n\n:::\n:::\n\n\n\n:::\n:::::\n\n<br>\n\n::: question\n2.  Which model would we choose based on $R^2$?\n3.  Which model would we choose based on Adjusted $R^2$?\n:::\n\n## Parsimony and Occam's razor {.small}\n\n-   The principle of **parsimony** is attributed to William of Occam (early 14th-century English nominalist philosopher), who insisted that, given a set of equally good explanations for a given phenomenon, *the correct explanation is the simplest explanation*[^1]\n\n-   Called **Occam's razor** because he \"shaved\" his explanations down to the bare minimum\n\n-   Parsimony in modeling:\n\n    ::: nonincremental\n    -   models should have as few parameters as possible\n    -   linear models should be preferred to non-linear models\n    -   experiments relying on few assumptions should be preferred to those relying on many\n    -   models should be pared down until they are *minimal adequate*\n    -   simple explanations should be preferred to complex explanations\n    :::\n\n[^1]: Source: The R Book by Michael J. Crawley.\n\n## In pursuit of Occam's razor\n\n-   Occam's razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\n\n-   Model selection follows this principle\n\n-   We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\n\n-   In other words, we prefer the simplest best model, i.e. **parsimonious** model\n\n## Alternate views {.midi}\n\n> Sometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.\n>\n> <br>\n>\n> Radford Neal - Bayesian Learning for Neural Networks[^2]\n\n[^2]: Suggested blog post: [Occam](https://statmodeling.stat.columbia.edu/2012/06/26/occam-2/) by Andrew Gelman\n\n## Evaluating models: training vs. testing sets {.midi}\n\n::: incremental\n-   The training set (i.e., the data used to fit the model) does not have the capacity to be a good arbiter of performance.\n\n-   It is not an independent piece of information; predicting the training set can only reflect what the model already knows.\n\n-   Suppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.\n\n-   We can reserve some data for a testing set that can be used to evaluate the model performance\n:::\n\n## Training and testing sets {.midi}\n\nCreate training and testing sets using functions from the **resample** R package (part of **tidymodels**)\n\n**Step 1:** Create an initial split:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(210)\ntips_split <- initial_split(tips, prop = 0.75) #prop = 3/4 by default\n```\n:::\n\n\n\n\n. . .\n\n**Step 2:** Save training data\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntips_train <- training(tips_split)\ndim(tips_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 126  13\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n**Step 3:** Save testing data\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntips_test <- testing(tips_split)\ndim(tips_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 43 13\n```\n\n\n:::\n:::\n\n\n\n\n# Application exercise\n\n::: appex\nðŸ“‹ [sta210-sp25.netlify.app/ae/ae-06-model-compare](../ae/ae-06-model-compare.html)\n:::\n\n## Recap\n\n-   ANOVA for multiple linear regression and sum of squares\n-   Comparing models with\n    -   $R^2$ vs.Â $Adj. R^2$\n    -   AIC and BIC\n-   Occam's razor and parsimony\n-   Training and testing data\n",
    "supporting": [
      "09-model-compare_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}