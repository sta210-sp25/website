{
  "hash": "82e125034ea4719ece441cef267dc435",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Inference for regression\"\nsubtitle: \"cont'd\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"2024-09-24\"\ndate-format: \"MMM DD, YYYY\"\nfooter: \"[ðŸ”— STA 221 - Fall 2024](https://sta221-fa24.netlify.app)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    include-before: [ '<script type=\"text/x-mathjax-config\">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nfilters:\n  - parse-latex\nbibliography: references.bib\n---\n\n\n\n\n\n## Announcements\n\n-   Project\n\n    -   Research questions due **Thursday at 11:59pm**\n\n    -   Proposal due Thursday, October 3 at 11:59pm\n\n-   Lab 03 due Thursday, October 3 at 11:59pm\n\n-   [Statistics experience](https://sta221-fa24.netlify.app/hw/stats-experience) due **Tue, Nov 26 at 11:59pm**\n\n## Topics\n\n-   Understand statistical inference in the context of regression\n\n-   Describe the assumptions for regression\n\n-   Understand connection between distribution of residuals and inferential procedures\n\n-   Conduct inference on a single coefficient\n\n-   Conduct inference on the overall regression model\n\n## Computing setup\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)  \nlibrary(tidymodels)  \nlibrary(knitr)       \nlibrary(kableExtra)  \nlibrary(patchwork)   \n\n# set default theme in ggplot2\nggplot2::theme_set(ggplot2::theme_bw())\n```\n:::\n\n\n\n## Data: NCAA Football expenditures {.midi}\n\nToday's data come from [Equity in Athletics Data Analysis](https://ope.ed.gov/athletics/#/datafile/list) and includes information about sports expenditures and revenues for colleges and universities in the United States. This data set was featured in a [March 2022 Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-03-29/readme.md).\n\nWe will focus on the 2019 - 2020 season expenditures on football for institutions in the NCAA - Division 1 FBS. The variables are :\n\n-   `total_exp_m`: Total expenditures on football in the 2019 - 2020 academic year (in millions USD)\n\n-   `enrollment_th`: Total student enrollment in the 2019 - 2020 academic year (in thousands)\n\n-   `type`: institution type (Public or Private)\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfootball <- read_csv(\"data/ncaa-football-exp.csv\")\n```\n:::\n\n\n\n## Univariate EDA\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-inference-pt2_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Bivariate EDA\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-inference-pt2_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Regression model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp_fit <- lm(total_exp_m ~ enrollment_th + type, data = football)\ntidy(exp_fit) |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term          | estimate| std.error| statistic| p.value|\n|:-------------|--------:|---------:|---------:|-------:|\n|(Intercept)   |   19.332|     2.984|     6.478|       0|\n|enrollment_th |    0.780|     0.110|     7.074|       0|\n|typePublic    |  -13.226|     3.153|    -4.195|       0|\n\n\n:::\n:::\n\n\n\n<br>\n\nFor every additional 1,000 students, we expect the institution's total expenditures on football to increase by \\$780,000, on average, holding institution type constant.\n\n# Inference for regression\n\n## Statistical inference {.midi}\n\n::: columns\n::: {.column width=\"40%\"}\n-   **Statistical inference** provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\n\n-   For our inferences to be valid, the sample should be representative (ideally random) of the population we're interested in\n:::\n\n::: {.column width=\"60%\"}\n![Image source: Eugene Morgan Â© Penn State](images/08/inference.png){fig-align=\"center\"}\n:::\n:::\n\n## Inference for linear regression\n\n-   **Inference based on ANOVA**\n\n    -   Hypothesis test for the statistical significance of the overall regression model\n\n    -   Hypothesis test for a subset of coefficients\n\n-   **Inference for a single coefficient** $\\beta_j$\n\n    -   Hypothesis test for a coefficient $\\beta_j$\n\n    -   Confidence interval for a coefficient $\\beta_j$\n\n## Linear regression model {.midi}\n\n$$\n\\begin{aligned}\n\\mathbf{y} &= Model + Error \\\\[5pt]\n&= f(\\mathbf{X}) + \\boldsymbol{\\epsilon} \\\\[5pt]\n&= E(\\mathbf{y}|\\mathbf{X}) + \\mathbf{\\epsilon} \\\\[5pt]\n&= \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{\\epsilon}\n\\end{aligned}\n$$\n\n. . .\n\n::: incremental\n-   We have discussed multiple ways to find the least squares estimates of $\\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0 \\\\\\beta_1\\end{bmatrix}$\n\n    -   None of these approaches depend on the distribution of $\\boldsymbol{\\epsilon}$\n\n-   Now we will use statistical inference to draw conclusions about $\\boldsymbol{\\beta}$ that depend on particular assumptions about the distribution of $\\boldsymbol{\\epsilon}$\n:::\n\n## Linear regression model {.midi}\n\n$$\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n$$\n\n![Image source: *Introduction to the Practice of Statistics (5th ed)*](images/08/regression.png){fig-align=\"center\"}\n\n## Expected value of $\\mathbf{y}$\n\nLet $\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}$ be a $p \\times 1$ vector of random variables.\n\n<br>\n\n. . .\n\nThen $E(\\mathbf{b}) = E\\begin{bmatrix}b_1 \\\\ \\vdots \\\\ b_p\\end{bmatrix} = \\begin{bmatrix}E(b_1) \\\\ \\vdots \\\\ E(b_p)\\end{bmatrix}$\n\n<br>\n\n. . .\n\n::: question\nUse this to find $E(\\mathbf{y}|\\mathbf{X})$.\n:::\n\n## Variance {.midi}\n\nLet $\\mathbf{b} = \\begin{bmatrix}b_1 \\\\ \\vdots \\\\b_p\\end{bmatrix}$ be a $p \\times 1$ vector of *independent* random variables.\n\n<br>\n\n. . .\n\nThen $Var(\\mathbf{b}) = \\begin{bmatrix}Var(b_1) & 0 & \\dots & 0 \\\\ 0 & Var(b_2) & \\dots & 0 \\\\ \\vdots & \\vdots & \\dots & \\cdot \\\\ 0 & 0 & \\dots & Var(b_p)\\end{bmatrix}$\n\n<br>\n\n. . .\n\n::: question\nUse this to find $Var(\\mathbf{y}|\\mathbf{X})$.\n:::\n\n## Assumptions of regression {.midi}\n\n::: columns\n::: {.column width=\"50%\"}\n$$\n\\mathbf{y}|\\mathbf{X} \\sim N(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma_\\epsilon^2\\mathbf{I})\n$$\n\n![Image source: *Introduction to the Practice of Statistics (5th ed)*](images/08/regression.png){fig-align=\"center\"}\n:::\n\n::: {.column width=\"50%\"}\n1.  **Linearity:** There is a linear relationship between the response and predictor variables.\n2.  **Constant Variance:** The variability about the least squares line is generally constant.\n3.  **Normality:** The distribution of the residuals is approximately normal.\n4.  **Independence:** The residuals are independent from one another.\n:::\n:::\n\n## Estimating $\\sigma^2_{\\epsilon}$ {.midi}\n\n-   Once we fit the model, we can use the residuals to estimate $\\sigma_{\\epsilon}^2$\n\n-   $\\hat{\\sigma}^2_{\\epsilon}$ is needed for hypothesis testing and constructing confidence intervals for regression\n\n$$\n\\hat{\\sigma}^2_\\epsilon = \\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-p-1} = \\frac{\\sum_\\limits{i=1}^ne_i^2}{n - p - 1} = \\frac{SSR}{n - p - 1}\n$$\n\n-   The **regression standard error** $\\hat{\\sigma}_{\\epsilon}$ is a measure of the average distance between the observations and regression line\n\n$$\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{SSR}{n - p - 1}} \n$$\n\n# Inference for a single coefficient\n\n## Inference for $\\beta_j$\n\nWe often want to conduct inference on individual model coefficients\n\n-   **Hypothesis test:** Is there a linear relationship between the response and $x_j$?\n\n-   **Confidence interval**: What is a plausible range of values $\\beta_j$ can take?\n\nBut first we need to understand the distribution of $\\hat{\\beta}_j$\n\n## Sampling distribution of $\\hat{\\beta}_j$\n\n$$\n\\hat{\\boldsymbol{\\beta}} \\sim N(\\boldsymbol{\\beta}, \\sigma^2_\\epsilon(\\mathbf{X}^T\\mathbf{X})^{-1})\n$$\n\nLet $\\mathbf{C} = (\\mathbf{X}^T\\mathbf{X})^{-1}$. Then, for each coefficient $\\hat{\\beta}_j$,\n\n::: incremental\n-   $E(\\hat{\\beta}_j) = \\boldsymbol{\\beta}_j$, the $j^{th}$ element of $\\boldsymbol{\\beta}$\n\n-   $Var(\\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{jj}$\n\n-   $Cov(\\hat{\\beta}_i, \\hat{\\beta}_j) = \\sigma^2_{\\epsilon}C_{ij}$\n:::\n\n# Hypothesis test for $\\beta_j$\n\n## Steps for a hypothesis test\n\n1.  State the null and alternative hypotheses.\n2.  Calculate a test statistic.\n3.  Calculate the p-value.\n4.  State the conclusion.\n\n## Hypothesis test for $\\beta_j$: Hypotheses\n\nWe will generally test the hypotheses:\n\n-   **Null Hypothesis**: $H_0: \\beta_j = 0$\n\n    -   There is no linear relationship between $\\beta_j$ and $y$ after accounting for the other variables in the model\n\n-   **Alternative hypothesis**: $H_a: \\beta_j \\neq 0$\n\n    -   There is a linear relationship between $\\beta_j$ and $y$ after accounting for the other variables in the model\n\n## Hypothesis test for $\\beta_j$: Test statistic {.midi}\n\n**Test statistic:** Number of standard errors the estimate is away from the null hypothesized value\n\n$$\n\\text{Test Statstic} = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n$$\n\n<br>\n\n. . .\n\n$$T = \\frac{\\hat{\\beta}_j - 0}{SE(\\hat{\\beta}_j)} ~ = ~\\frac{\\hat{\\beta}_j - 0}{\\sqrt{\\hat{\\sigma}^2_\\epsilon C_{jj}}} ~\\sim ~ t_{n-p-1}\n$$\n\n## Hypothesis test for $\\beta_j$: P-value\n\nThe **p-value** is the probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\n$$\np-value = P(|t| > |\\text{test statistic}|),\n$$\n\ncalculated from a $t$ distribution with $n- p - 1$ degrees of freedom\n\n## Understanding the p-value\n\n| Magnitude of p-value    | Interpretation                        |\n|:------------------------|:--------------------------------------|\n| p-value \\< 0.01         | strong evidence against $H_0$         |\n| 0.01 \\< p-value \\< 0.05 | moderate evidence against $H_0$       |\n| 0.05 \\< p-value \\< 0.1  | weak evidence against $H_0$           |\n| p-value \\> 0.1          | effectively no evidence against $H_0$ |\n\n**These are general guidelines. The strength of evidence depends on the context of the problem.**\n\n## Hypothesis test for $\\beta_j$: Conclusion\n\n**There are two parts to the conclusion**\n\n-   Make a conclusion by comparing the p-value to a predetermined decision-making threshold called the significance level ( $\\alpha$ level)\n\n    -   If $\\text{p-value} < \\alpha$: Reject $H_0$\n\n    -   If $\\text{p-value} \\geq \\alpha$: Fail to reject $H_0$\n\n-   State the conclusion in the context of the data\n\n# Application exercise\n\n::: appex\nðŸ“‹ <https://sta221-fa24.netlify.app/ae/ae-03-inference>\n:::\n\n# Confidence interval for $\\beta_j$\n\n## Confidence interval for $\\beta_j$ {.midi}\n\n::: incremental\n-   A plausible range of values for a population parameter is called a **confidence interval**\n\n-   Using only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\n    -   We can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\n\n    -   Similarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter\n:::\n\n## What \"confidence\" means {.midi}\n\n::: incremental\n-   We will construct $C\\%$ confidence intervals.\n\n    -   The confidence level impacts the width of the interval\n\n<br>\n\n-   \"Confident\" means if we were to take repeated samples of the same size as our data, fit regression lines using the same predictors, and calculate $C\\%$ CIs for the coefficient of $x_j$, then $C\\%$ of those intervals will contain the true value of the coefficient $\\beta_j$\n\n<br>\n\n-   Balance precision and accuracy when selecting a confidence level\n:::\n\n## Confidence interval for $\\beta_j$\n\n$$\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n$$\n\n<br>\n\n. . .\n\n$$\n\\hat{\\beta}_1 \\pm t^* \\times SE({\\hat{\\beta}_j})\n$$\n\nwhere $t^*$ is calculated from a $t$ distribution with $n-p-1$ degrees of freedom\n\n## Confidence interval: Critical value\n\n::: {.fragment fragment-index=\"1\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# confidence level: 95%\nqt(0.975, df = nrow(football) - 2 - 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.97928\n```\n\n\n:::\n:::\n\n\n:::\n\n<br>\n\n::: {.fragment fragment-index=\"2\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# confidence level: 90%\nqt(0.95, df = nrow(football) - 2 - 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.657235\n```\n\n\n:::\n:::\n\n\n:::\n\n<br>\n\n::: {.fragment fragment-index=\"3\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# confidence level: 99%\nqt(0.995, df = nrow(football) - 2 - 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.61606\n```\n\n\n:::\n:::\n\n\n:::\n\n## 95% CI for $\\beta_j$: Calculation\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term          | estimate| std.error| statistic| p.value|\n|:-------------|--------:|---------:|---------:|-------:|\n|(Intercept)   |   19.332|     2.984|     6.478|       0|\n|enrollment_th |    0.780|     0.110|     7.074|       0|\n|typePublic    |  -13.226|     3.153|    -4.195|       0|\n\n\n:::\n:::\n\n\n\n## 95% CI for $\\beta_j$ in R\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(exp_fit, conf.int = TRUE, conf.level = 0.95) |> \n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term          | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)   |   19.332|     2.984|     6.478|       0|   13.426|    25.239|\n|enrollment_th |    0.780|     0.110|     7.074|       0|    0.562|     0.999|\n|typePublic    |  -13.226|     3.153|    -4.195|       0|  -19.466|    -6.986|\n\n\n:::\n:::\n\n\n\n<br>\n\n**Interpretation**: We are 95% confident that for each additional 1,000 students enrolled, the institution's expenditures on football will be greater by \\$562,000 to \\$999,000, on average, holding institution type constant.\n\n# Test for overall significance\n\n## Test for overall significance: Hypotheses\n\nWe can conduct a hypothesis test using the ANOVA table to determine if there is at least one non-zero coefficient in the model\n\n$$\n\\begin{aligned}\n&H_0: \\beta_1 = \\dots = \\beta_p = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j \n\\end{aligned}\n$$\n\n. . .\n\n**For the football data**\n\n$$\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j \n\\end{aligned}\n$$\n\n## Test for overall significance: Test statistic {.midi}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|Source    |  Df|    Sum Sq|Mean Sq  |F Stat |Pr(> F) |\n|:---------|---:|---------:|:--------|:------|:-------|\n|Model     |   2|  7138.591|3569.296 |26.628 |0       |\n|Residuals | 124| 16621.344|134.043  |       |        |\n|Total     | 126| 23759.935|         |       |        |\n\n\n:::\n:::\n\n\n\n<br>\n\n**Test statistic**: Ratio of explained to unexplained variability\n\n$$\nF = \\frac{\\text{Mean Square Model}}{\\text{Mean Square Residuals}}\n$$\n\nThe test statistic follows an $F$ distribution with $p$ and $n -  p - 1$ degrees of freedom\n\n## Test for overall significance: P-value\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-inference-pt2_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n$$\n\\text{P-value} = \\text{Pr}(F > \\text{F Stat})\n$$\n\n## Test for overall significance: Conclusion {.midi}\n\n$$\n\\begin{aligned}\n&H_0: \\beta_1 = \\beta_2 = 0\\\\\n&H_a: \\beta_j \\neq 0 \\text{ for at least one }j \n\\end{aligned}\n$$\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfootball_anova |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|Source    |  Df|    Sum Sq|Mean Sq  |F Stat |Pr(> F) |\n|:---------|---:|---------:|:--------|:------|:-------|\n|Model     |   2|  7138.591|3569.296 |26.628 |0       |\n|Residuals | 124| 16621.344|134.043  |       |        |\n|Total     | 126| 23759.935|         |       |        |\n\n\n:::\n:::\n\n\n\n::: question\nWhat is the conclusion from this hypothesis test?\n:::\n\n## Recap\n\n-   Introduced statistical inference in the context of regression\n\n-   Described the assumptions for regression\n\n-   Connected the distribution of residuals and inferential procedures\n\n-   Conducted inference on a single coefficient\n\n-   Conducted inference on the overall regression model\n",
    "supporting": [
      "09-inference-pt2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}